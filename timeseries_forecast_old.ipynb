{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import graph as gr\n",
    "import utils as ut\n",
    "import feature_selection as fs\n",
    "import classification as cl\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import importlib\n",
    "import community\n",
    "import seaborn as sns\n",
    "from gensim.models import KeyedVectors\n",
    "from pyemd import emd\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.matutils import softcossim\n",
    "import copy\n",
    "import itertools\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dense, Dropout, Activation, Reshape\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_domain  = 0 #0:apnea ro 1:obesity\n",
    "domain = ['apnea','obesity']\n",
    "root = '../linkPrediction/'\n",
    "filepath=[['dataset/apnea-all,3.csv',\n",
    "         'dataset/apnea-distinct_keyword.csv'],\n",
    "        ['dataset/obesity-all,3.csv',\n",
    "         'dataset/obesity-distinct_keyword.csv']]\n",
    "graphpath=root+'graphs/'+domain[select_domain]\n",
    "datapath=root+'dataframes/'+domain[select_domain]\n",
    "modelpath=root+'models/'+domain[select_domain]\n",
    "column_split=['keyword','author_name','affiliation_1','affiliation_2','country']\n",
    "#time=[parent_start_year, train_start_year, test_start_year, total_test_period_in_year, total_year_in_each_iteration]\n",
    "times=[2007,2008,2015,1,1,200]\n",
    "df, key_list = ut.load_dataset(filepath[select_domain], column_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/graphs/apnea\\train_graph_2008.gpickle loaded, nodes: 459 edges: 773\n",
      "../linkPrediction/graphs/apnea\\train_graph_2009.gpickle loaded, nodes: 470 edges: 688\n",
      "../linkPrediction/graphs/apnea\\train_graph_2010.gpickle loaded, nodes: 496 edges: 786\n",
      "../linkPrediction/graphs/apnea\\train_graph_2011.gpickle loaded, nodes: 536 edges: 977\n",
      "../linkPrediction/graphs/apnea\\train_graph_2012.gpickle loaded, nodes: 584 edges: 1054\n",
      "../linkPrediction/graphs/apnea\\train_graph_2013.gpickle loaded, nodes: 634 edges: 1280\n",
      "../linkPrediction/graphs/apnea\\train_graph_2014.gpickle loaded, nodes: 583 edges: 1144\n",
      "../linkPrediction/graphs/apnea\\test_graph_2015.gpickle loaded, nodes: 1093 edges: 2019\n",
      "../linkPrediction/graphs/apnea\\parent_graph_2007-2008.gpickle loaded, nodes: 388 edges: 689\n",
      "../linkPrediction/graphs/apnea\\train_graph_2008-2015.gpickle loaded, nodes: 1093 edges: 5142\n",
      "../linkPrediction/graphs/apnea\\test_graph_2015-2016.gpickle loaded, nodes: 1093 edges: 2019\n"
     ]
    }
   ],
   "source": [
    "# time=[1991,1992,1994,1,1,20]\n",
    "g_train, g_test, g_parent, g_train_static, g_test_static = gr.graph_load(graphpath, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "train data length: 7\n",
      "node feature length: 7\n",
      "edge_list length: 12494\n",
      "test_data length: 12494\n",
      "test_node length: 1093\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ut)\n",
    "train_data = ut.load_data(datapath, domain[select_domain], \"train_data\", times)\n",
    "node_feature = ut.load_data(datapath, domain[select_domain], \"node_feature\", times)\n",
    "edge_list = ut.load_data(datapath, domain[select_domain], \"edge_list\", times)\n",
    "test_data = ut.load_data(datapath, domain[select_domain], \"test_data\", times)\n",
    "test_node = ut.load_data(datapath, domain[select_domain], \"test_node\", times)\n",
    "print('train data length:',len(train_data))\n",
    "print('node feature length:',len(node_feature))\n",
    "print('edge_list length:',len(edge_list))\n",
    "print('test_data length:',len(test_data[2015]))\n",
    "print('test_node length:',len(test_node[2015]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_key={0:[9875,1020],1:[7614,9953]}\n",
    "for t in range(2008,2015):\n",
    "    g_train[t].remove_nodes_from(s_key[select_domain])\n",
    "g_test[2015].remove_nodes_from(s_key[select_domain])\n",
    "g_parent.remove_nodes_from(s_key[select_domain])\n",
    "g_train_static.remove_nodes_from(s_key[select_domain])\n",
    "g_test_static.remove_nodes_from(s_key[select_domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_index</th>\n",
       "      <th>y_weight</th>\n",
       "      <th>term_art</th>\n",
       "      <th>term_aut</th>\n",
       "      <th>term_af1</th>\n",
       "      <th>term_af2</th>\n",
       "      <th>term_coun</th>\n",
       "      <th>closeness</th>\n",
       "      <th>degree</th>\n",
       "      <th>citation</th>\n",
       "      <th>degrees</th>\n",
       "      <th>node_type_aut</th>\n",
       "      <th>node_type_art</th>\n",
       "      <th>node_type_deg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7218</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700949</td>\n",
       "      <td>0.379414</td>\n",
       "      <td>-1.215046</td>\n",
       "      <td>-0.820928</td>\n",
       "      <td>-0.370452</td>\n",
       "      <td>0.193241</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14408</td>\n",
       "      <td>1</td>\n",
       "      <td>3.614369</td>\n",
       "      <td>2.936313</td>\n",
       "      <td>3.145723</td>\n",
       "      <td>2.828505</td>\n",
       "      <td>2.742535</td>\n",
       "      <td>0.252554</td>\n",
       "      <td>22</td>\n",
       "      <td>66</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13880</td>\n",
       "      <td>1</td>\n",
       "      <td>3.072535</td>\n",
       "      <td>2.257045</td>\n",
       "      <td>2.089515</td>\n",
       "      <td>2.025526</td>\n",
       "      <td>2.892028</td>\n",
       "      <td>0.215971</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11601</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523367</td>\n",
       "      <td>-0.001531</td>\n",
       "      <td>1.300971</td>\n",
       "      <td>-0.123124</td>\n",
       "      <td>-5.022255</td>\n",
       "      <td>0.166781</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13912</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939074</td>\n",
       "      <td>0.793199</td>\n",
       "      <td>1.279161</td>\n",
       "      <td>0.099309</td>\n",
       "      <td>-3.052839</td>\n",
       "      <td>0.213733</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>13827</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.316267</td>\n",
       "      <td>-0.976235</td>\n",
       "      <td>-2.676468</td>\n",
       "      <td>-0.891141</td>\n",
       "      <td>-1.018547</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>1138</td>\n",
       "      <td>1</td>\n",
       "      <td>0.374695</td>\n",
       "      <td>0.149918</td>\n",
       "      <td>0.120104</td>\n",
       "      <td>0.079677</td>\n",
       "      <td>-0.432329</td>\n",
       "      <td>0.207637</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>16014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.374695</td>\n",
       "      <td>0.149918</td>\n",
       "      <td>0.120104</td>\n",
       "      <td>0.079677</td>\n",
       "      <td>-0.432329</td>\n",
       "      <td>0.207637</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>6032</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.393156</td>\n",
       "      <td>-0.542765</td>\n",
       "      <td>-0.137003</td>\n",
       "      <td>-0.981454</td>\n",
       "      <td>-0.403052</td>\n",
       "      <td>0.170129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>16070</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.393156</td>\n",
       "      <td>-0.542765</td>\n",
       "      <td>-0.137003</td>\n",
       "      <td>-0.981454</td>\n",
       "      <td>-0.403052</td>\n",
       "      <td>0.170129</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1093 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      node_index  y_weight  term_art  term_aut  term_af1  term_af2  term_coun  \\\n",
       "0           7218         1  0.700949  0.379414 -1.215046 -0.820928  -0.370452   \n",
       "1          14408         1  3.614369  2.936313  3.145723  2.828505   2.742535   \n",
       "2          13880         1  3.072535  2.257045  2.089515  2.025526   2.892028   \n",
       "3          11601         1  0.523367 -0.001531  1.300971 -0.123124  -5.022255   \n",
       "4          13912         1  0.939074  0.793199  1.279161  0.099309  -3.052839   \n",
       "...          ...       ...       ...       ...       ...       ...        ...   \n",
       "1088       13827         1 -2.316267 -0.976235 -2.676468 -0.891141  -1.018547   \n",
       "1089        1138         1  0.374695  0.149918  0.120104  0.079677  -0.432329   \n",
       "1090       16014         1  0.374695  0.149918  0.120104  0.079677  -0.432329   \n",
       "1091        6032         1 -0.393156 -0.542765 -0.137003 -0.981454  -0.403052   \n",
       "1092       16070         1 -0.393156 -0.542765 -0.137003 -0.981454  -0.403052   \n",
       "\n",
       "      closeness  degree  citation   degrees  node_type_aut  node_type_art  \\\n",
       "0      0.193241       2        38  0.018519              3              3   \n",
       "1      0.252554      22        66  0.203704              5              5   \n",
       "2      0.215971      15        48  0.138889              3              3   \n",
       "3      0.166781       3         2  0.027778              3              3   \n",
       "4      0.213733       3         0  0.027778              5              5   \n",
       "...         ...     ...       ...       ...            ...            ...   \n",
       "1088   0.000916       1         1  0.009259              1              1   \n",
       "1089   0.207637       3         0  0.027778              5              5   \n",
       "1090   0.207637       3         0  0.027778              5              5   \n",
       "1091   0.170129       2         2  0.018519              3              3   \n",
       "1092   0.170129       2         2  0.018519              3              3   \n",
       "\n",
       "      node_type_deg  \n",
       "0                 3  \n",
       "1                 5  \n",
       "2                 3  \n",
       "3                 3  \n",
       "4                 5  \n",
       "...             ...  \n",
       "1088              1  \n",
       "1089              5  \n",
       "1090              5  \n",
       "1091              3  \n",
       "1092              3  \n",
       "\n",
       "[1093 rows x 14 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_node[2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/graphs/apnea\\train_graph_2008.gpickle loaded, nodes: 459 edges: 773\n",
      "../linkPrediction/graphs/apnea\\train_graph_2009.gpickle loaded, nodes: 470 edges: 688\n",
      "../linkPrediction/graphs/apnea\\train_graph_2010.gpickle loaded, nodes: 496 edges: 786\n",
      "../linkPrediction/graphs/apnea\\train_graph_2011.gpickle loaded, nodes: 536 edges: 977\n",
      "../linkPrediction/graphs/apnea\\train_graph_2012.gpickle loaded, nodes: 584 edges: 1054\n",
      "../linkPrediction/graphs/apnea\\train_graph_2013.gpickle loaded, nodes: 634 edges: 1280\n",
      "../linkPrediction/graphs/apnea\\train_graph_2014.gpickle loaded, nodes: 583 edges: 1144\n",
      "../linkPrediction/graphs/apnea\\test_graph_2015.gpickle loaded, nodes: 1093 edges: 2019\n",
      "../linkPrediction/graphs/apnea\\parent_graph_2007-2008.gpickle loaded, nodes: 388 edges: 689\n",
      "../linkPrediction/graphs/apnea\\train_graph_2008-2015.gpickle loaded, nodes: 1093 edges: 5142\n",
      "../linkPrediction/graphs/apnea\\test_graph_2015-2016.gpickle loaded, nodes: 1093 edges: 2019\n"
     ]
    }
   ],
   "source": [
    "# time=[1991,1992,1994,1,1,20]\n",
    "g_train, g_test, g_parent, g_train_static, g_test_static = gr.graph_load(graphpath, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_key={0:[9875,1020],1:[7614,9953]}\n",
    "for t in range(2008,2015):\n",
    "    g_train[t].remove_nodes_from(s_key[select_domain])\n",
    "g_test[2015].remove_nodes_from(s_key[select_domain])\n",
    "g_parent.remove_nodes_from(s_key[select_domain])\n",
    "g_train_static.remove_nodes_from(s_key[select_domain])\n",
    "g_test_static.remove_nodes_from(s_key[select_domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008 nodes: 459 edges: 773\n",
      "2009 nodes: 470 edges: 688\n",
      "2010 nodes: 496 edges: 786\n",
      "2011 nodes: 536 edges: 977\n",
      "2012 nodes: 584 edges: 1054\n",
      "2013 nodes: 634 edges: 1280\n",
      "2014 nodes: 583 edges: 1144\n",
      "2007 nodes: 388 edges: 689\n",
      "2015 nodes: 1093 edges: 2019\n"
     ]
    }
   ],
   "source": [
    "for t in range(2008,2015):\n",
    "    g=g_train[t]\n",
    "    print(t,'nodes:',len(g.nodes()),'edges:',len(g.edges()))\n",
    "print(2007,'nodes:',len(g_parent.nodes()),'edges:',len(g_parent.edges()))\n",
    "print(2015,'nodes:',len(g_test[2015].nodes()),'edges:',len(g_test[2015].edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reshape(train_data, node_feature, edge_list, test_data,test_node,times,features):\n",
    "    cat ={25:0,5:1,3:2,1:3}\n",
    "    ts = times[1]\n",
    "    te = times[2]+1\n",
    "    it_index = times[4]\n",
    "    times_range = te - ts\n",
    "    total_sample = len(edge_list)\n",
    "    train_data[times[2]] = test_data\n",
    "    node_feature[times[2]] = test_node\n",
    "    feature_length = len(features['edge'])+32\n",
    "    X = np.zeros([total_sample, times_range, feature_length])\n",
    "    y = np.zeros(total_sample)\n",
    "    print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n",
    "    for id, edge in enumerate(edge_list):\n",
    "        for t in range(ts, te, it_index):\n",
    "            t_data = train_data[t]\n",
    "            n_data = node_feature[t]\n",
    "            node_list = set(n_data['node_index'])\n",
    "            edge_list_t = set(t_data['row_name'])\n",
    "            if edge in edge_list_t:\n",
    "                train_row = np.asarray(t_data.loc[t_data['row_name'] == edge,features['edge']].values[0])\n",
    "                X[id][t - ts][0:6] = train_row\n",
    "                X[id][t - ts][3] = X[id][t - ts][3]*(t-ts+1)*2\n",
    "            if edge[0] in node_list:\n",
    "                node_row0 = np.asarray(n_data.loc[n_data['node_index'] == edge[0],features['node']].values[0])\n",
    "                X[id][t - ts][6:9] = node_row0[0:3]\n",
    "                X[id][t - ts][cat[node_row0[3]]+9] = 1\n",
    "                X[id][t - ts][cat[node_row0[4]]+13] = 1\n",
    "                X[id][t - ts][cat[node_row0[5]]+17] = 1\n",
    "                X[id][t - ts][21] = node_row0[6]\n",
    "                if edge[1] not in node_list:\n",
    "                    X[id][t - ts][3] = node_row0[6]*(t-ts+1)\n",
    "            if edge[1] in node_list:\n",
    "                node_row1 = np.asarray(n_data.loc[n_data['node_index'] == edge[1],features['node']].values[0])\n",
    "                X[id][t - ts][22:25] = node_row1[0:3]\n",
    "                X[id][t - ts][cat[node_row1[3]]+25] = 1\n",
    "                X[id][t - ts][cat[node_row1[4]]+29] = 1\n",
    "                X[id][t - ts][cat[node_row1[5]]+33] = 1\n",
    "                X[id][t - ts][37] = node_row1[6]\n",
    "                if edge[0] not in node_list:\n",
    "                    X[id][t - ts][3] = node_row1[6]*(t-ts+1)\n",
    "        y[id] = test_data.loc[test_data['row_name'] == edge,'label'].values[0]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_index</th>\n",
       "      <th>y_weight</th>\n",
       "      <th>term_art</th>\n",
       "      <th>term_aut</th>\n",
       "      <th>term_af1</th>\n",
       "      <th>term_af2</th>\n",
       "      <th>term_coun</th>\n",
       "      <th>closeness</th>\n",
       "      <th>degree</th>\n",
       "      <th>citation</th>\n",
       "      <th>degrees</th>\n",
       "      <th>node_type_aut</th>\n",
       "      <th>node_type_art</th>\n",
       "      <th>node_type_deg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7943</td>\n",
       "      <td>1</td>\n",
       "      <td>3.563167</td>\n",
       "      <td>3.278160</td>\n",
       "      <td>3.063238</td>\n",
       "      <td>2.763745</td>\n",
       "      <td>3.011017</td>\n",
       "      <td>0.345861</td>\n",
       "      <td>54</td>\n",
       "      <td>861</td>\n",
       "      <td>0.154286</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9516</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.402686</td>\n",
       "      <td>0.632127</td>\n",
       "      <td>0.203748</td>\n",
       "      <td>0.164155</td>\n",
       "      <td>-0.198249</td>\n",
       "      <td>0.251092</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1511</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325682</td>\n",
       "      <td>-0.688074</td>\n",
       "      <td>-0.557940</td>\n",
       "      <td>-0.495598</td>\n",
       "      <td>-1.313288</td>\n",
       "      <td>0.266475</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2459</td>\n",
       "      <td>1</td>\n",
       "      <td>1.994278</td>\n",
       "      <td>1.723824</td>\n",
       "      <td>1.637934</td>\n",
       "      <td>1.417986</td>\n",
       "      <td>1.122538</td>\n",
       "      <td>0.307244</td>\n",
       "      <td>16</td>\n",
       "      <td>113</td>\n",
       "      <td>0.045714</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4347</td>\n",
       "      <td>1</td>\n",
       "      <td>2.711948</td>\n",
       "      <td>2.788349</td>\n",
       "      <td>2.448573</td>\n",
       "      <td>2.219458</td>\n",
       "      <td>2.465206</td>\n",
       "      <td>0.320385</td>\n",
       "      <td>47</td>\n",
       "      <td>433</td>\n",
       "      <td>0.134286</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_index  y_weight  term_art  term_aut  term_af1  term_af2  term_coun  \\\n",
       "0        7943         1  3.563167  3.278160  3.063238  2.763745   3.011017   \n",
       "1        9516         1 -0.402686  0.632127  0.203748  0.164155  -0.198249   \n",
       "2        1511         1  0.325682 -0.688074 -0.557940 -0.495598  -1.313288   \n",
       "3        2459         1  1.994278  1.723824  1.637934  1.417986   1.122538   \n",
       "4        4347         1  2.711948  2.788349  2.448573  2.219458   2.465206   \n",
       "\n",
       "   closeness  degree  citation   degrees  node_type_aut  node_type_art  \\\n",
       "0   0.345861      54       861  0.154286              5              5   \n",
       "1   0.251092       4        47  0.011429              3              3   \n",
       "2   0.266475       5        38  0.014286              5              5   \n",
       "3   0.307244      16       113  0.045714              5              5   \n",
       "4   0.320385      47       433  0.134286              5              5   \n",
       "\n",
       "   node_type_deg  \n",
       "0              5  \n",
       "1              3  \n",
       "2              5  \n",
       "3              5  \n",
       "4              5  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feature[2008].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [{'node':['term_aut','node_type_aut'],\n",
    "           'edge':['typeaut']},\n",
    "           {'node':['term_art','node_type_art'],\n",
    "           'edge':['typeart']},\n",
    "           {'node':['degree','node_type_deg'],\n",
    "           'edge':['typenode']},\n",
    "           {'node':['citation'],\n",
    "           'edge':['citation1']},\n",
    "           {'node':['degree'],\n",
    "           'edge':['pref']},\n",
    "           {'node':['degree'],\n",
    "           'edge':['cm']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (131006, 8, 38) y shape: (131006,)\n",
      "31530.548484563828\n",
      "../linkPrediction/dataframes/obesity\\obesity-X-features_2008-2015.pkl\n",
      "../linkPrediction/dataframes/obesity\\obesity-y-features_2008-2015.pkl\n"
     ]
    }
   ],
   "source": [
    "#####################  6           7        8       9,10,11,12     13,14,15,16      17,18,19,20      21\n",
    "#####################  22          23       24      25,26,27,28    29,30,31,32      33,34,35,36      37\n",
    "feature = {'node':['term_aut','term_art','degree','node_type_aut','node_type_art','node_type_deg','citation'],\n",
    "           'edge':['typeaut','typeart','typenode','citation1','pref','cm']}\n",
    "################       0         1         2           3        4      5\n",
    "\n",
    "start = tm.time()\n",
    "X, y = reshape(train_data, node_feature, edge_list, test_data[2015],test_node[2015],times,feature)\n",
    "end = tm.time()\n",
    "print(end - start)\n",
    "ut.save_data(X, datapath, domain[select_domain], \"X-features\", times)\n",
    "ut.save_data(y, datapath, domain[select_domain], \"y-features\", times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = {\n",
    "'author':[0,6,22,9,10,11,12,25,26,27,28],\n",
    "'article': [1,7,23,13,14,15,16,29,30,31,32],\n",
    "'degree': [2,8,24,17,18,19,20,33,34,35,36],\n",
    "'citation': [3,21,37],\n",
    "'pref': [4,8,24],\n",
    "'cm': [5,8,24]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "class CustomSaver(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, param):\n",
    "        self.name = param[3]\n",
    "        self.times = param[4]\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        ep_set =set([100,500,1000])\n",
    "        if epoch in ep_set:  # or save after some epoch, each k-th epoch etc.\n",
    "            ut.save_data(self.model, datapath, domain[select_domain], \"model-\"+name+\"-\"+str(epoch), self.times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear(param):\n",
    "        inputx = Input(shape=(param[0], param[1]))\n",
    "        x = LSTM(20)(inputx)\n",
    "        x = LSTM(20, activation=\"relu\")(inputx)\n",
    "        x = Dense(40, activation=\"relu\")(x)\n",
    "        x = Dense(20, activation=\"relu\")(x)\n",
    "        x = Dense(param[2],activation='linear',name=\"lin\")(x)\n",
    "        model = Model(inputs=inputx, outputs=x)\n",
    "        return model\n",
    "\n",
    "def create_cat1(param):\n",
    "        inputx = Input(shape=(param[0], param[1]))\n",
    "        x = LSTM(20)(inputx)\n",
    "        x = Dense(20)(x)\n",
    "        x = Dense(10,activation='relu')(x)\n",
    "        x = Dense(param[2],activation='softmax',name=\"cat1\")(x)\n",
    "        model = Model(inputs=inputx, outputs=x)\n",
    "        return model\n",
    "    \n",
    "def create_cat2(param):\n",
    "        inputx = Input(shape=(param[0], param[1]))\n",
    "        x = LSTM(20)(inputx)\n",
    "        x = Dense(20)(x)\n",
    "        x = Dense(10,activation='relu')(x)\n",
    "        x = Dense(param[2],activation='softmax',name=\"cat2\")(x)\n",
    "        model = Model(inputs=inputx, outputs=x)\n",
    "        return model\n",
    "    \n",
    "def lstm_forecast(X,param):\n",
    "        X = ut.scale(X,0,1)\n",
    "        y = X[:,7]\n",
    "        X = X[:,0:7]\n",
    "        batch_size = param[1]\n",
    "        epoch = param[2]\n",
    "        names1 = set(['author','article','degree'])\n",
    "        names2 = set(['citation','pref','cm'])\n",
    "        print(X.shape,y.shape)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = param[0], random_state = 0)\n",
    "        ######## the first branch operates on the linear input\n",
    "\n",
    "        lin_parameters = [X_train[:,:,0:3].shape[1], X_train[:,:,0:3].shape[2], y_train[:,0:3].shape[1]]\n",
    "        lin = create_linear(lin_parameters)        \n",
    "        \n",
    "        saver = CustomSaver(param)\n",
    "        \n",
    "        if param[3] in names1:\n",
    "            cat_parameters1 = [X_train[:,:,3:7].shape[1], X_train[:,:,3:7].shape[2], y_train[:,3:7].shape[1]]\n",
    "            cat1 = create_cat1(cat_parameters1)\n",
    "\n",
    "            cat_parameters2 = [X_train[:,:,7:11].shape[1], X_train[:,:,7:11].shape[2], y_train[:,7:11].shape[1]]\n",
    "            cat2 = create_cat2(cat_parameters2)\n",
    "        \n",
    "            model = Model(inputs=[lin.input, cat1.input, cat2.input], outputs=[lin.output, cat1.output,cat2.output])\n",
    "            model.compile(loss={'lin':'mse','cat1':'categorical_crossentropy','cat2':'categorical_crossentropy'},\n",
    "                              optimizer='Adam',\n",
    "                              metrics={'lin':'accuracy','cat1':'categorical_accuracy','cat2':'categorical_accuracy'})\n",
    "            history = model.fit([X_train[:,:,0:3],X_train[:,:,3:7],X_train[:,:,7:11]],\n",
    "                                [y_train[:,0:3],y_train[:,3:7],y_train[:,7:11]],\n",
    "                                callbacks=[saver],\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epoch,\n",
    "                                verbose=1)\n",
    "        else:\n",
    "            model = Model(inputs=lin.input, outputs=lin.output)\n",
    "            model.compile(loss={'lin':'mse'},\n",
    "                              optimizer='Adam',\n",
    "                              metrics={'lin':'accuracy'})\n",
    "            history = model.fit(X_train[:,:,0:3],\n",
    "                                y_train[:,0:3],\n",
    "                                callbacks=[saver],\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epoch,\n",
    "                                verbose=1)\n",
    "#         y_pr = model.predict([X_test[:,:,0:3],X_test[:,:,3:7],X_test[:,:,7:11]])\n",
    "        return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "article ---------------------------------------------------------------------------------\n",
      "(12494, 7, 11) (12494, 11)\n",
      "Epoch 1/1001\n",
      "8745/8745 [==============================] - 2s 212us/step - loss: 2.4451 - lin_loss: 0.0281 - cat1_loss: 1.2064 - cat2_loss: 1.2107 - lin_acc: 0.5649 - cat1_categorical_accuracy: 0.4170 - cat2_categorical_accuracy: 0.3975\n",
      "Epoch 2/1001\n",
      "8745/8745 [==============================] - 2s 215us/step - loss: 2.0721 - lin_loss: 0.0150 - cat1_loss: 1.0175 - cat2_loss: 1.0396 - lin_acc: 0.6591 - cat1_categorical_accuracy: 0.4822 - cat2_categorical_accuracy: 0.4615\n",
      "Epoch 3/1001\n",
      "8745/8745 [==============================] - 2s 221us/step - loss: 2.0404 - lin_loss: 0.0146 - cat1_loss: 1.0031 - cat2_loss: 1.0227 - lin_acc: 0.6603 - cat1_categorical_accuracy: 0.4867 - cat2_categorical_accuracy: 0.4709\n",
      "Epoch 4/1001\n",
      "8745/8745 [==============================] - 2s 238us/step - loss: 2.0249 - lin_loss: 0.0143 - cat1_loss: 0.9929 - cat2_loss: 1.0178 - lin_acc: 0.6650 - cat1_categorical_accuracy: 0.4947 - cat2_categorical_accuracy: 0.47890s - loss: 2.0275 - lin_loss: 0.0142 - cat1_loss: 0.9944 - cat2_loss: 1.0189 - lin_acc: 0.6626 - cat1_categorical_accuracy: 0.4930 - cat2_categorical_accuracy: 0.\n",
      "Epoch 5/1001\n",
      "8745/8745 [==============================] - 2s 217us/step - loss: 2.0122 - lin_loss: 0.0141 - cat1_loss: 0.9867 - cat2_loss: 1.0113 - lin_acc: 0.6670 - cat1_categorical_accuracy: 0.4979 - cat2_categorical_accuracy: 0.4823\n",
      "Epoch 6/1001\n",
      "8745/8745 [==============================] - 2s 212us/step - loss: 2.0011 - lin_loss: 0.0140 - cat1_loss: 0.9805 - cat2_loss: 1.0066 - lin_acc: 0.6709 - cat1_categorical_accuracy: 0.5066 - cat2_categorical_accuracy: 0.4808\n",
      "Epoch 7/1001\n",
      "8745/8745 [==============================] - 2s 230us/step - loss: 1.9930 - lin_loss: 0.0138 - cat1_loss: 0.9744 - cat2_loss: 1.0048 - lin_acc: 0.6789 - cat1_categorical_accuracy: 0.5102 - cat2_categorical_accuracy: 0.4815\n",
      "Epoch 8/1001\n",
      "8745/8745 [==============================] - 2s 233us/step - loss: 1.9765 - lin_loss: 0.0138 - cat1_loss: 0.9658 - cat2_loss: 0.9969 - lin_acc: 0.6763 - cat1_categorical_accuracy: 0.5192 - cat2_categorical_accuracy: 0.4875\n",
      "Epoch 9/1001\n",
      "8745/8745 [==============================] - 2s 226us/step - loss: 1.9615 - lin_loss: 0.0137 - cat1_loss: 0.9584 - cat2_loss: 0.9894 - lin_acc: 0.6751 - cat1_categorical_accuracy: 0.5238 - cat2_categorical_accuracy: 0.4917\n",
      "Epoch 10/1001\n",
      "8745/8745 [==============================] - 2s 247us/step - loss: 1.9490 - lin_loss: 0.0137 - cat1_loss: 0.9502 - cat2_loss: 0.9852 - lin_acc: 0.6802 - cat1_categorical_accuracy: 0.5242 - cat2_categorical_accuracy: 0.49830s - loss: 1.9535 - lin_loss: 0.0137 - cat1_loss: 0.9549 - cat2_loss: 0.9849 - lin_acc: 0.6767 - cat1_categorical_accuracy: 0.5280 - cat\n",
      "Epoch 11/1001\n",
      "8745/8745 [==============================] - 2s 236us/step - loss: 1.9396 - lin_loss: 0.0136 - cat1_loss: 0.9442 - cat2_loss: 0.9819 - lin_acc: 0.6820 - cat1_categorical_accuracy: 0.5304 - cat2_categorical_accuracy: 0.49550s - loss: 1.9419 - lin_loss: 0.0136 - cat1_loss: 0.9470 - cat2_loss: 0.9813 - lin_acc: 0.6823 - cat1_categorical_accuracy: 0.5285 - cat2_categorical_accuracy: \n",
      "Epoch 12/1001\n",
      "8745/8745 [==============================] - 2s 227us/step - loss: 1.9246 - lin_loss: 0.0136 - cat1_loss: 0.9351 - cat2_loss: 0.9759 - lin_acc: 0.6813 - cat1_categorical_accuracy: 0.5338 - cat2_categorical_accuracy: 0.5010\n",
      "Epoch 13/1001\n",
      "8745/8745 [==============================] - 2s 226us/step - loss: 1.9094 - lin_loss: 0.0135 - cat1_loss: 0.9268 - cat2_loss: 0.9690 - lin_acc: 0.6773 - cat1_categorical_accuracy: 0.5441 - cat2_categorical_accuracy: 0.5065\n",
      "Epoch 14/1001\n",
      "8745/8745 [==============================] - 2s 245us/step - loss: 1.8973 - lin_loss: 0.0135 - cat1_loss: 0.9187 - cat2_loss: 0.9651 - lin_acc: 0.6846 - cat1_categorical_accuracy: 0.5490 - cat2_categorical_accuracy: 0.50600s - loss: 1.8800 - lin_loss: 0.0134 - cat1_loss: 0.9084 - cat2_loss: 0.9582 - lin_acc: 0.6908 - cat1_categorical_accuracy: 0.5529\n",
      "Epoch 15/1001\n",
      "8745/8745 [==============================] - 2s 221us/step - loss: 1.8794 - lin_loss: 0.0135 - cat1_loss: 0.9106 - cat2_loss: 0.9553 - lin_acc: 0.6853 - cat1_categorical_accuracy: 0.5499 - cat2_categorical_accuracy: 0.5082\n",
      "Epoch 16/1001\n",
      "8745/8745 [==============================] - 2s 233us/step - loss: 1.8659 - lin_loss: 0.0135 - cat1_loss: 0.9032 - cat2_loss: 0.9493 - lin_acc: 0.6826 - cat1_categorical_accuracy: 0.5646 - cat2_categorical_accuracy: 0.5102\n",
      "Epoch 17/1001\n",
      "8745/8745 [==============================] - 2s 228us/step - loss: 1.8496 - lin_loss: 0.0135 - cat1_loss: 0.8935 - cat2_loss: 0.9426 - lin_acc: 0.6854 - cat1_categorical_accuracy: 0.5679 - cat2_categorical_accuracy: 0.5163\n",
      "Epoch 18/1001\n",
      "8745/8745 [==============================] - 2s 220us/step - loss: 1.8362 - lin_loss: 0.0134 - cat1_loss: 0.8853 - cat2_loss: 0.9375 - lin_acc: 0.6860 - cat1_categorical_accuracy: 0.5776 - cat2_categorical_accuracy: 0.5193\n",
      "Epoch 19/1001\n",
      "8745/8745 [==============================] - 2s 242us/step - loss: 1.8162 - lin_loss: 0.0134 - cat1_loss: 0.8754 - cat2_loss: 0.9274 - lin_acc: 0.6866 - cat1_categorical_accuracy: 0.5801 - cat2_categorical_accuracy: 0.5316\n",
      "Epoch 20/1001\n",
      "8745/8745 [==============================] - 2s 244us/step - loss: 1.8024 - lin_loss: 0.0134 - cat1_loss: 0.8682 - cat2_loss: 0.9208 - lin_acc: 0.6867 - cat1_categorical_accuracy: 0.5883 - cat2_categorical_accuracy: 0.5340\n",
      "Epoch 21/1001\n",
      "8745/8745 [==============================] - 2s 231us/step - loss: 1.7809 - lin_loss: 0.0134 - cat1_loss: 0.8581 - cat2_loss: 0.9094 - lin_acc: 0.6879 - cat1_categorical_accuracy: 0.5898 - cat2_categorical_accuracy: 0.5368\n",
      "Epoch 22/1001\n",
      "8745/8745 [==============================] - 2s 242us/step - loss: 1.7729 - lin_loss: 0.0134 - cat1_loss: 0.8535 - cat2_loss: 0.9060 - lin_acc: 0.6847 - cat1_categorical_accuracy: 0.5971 - cat2_categorical_accuracy: 0.53850s - loss: 1.7745 - lin_loss: 0.0134 - cat1_loss: 0.8529 - cat2_loss: 0.9082 - lin_acc: 0.6871 - cat1_categorical_accuracy: 0.5982 - cat2_categorical_ac\n",
      "Epoch 23/1001\n",
      "8745/8745 [==============================] - 2s 223us/step - loss: 1.7486 - lin_loss: 0.0133 - cat1_loss: 0.8391 - cat2_loss: 0.8962 - lin_acc: 0.6870 - cat1_categorical_accuracy: 0.6031 - cat2_categorical_accuracy: 0.5427\n",
      "Epoch 24/1001\n",
      "8745/8745 [==============================] - 2s 237us/step - loss: 1.7332 - lin_loss: 0.0134 - cat1_loss: 0.8290 - cat2_loss: 0.8908 - lin_acc: 0.6834 - cat1_categorical_accuracy: 0.6010 - cat2_categorical_accuracy: 0.5512\n",
      "Epoch 25/1001\n",
      "8745/8745 [==============================] - 2s 253us/step - loss: 1.7114 - lin_loss: 0.0134 - cat1_loss: 0.8180 - cat2_loss: 0.8800 - lin_acc: 0.6859 - cat1_categorical_accuracy: 0.6152 - cat2_categorical_accuracy: 0.5569\n",
      "Epoch 26/1001\n",
      "8745/8745 [==============================] - 2s 236us/step - loss: 1.6950 - lin_loss: 0.0134 - cat1_loss: 0.8081 - cat2_loss: 0.8736 - lin_acc: 0.6863 - cat1_categorical_accuracy: 0.6173 - cat2_categorical_accuracy: 0.5561\n",
      "Epoch 27/1001\n",
      "8745/8745 [==============================] - 2s 238us/step - loss: 1.6772 - lin_loss: 0.0133 - cat1_loss: 0.8003 - cat2_loss: 0.8635 - lin_acc: 0.6855 - cat1_categorical_accuracy: 0.6252 - cat2_categorical_accuracy: 0.5658\n",
      "Epoch 28/1001\n",
      "8745/8745 [==============================] - 3s 290us/step - loss: 1.6525 - lin_loss: 0.0133 - cat1_loss: 0.7870 - cat2_loss: 0.8522 - lin_acc: 0.6870 - cat1_categorical_accuracy: 0.6269 - cat2_categorical_accuracy: 0.5731\n",
      "Epoch 29/1001\n",
      "8745/8745 [==============================] - 2s 254us/step - loss: 1.6329 - lin_loss: 0.0133 - cat1_loss: 0.7769 - cat2_loss: 0.8427 - lin_acc: 0.6796 - cat1_categorical_accuracy: 0.6364 - cat2_categorical_accuracy: 0.5814\n",
      "Epoch 30/1001\n",
      "8745/8745 [==============================] - 2s 264us/step - loss: 1.6167 - lin_loss: 0.0133 - cat1_loss: 0.7659 - cat2_loss: 0.8375 - lin_acc: 0.6872 - cat1_categorical_accuracy: 0.6446 - cat2_categorical_accuracy: 0.5823\n",
      "Epoch 31/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 253us/step - loss: 1.6002 - lin_loss: 0.0133 - cat1_loss: 0.7547 - cat2_loss: 0.8322 - lin_acc: 0.6898 - cat1_categorical_accuracy: 0.6539 - cat2_categorical_accuracy: 0.5830\n",
      "Epoch 32/1001\n",
      "8745/8745 [==============================] - 2s 255us/step - loss: 1.5744 - lin_loss: 0.0133 - cat1_loss: 0.7408 - cat2_loss: 0.8203 - lin_acc: 0.6919 - cat1_categorical_accuracy: 0.6636 - cat2_categorical_accuracy: 0.5909\n",
      "Epoch 33/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 1.5555 - lin_loss: 0.0132 - cat1_loss: 0.7291 - cat2_loss: 0.8132 - lin_acc: 0.6885 - cat1_categorical_accuracy: 0.6751 - cat2_categorical_accuracy: 0.6025\n",
      "Epoch 34/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 1.5425 - lin_loss: 0.0133 - cat1_loss: 0.7180 - cat2_loss: 0.8113 - lin_acc: 0.6874 - cat1_categorical_accuracy: 0.6790 - cat2_categorical_accuracy: 0.59782s - loss: 1.4916 - lin_loss: 0.0127 - cat1_loss: 0.6925 - cat2_loss: 0.7864 - lin_acc: 0.\n",
      "Epoch 35/1001\n",
      "8745/8745 [==============================] - 3s 299us/step - loss: 1.5155 - lin_loss: 0.0133 - cat1_loss: 0.7032 - cat2_loss: 0.7990 - lin_acc: 0.6848 - cat1_categorical_accuracy: 0.6847 - cat2_categorical_accuracy: 0.6047\n",
      "Epoch 36/1001\n",
      "8745/8745 [==============================] - 3s 290us/step - loss: 1.5005 - lin_loss: 0.0132 - cat1_loss: 0.6937 - cat2_loss: 0.7936 - lin_acc: 0.6862 - cat1_categorical_accuracy: 0.6978 - cat2_categorical_accuracy: 0.6086\n",
      "Epoch 37/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 1.4857 - lin_loss: 0.0133 - cat1_loss: 0.6832 - cat2_loss: 0.7892 - lin_acc: 0.6856 - cat1_categorical_accuracy: 0.6985 - cat2_categorical_accuracy: 0.6090\n",
      "Epoch 38/1001\n",
      "8745/8745 [==============================] - 3s 312us/step - loss: 1.4704 - lin_loss: 0.0132 - cat1_loss: 0.6761 - cat2_loss: 0.7811 - lin_acc: 0.6874 - cat1_categorical_accuracy: 0.7017 - cat2_categorical_accuracy: 0.6126\n",
      "Epoch 39/1001\n",
      "8745/8745 [==============================] - 3s 306us/step - loss: 1.4464 - lin_loss: 0.0132 - cat1_loss: 0.6615 - cat2_loss: 0.7716 - lin_acc: 0.6855 - cat1_categorical_accuracy: 0.7115 - cat2_categorical_accuracy: 0.6207\n",
      "Epoch 40/1001\n",
      "8745/8745 [==============================] - 3s 316us/step - loss: 1.4320 - lin_loss: 0.0132 - cat1_loss: 0.6534 - cat2_loss: 0.7654 - lin_acc: 0.6935 - cat1_categorical_accuracy: 0.7157 - cat2_categorical_accuracy: 0.6273\n",
      "Epoch 41/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 1.4128 - lin_loss: 0.0133 - cat1_loss: 0.6449 - cat2_loss: 0.7546 - lin_acc: 0.6871 - cat1_categorical_accuracy: 0.7187 - cat2_categorical_accuracy: 0.6260\n",
      "Epoch 42/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 1.3965 - lin_loss: 0.0131 - cat1_loss: 0.6348 - cat2_loss: 0.7486 - lin_acc: 0.6917 - cat1_categorical_accuracy: 0.7216 - cat2_categorical_accuracy: 0.6341\n",
      "Epoch 43/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 1.3805 - lin_loss: 0.0131 - cat1_loss: 0.6280 - cat2_loss: 0.7394 - lin_acc: 0.6882 - cat1_categorical_accuracy: 0.7248 - cat2_categorical_accuracy: 0.6441\n",
      "Epoch 44/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 1.3693 - lin_loss: 0.0132 - cat1_loss: 0.6243 - cat2_loss: 0.7318 - lin_acc: 0.6883 - cat1_categorical_accuracy: 0.7236 - cat2_categorical_accuracy: 0.64532s - loss: 1.3625 - lin_loss: 0.0131 - cat1_loss: 0.6193 - cat2_loss: 0.7301 - lin_acc: 0.6758 - cat1_categorica - ETA: 0s - loss: 1.3714 - lin_loss: 0.0132 - cat1_loss: 0.6265 - cat2_loss: 0.7317 - lin_acc: 0.6902 - cat1_categorical_accuracy: 0.7220 - cat2_categorical_\n",
      "Epoch 45/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 1.3468 - lin_loss: 0.0132 - cat1_loss: 0.6105 - cat2_loss: 0.7231 - lin_acc: 0.6848 - cat1_categorical_accuracy: 0.7323 - cat2_categorical_accuracy: 0.6435\n",
      "Epoch 46/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 1.3326 - lin_loss: 0.0131 - cat1_loss: 0.6042 - cat2_loss: 0.7153 - lin_acc: 0.6884 - cat1_categorical_accuracy: 0.7322 - cat2_categorical_accuracy: 0.65332s - loss: 1.4069 - lin_loss: 0.0135 - cat1_loss: 0.6243 - cat2_loss: 0.7691 - lin_acc\n",
      "Epoch 47/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 1.3149 - lin_loss: 0.0131 - cat1_loss: 0.5949 - cat2_loss: 0.7068 - lin_acc: 0.6908 - cat1_categorical_accuracy: 0.7373 - cat2_categorical_accuracy: 0.65810s - loss: 1.3064 - lin_loss: 0.0131 - cat1_loss: 0.5943 - cat2_loss: 0.6990 - lin_acc: 0.6904 - cat1_categorical_accuracy: 0.7374 - cat2_categorical_accu\n",
      "Epoch 48/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 1.3048 - lin_loss: 0.0132 - cat1_loss: 0.5896 - cat2_loss: 0.7020 - lin_acc: 0.6917 - cat1_categorical_accuracy: 0.7404 - cat2_categorical_accuracy: 0.6601\n",
      "Epoch 49/1001\n",
      "8745/8745 [==============================] - 3s 307us/step - loss: 1.2880 - lin_loss: 0.0131 - cat1_loss: 0.5814 - cat2_loss: 0.6935 - lin_acc: 0.6898 - cat1_categorical_accuracy: 0.7435 - cat2_categorical_accuracy: 0.6656\n",
      "Epoch 50/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 1.2700 - lin_loss: 0.0131 - cat1_loss: 0.5744 - cat2_loss: 0.6825 - lin_acc: 0.6903 - cat1_categorical_accuracy: 0.7488 - cat2_categorical_accuracy: 0.6685\n",
      "Epoch 51/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 1.2608 - lin_loss: 0.0131 - cat1_loss: 0.5687 - cat2_loss: 0.6791 - lin_acc: 0.6941 - cat1_categorical_accuracy: 0.7476 - cat2_categorical_accuracy: 0.6746\n",
      "Epoch 52/1001\n",
      "8745/8745 [==============================] - 3s 294us/step - loss: 1.2509 - lin_loss: 0.0131 - cat1_loss: 0.5643 - cat2_loss: 0.6735 - lin_acc: 0.6911 - cat1_categorical_accuracy: 0.7496 - cat2_categorical_accuracy: 0.6786\n",
      "Epoch 53/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 1.2302 - lin_loss: 0.0131 - cat1_loss: 0.5517 - cat2_loss: 0.6654 - lin_acc: 0.6919 - cat1_categorical_accuracy: 0.7565 - cat2_categorical_accuracy: 0.6840\n",
      "Epoch 54/1001\n",
      "8745/8745 [==============================] - 3s 306us/step - loss: 1.2257 - lin_loss: 0.0131 - cat1_loss: 0.5511 - cat2_loss: 0.6615 - lin_acc: 0.6945 - cat1_categorical_accuracy: 0.7546 - cat2_categorical_accuracy: 0.68322s - loss: 1.2190 - lin_loss: 0.0134 - cat1_loss: 0.5550 - cat2_loss: 0.6505 - lin_acc: 0.6955 - cat1_\n",
      "Epoch 55/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 1.2086 - lin_loss: 0.0131 - cat1_loss: 0.5403 - cat2_loss: 0.6552 - lin_acc: 0.6866 - cat1_categorical_accuracy: 0.7641 - cat2_categorical_accuracy: 0.6929\n",
      "Epoch 56/1001\n",
      "8745/8745 [==============================] - 3s 301us/step - loss: 1.1941 - lin_loss: 0.0131 - cat1_loss: 0.5343 - cat2_loss: 0.6467 - lin_acc: 0.6927 - cat1_categorical_accuracy: 0.7642 - cat2_categorical_accuracy: 0.6949\n",
      "Epoch 57/1001\n",
      "8745/8745 [==============================] - 3s 306us/step - loss: 1.1743 - lin_loss: 0.0131 - cat1_loss: 0.5244 - cat2_loss: 0.6368 - lin_acc: 0.6901 - cat1_categorical_accuracy: 0.7726 - cat2_categorical_accuracy: 0.69610s - loss: 1.1771 - lin_loss: 0.0129 - cat1_loss: 0.5287 - cat2_loss: 0.6355 - lin_acc: 0.6902 - cat1_categorical_accuracy: 0.7745 - c\n",
      "Epoch 58/1001\n",
      "8745/8745 [==============================] - 3s 309us/step - loss: 1.1625 - lin_loss: 0.0131 - cat1_loss: 0.5182 - cat2_loss: 0.6312 - lin_acc: 0.6885 - cat1_categorical_accuracy: 0.7714 - cat2_categorical_accuracy: 0.70290s - loss: 1.1581 - lin_loss: 0.0131 - cat1_loss: 0.5111 - cat2_loss: 0.6339 - lin_acc: 0.6900 - cat1_categorical_accuracy: 0.7747 - cat2_categorical_ac\n",
      "Epoch 59/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 1.1514 - lin_loss: 0.0130 - cat1_loss: 0.5123 - cat2_loss: 0.6261 - lin_acc: 0.6901 - cat1_categorical_accuracy: 0.7740 - cat2_categorical_accuracy: 0.7078\n",
      "Epoch 60/1001\n",
      "8745/8745 [==============================] - 3s 291us/step - loss: 1.1363 - lin_loss: 0.0131 - cat1_loss: 0.5036 - cat2_loss: 0.6197 - lin_acc: 0.6933 - cat1_categorical_accuracy: 0.7803 - cat2_categorical_accuracy: 0.7091\n",
      "Epoch 61/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 3s 393us/step - loss: 1.1249 - lin_loss: 0.0130 - cat1_loss: 0.4992 - cat2_loss: 0.6127 - lin_acc: 0.6931 - cat1_categorical_accuracy: 0.7820 - cat2_categorical_accuracy: 0.7153\n",
      "Epoch 62/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 1.1137 - lin_loss: 0.0130 - cat1_loss: 0.4931 - cat2_loss: 0.6076 - lin_acc: 0.6911 - cat1_categorical_accuracy: 0.7867 - cat2_categorical_accuracy: 0.71980s - loss: 1.1094 - lin_loss: 0.0130 - cat1_loss: 0.4898 - cat2_loss: 0.6067 - lin_acc: 0.6906 - cat1_categorical_accuracy: 0.7866 - cat2_categorical_accu\n",
      "Epoch 63/1001\n",
      "8745/8745 [==============================] - 3s 305us/step - loss: 1.1022 - lin_loss: 0.0130 - cat1_loss: 0.4865 - cat2_loss: 0.6027 - lin_acc: 0.6986 - cat1_categorical_accuracy: 0.7911 - cat2_categorical_accuracy: 0.7224\n",
      "Epoch 64/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 1.0956 - lin_loss: 0.0130 - cat1_loss: 0.4831 - cat2_loss: 0.5995 - lin_acc: 0.6934 - cat1_categorical_accuracy: 0.7891 - cat2_categorical_accuracy: 0.7222\n",
      "Epoch 65/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 1.0803 - lin_loss: 0.0131 - cat1_loss: 0.4762 - cat2_loss: 0.5909 - lin_acc: 0.6921 - cat1_categorical_accuracy: 0.7914 - cat2_categorical_accuracy: 0.7291\n",
      "Epoch 66/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 1.0698 - lin_loss: 0.0130 - cat1_loss: 0.4713 - cat2_loss: 0.5855 - lin_acc: 0.6885 - cat1_categorical_accuracy: 0.7926 - cat2_categorical_accuracy: 0.7356\n",
      "Epoch 67/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 1.0518 - lin_loss: 0.0130 - cat1_loss: 0.4603 - cat2_loss: 0.5785 - lin_acc: 0.6932 - cat1_categorical_accuracy: 0.7983 - cat2_categorical_accuracy: 0.7370\n",
      "Epoch 68/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 1.0430 - lin_loss: 0.0130 - cat1_loss: 0.4578 - cat2_loss: 0.5722 - lin_acc: 0.6973 - cat1_categorical_accuracy: 0.8011 - cat2_categorical_accuracy: 0.7366\n",
      "Epoch 69/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 1.0346 - lin_loss: 0.0130 - cat1_loss: 0.4522 - cat2_loss: 0.5694 - lin_acc: 0.6977 - cat1_categorical_accuracy: 0.8026 - cat2_categorical_accuracy: 0.73882s - loss: 1.0278 - lin_loss: 0.0129 - cat1_loss: 0.4539 - cat2_loss: 0.5610 - lin_acc: 0.7074 - cat\n",
      "Epoch 70/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 1.0267 - lin_loss: 0.0130 - cat1_loss: 0.4460 - cat2_loss: 0.5677 - lin_acc: 0.6943 - cat1_categorical_accuracy: 0.8071 - cat2_categorical_accuracy: 0.7379\n",
      "Epoch 71/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 1.0163 - lin_loss: 0.0130 - cat1_loss: 0.4466 - cat2_loss: 0.5567 - lin_acc: 0.6962 - cat1_categorical_accuracy: 0.8054 - cat2_categorical_accuracy: 0.7444\n",
      "Epoch 72/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 1.0099 - lin_loss: 0.0130 - cat1_loss: 0.4416 - cat2_loss: 0.5553 - lin_acc: 0.6951 - cat1_categorical_accuracy: 0.8073 - cat2_categorical_accuracy: 0.7437\n",
      "Epoch 73/1001\n",
      "8745/8745 [==============================] - 3s 312us/step - loss: 0.9906 - lin_loss: 0.0130 - cat1_loss: 0.4292 - cat2_loss: 0.5485 - lin_acc: 0.6970 - cat1_categorical_accuracy: 0.8156 - cat2_categorical_accuracy: 0.7524\n",
      "Epoch 74/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.9834 - lin_loss: 0.0129 - cat1_loss: 0.4271 - cat2_loss: 0.5434 - lin_acc: 0.6956 - cat1_categorical_accuracy: 0.8143 - cat2_categorical_accuracy: 0.7495\n",
      "Epoch 75/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.9780 - lin_loss: 0.0129 - cat1_loss: 0.4238 - cat2_loss: 0.5412 - lin_acc: 0.6996 - cat1_categorical_accuracy: 0.8173 - cat2_categorical_accuracy: 0.7520\n",
      "Epoch 76/1001\n",
      "8745/8745 [==============================] - 3s 315us/step - loss: 0.9757 - lin_loss: 0.0129 - cat1_loss: 0.4224 - cat2_loss: 0.5405 - lin_acc: 0.6957 - cat1_categorical_accuracy: 0.8156 - cat2_categorical_accuracy: 0.74881s - loss: 0.9684 - lin_loss: 0.0129 - cat1_loss: 0.4200 - cat2_loss: 0.5356 - lin_acc: 0.7001 - cat1_cate\n",
      "Epoch 77/1001\n",
      "8745/8745 [==============================] - 3s 334us/step - loss: 0.9666 - lin_loss: 0.0130 - cat1_loss: 0.4207 - cat2_loss: 0.5329 - lin_acc: 0.6982 - cat1_categorical_accuracy: 0.8178 - cat2_categorical_accuracy: 0.7561\n",
      "Epoch 78/1001\n",
      "8745/8745 [==============================] - 3s 308us/step - loss: 0.9508 - lin_loss: 0.0129 - cat1_loss: 0.4128 - cat2_loss: 0.5250 - lin_acc: 0.6981 - cat1_categorical_accuracy: 0.8234 - cat2_categorical_accuracy: 0.76020s - loss: 0.9522 - lin_loss: 0.0130 - cat1_loss: 0.4173 - cat2_loss: 0.5219 - lin_acc: 0.6936 - cat1_categorical_accuracy: 0.8201 - cat2_catego\n",
      "Epoch 79/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.9420 - lin_loss: 0.0130 - cat1_loss: 0.4082 - cat2_loss: 0.5208 - lin_acc: 0.6929 - cat1_categorical_accuracy: 0.8225 - cat2_categorical_accuracy: 0.7595\n",
      "Epoch 80/1001\n",
      "8745/8745 [==============================] - 3s 294us/step - loss: 0.9374 - lin_loss: 0.0130 - cat1_loss: 0.4048 - cat2_loss: 0.5197 - lin_acc: 0.6957 - cat1_categorical_accuracy: 0.8228 - cat2_categorical_accuracy: 0.7650\n",
      "Epoch 81/1001\n",
      "8745/8745 [==============================] - 3s 297us/step - loss: 0.9233 - lin_loss: 0.0129 - cat1_loss: 0.3975 - cat2_loss: 0.5129 - lin_acc: 0.6966 - cat1_categorical_accuracy: 0.8263 - cat2_categorical_accuracy: 0.7644\n",
      "Epoch 82/1001\n",
      "8745/8745 [==============================] - 3s 323us/step - loss: 0.9206 - lin_loss: 0.0129 - cat1_loss: 0.3973 - cat2_loss: 0.5104 - lin_acc: 0.6979 - cat1_categorical_accuracy: 0.8292 - cat2_categorical_accuracy: 0.7671\n",
      "Epoch 83/1001\n",
      "8745/8745 [==============================] - 3s 319us/step - loss: 0.9128 - lin_loss: 0.0129 - cat1_loss: 0.3927 - cat2_loss: 0.5072 - lin_acc: 0.6938 - cat1_categorical_accuracy: 0.8279 - cat2_categorical_accuracy: 0.76490s - loss: 0.9120 - lin_loss: 0.0128 - cat1_loss: 0.3958 - cat2_loss: 0.5034 - lin_acc: 0.6967 - cat1_categorical_accuracy: 0.8268 - cat2_categorica\n",
      "Epoch 84/1001\n",
      "8745/8745 [==============================] - 3s 332us/step - loss: 0.9060 - lin_loss: 0.0129 - cat1_loss: 0.3889 - cat2_loss: 0.5042 - lin_acc: 0.6969 - cat1_categorical_accuracy: 0.8278 - cat2_categorical_accuracy: 0.77242s - loss: 0.9153 - lin_loss: 0.0127 - cat1_loss: 0.3827 - cat2_loss: 0.5198 - lin_acc: 0.6972 - cat1_categorical_accuracy: 0.8260 - cat2_categorical_accuracy: 0. - ETA: 2s - loss: 0.9126 - lin_loss: 0.0128 - cat1_loss: 0.3821 - cat2_loss: 0.5178 - lin_acc: 0.6986 - cat\n",
      "Epoch 85/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.9023 - lin_loss: 0.0129 - cat1_loss: 0.3920 - cat2_loss: 0.4974 - lin_acc: 0.6954 - cat1_categorical_accuracy: 0.8249 - cat2_categorical_accuracy: 0.7744\n",
      "Epoch 86/1001\n",
      "8745/8745 [==============================] - 3s 301us/step - loss: 0.8951 - lin_loss: 0.0129 - cat1_loss: 0.3857 - cat2_loss: 0.4965 - lin_acc: 0.6947 - cat1_categorical_accuracy: 0.8317 - cat2_categorical_accuracy: 0.77522s - loss: 0.8466 - lin_loss: 0.0133 - cat1_loss: 0.3802 - cat2_loss: 0.4531 - lin_acc:  - ETA: 0s - loss: 0.8963 - lin_loss: 0.0129 - cat1_loss: 0.3835 - cat2_loss: 0.4999 - lin_acc: 0.6930 - cat1_categorical_accuracy: 0.8316 - cat2_categorical_accuracy\n",
      "Epoch 87/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.8911 - lin_loss: 0.0128 - cat1_loss: 0.3833 - cat2_loss: 0.4949 - lin_acc: 0.6955 - cat1_categorical_accuracy: 0.8308 - cat2_categorical_accuracy: 0.77751s - loss: 0.8904 - lin_loss: 0.0129 - cat1_loss: 0.3779 - cat2_loss: 0.4996 - lin_acc: 0.6920 - cat1_categorical_accu\n",
      "Epoch 88/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.8833 - lin_loss: 0.0129 - cat1_loss: 0.3801 - cat2_loss: 0.4903 - lin_acc: 0.6974 - cat1_categorical_accuracy: 0.8336 - cat2_categorical_accuracy: 0.7787\n",
      "Epoch 89/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.8705 - lin_loss: 0.0129 - cat1_loss: 0.3763 - cat2_loss: 0.4813 - lin_acc: 0.6935 - cat1_categorical_accuracy: 0.8368 - cat2_categorical_accuracy: 0.78152s - loss: 0.9061 - lin_loss: 0.0132 - cat1_loss: 0.3802 - cat2_loss: 0.5127 - lin_acc: 0.7057 -\n",
      "Epoch 90/1001\n",
      "8745/8745 [==============================] - 2s 261us/step - loss: 0.8671 - lin_loss: 0.0129 - cat1_loss: 0.3720 - cat2_loss: 0.4822 - lin_acc: 0.6965 - cat1_categorical_accuracy: 0.8397 - cat2_categorical_accuracy: 0.7847\n",
      "Epoch 91/1001\n",
      "8745/8745 [==============================] - ETA: 0s - loss: 0.8597 - lin_loss: 0.0128 - cat1_loss: 0.3685 - cat2_loss: 0.4784 - lin_acc: 0.6954 - cat1_categorical_accuracy: 0.8411 - cat2_categorical_accuracy: 0.7817 ETA: 1s - loss: 0.8610 - lin_loss: 0.0128 - cat1_loss: 0.3726 - cat2_loss: 0.4756 - lin_acc: 0.6959 - cat1_categorical_accuracy:  - 2s 275us/step - loss: 0.8571 - lin_loss: 0.0128 - cat1_loss: 0.3673 - cat2_loss: 0.4770 - lin_acc: 0.6949 - cat1_categorical_accuracy: 0.8415 - cat2_categorical_accuracy: 0.7827\n",
      "Epoch 92/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.8535 - lin_loss: 0.0128 - cat1_loss: 0.3687 - cat2_loss: 0.4720 - lin_acc: 0.6983 - cat1_categorical_accuracy: 0.8388 - cat2_categorical_accuracy: 0.79330s - loss: 0.8501 - lin_loss: 0.0128 - cat1_loss: 0.3680 - cat2_loss: 0.4692 - lin_acc: 0.7004 - cat1_categorical_accuracy: 0.8402 - cat2_categorical_accuracy\n",
      "Epoch 93/1001\n",
      "8745/8745 [==============================] - 2s 266us/step - loss: 0.8447 - lin_loss: 0.0129 - cat1_loss: 0.3634 - cat2_loss: 0.4684 - lin_acc: 0.6941 - cat1_categorical_accuracy: 0.8409 - cat2_categorical_accuracy: 0.7910\n",
      "Epoch 94/1001\n",
      "8745/8745 [==============================] - 2s 259us/step - loss: 0.8410 - lin_loss: 0.0128 - cat1_loss: 0.3631 - cat2_loss: 0.4651 - lin_acc: 0.6999 - cat1_categorical_accuracy: 0.8428 - cat2_categorical_accuracy: 0.7946\n",
      "Epoch 95/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.8301 - lin_loss: 0.0128 - cat1_loss: 0.3587 - cat2_loss: 0.4586 - lin_acc: 0.6965 - cat1_categorical_accuracy: 0.8446 - cat2_categorical_accuracy: 0.79750s - loss: 0.8294 - lin_loss: 0.0128 - cat1_loss: 0.3602 - cat2_loss: 0.4564 - lin_acc: 0.6996 - cat1_categorical_accuracy: 0.8468 - cat\n",
      "Epoch 96/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 0.8259 - lin_loss: 0.0129 - cat1_loss: 0.3565 - cat2_loss: 0.4565 - lin_acc: 0.6931 - cat1_categorical_accuracy: 0.8471 - cat2_categorical_accuracy: 0.8006\n",
      "Epoch 97/1001\n",
      "8745/8745 [==============================] - 2s 262us/step - loss: 0.8181 - lin_loss: 0.0128 - cat1_loss: 0.3538 - cat2_loss: 0.4515 - lin_acc: 0.6949 - cat1_categorical_accuracy: 0.8451 - cat2_categorical_accuracy: 0.80240s - loss: 0.8206 - lin_loss: 0.0127 - cat1_loss: 0.3533 - cat2_loss: 0.4546 - lin_acc: 0.6943 - cat1_categorical_accuracy: 0.8469 - cat\n",
      "Epoch 98/1001\n",
      "8745/8745 [==============================] - 2s 264us/step - loss: 0.8155 - lin_loss: 0.0129 - cat1_loss: 0.3543 - cat2_loss: 0.4483 - lin_acc: 0.6988 - cat1_categorical_accuracy: 0.8461 - cat2_categorical_accuracy: 0.8065\n",
      "Epoch 99/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.8113 - lin_loss: 0.0128 - cat1_loss: 0.3484 - cat2_loss: 0.4502 - lin_acc: 0.6948 - cat1_categorical_accuracy: 0.8467 - cat2_categorical_accuracy: 0.8018\n",
      "Epoch 100/1001\n",
      "8745/8745 [==============================] - 2s 261us/step - loss: 0.8050 - lin_loss: 0.0128 - cat1_loss: 0.3480 - cat2_loss: 0.4442 - lin_acc: 0.7017 - cat1_categorical_accuracy: 0.8476 - cat2_categorical_accuracy: 0.8062\n",
      "Epoch 101/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 0.7997 - lin_loss: 0.0128 - cat1_loss: 0.3485 - cat2_loss: 0.4385 - lin_acc: 0.6991 - cat1_categorical_accuracy: 0.8497 - cat2_categorical_accuracy: 0.8074\n",
      "../linkPrediction/dataframes/apnea\\apnea-model-article-100_2008-2015.pkl\n",
      "Epoch 102/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.8028 - lin_loss: 0.0128 - cat1_loss: 0.3484 - cat2_loss: 0.4416 - lin_acc: 0.7005 - cat1_categorical_accuracy: 0.8483 - cat2_categorical_accuracy: 0.81150s - loss: 0.8109 - lin_loss: 0.0126 - cat1_loss: 0.3497 - cat2_loss: 0.4486 - lin_acc: 0.7025 - cat1_categorical_accuracy: 0.8492 -\n",
      "Epoch 103/1001\n",
      "8745/8745 [==============================] - 2s 284us/step - loss: 0.7811 - lin_loss: 0.0127 - cat1_loss: 0.3380 - cat2_loss: 0.4303 - lin_acc: 0.6999 - cat1_categorical_accuracy: 0.8536 - cat2_categorical_accuracy: 0.8126\n",
      "Epoch 104/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.7801 - lin_loss: 0.0128 - cat1_loss: 0.3389 - cat2_loss: 0.4285 - lin_acc: 0.6950 - cat1_categorical_accuracy: 0.8545 - cat2_categorical_accuracy: 0.8204\n",
      "Epoch 105/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.7761 - lin_loss: 0.0128 - cat1_loss: 0.3395 - cat2_loss: 0.4238 - lin_acc: 0.7059 - cat1_categorical_accuracy: 0.8528 - cat2_categorical_accuracy: 0.8174\n",
      "Epoch 106/1001\n",
      "8745/8745 [==============================] - ETA: 0s - loss: 0.7763 - lin_loss: 0.0128 - cat1_loss: 0.3344 - cat2_loss: 0.4291 - lin_acc: 0.7024 - cat1_categorical_accuracy: 0.8537 - cat2_categorical_accuracy: 0.81 - 2s 263us/step - loss: 0.7764 - lin_loss: 0.0128 - cat1_loss: 0.3344 - cat2_loss: 0.4291 - lin_acc: 0.7026 - cat1_categorical_accuracy: 0.8539 - cat2_categorical_accuracy: 0.8182\n",
      "Epoch 107/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.7710 - lin_loss: 0.0127 - cat1_loss: 0.3384 - cat2_loss: 0.4199 - lin_acc: 0.7004 - cat1_categorical_accuracy: 0.8517 - cat2_categorical_accuracy: 0.8198\n",
      "Epoch 108/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.7658 - lin_loss: 0.0127 - cat1_loss: 0.3367 - cat2_loss: 0.4164 - lin_acc: 0.7020 - cat1_categorical_accuracy: 0.8537 - cat2_categorical_accuracy: 0.8185\n",
      "Epoch 109/1001\n",
      "8745/8745 [==============================] - 3s 305us/step - loss: 0.7555 - lin_loss: 0.0127 - cat1_loss: 0.3283 - cat2_loss: 0.4145 - lin_acc: 0.7042 - cat1_categorical_accuracy: 0.8587 - cat2_categorical_accuracy: 0.8216\n",
      "Epoch 110/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 0.7538 - lin_loss: 0.0127 - cat1_loss: 0.3282 - cat2_loss: 0.4128 - lin_acc: 0.6969 - cat1_categorical_accuracy: 0.8524 - cat2_categorical_accuracy: 0.8245\n",
      "Epoch 111/1001\n",
      "8745/8745 [==============================] - 2s 264us/step - loss: 0.7525 - lin_loss: 0.0127 - cat1_loss: 0.3272 - cat2_loss: 0.4126 - lin_acc: 0.7019 - cat1_categorical_accuracy: 0.8565 - cat2_categorical_accuracy: 0.8221\n",
      "Epoch 112/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.7437 - lin_loss: 0.0128 - cat1_loss: 0.3240 - cat2_loss: 0.4070 - lin_acc: 0.6977 - cat1_categorical_accuracy: 0.8571 - cat2_categorical_accuracy: 0.8234\n",
      "Epoch 113/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.7471 - lin_loss: 0.0127 - cat1_loss: 0.3232 - cat2_loss: 0.4112 - lin_acc: 0.6974 - cat1_categorical_accuracy: 0.8569 - cat2_categorical_accuracy: 0.8217\n",
      "Epoch 114/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.7417 - lin_loss: 0.0127 - cat1_loss: 0.3244 - cat2_loss: 0.4046 - lin_acc: 0.7030 - cat1_categorical_accuracy: 0.8559 - cat2_categorical_accuracy: 0.8258\n",
      "Epoch 115/1001\n",
      "8745/8745 [==============================] - 2s 265us/step - loss: 0.7325 - lin_loss: 0.0127 - cat1_loss: 0.3172 - cat2_loss: 0.4025 - lin_acc: 0.7037 - cat1_categorical_accuracy: 0.8611 - cat2_categorical_accuracy: 0.8276\n",
      "Epoch 116/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.7297 - lin_loss: 0.0127 - cat1_loss: 0.3162 - cat2_loss: 0.4008 - lin_acc: 0.7044 - cat1_categorical_accuracy: 0.8599 - cat2_categorical_accuracy: 0.8300\n",
      "Epoch 117/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.7197 - lin_loss: 0.0128 - cat1_loss: 0.3124 - cat2_loss: 0.3946 - lin_acc: 0.7004 - cat1_categorical_accuracy: 0.8613 - cat2_categorical_accuracy: 0.83201s - loss: 0.7213 - lin_loss: 0.0126 - cat1_loss: 0.3107 - cat2_loss: 0.3980 - lin_acc: 0.6992 - cat1_categorical_accuracy: 0.86\n",
      "Epoch 118/1001\n",
      "8745/8745 [==============================] - 2s 261us/step - loss: 0.7243 - lin_loss: 0.0127 - cat1_loss: 0.3125 - cat2_loss: 0.3992 - lin_acc: 0.7042 - cat1_categorical_accuracy: 0.8622 - cat2_categorical_accuracy: 0.8270\n",
      "Epoch 119/1001\n",
      "8745/8745 [==============================] - 2s 264us/step - loss: 0.7212 - lin_loss: 0.0128 - cat1_loss: 0.3165 - cat2_loss: 0.3919 - lin_acc: 0.7028 - cat1_categorical_accuracy: 0.8607 - cat2_categorical_accuracy: 0.8367\n",
      "Epoch 120/1001\n",
      "8745/8745 [==============================] - 2s 264us/step - loss: 0.7167 - lin_loss: 0.0127 - cat1_loss: 0.3148 - cat2_loss: 0.3892 - lin_acc: 0.7039 - cat1_categorical_accuracy: 0.8612 - cat2_categorical_accuracy: 0.8301\n",
      "Epoch 121/1001\n",
      "8745/8745 [==============================] - 3s 302us/step - loss: 0.7109 - lin_loss: 0.0127 - cat1_loss: 0.3122 - cat2_loss: 0.3861 - lin_acc: 0.7058 - cat1_categorical_accuracy: 0.8609 - cat2_categorical_accuracy: 0.8360\n",
      "Epoch 122/1001\n",
      "8745/8745 [==============================] - 2s 262us/step - loss: 0.7084 - lin_loss: 0.0127 - cat1_loss: 0.3090 - cat2_loss: 0.3868 - lin_acc: 0.7021 - cat1_categorical_accuracy: 0.8611 - cat2_categorical_accuracy: 0.8379\n",
      "Epoch 123/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.7055 - lin_loss: 0.0126 - cat1_loss: 0.3094 - cat2_loss: 0.3835 - lin_acc: 0.7050 - cat1_categorical_accuracy: 0.8638 - cat2_categorical_accuracy: 0.8377\n",
      "Epoch 124/1001\n",
      "8745/8745 [==============================] - 3s 290us/step - loss: 0.7007 - lin_loss: 0.0127 - cat1_loss: 0.3061 - cat2_loss: 0.3819 - lin_acc: 0.7004 - cat1_categorical_accuracy: 0.8639 - cat2_categorical_accuracy: 0.8354\n",
      "Epoch 125/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.6962 - lin_loss: 0.0126 - cat1_loss: 0.3066 - cat2_loss: 0.3770 - lin_acc: 0.7067 - cat1_categorical_accuracy: 0.8639 - cat2_categorical_accuracy: 0.8388\n",
      "Epoch 126/1001\n",
      "8745/8745 [==============================] - 2s 266us/step - loss: 0.6925 - lin_loss: 0.0126 - cat1_loss: 0.3055 - cat2_loss: 0.3744 - lin_acc: 0.7011 - cat1_categorical_accuracy: 0.8615 - cat2_categorical_accuracy: 0.83950s - loss: 0.6833 - lin_loss: 0.0127 - cat1_loss: 0.3050 - cat2_loss: 0.3656 - lin_acc: 0.6974 - cat1_categorical_accuracy: 0.8583 - c\n",
      "Epoch 127/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.6896 - lin_loss: 0.0126 - cat1_loss: 0.3031 - cat2_loss: 0.3738 - lin_acc: 0.6990 - cat1_categorical_accuracy: 0.8636 - cat2_categorical_accuracy: 0.8445\n",
      "Epoch 128/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.6940 - lin_loss: 0.0126 - cat1_loss: 0.3089 - cat2_loss: 0.3724 - lin_acc: 0.7001 - cat1_categorical_accuracy: 0.8640 - cat2_categorical_accuracy: 0.83751s - loss: 0.6904 - lin_loss: 0.0126 - cat1_loss: 0.3143 - cat2_loss: 0.3635 - lin_acc: 0.6980 - cat1_categorical_accuracy: 0.8629 - cat2_categorical_accuracy: 0.84 - ETA: 1s - loss: 0.6820 - lin_loss: 0.0127 - cat1_loss: 0.3100 - cat2_loss: 0.3593 - lin_acc: 0.6988 - cat1_catego\n",
      "Epoch 129/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.6829 - lin_loss: 0.0126 - cat1_loss: 0.3018 - cat2_loss: 0.3685 - lin_acc: 0.7027 - cat1_categorical_accuracy: 0.8627 - cat2_categorical_accuracy: 0.8430\n",
      "Epoch 130/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.6858 - lin_loss: 0.0126 - cat1_loss: 0.3053 - cat2_loss: 0.3678 - lin_acc: 0.7046 - cat1_categorical_accuracy: 0.8626 - cat2_categorical_accuracy: 0.8439\n",
      "Epoch 131/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.6741 - lin_loss: 0.0126 - cat1_loss: 0.2974 - cat2_loss: 0.3640 - lin_acc: 0.7036 - cat1_categorical_accuracy: 0.8663 - cat2_categorical_accuracy: 0.84471s - loss: 0.6837 - lin_loss: 0.0125 - cat1_loss: 0.3030 - cat2_loss: 0.3682 - lin_acc: 0.7088 - cat1_categorical_accuracy: 0.86\n",
      "Epoch 132/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.6773 - lin_loss: 0.0126 - cat1_loss: 0.2977 - cat2_loss: 0.3670 - lin_acc: 0.7012 - cat1_categorical_accuracy: 0.8700 - cat2_categorical_accuracy: 0.8411\n",
      "Epoch 133/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.6722 - lin_loss: 0.0126 - cat1_loss: 0.2972 - cat2_loss: 0.3624 - lin_acc: 0.7028 - cat1_categorical_accuracy: 0.8662 - cat2_categorical_accuracy: 0.8444\n",
      "Epoch 134/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.6736 - lin_loss: 0.0126 - cat1_loss: 0.3002 - cat2_loss: 0.3608 - lin_acc: 0.7039 - cat1_categorical_accuracy: 0.8652 - cat2_categorical_accuracy: 0.8428\n",
      "Epoch 135/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.6703 - lin_loss: 0.0126 - cat1_loss: 0.2941 - cat2_loss: 0.3636 - lin_acc: 0.7010 - cat1_categorical_accuracy: 0.8678 - cat2_categorical_accuracy: 0.8452\n",
      "Epoch 136/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 0.6645 - lin_loss: 0.0126 - cat1_loss: 0.2946 - cat2_loss: 0.3573 - lin_acc: 0.7017 - cat1_categorical_accuracy: 0.8646 - cat2_categorical_accuracy: 0.84531s - loss: 0.6595 - lin_loss: 0.0126 - cat1_loss: 0.2962 - cat2_loss: 0.3507 - lin_acc: 0.7017 - cat1_categorical_accura\n",
      "Epoch 137/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 0.6608 - lin_loss: 0.0126 - cat1_loss: 0.2942 - cat2_loss: 0.3541 - lin_acc: 0.7041 - cat1_categorical_accuracy: 0.8674 - cat2_categorical_accuracy: 0.8475\n",
      "Epoch 138/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.6634 - lin_loss: 0.0126 - cat1_loss: 0.2932 - cat2_loss: 0.3577 - lin_acc: 0.7054 - cat1_categorical_accuracy: 0.8700 - cat2_categorical_accuracy: 0.8454\n",
      "Epoch 139/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.6589 - lin_loss: 0.0126 - cat1_loss: 0.2903 - cat2_loss: 0.3561 - lin_acc: 0.7050 - cat1_categorical_accuracy: 0.8678 - cat2_categorical_accuracy: 0.8456\n",
      "Epoch 140/1001\n",
      "8745/8745 [==============================] - 2s 265us/step - loss: 0.6568 - lin_loss: 0.0126 - cat1_loss: 0.2920 - cat2_loss: 0.3522 - lin_acc: 0.7038 - cat1_categorical_accuracy: 0.8702 - cat2_categorical_accuracy: 0.8455\n",
      "Epoch 141/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.6505 - lin_loss: 0.0126 - cat1_loss: 0.2873 - cat2_loss: 0.3507 - lin_acc: 0.7039 - cat1_categorical_accuracy: 0.8707 - cat2_categorical_accuracy: 0.8503\n",
      "Epoch 142/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 0.6505 - lin_loss: 0.0125 - cat1_loss: 0.2915 - cat2_loss: 0.3465 - lin_acc: 0.7042 - cat1_categorical_accuracy: 0.8683 - cat2_categorical_accuracy: 0.8471\n",
      "Epoch 143/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.6519 - lin_loss: 0.0126 - cat1_loss: 0.2927 - cat2_loss: 0.3466 - lin_acc: 0.7019 - cat1_categorical_accuracy: 0.8699 - cat2_categorical_accuracy: 0.84940s - loss: 0.6568 - lin_loss: 0.0127 - cat1_loss: 0.2888 - cat2_loss: 0.3553 - lin_acc: 0.6971 - cat1_categorical_accuracy: 0.8754\n",
      "Epoch 144/1001\n",
      "8745/8745 [==============================] - 2s 254us/step - loss: 0.6558 - lin_loss: 0.0125 - cat1_loss: 0.2904 - cat2_loss: 0.3529 - lin_acc: 0.7037 - cat1_categorical_accuracy: 0.8669 - cat2_categorical_accuracy: 0.8457\n",
      "Epoch 145/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.6467 - lin_loss: 0.0126 - cat1_loss: 0.2884 - cat2_loss: 0.3457 - lin_acc: 0.7035 - cat1_categorical_accuracy: 0.8708 - cat2_categorical_accuracy: 0.8488\n",
      "Epoch 146/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 0.6434 - lin_loss: 0.0125 - cat1_loss: 0.2860 - cat2_loss: 0.3448 - lin_acc: 0.7041 - cat1_categorical_accuracy: 0.8723 - cat2_categorical_accuracy: 0.8509\n",
      "Epoch 147/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.6445 - lin_loss: 0.0125 - cat1_loss: 0.2871 - cat2_loss: 0.3449 - lin_acc: 0.7089 - cat1_categorical_accuracy: 0.8704 - cat2_categorical_accuracy: 0.8526\n",
      "Epoch 148/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.6504 - lin_loss: 0.0125 - cat1_loss: 0.2926 - cat2_loss: 0.3452 - lin_acc: 0.7076 - cat1_categorical_accuracy: 0.8700 - cat2_categorical_accuracy: 0.85082s - loss: 0.5702 - lin_loss: 0.0129 - cat1_loss: 0.2423 - cat2_loss: 0.3150 - lin_acc: \n",
      "Epoch 149/1001\n",
      "8745/8745 [==============================] - 2s 262us/step - loss: 0.6348 - lin_loss: 0.0125 - cat1_loss: 0.2840 - cat2_loss: 0.3383 - lin_acc: 0.7034 - cat1_categorical_accuracy: 0.8722 - cat2_categorical_accuracy: 0.8527\n",
      "Epoch 150/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.6460 - lin_loss: 0.0126 - cat1_loss: 0.2916 - cat2_loss: 0.3419 - lin_acc: 0.7049 - cat1_categorical_accuracy: 0.8701 - cat2_categorical_accuracy: 0.8510\n",
      "Epoch 151/1001\n",
      "8745/8745 [==============================] - 2s 266us/step - loss: 0.6423 - lin_loss: 0.0125 - cat1_loss: 0.2883 - cat2_loss: 0.3415 - lin_acc: 0.7041 - cat1_categorical_accuracy: 0.8686 - cat2_categorical_accuracy: 0.8512\n",
      "Epoch 152/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.6362 - lin_loss: 0.0126 - cat1_loss: 0.2847 - cat2_loss: 0.3389 - lin_acc: 0.7058 - cat1_categorical_accuracy: 0.8730 - cat2_categorical_accuracy: 0.8521\n",
      "Epoch 153/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.6339 - lin_loss: 0.0126 - cat1_loss: 0.2842 - cat2_loss: 0.3371 - lin_acc: 0.7057 - cat1_categorical_accuracy: 0.8724 - cat2_categorical_accuracy: 0.85101s - loss: 0.6456 - lin_loss: 0.0126 - cat1_loss: 0.2842 - cat2_loss: 0.3487 - lin_acc: 0.7122 - cat1_categori\n",
      "Epoch 154/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.6260 - lin_loss: 0.0126 - cat1_loss: 0.2792 - cat2_loss: 0.3342 - lin_acc: 0.7042 - cat1_categorical_accuracy: 0.8719 - cat2_categorical_accuracy: 0.8550\n",
      "Epoch 155/1001\n",
      "8745/8745 [==============================] - 2s 264us/step - loss: 0.6298 - lin_loss: 0.0125 - cat1_loss: 0.2823 - cat2_loss: 0.3350 - lin_acc: 0.7068 - cat1_categorical_accuracy: 0.8719 - cat2_categorical_accuracy: 0.8569\n",
      "Epoch 156/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.6287 - lin_loss: 0.0125 - cat1_loss: 0.2850 - cat2_loss: 0.3312 - lin_acc: 0.7036 - cat1_categorical_accuracy: 0.8708 - cat2_categorical_accuracy: 0.8571\n",
      "Epoch 157/1001\n",
      "8745/8745 [==============================] - 2s 264us/step - loss: 0.6247 - lin_loss: 0.0125 - cat1_loss: 0.2820 - cat2_loss: 0.3302 - lin_acc: 0.7023 - cat1_categorical_accuracy: 0.8730 - cat2_categorical_accuracy: 0.8580\n",
      "Epoch 158/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.6282 - lin_loss: 0.0125 - cat1_loss: 0.2829 - cat2_loss: 0.3328 - lin_acc: 0.7073 - cat1_categorical_accuracy: 0.8712 - cat2_categorical_accuracy: 0.8544\n",
      "Epoch 159/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.6258 - lin_loss: 0.0125 - cat1_loss: 0.2794 - cat2_loss: 0.3339 - lin_acc: 0.7015 - cat1_categorical_accuracy: 0.8716 - cat2_categorical_accuracy: 0.85091s - loss: 0.6352 - lin_loss: 0.0124 - cat1_loss: 0.2699 - cat2_loss: 0.3529 - lin_acc: 0.7023 - cat1_categorical_\n",
      "Epoch 160/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.6251 - lin_loss: 0.0125 - cat1_loss: 0.2821 - cat2_loss: 0.3305 - lin_acc: 0.7067 - cat1_categorical_accuracy: 0.8714 - cat2_categorical_accuracy: 0.8564\n",
      "Epoch 161/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 0.6188 - lin_loss: 0.0125 - cat1_loss: 0.2783 - cat2_loss: 0.3281 - lin_acc: 0.7078 - cat1_categorical_accuracy: 0.8734 - cat2_categorical_accuracy: 0.85890s - loss: 0.6125 - lin_loss: 0.0125 - cat1_loss: 0.2754 - cat2_loss: 0.3245 - lin_acc: 0.7061 - cat1_categorical_accuracy: 0.8738 - cat2_\n",
      "Epoch 162/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.6217 - lin_loss: 0.0126 - cat1_loss: 0.2783 - cat2_loss: 0.3309 - lin_acc: 0.7041 - cat1_categorical_accuracy: 0.8738 - cat2_categorical_accuracy: 0.8523\n",
      "Epoch 163/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.6201 - lin_loss: 0.0125 - cat1_loss: 0.2793 - cat2_loss: 0.3283 - lin_acc: 0.7087 - cat1_categorical_accuracy: 0.8716 - cat2_categorical_accuracy: 0.85742s - loss: 0.6919 - lin_loss: 0.0131 - cat1_loss: 0.2995 - cat2_loss: 0.3793 - lin_acc: 0.\n",
      "Epoch 164/1001\n",
      "8745/8745 [==============================] - 3s 296us/step - loss: 0.6129 - lin_loss: 0.0125 - cat1_loss: 0.2742 - cat2_loss: 0.3262 - lin_acc: 0.7012 - cat1_categorical_accuracy: 0.8754 - cat2_categorical_accuracy: 0.8539\n",
      "Epoch 165/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.6146 - lin_loss: 0.0125 - cat1_loss: 0.2780 - cat2_loss: 0.3242 - lin_acc: 0.7038 - cat1_categorical_accuracy: 0.8738 - cat2_categorical_accuracy: 0.85680s - loss: 0.6082 - lin_loss: 0.0124 - cat1_loss: 0.2733 - cat2_loss: 0.3225 - lin_acc: 0.7106 - cat1_categorical_accuracy: 0.8758 - cat2_cate\n",
      "Epoch 166/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.6149 - lin_loss: 0.0125 - cat1_loss: 0.2806 - cat2_loss: 0.3218 - lin_acc: 0.7078 - cat1_categorical_accuracy: 0.8725 - cat2_categorical_accuracy: 0.8592\n",
      "Epoch 167/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.6071 - lin_loss: 0.0125 - cat1_loss: 0.2768 - cat2_loss: 0.3178 - lin_acc: 0.7020 - cat1_categorical_accuracy: 0.8743 - cat2_categorical_accuracy: 0.8582\n",
      "Epoch 168/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.6136 - lin_loss: 0.0125 - cat1_loss: 0.2789 - cat2_loss: 0.3222 - lin_acc: 0.7022 - cat1_categorical_accuracy: 0.8694 - cat2_categorical_accuracy: 0.85810s - loss: 0.6211 - lin_loss: 0.0124 - cat1_loss: 0.2859 - cat2_loss: 0.3228 - lin_acc: 0.7041 - cat1_categorical_accuracy: 0.8644 - cat\n",
      "Epoch 169/1001\n",
      "8745/8745 [==============================] - 2s 261us/step - loss: 0.6098 - lin_loss: 0.0124 - cat1_loss: 0.2768 - cat2_loss: 0.3206 - lin_acc: 0.7045 - cat1_categorical_accuracy: 0.8725 - cat2_categorical_accuracy: 0.8579\n",
      "Epoch 170/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.6137 - lin_loss: 0.0125 - cat1_loss: 0.2780 - cat2_loss: 0.3232 - lin_acc: 0.7060 - cat1_categorical_accuracy: 0.8732 - cat2_categorical_accuracy: 0.8583\n",
      "Epoch 171/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 0.6079 - lin_loss: 0.0124 - cat1_loss: 0.2756 - cat2_loss: 0.3198 - lin_acc: 0.7060 - cat1_categorical_accuracy: 0.8755 - cat2_categorical_accuracy: 0.8574\n",
      "Epoch 172/1001\n",
      "8745/8745 [==============================] - 2s 264us/step - loss: 0.6108 - lin_loss: 0.0124 - cat1_loss: 0.2796 - cat2_loss: 0.3188 - lin_acc: 0.7046 - cat1_categorical_accuracy: 0.8722 - cat2_categorical_accuracy: 0.8590\n",
      "Epoch 173/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.6030 - lin_loss: 0.0124 - cat1_loss: 0.2721 - cat2_loss: 0.3184 - lin_acc: 0.6991 - cat1_categorical_accuracy: 0.8752 - cat2_categorical_accuracy: 0.8600\n",
      "Epoch 174/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.6041 - lin_loss: 0.0124 - cat1_loss: 0.2766 - cat2_loss: 0.3151 - lin_acc: 0.7122 - cat1_categorical_accuracy: 0.8710 - cat2_categorical_accuracy: 0.86032s - loss: 0.5543 - lin_loss: 0.0125 - cat1_loss: 0.2542 - cat2_loss: 0.2876 - lin_acc: 0.72\n",
      "Epoch 175/1001\n",
      "8745/8745 [==============================] - 2s 255us/step - loss: 0.6053 - lin_loss: 0.0124 - cat1_loss: 0.2760 - cat2_loss: 0.3169 - lin_acc: 0.7073 - cat1_categorical_accuracy: 0.8719 - cat2_categorical_accuracy: 0.8607\n",
      "Epoch 176/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5994 - lin_loss: 0.0124 - cat1_loss: 0.2724 - cat2_loss: 0.3147 - lin_acc: 0.7046 - cat1_categorical_accuracy: 0.8743 - cat2_categorical_accuracy: 0.8589\n",
      "Epoch 177/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 3s 358us/step - loss: 0.5982 - lin_loss: 0.0124 - cat1_loss: 0.2708 - cat2_loss: 0.3150 - lin_acc: 0.7084 - cat1_categorical_accuracy: 0.8739 - cat2_categorical_accuracy: 0.8601\n",
      "Epoch 178/1001\n",
      "8745/8745 [==============================] - 3s 328us/step - loss: 0.5989 - lin_loss: 0.0124 - cat1_loss: 0.2715 - cat2_loss: 0.3149 - lin_acc: 0.7047 - cat1_categorical_accuracy: 0.8706 - cat2_categorical_accuracy: 0.8584\n",
      "Epoch 179/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.6065 - lin_loss: 0.0125 - cat1_loss: 0.2766 - cat2_loss: 0.3174 - lin_acc: 0.7061 - cat1_categorical_accuracy: 0.8706 - cat2_categorical_accuracy: 0.8542\n",
      "Epoch 180/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.6022 - lin_loss: 0.0124 - cat1_loss: 0.2731 - cat2_loss: 0.3167 - lin_acc: 0.7087 - cat1_categorical_accuracy: 0.8751 - cat2_categorical_accuracy: 0.8589\n",
      "Epoch 181/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5993 - lin_loss: 0.0124 - cat1_loss: 0.2724 - cat2_loss: 0.3144 - lin_acc: 0.7069 - cat1_categorical_accuracy: 0.8723 - cat2_categorical_accuracy: 0.8614\n",
      "Epoch 182/1001\n",
      "8745/8745 [==============================] - 3s 286us/step - loss: 0.5943 - lin_loss: 0.0124 - cat1_loss: 0.2755 - cat2_loss: 0.3065 - lin_acc: 0.7076 - cat1_categorical_accuracy: 0.8730 - cat2_categorical_accuracy: 0.86221s - loss: 0.5887 - lin_loss: 0.0125 - cat1_loss: 0.2709 - cat2_loss: 0.3054 - lin_acc: 0.6955 - cat1_categorical_accuracy: \n",
      "Epoch 183/1001\n",
      "8745/8745 [==============================] - 3s 302us/step - loss: 0.5988 - lin_loss: 0.0124 - cat1_loss: 0.2774 - cat2_loss: 0.3090 - lin_acc: 0.7061 - cat1_categorical_accuracy: 0.8716 - cat2_categorical_accuracy: 0.8630\n",
      "Epoch 184/1001\n",
      "8745/8745 [==============================] - 2s 255us/step - loss: 0.5956 - lin_loss: 0.0124 - cat1_loss: 0.2710 - cat2_loss: 0.3122 - lin_acc: 0.7069 - cat1_categorical_accuracy: 0.8756 - cat2_categorical_accuracy: 0.8596\n",
      "Epoch 185/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5896 - lin_loss: 0.0124 - cat1_loss: 0.2694 - cat2_loss: 0.3078 - lin_acc: 0.7063 - cat1_categorical_accuracy: 0.8748 - cat2_categorical_accuracy: 0.8617\n",
      "Epoch 186/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5924 - lin_loss: 0.0124 - cat1_loss: 0.2720 - cat2_loss: 0.3080 - lin_acc: 0.7050 - cat1_categorical_accuracy: 0.8728 - cat2_categorical_accuracy: 0.8639\n",
      "Epoch 187/1001\n",
      "8745/8745 [==============================] - 2s 259us/step - loss: 0.5913 - lin_loss: 0.0124 - cat1_loss: 0.2727 - cat2_loss: 0.3061 - lin_acc: 0.7020 - cat1_categorical_accuracy: 0.8718 - cat2_categorical_accuracy: 0.8617\n",
      "Epoch 188/1001\n",
      "8745/8745 [==============================] - 3s 286us/step - loss: 0.5942 - lin_loss: 0.0124 - cat1_loss: 0.2746 - cat2_loss: 0.3073 - lin_acc: 0.7062 - cat1_categorical_accuracy: 0.8726 - cat2_categorical_accuracy: 0.8620\n",
      "Epoch 189/1001\n",
      "8745/8745 [==============================] - 2s 254us/step - loss: 0.5919 - lin_loss: 0.0124 - cat1_loss: 0.2708 - cat2_loss: 0.3088 - lin_acc: 0.7073 - cat1_categorical_accuracy: 0.8755 - cat2_categorical_accuracy: 0.8623\n",
      "Epoch 190/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 0.5861 - lin_loss: 0.0123 - cat1_loss: 0.2698 - cat2_loss: 0.3040 - lin_acc: 0.7110 - cat1_categorical_accuracy: 0.8739 - cat2_categorical_accuracy: 0.8638\n",
      "Epoch 191/1001\n",
      "8745/8745 [==============================] - 3s 308us/step - loss: 0.5880 - lin_loss: 0.0124 - cat1_loss: 0.2673 - cat2_loss: 0.3083 - lin_acc: 0.7073 - cat1_categorical_accuracy: 0.8741 - cat2_categorical_accuracy: 0.8590\n",
      "Epoch 192/1001\n",
      "8745/8745 [==============================] - 3s 290us/step - loss: 0.5866 - lin_loss: 0.0123 - cat1_loss: 0.2685 - cat2_loss: 0.3057 - lin_acc: 0.7081 - cat1_categorical_accuracy: 0.8733 - cat2_categorical_accuracy: 0.86350s - loss: 0.5940 - lin_loss: 0.0124 - cat1_loss: 0.2729 - cat2_loss: 0.3087 - lin_acc: 0.7080 - cat1_categorical_accuracy: 0.8714 - cat2_categorical_ - ETA: 0s - loss: 0.5871 - lin_loss: 0.0124 - cat1_loss: 0.2686 - cat2_loss: 0.3060 - lin_acc: 0.7074 - cat1_categorical_accuracy: 0.8731 - cat2_categorical_accuracy: 0.\n",
      "Epoch 193/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5879 - lin_loss: 0.0124 - cat1_loss: 0.2715 - cat2_loss: 0.3040 - lin_acc: 0.7077 - cat1_categorical_accuracy: 0.8739 - cat2_categorical_accuracy: 0.86303s - loss: 0.5343 - lin_loss: 0.0123 - cat1_loss: 0.2682 - cat2_loss: 0.2537 - lin_acc\n",
      "Epoch 194/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5912 - lin_loss: 0.0124 - cat1_loss: 0.2703 - cat2_loss: 0.3086 - lin_acc: 0.7075 - cat1_categorical_accuracy: 0.8725 - cat2_categorical_accuracy: 0.8604\n",
      "Epoch 195/1001\n",
      "8745/8745 [==============================] - 3s 300us/step - loss: 0.5841 - lin_loss: 0.0123 - cat1_loss: 0.2699 - cat2_loss: 0.3019 - lin_acc: 0.7068 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.8671\n",
      "Epoch 196/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5959 - lin_loss: 0.0123 - cat1_loss: 0.2714 - cat2_loss: 0.3122 - lin_acc: 0.7084 - cat1_categorical_accuracy: 0.8712 - cat2_categorical_accuracy: 0.8596\n",
      "Epoch 197/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5839 - lin_loss: 0.0124 - cat1_loss: 0.2694 - cat2_loss: 0.3021 - lin_acc: 0.7086 - cat1_categorical_accuracy: 0.8749 - cat2_categorical_accuracy: 0.8592\n",
      "Epoch 198/1001\n",
      "8745/8745 [==============================] - 2s 258us/step - loss: 0.5862 - lin_loss: 0.0123 - cat1_loss: 0.2729 - cat2_loss: 0.3009 - lin_acc: 0.7129 - cat1_categorical_accuracy: 0.8711 - cat2_categorical_accuracy: 0.8635\n",
      "Epoch 199/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5817 - lin_loss: 0.0124 - cat1_loss: 0.2692 - cat2_loss: 0.3002 - lin_acc: 0.7054 - cat1_categorical_accuracy: 0.8733 - cat2_categorical_accuracy: 0.8653\n",
      "Epoch 200/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.5790 - lin_loss: 0.0123 - cat1_loss: 0.2661 - cat2_loss: 0.3005 - lin_acc: 0.7097 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.86480s - loss: 0.5790 - lin_loss: 0.0123 - cat1_loss: 0.2645 - cat2_loss: 0.3022 - lin_acc: 0.7092 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy\n",
      "Epoch 201/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5813 - lin_loss: 0.0123 - cat1_loss: 0.2698 - cat2_loss: 0.2992 - lin_acc: 0.7060 - cat1_categorical_accuracy: 0.8751 - cat2_categorical_accuracy: 0.8652\n",
      "Epoch 202/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5813 - lin_loss: 0.0123 - cat1_loss: 0.2686 - cat2_loss: 0.3004 - lin_acc: 0.7094 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8639\n",
      "Epoch 203/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5814 - lin_loss: 0.0123 - cat1_loss: 0.2689 - cat2_loss: 0.3001 - lin_acc: 0.7071 - cat1_categorical_accuracy: 0.8735 - cat2_categorical_accuracy: 0.8620\n",
      "Epoch 204/1001\n",
      "8745/8745 [==============================] - 2s 263us/step - loss: 0.5824 - lin_loss: 0.0123 - cat1_loss: 0.2702 - cat2_loss: 0.2999 - lin_acc: 0.7042 - cat1_categorical_accuracy: 0.8748 - cat2_categorical_accuracy: 0.8626\n",
      "Epoch 205/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5758 - lin_loss: 0.0124 - cat1_loss: 0.2661 - cat2_loss: 0.2973 - lin_acc: 0.7058 - cat1_categorical_accuracy: 0.8747 - cat2_categorical_accuracy: 0.8654\n",
      "Epoch 206/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5817 - lin_loss: 0.0123 - cat1_loss: 0.2695 - cat2_loss: 0.2998 - lin_acc: 0.7061 - cat1_categorical_accuracy: 0.8728 - cat2_categorical_accuracy: 0.8646\n",
      "Epoch 207/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 0.5735 - lin_loss: 0.0123 - cat1_loss: 0.2675 - cat2_loss: 0.2937 - lin_acc: 0.7053 - cat1_categorical_accuracy: 0.8738 - cat2_categorical_accuracy: 0.8653\n",
      "Epoch 208/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5729 - lin_loss: 0.0123 - cat1_loss: 0.2633 - cat2_loss: 0.2973 - lin_acc: 0.7090 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.86441s - loss: 0.5748 - lin_loss: 0.0122 - cat1_loss: 0.2606 - cat2_loss: 0.3020 - lin_acc: 0.7068 - cat1_categorical_accu\n",
      "Epoch 209/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5759 - lin_loss: 0.0123 - cat1_loss: 0.2656 - cat2_loss: 0.2980 - lin_acc: 0.7061 - cat1_categorical_accuracy: 0.8752 - cat2_categorical_accuracy: 0.8631\n",
      "Epoch 210/1001\n",
      "8745/8745 [==============================] - 2s 262us/step - loss: 0.5724 - lin_loss: 0.0123 - cat1_loss: 0.2648 - cat2_loss: 0.2953 - lin_acc: 0.7030 - cat1_categorical_accuracy: 0.8738 - cat2_categorical_accuracy: 0.8623\n",
      "Epoch 211/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5762 - lin_loss: 0.0123 - cat1_loss: 0.2654 - cat2_loss: 0.2985 - lin_acc: 0.7078 - cat1_categorical_accuracy: 0.8749 - cat2_categorical_accuracy: 0.8630\n",
      "Epoch 212/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5755 - lin_loss: 0.0123 - cat1_loss: 0.2673 - cat2_loss: 0.2959 - lin_acc: 0.7111 - cat1_categorical_accuracy: 0.8739 - cat2_categorical_accuracy: 0.8636\n",
      "Epoch 213/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5780 - lin_loss: 0.0123 - cat1_loss: 0.2680 - cat2_loss: 0.2978 - lin_acc: 0.7045 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8664\n",
      "Epoch 214/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 0.5773 - lin_loss: 0.0123 - cat1_loss: 0.2675 - cat2_loss: 0.2975 - lin_acc: 0.7085 - cat1_categorical_accuracy: 0.8736 - cat2_categorical_accuracy: 0.8593\n",
      "Epoch 215/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5807 - lin_loss: 0.0123 - cat1_loss: 0.2672 - cat2_loss: 0.3013 - lin_acc: 0.7030 - cat1_categorical_accuracy: 0.8724 - cat2_categorical_accuracy: 0.8621\n",
      "Epoch 216/1001\n",
      "8745/8745 [==============================] - 2s 264us/step - loss: 0.5778 - lin_loss: 0.0124 - cat1_loss: 0.2671 - cat2_loss: 0.2983 - lin_acc: 0.7043 - cat1_categorical_accuracy: 0.8744 - cat2_categorical_accuracy: 0.8600\n",
      "Epoch 217/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5747 - lin_loss: 0.0123 - cat1_loss: 0.2672 - cat2_loss: 0.2953 - lin_acc: 0.7121 - cat1_categorical_accuracy: 0.8725 - cat2_categorical_accuracy: 0.8617\n",
      "Epoch 218/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.5764 - lin_loss: 0.0123 - cat1_loss: 0.2686 - cat2_loss: 0.2956 - lin_acc: 0.7091 - cat1_categorical_accuracy: 0.8736 - cat2_categorical_accuracy: 0.8639\n",
      "Epoch 219/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5735 - lin_loss: 0.0123 - cat1_loss: 0.2685 - cat2_loss: 0.2927 - lin_acc: 0.7033 - cat1_categorical_accuracy: 0.8720 - cat2_categorical_accuracy: 0.8659\n",
      "Epoch 220/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5735 - lin_loss: 0.0123 - cat1_loss: 0.2655 - cat2_loss: 0.2958 - lin_acc: 0.7100 - cat1_categorical_accuracy: 0.8734 - cat2_categorical_accuracy: 0.86031s - loss: 0.5682 - lin_loss: 0.0123 - cat1_loss: 0.2595 - cat2_loss: 0.2964 - lin_acc: 0.7114 - cat1_categorical_accuracy: 0.\n",
      "Epoch 221/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5690 - lin_loss: 0.0123 - cat1_loss: 0.2654 - cat2_loss: 0.2914 - lin_acc: 0.7086 - cat1_categorical_accuracy: 0.8755 - cat2_categorical_accuracy: 0.8645\n",
      "Epoch 222/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.5703 - lin_loss: 0.0123 - cat1_loss: 0.2674 - cat2_loss: 0.2906 - lin_acc: 0.7087 - cat1_categorical_accuracy: 0.8751 - cat2_categorical_accuracy: 0.8652\n",
      "Epoch 223/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5699 - lin_loss: 0.0122 - cat1_loss: 0.2656 - cat2_loss: 0.2921 - lin_acc: 0.7089 - cat1_categorical_accuracy: 0.8752 - cat2_categorical_accuracy: 0.8664\n",
      "Epoch 224/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5734 - lin_loss: 0.0122 - cat1_loss: 0.2665 - cat2_loss: 0.2946 - lin_acc: 0.7069 - cat1_categorical_accuracy: 0.8741 - cat2_categorical_accuracy: 0.86391s - loss: 0.5689 - lin_loss: 0.0121 - cat1_loss: 0.2610 - cat2_loss: 0.2958 - lin_acc: 0.7083 - cat1_categorical_accuracy\n",
      "Epoch 225/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5709 - lin_loss: 0.0122 - cat1_loss: 0.2645 - cat2_loss: 0.2942 - lin_acc: 0.7100 - cat1_categorical_accuracy: 0.8742 - cat2_categorical_accuracy: 0.86360s - loss: 0.5717 - lin_loss: 0.0123 - cat1_loss: 0.2655 - cat2_loss: 0.2940 - lin_acc: 0.7107 - cat1_categorical_accuracy: 0.8734 - cat2_categorical_accuracy: 0.86\n",
      "Epoch 226/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 0.5664 - lin_loss: 0.0122 - cat1_loss: 0.2623 - cat2_loss: 0.2919 - lin_acc: 0.7084 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.86562s - loss: 0.5337 - lin_loss: 0.0124 - cat1_loss: 0.2374 - cat2_loss: 0.2838 - lin_acc: 0.\n",
      "Epoch 227/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5642 - lin_loss: 0.0123 - cat1_loss: 0.2633 - cat2_loss: 0.2887 - lin_acc: 0.7073 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 228/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5684 - lin_loss: 0.0122 - cat1_loss: 0.2625 - cat2_loss: 0.2937 - lin_acc: 0.7085 - cat1_categorical_accuracy: 0.8743 - cat2_categorical_accuracy: 0.8636\n",
      "Epoch 229/1001\n",
      "8745/8745 [==============================] - 2s 265us/step - loss: 0.5631 - lin_loss: 0.0123 - cat1_loss: 0.2623 - cat2_loss: 0.2885 - lin_acc: 0.7084 - cat1_categorical_accuracy: 0.8726 - cat2_categorical_accuracy: 0.8658\n",
      "Epoch 230/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 0.5669 - lin_loss: 0.0123 - cat1_loss: 0.2632 - cat2_loss: 0.2914 - lin_acc: 0.7124 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8654\n",
      "Epoch 231/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5659 - lin_loss: 0.0122 - cat1_loss: 0.2613 - cat2_loss: 0.2924 - lin_acc: 0.7089 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8624\n",
      "Epoch 232/1001\n",
      "8745/8745 [==============================] - 3s 303us/step - loss: 0.5613 - lin_loss: 0.0123 - cat1_loss: 0.2638 - cat2_loss: 0.2853 - lin_acc: 0.7108 - cat1_categorical_accuracy: 0.8747 - cat2_categorical_accuracy: 0.86671s - loss: 0.5562 - lin_loss: 0.0123 - cat1_loss: 0.2644 - cat2_loss: 0.2795 - lin_acc: 0.7235 - cat1_ca\n",
      "Epoch 233/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5712 - lin_loss: 0.0122 - cat1_loss: 0.2663 - cat2_loss: 0.2927 - lin_acc: 0.7124 - cat1_categorical_accuracy: 0.8752 - cat2_categorical_accuracy: 0.8660\n",
      "Epoch 234/1001\n",
      "8745/8745 [==============================] - 2s 262us/step - loss: 0.5678 - lin_loss: 0.0122 - cat1_loss: 0.2639 - cat2_loss: 0.2916 - lin_acc: 0.7101 - cat1_categorical_accuracy: 0.8756 - cat2_categorical_accuracy: 0.8646\n",
      "Epoch 235/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5660 - lin_loss: 0.0122 - cat1_loss: 0.2642 - cat2_loss: 0.2896 - lin_acc: 0.7117 - cat1_categorical_accuracy: 0.8744 - cat2_categorical_accuracy: 0.8648\n",
      "Epoch 236/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5648 - lin_loss: 0.0122 - cat1_loss: 0.2641 - cat2_loss: 0.2884 - lin_acc: 0.7058 - cat1_categorical_accuracy: 0.8797 - cat2_categorical_accuracy: 0.8679\n",
      "Epoch 237/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5684 - lin_loss: 0.0122 - cat1_loss: 0.2655 - cat2_loss: 0.2907 - lin_acc: 0.7117 - cat1_categorical_accuracy: 0.8726 - cat2_categorical_accuracy: 0.8615\n",
      "Epoch 238/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5637 - lin_loss: 0.0122 - cat1_loss: 0.2638 - cat2_loss: 0.2878 - lin_acc: 0.7126 - cat1_categorical_accuracy: 0.8741 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 239/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.5625 - lin_loss: 0.0122 - cat1_loss: 0.2611 - cat2_loss: 0.2892 - lin_acc: 0.7058 - cat1_categorical_accuracy: 0.8724 - cat2_categorical_accuracy: 0.8634\n",
      "Epoch 240/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5637 - lin_loss: 0.0122 - cat1_loss: 0.2612 - cat2_loss: 0.2904 - lin_acc: 0.7132 - cat1_categorical_accuracy: 0.8739 - cat2_categorical_accuracy: 0.86350s - loss: 0.5628 - lin_loss: 0.0122 - cat1_loss: 0.2606 - cat2_loss: 0.2900 - lin_acc: 0.7136 - cat1_categorical_accuracy: 0.8741 - cat2_categorical_accuracy: 0.86\n",
      "Epoch 241/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5628 - lin_loss: 0.0122 - cat1_loss: 0.2648 - cat2_loss: 0.2858 - lin_acc: 0.7060 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 242/1001\n",
      "8745/8745 [==============================] - 2s 260us/step - loss: 0.5568 - lin_loss: 0.0122 - cat1_loss: 0.2577 - cat2_loss: 0.2869 - lin_acc: 0.7103 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.8664\n",
      "Epoch 243/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5670 - lin_loss: 0.0122 - cat1_loss: 0.2651 - cat2_loss: 0.2898 - lin_acc: 0.7129 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8637\n",
      "Epoch 244/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5609 - lin_loss: 0.0122 - cat1_loss: 0.2630 - cat2_loss: 0.2858 - lin_acc: 0.7052 - cat1_categorical_accuracy: 0.8751 - cat2_categorical_accuracy: 0.8661\n",
      "Epoch 245/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 0.5640 - lin_loss: 0.0122 - cat1_loss: 0.2640 - cat2_loss: 0.2879 - lin_acc: 0.7106 - cat1_categorical_accuracy: 0.8731 - cat2_categorical_accuracy: 0.8637\n",
      "Epoch 246/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5624 - lin_loss: 0.0122 - cat1_loss: 0.2619 - cat2_loss: 0.2883 - lin_acc: 0.7054 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8631\n",
      "Epoch 247/1001\n",
      "8745/8745 [==============================] - 3s 313us/step - loss: 0.5623 - lin_loss: 0.0122 - cat1_loss: 0.2636 - cat2_loss: 0.2865 - lin_acc: 0.7116 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8668\n",
      "Epoch 248/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5586 - lin_loss: 0.0121 - cat1_loss: 0.2624 - cat2_loss: 0.2841 - lin_acc: 0.7083 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 249/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5604 - lin_loss: 0.0121 - cat1_loss: 0.2588 - cat2_loss: 0.2895 - lin_acc: 0.7101 - cat1_categorical_accuracy: 0.8735 - cat2_categorical_accuracy: 0.8643\n",
      "Epoch 250/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5659 - lin_loss: 0.0122 - cat1_loss: 0.2647 - cat2_loss: 0.2891 - lin_acc: 0.7129 - cat1_categorical_accuracy: 0.8685 - cat2_categorical_accuracy: 0.8647\n",
      "Epoch 251/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5622 - lin_loss: 0.0122 - cat1_loss: 0.2615 - cat2_loss: 0.2885 - lin_acc: 0.7103 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8627\n",
      "Epoch 252/1001\n",
      "8745/8745 [==============================] - 2s 266us/step - loss: 0.5563 - lin_loss: 0.0121 - cat1_loss: 0.2606 - cat2_loss: 0.2835 - lin_acc: 0.7115 - cat1_categorical_accuracy: 0.8762 - cat2_categorical_accuracy: 0.8663\n",
      "Epoch 253/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5552 - lin_loss: 0.0122 - cat1_loss: 0.2606 - cat2_loss: 0.2825 - lin_acc: 0.7103 - cat1_categorical_accuracy: 0.8750 - cat2_categorical_accuracy: 0.8666\n",
      "Epoch 254/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5580 - lin_loss: 0.0121 - cat1_loss: 0.2598 - cat2_loss: 0.2862 - lin_acc: 0.7062 - cat1_categorical_accuracy: 0.8738 - cat2_categorical_accuracy: 0.8654\n",
      "Epoch 255/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5568 - lin_loss: 0.0122 - cat1_loss: 0.2594 - cat2_loss: 0.2852 - lin_acc: 0.7092 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8704\n",
      "Epoch 256/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5571 - lin_loss: 0.0122 - cat1_loss: 0.2602 - cat2_loss: 0.2847 - lin_acc: 0.7075 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.8664\n",
      "Epoch 257/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5642 - lin_loss: 0.0121 - cat1_loss: 0.2661 - cat2_loss: 0.2860 - lin_acc: 0.7130 - cat1_categorical_accuracy: 0.8741 - cat2_categorical_accuracy: 0.8658\n",
      "Epoch 258/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5553 - lin_loss: 0.0121 - cat1_loss: 0.2575 - cat2_loss: 0.2856 - lin_acc: 0.7095 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8638\n",
      "Epoch 259/1001\n",
      "8745/8745 [==============================] - 2s 262us/step - loss: 0.5581 - lin_loss: 0.0121 - cat1_loss: 0.2581 - cat2_loss: 0.2879 - lin_acc: 0.7126 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.8621\n",
      "Epoch 260/1001\n",
      "8745/8745 [==============================] - 2s 266us/step - loss: 0.5576 - lin_loss: 0.0121 - cat1_loss: 0.2618 - cat2_loss: 0.2837 - lin_acc: 0.7090 - cat1_categorical_accuracy: 0.8740 - cat2_categorical_accuracy: 0.8656\n",
      "Epoch 261/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5571 - lin_loss: 0.0121 - cat1_loss: 0.2590 - cat2_loss: 0.2859 - lin_acc: 0.7102 - cat1_categorical_accuracy: 0.8750 - cat2_categorical_accuracy: 0.8642\n",
      "Epoch 262/1001\n",
      "8745/8745 [==============================] - 2s 262us/step - loss: 0.5594 - lin_loss: 0.0122 - cat1_loss: 0.2635 - cat2_loss: 0.2838 - lin_acc: 0.7142 - cat1_categorical_accuracy: 0.8751 - cat2_categorical_accuracy: 0.8679\n",
      "Epoch 263/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5580 - lin_loss: 0.0121 - cat1_loss: 0.2596 - cat2_loss: 0.2863 - lin_acc: 0.7098 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8636\n",
      "Epoch 264/1001\n",
      "8745/8745 [==============================] - 2s 266us/step - loss: 0.5545 - lin_loss: 0.0121 - cat1_loss: 0.2587 - cat2_loss: 0.2837 - lin_acc: 0.7115 - cat1_categorical_accuracy: 0.8741 - cat2_categorical_accuracy: 0.8619\n",
      "Epoch 265/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5535 - lin_loss: 0.0121 - cat1_loss: 0.2571 - cat2_loss: 0.2843 - lin_acc: 0.7116 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8670\n",
      "Epoch 266/1001\n",
      "8745/8745 [==============================] - 3s 294us/step - loss: 0.5576 - lin_loss: 0.0121 - cat1_loss: 0.2593 - cat2_loss: 0.2861 - lin_acc: 0.7119 - cat1_categorical_accuracy: 0.8751 - cat2_categorical_accuracy: 0.8670\n",
      "Epoch 267/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5560 - lin_loss: 0.0121 - cat1_loss: 0.2597 - cat2_loss: 0.2842 - lin_acc: 0.7091 - cat1_categorical_accuracy: 0.8739 - cat2_categorical_accuracy: 0.8648\n",
      "Epoch 268/1001\n",
      "8745/8745 [==============================] - 2s 263us/step - loss: 0.5527 - lin_loss: 0.0121 - cat1_loss: 0.2602 - cat2_loss: 0.2804 - lin_acc: 0.7075 - cat1_categorical_accuracy: 0.8747 - cat2_categorical_accuracy: 0.8668\n",
      "Epoch 269/1001\n",
      "8745/8745 [==============================] - 3s 296us/step - loss: 0.5522 - lin_loss: 0.0121 - cat1_loss: 0.2605 - cat2_loss: 0.2796 - lin_acc: 0.7115 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8654\n",
      "Epoch 270/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5614 - lin_loss: 0.0121 - cat1_loss: 0.2623 - cat2_loss: 0.2870 - lin_acc: 0.7121 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.86291s - loss: 0.5468 - lin_loss: 0.0121 - cat1_loss: 0.2527 - cat2_loss: 0.2819 - lin_acc: 0.7188 - cat1_cate\n",
      "Epoch 271/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5501 - lin_loss: 0.0121 - cat1_loss: 0.2564 - cat2_loss: 0.2815 - lin_acc: 0.7113 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.86631s - loss: 0.5507 - lin_loss: 0.0120 - cat1_loss: 0.2595 - cat2_loss: 0.2791 - lin_acc: 0.7179 - cat1_categorical_accuracy: 0.\n",
      "Epoch 272/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 0.5526 - lin_loss: 0.0121 - cat1_loss: 0.2574 - cat2_loss: 0.2832 - lin_acc: 0.7108 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8662\n",
      "Epoch 273/1001\n",
      "8745/8745 [==============================] - 2s 286us/step - loss: 0.5505 - lin_loss: 0.0121 - cat1_loss: 0.2574 - cat2_loss: 0.2810 - lin_acc: 0.7145 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.8683\n",
      "Epoch 274/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.5506 - lin_loss: 0.0121 - cat1_loss: 0.2571 - cat2_loss: 0.2814 - lin_acc: 0.7095 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.86701s - loss: 0.5208 - lin_loss: 0.0119 - cat1_loss: 0.2380 - cat2_loss: 0.2709 - lin_acc: 0.6855 - cat1_categorical_ac - ETA: 0s - loss: 0.5459 - lin_loss: 0.0121 - cat1_loss: 0.2535 - cat2_loss: 0.2804 - lin_acc: 0.7090 - cat1_categorical_accuracy: 0.8791 - cat2_cate\n",
      "Epoch 275/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5490 - lin_loss: 0.0121 - cat1_loss: 0.2586 - cat2_loss: 0.2783 - lin_acc: 0.7074 - cat1_categorical_accuracy: 0.8758 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 276/1001\n",
      "8745/8745 [==============================] - 3s 294us/step - loss: 0.5526 - lin_loss: 0.0120 - cat1_loss: 0.2577 - cat2_loss: 0.2829 - lin_acc: 0.7090 - cat1_categorical_accuracy: 0.8738 - cat2_categorical_accuracy: 0.86461s - loss: 0.5582 - lin_loss: 0.0120 - cat1_loss: 0.2617 - cat2_loss: 0.2845 - lin_acc: 0.7126 - cat1_categorical_accuracy: \n",
      "Epoch 277/1001\n",
      "8745/8745 [==============================] - 2s 263us/step - loss: 0.5563 - lin_loss: 0.0121 - cat1_loss: 0.2615 - cat2_loss: 0.2827 - lin_acc: 0.7074 - cat1_categorical_accuracy: 0.8742 - cat2_categorical_accuracy: 0.8622\n",
      "Epoch 278/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5553 - lin_loss: 0.0120 - cat1_loss: 0.2614 - cat2_loss: 0.2819 - lin_acc: 0.7122 - cat1_categorical_accuracy: 0.8748 - cat2_categorical_accuracy: 0.8663\n",
      "Epoch 279/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5516 - lin_loss: 0.0120 - cat1_loss: 0.2567 - cat2_loss: 0.2829 - lin_acc: 0.7129 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8638\n",
      "Epoch 280/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5526 - lin_loss: 0.0121 - cat1_loss: 0.2607 - cat2_loss: 0.2799 - lin_acc: 0.7087 - cat1_categorical_accuracy: 0.8748 - cat2_categorical_accuracy: 0.8654\n",
      "Epoch 281/1001\n",
      "8745/8745 [==============================] - 2s 265us/step - loss: 0.5526 - lin_loss: 0.0121 - cat1_loss: 0.2568 - cat2_loss: 0.2836 - lin_acc: 0.7119 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8647\n",
      "Epoch 282/1001\n",
      "8745/8745 [==============================] - 3s 301us/step - loss: 0.5517 - lin_loss: 0.0120 - cat1_loss: 0.2587 - cat2_loss: 0.2810 - lin_acc: 0.7131 - cat1_categorical_accuracy: 0.8762 - cat2_categorical_accuracy: 0.8623\n",
      "Epoch 283/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.5528 - lin_loss: 0.0120 - cat1_loss: 0.2594 - cat2_loss: 0.2813 - lin_acc: 0.7109 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8644\n",
      "Epoch 284/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5470 - lin_loss: 0.0121 - cat1_loss: 0.2565 - cat2_loss: 0.2785 - lin_acc: 0.7149 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8679\n",
      "Epoch 285/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5495 - lin_loss: 0.0121 - cat1_loss: 0.2572 - cat2_loss: 0.2802 - lin_acc: 0.7138 - cat1_categorical_accuracy: 0.8742 - cat2_categorical_accuracy: 0.86521s - loss: 0.5294 - lin_loss: 0.0120 - cat1_loss: 0.2483 - cat2_loss: 0.2691 - lin_acc: 0.7121 - cat1_categorical_accuracy: 0.8776 - c - ETA: 0s - loss: 0.5417 - lin_loss: 0.0119 - cat1_loss: 0.2553 - cat2_loss: 0.2745 - lin_acc: 0.7134 - cat1_categorical_accuracy: 0.8739 - cat2_ca\n",
      "Epoch 286/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.5504 - lin_loss: 0.0120 - cat1_loss: 0.2594 - cat2_loss: 0.2789 - lin_acc: 0.7128 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8645\n",
      "Epoch 287/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5511 - lin_loss: 0.0120 - cat1_loss: 0.2575 - cat2_loss: 0.2816 - lin_acc: 0.7148 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8658\n",
      "Epoch 288/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5556 - lin_loss: 0.0121 - cat1_loss: 0.2609 - cat2_loss: 0.2826 - lin_acc: 0.7106 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8615\n",
      "Epoch 289/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5556 - lin_loss: 0.0120 - cat1_loss: 0.2606 - cat2_loss: 0.2829 - lin_acc: 0.7115 - cat1_categorical_accuracy: 0.8743 - cat2_categorical_accuracy: 0.8644\n",
      "Epoch 290/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5508 - lin_loss: 0.0120 - cat1_loss: 0.2590 - cat2_loss: 0.2797 - lin_acc: 0.7092 - cat1_categorical_accuracy: 0.8726 - cat2_categorical_accuracy: 0.8683\n",
      "Epoch 291/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5512 - lin_loss: 0.0120 - cat1_loss: 0.2600 - cat2_loss: 0.2792 - lin_acc: 0.7147 - cat1_categorical_accuracy: 0.8723 - cat2_categorical_accuracy: 0.8683\n",
      "Epoch 292/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5532 - lin_loss: 0.0120 - cat1_loss: 0.2607 - cat2_loss: 0.2805 - lin_acc: 0.7111 - cat1_categorical_accuracy: 0.8733 - cat2_categorical_accuracy: 0.8646\n",
      "Epoch 293/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 0.5490 - lin_loss: 0.0120 - cat1_loss: 0.2593 - cat2_loss: 0.2776 - lin_acc: 0.7137 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.86771s - loss: 0.5440 - lin_loss: 0.0121 - cat1_loss: 0.2559 - cat2_loss: 0.2760 - lin_acc: 0.7123 - cat1_categorical_accuracy: 0.\n",
      "Epoch 294/1001\n",
      "8745/8745 [==============================] - 3s 294us/step - loss: 0.5526 - lin_loss: 0.0120 - cat1_loss: 0.2604 - cat2_loss: 0.2802 - lin_acc: 0.7137 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8686\n",
      "Epoch 295/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5544 - lin_loss: 0.0120 - cat1_loss: 0.2616 - cat2_loss: 0.2808 - lin_acc: 0.7142 - cat1_categorical_accuracy: 0.8754 - cat2_categorical_accuracy: 0.8652\n",
      "Epoch 296/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5489 - lin_loss: 0.0120 - cat1_loss: 0.2592 - cat2_loss: 0.2777 - lin_acc: 0.7133 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.8635\n",
      "Epoch 297/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5480 - lin_loss: 0.0120 - cat1_loss: 0.2578 - cat2_loss: 0.2783 - lin_acc: 0.7124 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8636\n",
      "Epoch 298/1001\n",
      "8745/8745 [==============================] - 3s 294us/step - loss: 0.5457 - lin_loss: 0.0120 - cat1_loss: 0.2570 - cat2_loss: 0.2767 - lin_acc: 0.7153 - cat1_categorical_accuracy: 0.8747 - cat2_categorical_accuracy: 0.8722\n",
      "Epoch 299/1001\n",
      "8745/8745 [==============================] - 3s 302us/step - loss: 0.5497 - lin_loss: 0.0120 - cat1_loss: 0.2564 - cat2_loss: 0.2813 - lin_acc: 0.7118 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 300/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 3s 299us/step - loss: 0.5409 - lin_loss: 0.0120 - cat1_loss: 0.2548 - cat2_loss: 0.2741 - lin_acc: 0.7142 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.86740s - loss: 0.5384 - lin_loss: 0.0121 - cat1_loss: 0.2520 - cat2_loss: 0.2743 - lin_acc: 0.7135 - cat1_categorical_accuracy: 0.8801 - cat2_categori\n",
      "Epoch 301/1001\n",
      "8745/8745 [==============================] - 3s 290us/step - loss: 0.5456 - lin_loss: 0.0119 - cat1_loss: 0.2576 - cat2_loss: 0.2761 - lin_acc: 0.7140 - cat1_categorical_accuracy: 0.8730 - cat2_categorical_accuracy: 0.8700\n",
      "Epoch 302/1001\n",
      "8745/8745 [==============================] - 2s 263us/step - loss: 0.5469 - lin_loss: 0.0121 - cat1_loss: 0.2570 - cat2_loss: 0.2778 - lin_acc: 0.7118 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8698\n",
      "Epoch 303/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5472 - lin_loss: 0.0120 - cat1_loss: 0.2523 - cat2_loss: 0.2829 - lin_acc: 0.7110 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.86290s - loss: 0.5366 - lin_loss: 0.0121 - cat1_loss: 0.2451 - cat2_loss: 0.2794 - lin_acc: 0.7105 - cat1_categorical_accuracy: 0.8795 - cat2_\n",
      "Epoch 304/1001\n",
      "8745/8745 [==============================] - 2s 260us/step - loss: 0.5499 - lin_loss: 0.0119 - cat1_loss: 0.2586 - cat2_loss: 0.2794 - lin_acc: 0.7169 - cat1_categorical_accuracy: 0.8731 - cat2_categorical_accuracy: 0.8664\n",
      "Epoch 305/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5504 - lin_loss: 0.0120 - cat1_loss: 0.2608 - cat2_loss: 0.2776 - lin_acc: 0.7156 - cat1_categorical_accuracy: 0.8717 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 306/1001\n",
      "8745/8745 [==============================] - 3s 316us/step - loss: 0.5471 - lin_loss: 0.0119 - cat1_loss: 0.2586 - cat2_loss: 0.2765 - lin_acc: 0.7170 - cat1_categorical_accuracy: 0.8754 - cat2_categorical_accuracy: 0.8702\n",
      "Epoch 307/1001\n",
      "8745/8745 [==============================] - 2s 259us/step - loss: 0.5490 - lin_loss: 0.0120 - cat1_loss: 0.2570 - cat2_loss: 0.2800 - lin_acc: 0.7099 - cat1_categorical_accuracy: 0.8756 - cat2_categorical_accuracy: 0.8638\n",
      "Epoch 308/1001\n",
      "8745/8745 [==============================] - 2s 263us/step - loss: 0.5473 - lin_loss: 0.0119 - cat1_loss: 0.2579 - cat2_loss: 0.2774 - lin_acc: 0.7163 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8654\n",
      "Epoch 309/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5485 - lin_loss: 0.0120 - cat1_loss: 0.2570 - cat2_loss: 0.2796 - lin_acc: 0.7154 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.8653\n",
      "Epoch 310/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5472 - lin_loss: 0.0119 - cat1_loss: 0.2578 - cat2_loss: 0.2775 - lin_acc: 0.7190 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 311/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5491 - lin_loss: 0.0120 - cat1_loss: 0.2554 - cat2_loss: 0.2817 - lin_acc: 0.7147 - cat1_categorical_accuracy: 0.8758 - cat2_categorical_accuracy: 0.8628\n",
      "Epoch 312/1001\n",
      "8745/8745 [==============================] - 2s 264us/step - loss: 0.5490 - lin_loss: 0.0119 - cat1_loss: 0.2588 - cat2_loss: 0.2782 - lin_acc: 0.7138 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.8658\n",
      "Epoch 313/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5409 - lin_loss: 0.0120 - cat1_loss: 0.2535 - cat2_loss: 0.2754 - lin_acc: 0.7110 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.86472s - loss: 0.5365 - lin_loss: 0.0122 - cat1_loss: 0.2451 - cat2_loss: 0.2792 - lin_acc: 0.6995 - cat1_categorical_accuracy - ETA: 0s - loss: 0.5392 - lin_loss: 0.0120 - cat1_loss: 0.2515 - cat2_loss: 0.2757 - lin_acc: 0.7090 - cat1_categorical_accuracy: 0.8789 - c\n",
      "Epoch 314/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5425 - lin_loss: 0.0119 - cat1_loss: 0.2544 - cat2_loss: 0.2762 - lin_acc: 0.7133 - cat1_categorical_accuracy: 0.8762 - cat2_categorical_accuracy: 0.8703\n",
      "Epoch 315/1001\n",
      "8745/8745 [==============================] - 2s 265us/step - loss: 0.5431 - lin_loss: 0.0119 - cat1_loss: 0.2535 - cat2_loss: 0.2777 - lin_acc: 0.7147 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8670\n",
      "Epoch 316/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5467 - lin_loss: 0.0119 - cat1_loss: 0.2559 - cat2_loss: 0.2788 - lin_acc: 0.7155 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8671\n",
      "Epoch 317/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5453 - lin_loss: 0.0119 - cat1_loss: 0.2563 - cat2_loss: 0.2770 - lin_acc: 0.7098 - cat1_categorical_accuracy: 0.8731 - cat2_categorical_accuracy: 0.8635\n",
      "Epoch 318/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5461 - lin_loss: 0.0120 - cat1_loss: 0.2578 - cat2_loss: 0.2764 - lin_acc: 0.7090 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8660\n",
      "Epoch 319/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 0.5500 - lin_loss: 0.0119 - cat1_loss: 0.2556 - cat2_loss: 0.2825 - lin_acc: 0.7162 - cat1_categorical_accuracy: 0.8744 - cat2_categorical_accuracy: 0.8648\n",
      "Epoch 320/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5480 - lin_loss: 0.0119 - cat1_loss: 0.2559 - cat2_loss: 0.2802 - lin_acc: 0.7134 - cat1_categorical_accuracy: 0.8749 - cat2_categorical_accuracy: 0.8653\n",
      "Epoch 321/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5428 - lin_loss: 0.0119 - cat1_loss: 0.2563 - cat2_loss: 0.2746 - lin_acc: 0.7149 - cat1_categorical_accuracy: 0.8783 - cat2_categorical_accuracy: 0.8664\n",
      "Epoch 322/1001\n",
      "8745/8745 [==============================] - 2s 262us/step - loss: 0.5501 - lin_loss: 0.0119 - cat1_loss: 0.2576 - cat2_loss: 0.2805 - lin_acc: 0.7148 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8645\n",
      "Epoch 323/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5407 - lin_loss: 0.0119 - cat1_loss: 0.2536 - cat2_loss: 0.2752 - lin_acc: 0.7181 - cat1_categorical_accuracy: 0.8797 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 324/1001\n",
      "8745/8745 [==============================] - ETA: 0s - loss: 0.5493 - lin_loss: 0.0119 - cat1_loss: 0.2576 - cat2_loss: 0.2799 - lin_acc: 0.7139 - cat1_categorical_accuracy: 0.8756 - cat2_categorical_accuracy: 0.86 - 2s 283us/step - loss: 0.5499 - lin_loss: 0.0119 - cat1_loss: 0.2583 - cat2_loss: 0.2797 - lin_acc: 0.7142 - cat1_categorical_accuracy: 0.8749 - cat2_categorical_accuracy: 0.8656\n",
      "Epoch 325/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5467 - lin_loss: 0.0119 - cat1_loss: 0.2542 - cat2_loss: 0.2805 - lin_acc: 0.7138 - cat1_categorical_accuracy: 0.8794 - cat2_categorical_accuracy: 0.8637\n",
      "Epoch 326/1001\n",
      "8745/8745 [==============================] - 3s 294us/step - loss: 0.5406 - lin_loss: 0.0119 - cat1_loss: 0.2522 - cat2_loss: 0.2765 - lin_acc: 0.7166 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 327/1001\n",
      "8745/8745 [==============================] - 3s 296us/step - loss: 0.5407 - lin_loss: 0.0119 - cat1_loss: 0.2544 - cat2_loss: 0.2744 - lin_acc: 0.7158 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.86911s - loss: 0.5425 - lin_loss: 0.0117 - cat1_loss: 0.2558 - cat2_loss: 0.2750 - lin_acc: 0.7188 - cat1_categori\n",
      "Epoch 328/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5468 - lin_loss: 0.0119 - cat1_loss: 0.2574 - cat2_loss: 0.2776 - lin_acc: 0.7156 - cat1_categorical_accuracy: 0.8747 - cat2_categorical_accuracy: 0.8667\n",
      "Epoch 329/1001\n",
      "8745/8745 [==============================] - 3s 302us/step - loss: 0.5434 - lin_loss: 0.0118 - cat1_loss: 0.2573 - cat2_loss: 0.2743 - lin_acc: 0.7163 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 330/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5452 - lin_loss: 0.0119 - cat1_loss: 0.2583 - cat2_loss: 0.2750 - lin_acc: 0.7160 - cat1_categorical_accuracy: 0.8751 - cat2_categorical_accuracy: 0.8672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 0.5486 - lin_loss: 0.0119 - cat1_loss: 0.2555 - cat2_loss: 0.2813 - lin_acc: 0.7100 - cat1_categorical_accuracy: 0.8783 - cat2_categorical_accuracy: 0.86521s - loss: 0.5436 - lin_loss: 0.0120 - cat1_loss: 0.2494 - cat2_loss: 0.2822 - lin_acc: 0.7102 - cat1_categorical_ac\n",
      "Epoch 332/1001\n",
      "8745/8745 [==============================] - 2s 261us/step - loss: 0.5381 - lin_loss: 0.0119 - cat1_loss: 0.2545 - cat2_loss: 0.2717 - lin_acc: 0.7174 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8671\n",
      "Epoch 333/1001\n",
      "8745/8745 [==============================] - 2s 284us/step - loss: 0.5451 - lin_loss: 0.0119 - cat1_loss: 0.2563 - cat2_loss: 0.2769 - lin_acc: 0.7172 - cat1_categorical_accuracy: 0.8738 - cat2_categorical_accuracy: 0.8628\n",
      "Epoch 334/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5379 - lin_loss: 0.0119 - cat1_loss: 0.2528 - cat2_loss: 0.2733 - lin_acc: 0.7178 - cat1_categorical_accuracy: 0.8796 - cat2_categorical_accuracy: 0.8690\n",
      "Epoch 335/1001\n",
      "8745/8745 [==============================] - 2s 263us/step - loss: 0.5410 - lin_loss: 0.0119 - cat1_loss: 0.2561 - cat2_loss: 0.2730 - lin_acc: 0.7163 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.8710\n",
      "Epoch 336/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5427 - lin_loss: 0.0119 - cat1_loss: 0.2573 - cat2_loss: 0.2736 - lin_acc: 0.7155 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.8677\n",
      "Epoch 337/1001\n",
      "8745/8745 [==============================] - 2s 266us/step - loss: 0.5421 - lin_loss: 0.0118 - cat1_loss: 0.2564 - cat2_loss: 0.2739 - lin_acc: 0.7145 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8654\n",
      "Epoch 338/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5421 - lin_loss: 0.0118 - cat1_loss: 0.2530 - cat2_loss: 0.2773 - lin_acc: 0.7141 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8656\n",
      "Epoch 339/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5454 - lin_loss: 0.0118 - cat1_loss: 0.2570 - cat2_loss: 0.2766 - lin_acc: 0.7130 - cat1_categorical_accuracy: 0.8730 - cat2_categorical_accuracy: 0.8636\n",
      "Epoch 340/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5447 - lin_loss: 0.0119 - cat1_loss: 0.2581 - cat2_loss: 0.2748 - lin_acc: 0.7134 - cat1_categorical_accuracy: 0.8765 - cat2_categorical_accuracy: 0.8676\n",
      "Epoch 341/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5456 - lin_loss: 0.0118 - cat1_loss: 0.2552 - cat2_loss: 0.2786 - lin_acc: 0.7133 - cat1_categorical_accuracy: 0.8750 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 342/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5434 - lin_loss: 0.0118 - cat1_loss: 0.2572 - cat2_loss: 0.2743 - lin_acc: 0.7166 - cat1_categorical_accuracy: 0.8731 - cat2_categorical_accuracy: 0.8686\n",
      "Epoch 343/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5439 - lin_loss: 0.0118 - cat1_loss: 0.2524 - cat2_loss: 0.2796 - lin_acc: 0.7154 - cat1_categorical_accuracy: 0.8791 - cat2_categorical_accuracy: 0.8660\n",
      "Epoch 344/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 0.5398 - lin_loss: 0.0118 - cat1_loss: 0.2553 - cat2_loss: 0.2727 - lin_acc: 0.7134 - cat1_categorical_accuracy: 0.8742 - cat2_categorical_accuracy: 0.8688\n",
      "Epoch 345/1001\n",
      "8745/8745 [==============================] - 2s 262us/step - loss: 0.5427 - lin_loss: 0.0118 - cat1_loss: 0.2569 - cat2_loss: 0.2740 - lin_acc: 0.7180 - cat1_categorical_accuracy: 0.8756 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 346/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.5383 - lin_loss: 0.0118 - cat1_loss: 0.2539 - cat2_loss: 0.2727 - lin_acc: 0.7190 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.8674\n",
      "Epoch 347/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5421 - lin_loss: 0.0118 - cat1_loss: 0.2540 - cat2_loss: 0.2763 - lin_acc: 0.7160 - cat1_categorical_accuracy: 0.8752 - cat2_categorical_accuracy: 0.8667\n",
      "Epoch 348/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5440 - lin_loss: 0.0118 - cat1_loss: 0.2581 - cat2_loss: 0.2740 - lin_acc: 0.7154 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.8644\n",
      "Epoch 349/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5438 - lin_loss: 0.0118 - cat1_loss: 0.2562 - cat2_loss: 0.2759 - lin_acc: 0.7202 - cat1_categorical_accuracy: 0.8748 - cat2_categorical_accuracy: 0.8675\n",
      "Epoch 350/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5383 - lin_loss: 0.0118 - cat1_loss: 0.2547 - cat2_loss: 0.2719 - lin_acc: 0.7154 - cat1_categorical_accuracy: 0.8760 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 351/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5417 - lin_loss: 0.0118 - cat1_loss: 0.2542 - cat2_loss: 0.2757 - lin_acc: 0.7147 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 352/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5401 - lin_loss: 0.0118 - cat1_loss: 0.2542 - cat2_loss: 0.2741 - lin_acc: 0.7166 - cat1_categorical_accuracy: 0.8754 - cat2_categorical_accuracy: 0.8661\n",
      "Epoch 353/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5415 - lin_loss: 0.0117 - cat1_loss: 0.2544 - cat2_loss: 0.2754 - lin_acc: 0.7176 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8646\n",
      "Epoch 354/1001\n",
      "8745/8745 [==============================] - 3s 301us/step - loss: 0.5384 - lin_loss: 0.0118 - cat1_loss: 0.2528 - cat2_loss: 0.2738 - lin_acc: 0.7173 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8676\n",
      "Epoch 355/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5405 - lin_loss: 0.0117 - cat1_loss: 0.2550 - cat2_loss: 0.2737 - lin_acc: 0.7156 - cat1_categorical_accuracy: 0.8734 - cat2_categorical_accuracy: 0.8666\n",
      "Epoch 356/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 0.5392 - lin_loss: 0.0118 - cat1_loss: 0.2538 - cat2_loss: 0.2737 - lin_acc: 0.7148 - cat1_categorical_accuracy: 0.8756 - cat2_categorical_accuracy: 0.86511s - loss: 0.5235 - lin_loss: 0.0117 - cat1_loss: 0.2468 - cat2_loss: 0.2650 - lin_acc: 0.7101 - cat1_categorical_\n",
      "Epoch 357/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5412 - lin_loss: 0.0118 - cat1_loss: 0.2546 - cat2_loss: 0.2748 - lin_acc: 0.7139 - cat1_categorical_accuracy: 0.8760 - cat2_categorical_accuracy: 0.8675\n",
      "Epoch 358/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5384 - lin_loss: 0.0118 - cat1_loss: 0.2541 - cat2_loss: 0.2725 - lin_acc: 0.7124 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.8695\n",
      "Epoch 359/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5365 - lin_loss: 0.0117 - cat1_loss: 0.2523 - cat2_loss: 0.2725 - lin_acc: 0.7202 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.87001s - loss: 0.5388 - lin_loss: 0.0118 - cat1_loss: 0.2586 - cat2_loss: 0.2684 - lin_acc: 0.7171 - cat1_categorical_accuracy: 0.87\n",
      "Epoch 360/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5424 - lin_loss: 0.0118 - cat1_loss: 0.2558 - cat2_loss: 0.2748 - lin_acc: 0.7153 - cat1_categorical_accuracy: 0.8749 - cat2_categorical_accuracy: 0.86781s - loss: 0.5355 - lin_loss: 0.0119 - cat1_loss: 0.2575 - cat2_loss: 0.2661 - lin_acc: 0.7145 - cat1_categorica\n",
      "Epoch 361/1001\n",
      "8745/8745 [==============================] - 2s 263us/step - loss: 0.5409 - lin_loss: 0.0118 - cat1_loss: 0.2546 - cat2_loss: 0.2745 - lin_acc: 0.7176 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.86741s - loss: 0.5370 - lin_loss: 0.0119 - cat1_loss: 0.2555 - cat2_loss: 0.2696 - lin_acc: 0.7140 - cat1_categorical_accuracy: 0.8772 - c\n",
      "Epoch 362/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 254us/step - loss: 0.5408 - lin_loss: 0.0118 - cat1_loss: 0.2548 - cat2_loss: 0.2743 - lin_acc: 0.7158 - cat1_categorical_accuracy: 0.8749 - cat2_categorical_accuracy: 0.8660\n",
      "Epoch 363/1001\n",
      "8745/8745 [==============================] - 2s 263us/step - loss: 0.5399 - lin_loss: 0.0117 - cat1_loss: 0.2553 - cat2_loss: 0.2729 - lin_acc: 0.7142 - cat1_categorical_accuracy: 0.8760 - cat2_categorical_accuracy: 0.8666\n",
      "Epoch 364/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5421 - lin_loss: 0.0117 - cat1_loss: 0.2571 - cat2_loss: 0.2732 - lin_acc: 0.7140 - cat1_categorical_accuracy: 0.8760 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 365/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5346 - lin_loss: 0.0118 - cat1_loss: 0.2517 - cat2_loss: 0.2711 - lin_acc: 0.7189 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8722\n",
      "Epoch 366/1001\n",
      "8745/8745 [==============================] - 2s 266us/step - loss: 0.5466 - lin_loss: 0.0117 - cat1_loss: 0.2580 - cat2_loss: 0.2768 - lin_acc: 0.7145 - cat1_categorical_accuracy: 0.8751 - cat2_categorical_accuracy: 0.8663\n",
      "Epoch 367/1001\n",
      "8745/8745 [==============================] - 2s 265us/step - loss: 0.5366 - lin_loss: 0.0117 - cat1_loss: 0.2524 - cat2_loss: 0.2724 - lin_acc: 0.7185 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8668\n",
      "Epoch 368/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 0.5400 - lin_loss: 0.0117 - cat1_loss: 0.2519 - cat2_loss: 0.2764 - lin_acc: 0.7158 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8679\n",
      "Epoch 369/1001\n",
      "8745/8745 [==============================] - 2s 263us/step - loss: 0.5390 - lin_loss: 0.0118 - cat1_loss: 0.2543 - cat2_loss: 0.2728 - lin_acc: 0.7168 - cat1_categorical_accuracy: 0.8744 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 370/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5374 - lin_loss: 0.0117 - cat1_loss: 0.2538 - cat2_loss: 0.2718 - lin_acc: 0.7190 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8677\n",
      "Epoch 371/1001\n",
      "8745/8745 [==============================] - 3s 306us/step - loss: 0.5376 - lin_loss: 0.0117 - cat1_loss: 0.2515 - cat2_loss: 0.2744 - lin_acc: 0.7202 - cat1_categorical_accuracy: 0.8805 - cat2_categorical_accuracy: 0.8659\n",
      "Epoch 372/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5419 - lin_loss: 0.0117 - cat1_loss: 0.2556 - cat2_loss: 0.2747 - lin_acc: 0.7180 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8644\n",
      "Epoch 373/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5404 - lin_loss: 0.0118 - cat1_loss: 0.2536 - cat2_loss: 0.2750 - lin_acc: 0.7168 - cat1_categorical_accuracy: 0.8738 - cat2_categorical_accuracy: 0.86610s - loss: 0.5399 - lin_loss: 0.0118 - cat1_loss: 0.2521 - cat2_loss: 0.2761 - lin_acc: 0.7166 - cat1_categorical_accuracy: 0.8750 - cat2_categorical_accuracy: 0.\n",
      "Epoch 374/1001\n",
      "8745/8745 [==============================] - 3s 291us/step - loss: 0.5389 - lin_loss: 0.0117 - cat1_loss: 0.2536 - cat2_loss: 0.2736 - lin_acc: 0.7185 - cat1_categorical_accuracy: 0.8747 - cat2_categorical_accuracy: 0.86380s - loss: 0.5384 - lin_loss: 0.0116 - cat1_loss: 0.2538 - cat2_loss: 0.2729 - lin_acc: 0.7182 - cat1_categorical_accuracy: 0.8745 - cat2_categorical_accuracy: 0.\n",
      "Epoch 375/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5422 - lin_loss: 0.0117 - cat1_loss: 0.2537 - cat2_loss: 0.2768 - lin_acc: 0.7194 - cat1_categorical_accuracy: 0.8748 - cat2_categorical_accuracy: 0.86691s - loss: 0.5319 - lin_loss: 0.0117 - cat1_loss: 0.2474 - cat2_loss: 0.2728 - lin_acc: 0.7234 - cat1_ca\n",
      "Epoch 376/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5341 - lin_loss: 0.0117 - cat1_loss: 0.2509 - cat2_loss: 0.2715 - lin_acc: 0.7184 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 377/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5416 - lin_loss: 0.0117 - cat1_loss: 0.2552 - cat2_loss: 0.2747 - lin_acc: 0.7163 - cat1_categorical_accuracy: 0.8754 - cat2_categorical_accuracy: 0.8652\n",
      "Epoch 378/1001\n",
      "8745/8745 [==============================] - 2s 264us/step - loss: 0.5332 - lin_loss: 0.0117 - cat1_loss: 0.2530 - cat2_loss: 0.2685 - lin_acc: 0.7173 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 379/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5354 - lin_loss: 0.0117 - cat1_loss: 0.2534 - cat2_loss: 0.2704 - lin_acc: 0.7162 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 380/1001\n",
      "8745/8745 [==============================] - 3s 290us/step - loss: 0.5396 - lin_loss: 0.0117 - cat1_loss: 0.2538 - cat2_loss: 0.2740 - lin_acc: 0.7178 - cat1_categorical_accuracy: 0.8744 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 381/1001\n",
      "8745/8745 [==============================] - 3s 307us/step - loss: 0.5357 - lin_loss: 0.0117 - cat1_loss: 0.2514 - cat2_loss: 0.2726 - lin_acc: 0.7176 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.86902s - loss: 0.5244 - lin_loss: 0.0117 - cat1_loss: 0.2524 - cat2_loss: 0.2603 - lin_acc\n",
      "Epoch 382/1001\n",
      "8745/8745 [==============================] - 2s 284us/step - loss: 0.5356 - lin_loss: 0.0116 - cat1_loss: 0.2520 - cat2_loss: 0.2719 - lin_acc: 0.7217 - cat1_categorical_accuracy: 0.8760 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 383/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5367 - lin_loss: 0.0117 - cat1_loss: 0.2525 - cat2_loss: 0.2725 - lin_acc: 0.7203 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8661\n",
      "Epoch 384/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5351 - lin_loss: 0.0117 - cat1_loss: 0.2521 - cat2_loss: 0.2713 - lin_acc: 0.7198 - cat1_categorical_accuracy: 0.8794 - cat2_categorical_accuracy: 0.86711s - loss: 0.5324 - lin_loss: 0.0115 - cat1_loss: 0.2456 - cat2_loss: 0.2754 - lin_acc: 0.\n",
      "Epoch 385/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5343 - lin_loss: 0.0118 - cat1_loss: 0.2537 - cat2_loss: 0.2688 - lin_acc: 0.7187 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 386/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5358 - lin_loss: 0.0116 - cat1_loss: 0.2532 - cat2_loss: 0.2709 - lin_acc: 0.7181 - cat1_categorical_accuracy: 0.8750 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 387/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.5362 - lin_loss: 0.0117 - cat1_loss: 0.2535 - cat2_loss: 0.2710 - lin_acc: 0.7184 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8652\n",
      "Epoch 388/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5384 - lin_loss: 0.0117 - cat1_loss: 0.2530 - cat2_loss: 0.2737 - lin_acc: 0.7197 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.86692s - loss: 0.5356 - lin_loss: 0.0119 - cat1_loss: 0.2520 - cat2_loss: 0.2717 - lin_acc: 0.7220 -\n",
      "Epoch 389/1001\n",
      "8745/8745 [==============================] - 3s 299us/step - loss: 0.5313 - lin_loss: 0.0117 - cat1_loss: 0.2518 - cat2_loss: 0.2678 - lin_acc: 0.7189 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.86712s - loss: 0.5315 - lin_loss: 0.0112 - cat1_loss: 0.2472 - cat2_loss: 0.2732 - lin_acc: 0.7194 -\n",
      "Epoch 390/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5383 - lin_loss: 0.0116 - cat1_loss: 0.2514 - cat2_loss: 0.2754 - lin_acc: 0.7245 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8688\n",
      "Epoch 391/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5346 - lin_loss: 0.0116 - cat1_loss: 0.2525 - cat2_loss: 0.2705 - lin_acc: 0.7189 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.8675\n",
      "Epoch 392/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5425 - lin_loss: 0.0117 - cat1_loss: 0.2569 - cat2_loss: 0.2739 - lin_acc: 0.7182 - cat1_categorical_accuracy: 0.8739 - cat2_categorical_accuracy: 0.8640\n",
      "Epoch 393/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 3s 300us/step - loss: 0.5386 - lin_loss: 0.0116 - cat1_loss: 0.2551 - cat2_loss: 0.2719 - lin_acc: 0.7193 - cat1_categorical_accuracy: 0.8760 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 394/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5374 - lin_loss: 0.0116 - cat1_loss: 0.2531 - cat2_loss: 0.2726 - lin_acc: 0.7192 - cat1_categorical_accuracy: 0.8754 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 395/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5380 - lin_loss: 0.0116 - cat1_loss: 0.2538 - cat2_loss: 0.2726 - lin_acc: 0.7196 - cat1_categorical_accuracy: 0.8752 - cat2_categorical_accuracy: 0.8655\n",
      "Epoch 396/1001\n",
      "8745/8745 [==============================] - 2s 263us/step - loss: 0.5363 - lin_loss: 0.0116 - cat1_loss: 0.2539 - cat2_loss: 0.2708 - lin_acc: 0.7221 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 397/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5353 - lin_loss: 0.0116 - cat1_loss: 0.2518 - cat2_loss: 0.2719 - lin_acc: 0.7209 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.8677\n",
      "Epoch 398/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5343 - lin_loss: 0.0117 - cat1_loss: 0.2501 - cat2_loss: 0.2725 - lin_acc: 0.7180 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8674\n",
      "Epoch 399/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5367 - lin_loss: 0.0116 - cat1_loss: 0.2532 - cat2_loss: 0.2718 - lin_acc: 0.7217 - cat1_categorical_accuracy: 0.8751 - cat2_categorical_accuracy: 0.8702\n",
      "Epoch 400/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 0.5362 - lin_loss: 0.0117 - cat1_loss: 0.2530 - cat2_loss: 0.2715 - lin_acc: 0.7200 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8664\n",
      "Epoch 401/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5392 - lin_loss: 0.0116 - cat1_loss: 0.2549 - cat2_loss: 0.2726 - lin_acc: 0.7163 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8709\n",
      "Epoch 402/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5316 - lin_loss: 0.0116 - cat1_loss: 0.2497 - cat2_loss: 0.2703 - lin_acc: 0.7203 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.8670\n",
      "Epoch 403/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5332 - lin_loss: 0.0116 - cat1_loss: 0.2518 - cat2_loss: 0.2698 - lin_acc: 0.7213 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 404/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.5334 - lin_loss: 0.0116 - cat1_loss: 0.2540 - cat2_loss: 0.2678 - lin_acc: 0.7201 - cat1_categorical_accuracy: 0.8744 - cat2_categorical_accuracy: 0.8680\n",
      "Epoch 405/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5324 - lin_loss: 0.0116 - cat1_loss: 0.2500 - cat2_loss: 0.2708 - lin_acc: 0.7195 - cat1_categorical_accuracy: 0.8758 - cat2_categorical_accuracy: 0.8672\n",
      "Epoch 406/1001\n",
      "8745/8745 [==============================] - 3s 290us/step - loss: 0.5366 - lin_loss: 0.0116 - cat1_loss: 0.2524 - cat2_loss: 0.2726 - lin_acc: 0.7200 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.86500s - loss: 0.5361 - lin_loss: 0.0117 - cat1_loss: 0.2555 - cat2_loss: 0.2689 - lin_acc: 0.7217 - cat1_categorical_accuracy: 0.8749 - cat2_categorical_accura\n",
      "Epoch 407/1001\n",
      "8745/8745 [==============================] - 3s 309us/step - loss: 0.5372 - lin_loss: 0.0116 - cat1_loss: 0.2539 - cat2_loss: 0.2718 - lin_acc: 0.7218 - cat1_categorical_accuracy: 0.8756 - cat2_categorical_accuracy: 0.86721s - loss: 0.5240 - lin_loss: 0.0114 - cat1_loss: 0.2506 - cat2_loss: 0.2620 - lin_acc: 0.7161 - cat1_categorical_ac\n",
      "Epoch 408/1001\n",
      "8745/8745 [==============================] - 3s 300us/step - loss: 0.5378 - lin_loss: 0.0116 - cat1_loss: 0.2542 - cat2_loss: 0.2720 - lin_acc: 0.7195 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.8675\n",
      "Epoch 409/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5317 - lin_loss: 0.0115 - cat1_loss: 0.2497 - cat2_loss: 0.2704 - lin_acc: 0.7187 - cat1_categorical_accuracy: 0.8802 - cat2_categorical_accuracy: 0.8654\n",
      "Epoch 410/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 0.5350 - lin_loss: 0.0116 - cat1_loss: 0.2534 - cat2_loss: 0.2700 - lin_acc: 0.7197 - cat1_categorical_accuracy: 0.8751 - cat2_categorical_accuracy: 0.8659\n",
      "Epoch 411/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5334 - lin_loss: 0.0116 - cat1_loss: 0.2532 - cat2_loss: 0.2685 - lin_acc: 0.7211 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 412/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.5369 - lin_loss: 0.0115 - cat1_loss: 0.2536 - cat2_loss: 0.2717 - lin_acc: 0.7193 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.8667\n",
      "Epoch 413/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5308 - lin_loss: 0.0116 - cat1_loss: 0.2506 - cat2_loss: 0.2686 - lin_acc: 0.7208 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.86842s - loss: 0.5349 - lin_loss: 0.0112 - cat1_loss: 0.2418 - cat2_loss: 0.2819 - lin_acc: 0.7266 - cat\n",
      "Epoch 414/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5349 - lin_loss: 0.0116 - cat1_loss: 0.2517 - cat2_loss: 0.2716 - lin_acc: 0.7189 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.8640\n",
      "Epoch 415/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5313 - lin_loss: 0.0117 - cat1_loss: 0.2515 - cat2_loss: 0.2681 - lin_acc: 0.7178 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 416/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5366 - lin_loss: 0.0116 - cat1_loss: 0.2529 - cat2_loss: 0.2721 - lin_acc: 0.7225 - cat1_categorical_accuracy: 0.8803 - cat2_categorical_accuracy: 0.8659\n",
      "Epoch 417/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 0.5343 - lin_loss: 0.0116 - cat1_loss: 0.2514 - cat2_loss: 0.2713 - lin_acc: 0.7186 - cat1_categorical_accuracy: 0.8762 - cat2_categorical_accuracy: 0.8656\n",
      "Epoch 418/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5325 - lin_loss: 0.0115 - cat1_loss: 0.2513 - cat2_loss: 0.2697 - lin_acc: 0.7211 - cat1_categorical_accuracy: 0.8783 - cat2_categorical_accuracy: 0.8702\n",
      "Epoch 419/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5338 - lin_loss: 0.0116 - cat1_loss: 0.2528 - cat2_loss: 0.2695 - lin_acc: 0.7229 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8688\n",
      "Epoch 420/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5316 - lin_loss: 0.0116 - cat1_loss: 0.2500 - cat2_loss: 0.2701 - lin_acc: 0.7237 - cat1_categorical_accuracy: 0.8783 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 421/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5322 - lin_loss: 0.0115 - cat1_loss: 0.2533 - cat2_loss: 0.2674 - lin_acc: 0.7195 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.8667\n",
      "Epoch 422/1001\n",
      "8745/8745 [==============================] - 2s 284us/step - loss: 0.5335 - lin_loss: 0.0115 - cat1_loss: 0.2504 - cat2_loss: 0.2715 - lin_acc: 0.7200 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8654\n",
      "Epoch 423/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5261 - lin_loss: 0.0116 - cat1_loss: 0.2489 - cat2_loss: 0.2656 - lin_acc: 0.7204 - cat1_categorical_accuracy: 0.8804 - cat2_categorical_accuracy: 0.8683\n",
      "Epoch 424/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5348 - lin_loss: 0.0115 - cat1_loss: 0.2547 - cat2_loss: 0.2687 - lin_acc: 0.7216 - cat1_categorical_accuracy: 0.8744 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 425/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5357 - lin_loss: 0.0116 - cat1_loss: 0.2553 - cat2_loss: 0.2689 - lin_acc: 0.7234 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 426/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5329 - lin_loss: 0.0115 - cat1_loss: 0.2524 - cat2_loss: 0.2691 - lin_acc: 0.7205 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8655\n",
      "Epoch 427/1001\n",
      "8745/8745 [==============================] - 2s 286us/step - loss: 0.5320 - lin_loss: 0.0115 - cat1_loss: 0.2522 - cat2_loss: 0.2682 - lin_acc: 0.7197 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8659\n",
      "Epoch 428/1001\n",
      "8745/8745 [==============================] - 3s 302us/step - loss: 0.5325 - lin_loss: 0.0115 - cat1_loss: 0.2497 - cat2_loss: 0.2713 - lin_acc: 0.7189 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8635\n",
      "Epoch 429/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5371 - lin_loss: 0.0115 - cat1_loss: 0.2540 - cat2_loss: 0.2716 - lin_acc: 0.7246 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8667\n",
      "Epoch 430/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5313 - lin_loss: 0.0115 - cat1_loss: 0.2502 - cat2_loss: 0.2696 - lin_acc: 0.7221 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8688\n",
      "Epoch 431/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5326 - lin_loss: 0.0115 - cat1_loss: 0.2517 - cat2_loss: 0.2694 - lin_acc: 0.7212 - cat1_categorical_accuracy: 0.8805 - cat2_categorical_accuracy: 0.8698\n",
      "Epoch 432/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5333 - lin_loss: 0.0115 - cat1_loss: 0.2506 - cat2_loss: 0.2712 - lin_acc: 0.7232 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 433/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5299 - lin_loss: 0.0115 - cat1_loss: 0.2512 - cat2_loss: 0.2671 - lin_acc: 0.7212 - cat1_categorical_accuracy: 0.8749 - cat2_categorical_accuracy: 0.86560s - loss: 0.5318 - lin_loss: 0.0115 - cat1_loss: 0.2526 - cat2_loss: 0.2677 - lin_acc: 0.7186 - cat1_categorical_accuracy: 0.8745 - cat2_categorical_accura\n",
      "Epoch 434/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 0.5307 - lin_loss: 0.0115 - cat1_loss: 0.2498 - cat2_loss: 0.2694 - lin_acc: 0.7192 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.86791s - loss: 0.5179 - lin_loss: 0.0115 - cat1_loss: 0.2437 - cat2_loss: 0.2628 - lin_acc: 0.7251 - cat1_categorical_accuracy: 0.8808\n",
      "Epoch 435/1001\n",
      "8745/8745 [==============================] - 3s 297us/step - loss: 0.5290 - lin_loss: 0.0115 - cat1_loss: 0.2496 - cat2_loss: 0.2680 - lin_acc: 0.7208 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8672\n",
      "Epoch 436/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5333 - lin_loss: 0.0115 - cat1_loss: 0.2494 - cat2_loss: 0.2724 - lin_acc: 0.7238 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.8655\n",
      "Epoch 437/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5306 - lin_loss: 0.0115 - cat1_loss: 0.2514 - cat2_loss: 0.2677 - lin_acc: 0.7184 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.86720s - loss: 0.5281 - lin_loss: 0.0114 - cat1_loss: 0.2559 - cat2_loss: 0.2608 - lin_acc: 0.7191 - cat1_categorical_accuracy: 0.8784 - cat\n",
      "Epoch 438/1001\n",
      "8745/8745 [==============================] - 2s 284us/step - loss: 0.5312 - lin_loss: 0.0115 - cat1_loss: 0.2527 - cat2_loss: 0.2670 - lin_acc: 0.7198 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8656\n",
      "Epoch 439/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5321 - lin_loss: 0.0115 - cat1_loss: 0.2519 - cat2_loss: 0.2687 - lin_acc: 0.7201 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 440/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5312 - lin_loss: 0.0115 - cat1_loss: 0.2506 - cat2_loss: 0.2691 - lin_acc: 0.7198 - cat1_categorical_accuracy: 0.8760 - cat2_categorical_accuracy: 0.86721s - loss: 0.5127 - lin_loss: 0.0115 - cat1_loss: 0.2426 - cat2_loss: 0.2585 - lin_acc: 0.7214 - cat1_categorical_accuracy: 0.\n",
      "Epoch 441/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5335 - lin_loss: 0.0115 - cat1_loss: 0.2514 - cat2_loss: 0.2706 - lin_acc: 0.7217 - cat1_categorical_accuracy: 0.8758 - cat2_categorical_accuracy: 0.8648\n",
      "Epoch 442/1001\n",
      "8745/8745 [==============================] - 3s 309us/step - loss: 0.5348 - lin_loss: 0.0114 - cat1_loss: 0.2517 - cat2_loss: 0.2716 - lin_acc: 0.7208 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8656\n",
      "Epoch 443/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5352 - lin_loss: 0.0115 - cat1_loss: 0.2533 - cat2_loss: 0.2704 - lin_acc: 0.7198 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8652\n",
      "Epoch 444/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5312 - lin_loss: 0.0115 - cat1_loss: 0.2535 - cat2_loss: 0.2662 - lin_acc: 0.7222 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 445/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5294 - lin_loss: 0.0115 - cat1_loss: 0.2499 - cat2_loss: 0.2680 - lin_acc: 0.7195 - cat1_categorical_accuracy: 0.8754 - cat2_categorical_accuracy: 0.87012s - loss: 0.5388 - lin_loss: 0.0112 - cat1_loss: 0.2420 - cat2_loss: 0.2856 - lin_acc\n",
      "Epoch 446/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5360 - lin_loss: 0.0114 - cat1_loss: 0.2519 - cat2_loss: 0.2726 - lin_acc: 0.7221 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.86901s - loss: 0.5370 - lin_loss: 0.0115 - cat1_loss: 0.2609 - cat2_loss: 0.2645 - lin_acc: 0.7198 - cat1_categorical_accuracy: 0.8726 - cat2_categorical_accuracy - ETA: 0s - loss: 0.5313 - lin_loss: 0.0115 - cat1_loss: 0.2554 - cat2_loss: 0.2643 - lin_acc: 0.7195 - cat1_categorical_accuracy: 0.8754 - c\n",
      "Epoch 447/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.5304 - lin_loss: 0.0115 - cat1_loss: 0.2505 - cat2_loss: 0.2684 - lin_acc: 0.7213 - cat1_categorical_accuracy: 0.8798 - cat2_categorical_accuracy: 0.8658\n",
      "Epoch 448/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 0.5323 - lin_loss: 0.0114 - cat1_loss: 0.2509 - cat2_loss: 0.2699 - lin_acc: 0.7224 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8667\n",
      "Epoch 449/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5299 - lin_loss: 0.0115 - cat1_loss: 0.2514 - cat2_loss: 0.2670 - lin_acc: 0.7265 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8693\n",
      "Epoch 450/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5331 - lin_loss: 0.0114 - cat1_loss: 0.2538 - cat2_loss: 0.2679 - lin_acc: 0.7240 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8675\n",
      "Epoch 451/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 0.5301 - lin_loss: 0.0115 - cat1_loss: 0.2518 - cat2_loss: 0.2668 - lin_acc: 0.7238 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8695\n",
      "Epoch 452/1001\n",
      "8745/8745 [==============================] - 3s 327us/step - loss: 0.5334 - lin_loss: 0.0115 - cat1_loss: 0.2508 - cat2_loss: 0.2712 - lin_acc: 0.7225 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.86562s - loss: 0.5509 - lin_loss: 0.0113 - cat1_loss: 0.2547 - cat2_loss: 0.2849 - lin_acc: 0.7445 - cat1_categorical_ac - ETA: 1s - loss: 0.5372 - lin_loss: 0.0115 - cat1_loss: 0.2522 - cat2_loss: 0.2735 - lin_acc: 0.7205 - cat1_categorical_accuracy: 0.8792 - cat2_categorical_accu - ETA: 0s - loss: 0.5349 - lin_loss: 0.0114 - cat1_loss: 0.2490 - cat2_loss: 0.2746 - lin_acc: 0.7246 - cat1_categorical_accuracy: 0.8810 - cat2_cate\n",
      "Epoch 453/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5286 - lin_loss: 0.0115 - cat1_loss: 0.2492 - cat2_loss: 0.2679 - lin_acc: 0.7221 - cat1_categorical_accuracy: 0.8790 - cat2_categorical_accuracy: 0.86551s - loss: 0.5165 - lin_loss: 0.0114 - cat1_loss: 0.2433 - cat2_loss: 0.2618 - lin_acc: 0.7286 - cat1_categorical_accuracy: \n",
      "Epoch 454/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5327 - lin_loss: 0.0114 - cat1_loss: 0.2505 - cat2_loss: 0.2708 - lin_acc: 0.7245 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 455/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5344 - lin_loss: 0.0114 - cat1_loss: 0.2537 - cat2_loss: 0.2692 - lin_acc: 0.7234 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 456/1001\n",
      "8745/8745 [==============================] - 2s 264us/step - loss: 0.5329 - lin_loss: 0.0114 - cat1_loss: 0.2508 - cat2_loss: 0.2706 - lin_acc: 0.7243 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 457/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5307 - lin_loss: 0.0114 - cat1_loss: 0.2504 - cat2_loss: 0.2689 - lin_acc: 0.7249 - cat1_categorical_accuracy: 0.8802 - cat2_categorical_accuracy: 0.8661\n",
      "Epoch 458/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5289 - lin_loss: 0.0114 - cat1_loss: 0.2488 - cat2_loss: 0.2687 - lin_acc: 0.7189 - cat1_categorical_accuracy: 0.8792 - cat2_categorical_accuracy: 0.8668\n",
      "Epoch 459/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5312 - lin_loss: 0.0114 - cat1_loss: 0.2504 - cat2_loss: 0.2695 - lin_acc: 0.7233 - cat1_categorical_accuracy: 0.8741 - cat2_categorical_accuracy: 0.86641s - loss: 0.5190 - lin_loss: 0.0115 - cat1_loss: 0.2360 - cat2_loss: 0.2716 - lin_acc: 0.7203 - cat1_categorical_accuracy: 0.\n",
      "Epoch 460/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5300 - lin_loss: 0.0115 - cat1_loss: 0.2492 - cat2_loss: 0.2694 - lin_acc: 0.7198 - cat1_categorical_accuracy: 0.8788 - cat2_categorical_accuracy: 0.8644\n",
      "Epoch 461/1001\n",
      "8745/8745 [==============================] - 3s 312us/step - loss: 0.5273 - lin_loss: 0.0114 - cat1_loss: 0.2496 - cat2_loss: 0.2663 - lin_acc: 0.7240 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 462/1001\n",
      "8745/8745 [==============================] - 3s 314us/step - loss: 0.5338 - lin_loss: 0.0114 - cat1_loss: 0.2520 - cat2_loss: 0.2705 - lin_acc: 0.7246 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.87011s - loss: 0.5309 - lin_loss: 0.0114 - cat1_loss: 0.2483 - cat2_loss: 0.2712 - lin_acc: 0.7305 - cat1_categorical_accuracy: 0.8812 - cat2_categorical_accu - ETA: 0s - loss: 0.5339 - lin_loss: 0.0113 - cat1_loss: 0.2496 - cat2_loss: 0.2729 - lin_acc: 0.7266 - cat1_categorical_accuracy: 0.8788 - cat2_cate\n",
      "Epoch 463/1001\n",
      "8745/8745 [==============================] - 2s 266us/step - loss: 0.5286 - lin_loss: 0.0114 - cat1_loss: 0.2492 - cat2_loss: 0.2680 - lin_acc: 0.7245 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 464/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5280 - lin_loss: 0.0114 - cat1_loss: 0.2503 - cat2_loss: 0.2662 - lin_acc: 0.7228 - cat1_categorical_accuracy: 0.8796 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 465/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5340 - lin_loss: 0.0114 - cat1_loss: 0.2540 - cat2_loss: 0.2685 - lin_acc: 0.7273 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.86832s - loss: 0.5573 - lin_loss: 0.0110 - cat1_loss: 0.2696 - cat2_loss: 0.2767 - lin_acc: \n",
      "Epoch 466/1001\n",
      "8745/8745 [==============================] - 3s 297us/step - loss: 0.5361 - lin_loss: 0.0113 - cat1_loss: 0.2568 - cat2_loss: 0.2680 - lin_acc: 0.7227 - cat1_categorical_accuracy: 0.8755 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 467/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5282 - lin_loss: 0.0114 - cat1_loss: 0.2499 - cat2_loss: 0.2669 - lin_acc: 0.7262 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8658\n",
      "Epoch 468/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5284 - lin_loss: 0.0114 - cat1_loss: 0.2509 - cat2_loss: 0.2661 - lin_acc: 0.7268 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8674\n",
      "Epoch 469/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5314 - lin_loss: 0.0114 - cat1_loss: 0.2523 - cat2_loss: 0.2677 - lin_acc: 0.7252 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8666\n",
      "Epoch 470/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5286 - lin_loss: 0.0115 - cat1_loss: 0.2499 - cat2_loss: 0.2673 - lin_acc: 0.7236 - cat1_categorical_accuracy: 0.8760 - cat2_categorical_accuracy: 0.8661\n",
      "Epoch 471/1001\n",
      "8745/8745 [==============================] - 2s 286us/step - loss: 0.5316 - lin_loss: 0.0114 - cat1_loss: 0.2533 - cat2_loss: 0.2668 - lin_acc: 0.7248 - cat1_categorical_accuracy: 0.8760 - cat2_categorical_accuracy: 0.8688\n",
      "Epoch 472/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 0.5359 - lin_loss: 0.0114 - cat1_loss: 0.2517 - cat2_loss: 0.2728 - lin_acc: 0.7233 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8648\n",
      "Epoch 473/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5286 - lin_loss: 0.0114 - cat1_loss: 0.2493 - cat2_loss: 0.2679 - lin_acc: 0.7257 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 474/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5257 - lin_loss: 0.0114 - cat1_loss: 0.2494 - cat2_loss: 0.2650 - lin_acc: 0.7219 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8706\n",
      "Epoch 475/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5280 - lin_loss: 0.0114 - cat1_loss: 0.2491 - cat2_loss: 0.2676 - lin_acc: 0.7282 - cat1_categorical_accuracy: 0.8783 - cat2_categorical_accuracy: 0.86750s - loss: 0.5347 - lin_loss: 0.0113 - cat1_loss: 0.2515 - cat2_loss: 0.2719 - lin_acc: 0.7276 - cat1_categorical_accuracy: 0.8771 - cat2_cate\n",
      "Epoch 476/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 0.5309 - lin_loss: 0.0113 - cat1_loss: 0.2489 - cat2_loss: 0.2706 - lin_acc: 0.7248 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8672\n",
      "Epoch 477/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 0.5268 - lin_loss: 0.0113 - cat1_loss: 0.2479 - cat2_loss: 0.2675 - lin_acc: 0.7275 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.8655\n",
      "Epoch 478/1001\n",
      "8745/8745 [==============================] - 3s 291us/step - loss: 0.5309 - lin_loss: 0.0114 - cat1_loss: 0.2528 - cat2_loss: 0.2667 - lin_acc: 0.7237 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8659\n",
      "Epoch 479/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5288 - lin_loss: 0.0114 - cat1_loss: 0.2502 - cat2_loss: 0.2673 - lin_acc: 0.7186 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8690\n",
      "Epoch 480/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5318 - lin_loss: 0.0114 - cat1_loss: 0.2537 - cat2_loss: 0.2667 - lin_acc: 0.7237 - cat1_categorical_accuracy: 0.8755 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 481/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5283 - lin_loss: 0.0113 - cat1_loss: 0.2486 - cat2_loss: 0.2684 - lin_acc: 0.7274 - cat1_categorical_accuracy: 0.8765 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 482/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5315 - lin_loss: 0.0113 - cat1_loss: 0.2536 - cat2_loss: 0.2665 - lin_acc: 0.7269 - cat1_categorical_accuracy: 0.8758 - cat2_categorical_accuracy: 0.8688\n",
      "Epoch 483/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5296 - lin_loss: 0.0113 - cat1_loss: 0.2526 - cat2_loss: 0.2657 - lin_acc: 0.7256 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8670\n",
      "Epoch 484/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5271 - lin_loss: 0.0113 - cat1_loss: 0.2482 - cat2_loss: 0.2675 - lin_acc: 0.7275 - cat1_categorical_accuracy: 0.8803 - cat2_categorical_accuracy: 0.86980s - loss: 0.5263 - lin_loss: 0.0112 - cat1_loss: 0.2492 - cat2_loss: 0.2659 - lin_acc: 0.7274 - cat1_categorical_accuracy: 0.8805 - cat2_categori\n",
      "Epoch 485/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.5252 - lin_loss: 0.0113 - cat1_loss: 0.2492 - cat2_loss: 0.2646 - lin_acc: 0.7260 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 486/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5267 - lin_loss: 0.0113 - cat1_loss: 0.2503 - cat2_loss: 0.2651 - lin_acc: 0.7272 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.8656\n",
      "Epoch 487/1001\n",
      "8745/8745 [==============================] - 2s 265us/step - loss: 0.5268 - lin_loss: 0.0113 - cat1_loss: 0.2486 - cat2_loss: 0.2669 - lin_acc: 0.7249 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.8709\n",
      "Epoch 488/1001\n",
      "8745/8745 [==============================] - 3s 297us/step - loss: 0.5289 - lin_loss: 0.0113 - cat1_loss: 0.2495 - cat2_loss: 0.2680 - lin_acc: 0.7244 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 489/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5308 - lin_loss: 0.0114 - cat1_loss: 0.2518 - cat2_loss: 0.2677 - lin_acc: 0.7232 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8675\n",
      "Epoch 490/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5288 - lin_loss: 0.0113 - cat1_loss: 0.2502 - cat2_loss: 0.2673 - lin_acc: 0.7272 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.86860s - loss: 0.5353 - lin_loss: 0.0113 - cat1_loss: 0.2553 - cat2_loss: 0.2687 - lin_acc: 0.7290 - cat1_categorical_accuracy: 0.8732 - cat2_ca\n",
      "Epoch 491/1001\n",
      "8745/8745 [==============================] - 3s 302us/step - loss: 0.5286 - lin_loss: 0.0113 - cat1_loss: 0.2499 - cat2_loss: 0.2674 - lin_acc: 0.7283 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8691\n",
      "Epoch 492/1001\n",
      "8745/8745 [==============================] - 3s 299us/step - loss: 0.5281 - lin_loss: 0.0113 - cat1_loss: 0.2497 - cat2_loss: 0.2670 - lin_acc: 0.7254 - cat1_categorical_accuracy: 0.8796 - cat2_categorical_accuracy: 0.8658\n",
      "Epoch 493/1001\n",
      "8745/8745 [==============================] - 3s 339us/step - loss: 0.5277 - lin_loss: 0.0113 - cat1_loss: 0.2488 - cat2_loss: 0.2676 - lin_acc: 0.7276 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8686\n",
      "Epoch 494/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5275 - lin_loss: 0.0113 - cat1_loss: 0.2512 - cat2_loss: 0.2650 - lin_acc: 0.7242 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8690\n",
      "Epoch 495/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5299 - lin_loss: 0.0113 - cat1_loss: 0.2505 - cat2_loss: 0.2681 - lin_acc: 0.7240 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8676\n",
      "Epoch 496/1001\n",
      "8745/8745 [==============================] - 3s 291us/step - loss: 0.5285 - lin_loss: 0.0113 - cat1_loss: 0.2496 - cat2_loss: 0.2676 - lin_acc: 0.7256 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.8686\n",
      "Epoch 497/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5297 - lin_loss: 0.0113 - cat1_loss: 0.2506 - cat2_loss: 0.2678 - lin_acc: 0.7280 - cat1_categorical_accuracy: 0.8749 - cat2_categorical_accuracy: 0.8668\n",
      "Epoch 498/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.5289 - lin_loss: 0.0113 - cat1_loss: 0.2506 - cat2_loss: 0.2669 - lin_acc: 0.7267 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8672\n",
      "Epoch 499/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5275 - lin_loss: 0.0112 - cat1_loss: 0.2487 - cat2_loss: 0.2676 - lin_acc: 0.7261 - cat1_categorical_accuracy: 0.8790 - cat2_categorical_accuracy: 0.8707\n",
      "Epoch 500/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5293 - lin_loss: 0.0113 - cat1_loss: 0.2510 - cat2_loss: 0.2670 - lin_acc: 0.7272 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.86712s - loss: 0.5557 - lin_loss: 0.0110 - cat1_loss: 0.2898 - cat2_loss: 0.2550 - lin_acc: 0.72\n",
      "Epoch 501/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5260 - lin_loss: 0.0113 - cat1_loss: 0.2473 - cat2_loss: 0.2674 - lin_acc: 0.7266 - cat1_categorical_accuracy: 0.8746 - cat2_categorical_accuracy: 0.8670\n",
      "../linkPrediction/dataframes/apnea\\apnea-model-article-500_2008-2015.pkl\n",
      "Epoch 502/1001\n",
      "8745/8745 [==============================] - 3s 312us/step - loss: 0.5262 - lin_loss: 0.0113 - cat1_loss: 0.2511 - cat2_loss: 0.2639 - lin_acc: 0.7258 - cat1_categorical_accuracy: 0.8760 - cat2_categorical_accuracy: 0.87100s - loss: 0.5255 - lin_loss: 0.0112 - cat1_loss: 0.2505 - cat2_loss: 0.2638 - lin_acc: 0.7259 - cat1_categorical_accuracy: 0.8760 - cat2_categorical_accuracy: \n",
      "Epoch 503/1001\n",
      "8745/8745 [==============================] - 3s 290us/step - loss: 0.5284 - lin_loss: 0.0113 - cat1_loss: 0.2511 - cat2_loss: 0.2660 - lin_acc: 0.7278 - cat1_categorical_accuracy: 0.8765 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 504/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5313 - lin_loss: 0.0113 - cat1_loss: 0.2508 - cat2_loss: 0.2692 - lin_acc: 0.7262 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8667\n",
      "Epoch 505/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5328 - lin_loss: 0.0114 - cat1_loss: 0.2529 - cat2_loss: 0.2685 - lin_acc: 0.7258 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8654\n",
      "Epoch 506/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5277 - lin_loss: 0.0112 - cat1_loss: 0.2507 - cat2_loss: 0.2658 - lin_acc: 0.7286 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.8676\n",
      "Epoch 507/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5277 - lin_loss: 0.0113 - cat1_loss: 0.2497 - cat2_loss: 0.2667 - lin_acc: 0.7280 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.87081s - loss: 0.5230 - lin_loss: 0.0112 - cat1_loss: 0.2423 - cat2_loss: 0.2695 - lin_acc: 0.7275 - cat1_categorical_accuracy: 0.\n",
      "Epoch 508/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5292 - lin_loss: 0.0112 - cat1_loss: 0.2503 - cat2_loss: 0.2676 - lin_acc: 0.7276 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.86822s - loss: 0.5187 - lin_loss: 0.0108 - cat1_loss: 0.2600 - cat2_loss: 0.2479 - lin_acc: 0.73\n",
      "Epoch 509/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5246 - lin_loss: 0.0113 - cat1_loss: 0.2474 - cat2_loss: 0.2659 - lin_acc: 0.7292 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8671\n",
      "Epoch 510/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5276 - lin_loss: 0.0113 - cat1_loss: 0.2503 - cat2_loss: 0.2660 - lin_acc: 0.7242 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.86792s - loss: 0.5424 - lin_loss: 0.0113 - cat1_loss: 0.2467 - cat2_loss: 0.2844 - lin_acc: 0.7253 - c\n",
      "Epoch 511/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5256 - lin_loss: 0.0113 - cat1_loss: 0.2486 - cat2_loss: 0.2658 - lin_acc: 0.7300 - cat1_categorical_accuracy: 0.8799 - cat2_categorical_accuracy: 0.86930s - loss: 0.5245 - lin_loss: 0.0113 - cat1_loss: 0.2466 - cat2_loss: 0.2666 - lin_acc: 0.7314 - cat1_categorical_accuracy: 0.8818 - cat2_categorical_ac\n",
      "Epoch 512/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5249 - lin_loss: 0.0112 - cat1_loss: 0.2491 - cat2_loss: 0.2646 - lin_acc: 0.7257 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8683\n",
      "Epoch 513/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5276 - lin_loss: 0.0112 - cat1_loss: 0.2496 - cat2_loss: 0.2668 - lin_acc: 0.7294 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.86712s - loss: 0.5174 - lin_loss: 0.0110 - cat1_loss: 0.2384 - cat2_loss: 0.2679 - lin_acc: 0.7365 - cat\n",
      "Epoch 514/1001\n",
      "8745/8745 [==============================] - 3s 306us/step - loss: 0.5264 - lin_loss: 0.0112 - cat1_loss: 0.2498 - cat2_loss: 0.2654 - lin_acc: 0.7290 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 515/1001\n",
      "8745/8745 [==============================] - 3s 324us/step - loss: 0.5303 - lin_loss: 0.0112 - cat1_loss: 0.2506 - cat2_loss: 0.2685 - lin_acc: 0.7312 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8645\n",
      "Epoch 516/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5285 - lin_loss: 0.0112 - cat1_loss: 0.2515 - cat2_loss: 0.2658 - lin_acc: 0.7283 - cat1_categorical_accuracy: 0.8748 - cat2_categorical_accuracy: 0.86900s - loss: 0.5283 - lin_loss: 0.0112 - cat1_loss: 0.2545 - cat2_loss: 0.2627 - lin_acc: 0.7315 - cat1_categorical_accuracy: 0.8738 - cat2_cate\n",
      "Epoch 517/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5219 - lin_loss: 0.0113 - cat1_loss: 0.2482 - cat2_loss: 0.2624 - lin_acc: 0.7264 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8702\n",
      "Epoch 518/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5269 - lin_loss: 0.0112 - cat1_loss: 0.2500 - cat2_loss: 0.2657 - lin_acc: 0.7297 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 519/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5328 - lin_loss: 0.0113 - cat1_loss: 0.2516 - cat2_loss: 0.2699 - lin_acc: 0.7243 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8626\n",
      "Epoch 520/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5271 - lin_loss: 0.0112 - cat1_loss: 0.2491 - cat2_loss: 0.2668 - lin_acc: 0.7272 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8655\n",
      "Epoch 521/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5257 - lin_loss: 0.0112 - cat1_loss: 0.2496 - cat2_loss: 0.2649 - lin_acc: 0.7323 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8725\n",
      "Epoch 522/1001\n",
      "8745/8745 [==============================] - 3s 291us/step - loss: 0.5269 - lin_loss: 0.0111 - cat1_loss: 0.2481 - cat2_loss: 0.2677 - lin_acc: 0.7314 - cat1_categorical_accuracy: 0.8786 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 523/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5276 - lin_loss: 0.0112 - cat1_loss: 0.2493 - cat2_loss: 0.2671 - lin_acc: 0.7297 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.86770s - loss: 0.5305 - lin_loss: 0.0113 - cat1_loss: 0.2513 - cat2_loss: 0.2680 - lin_acc: 0.7290 - cat1_categorical_accuracy: 0.8758 - cat2_categorical_ac\n",
      "Epoch 524/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5265 - lin_loss: 0.0112 - cat1_loss: 0.2481 - cat2_loss: 0.2672 - lin_acc: 0.7278 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8671\n",
      "Epoch 525/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 0.5316 - lin_loss: 0.0112 - cat1_loss: 0.2529 - cat2_loss: 0.2674 - lin_acc: 0.7273 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 526/1001\n",
      "8745/8745 [==============================] - 3s 286us/step - loss: 0.5301 - lin_loss: 0.0112 - cat1_loss: 0.2518 - cat2_loss: 0.2670 - lin_acc: 0.7299 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8674\n",
      "Epoch 527/1001\n",
      "8745/8745 [==============================] - 3s 294us/step - loss: 0.5253 - lin_loss: 0.0112 - cat1_loss: 0.2480 - cat2_loss: 0.2661 - lin_acc: 0.7293 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8662\n",
      "Epoch 528/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5273 - lin_loss: 0.0112 - cat1_loss: 0.2503 - cat2_loss: 0.2658 - lin_acc: 0.7291 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8664\n",
      "Epoch 529/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5280 - lin_loss: 0.0113 - cat1_loss: 0.2503 - cat2_loss: 0.2664 - lin_acc: 0.7285 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.8675\n",
      "Epoch 530/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5235 - lin_loss: 0.0112 - cat1_loss: 0.2475 - cat2_loss: 0.2648 - lin_acc: 0.7278 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8686\n",
      "Epoch 531/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5243 - lin_loss: 0.0112 - cat1_loss: 0.2479 - cat2_loss: 0.2652 - lin_acc: 0.7297 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8672\n",
      "Epoch 532/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5246 - lin_loss: 0.0111 - cat1_loss: 0.2489 - cat2_loss: 0.2645 - lin_acc: 0.7306 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8706\n",
      "Epoch 533/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5253 - lin_loss: 0.0112 - cat1_loss: 0.2486 - cat2_loss: 0.2655 - lin_acc: 0.7296 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8675\n",
      "Epoch 534/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 0.5278 - lin_loss: 0.0112 - cat1_loss: 0.2494 - cat2_loss: 0.2673 - lin_acc: 0.7268 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.8661\n",
      "Epoch 535/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5278 - lin_loss: 0.0111 - cat1_loss: 0.2487 - cat2_loss: 0.2680 - lin_acc: 0.7292 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8700\n",
      "Epoch 536/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5272 - lin_loss: 0.0112 - cat1_loss: 0.2491 - cat2_loss: 0.2669 - lin_acc: 0.7294 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8704\n",
      "Epoch 537/1001\n",
      "8745/8745 [==============================] - 2s 286us/step - loss: 0.5239 - lin_loss: 0.0112 - cat1_loss: 0.2477 - cat2_loss: 0.2650 - lin_acc: 0.7275 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8702\n",
      "Epoch 538/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5267 - lin_loss: 0.0112 - cat1_loss: 0.2489 - cat2_loss: 0.2666 - lin_acc: 0.7281 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8696\n",
      "Epoch 539/1001\n",
      "8745/8745 [==============================] - 3s 301us/step - loss: 0.5241 - lin_loss: 0.0111 - cat1_loss: 0.2488 - cat2_loss: 0.2641 - lin_acc: 0.7276 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.86790s - loss: 0.5230 - lin_loss: 0.0111 - cat1_loss: 0.2481 - cat2_loss: 0.2639 - lin_acc: 0.7271 - cat1_categorical_accuracy: 0.8788 - cat2_categorical_accuracy: 0.\n",
      "Epoch 540/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 0.5237 - lin_loss: 0.0112 - cat1_loss: 0.2493 - cat2_loss: 0.2632 - lin_acc: 0.7292 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8679\n",
      "Epoch 541/1001\n",
      "8745/8745 [==============================] - 3s 308us/step - loss: 0.5278 - lin_loss: 0.0112 - cat1_loss: 0.2491 - cat2_loss: 0.2675 - lin_acc: 0.7276 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8654\n",
      "Epoch 542/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.5272 - lin_loss: 0.0111 - cat1_loss: 0.2506 - cat2_loss: 0.2655 - lin_acc: 0.7298 - cat1_categorical_accuracy: 0.8748 - cat2_categorical_accuracy: 0.8671\n",
      "Epoch 543/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5249 - lin_loss: 0.0112 - cat1_loss: 0.2479 - cat2_loss: 0.2658 - lin_acc: 0.7321 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.86881s - loss: 0.5171 - lin_loss: 0.0111 - cat1_loss: 0.2466 - cat2_loss: 0.2593 - lin_acc: 0.7283 - cat1_categorical_accuracy: 0.87\n",
      "Epoch 544/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5264 - lin_loss: 0.0111 - cat1_loss: 0.2496 - cat2_loss: 0.2657 - lin_acc: 0.7314 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8688\n",
      "Epoch 545/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5307 - lin_loss: 0.0111 - cat1_loss: 0.2511 - cat2_loss: 0.2685 - lin_acc: 0.7310 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8655\n",
      "Epoch 546/1001\n",
      "8745/8745 [==============================] - 2s 266us/step - loss: 0.5274 - lin_loss: 0.0111 - cat1_loss: 0.2483 - cat2_loss: 0.2680 - lin_acc: 0.7289 - cat1_categorical_accuracy: 0.8805 - cat2_categorical_accuracy: 0.8658\n",
      "Epoch 547/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5256 - lin_loss: 0.0111 - cat1_loss: 0.2491 - cat2_loss: 0.2654 - lin_acc: 0.7325 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8667\n",
      "Epoch 548/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5276 - lin_loss: 0.0111 - cat1_loss: 0.2481 - cat2_loss: 0.2685 - lin_acc: 0.7344 - cat1_categorical_accuracy: 0.8731 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 549/1001\n",
      "8745/8745 [==============================] - 2s 264us/step - loss: 0.5252 - lin_loss: 0.0111 - cat1_loss: 0.2500 - cat2_loss: 0.2641 - lin_acc: 0.7299 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.8707\n",
      "Epoch 550/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5265 - lin_loss: 0.0111 - cat1_loss: 0.2498 - cat2_loss: 0.2656 - lin_acc: 0.7322 - cat1_categorical_accuracy: 0.8758 - cat2_categorical_accuracy: 0.8662\n",
      "Epoch 551/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 0.5252 - lin_loss: 0.0111 - cat1_loss: 0.2485 - cat2_loss: 0.2655 - lin_acc: 0.7277 - cat1_categorical_accuracy: 0.8755 - cat2_categorical_accuracy: 0.8679\n",
      "Epoch 552/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5277 - lin_loss: 0.0111 - cat1_loss: 0.2487 - cat2_loss: 0.2678 - lin_acc: 0.7292 - cat1_categorical_accuracy: 0.8797 - cat2_categorical_accuracy: 0.8672\n",
      "Epoch 553/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 0.5284 - lin_loss: 0.0111 - cat1_loss: 0.2518 - cat2_loss: 0.2656 - lin_acc: 0.7360 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.86782s - loss: 0.5677 - lin_loss: 0.0110 - cat1_loss: 0.2597 - cat2_loss: 0.2970 - lin_a\n",
      "Epoch 554/1001\n",
      "8745/8745 [==============================] - 3s 341us/step - loss: 0.5241 - lin_loss: 0.0111 - cat1_loss: 0.2476 - cat2_loss: 0.2654 - lin_acc: 0.7304 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8661\n",
      "Epoch 555/1001\n",
      "8745/8745 [==============================] - 4s 405us/step - loss: 0.5251 - lin_loss: 0.0111 - cat1_loss: 0.2509 - cat2_loss: 0.2630 - lin_acc: 0.7297 - cat1_categorical_accuracy: 0.8747 - cat2_categorical_accuracy: 0.8654\n",
      "Epoch 556/1001\n",
      "8745/8745 [==============================] - 3s 342us/step - loss: 0.5238 - lin_loss: 0.0112 - cat1_loss: 0.2488 - cat2_loss: 0.2637 - lin_acc: 0.7320 - cat1_categorical_accuracy: 0.8798 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 557/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5260 - lin_loss: 0.0111 - cat1_loss: 0.2488 - cat2_loss: 0.2661 - lin_acc: 0.7284 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8672\n",
      "Epoch 558/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 0.5232 - lin_loss: 0.0111 - cat1_loss: 0.2461 - cat2_loss: 0.2660 - lin_acc: 0.7284 - cat1_categorical_accuracy: 0.8791 - cat2_categorical_accuracy: 0.8698\n",
      "Epoch 559/1001\n",
      "8745/8745 [==============================] - 3s 291us/step - loss: 0.5253 - lin_loss: 0.0111 - cat1_loss: 0.2490 - cat2_loss: 0.2652 - lin_acc: 0.7325 - cat1_categorical_accuracy: 0.8791 - cat2_categorical_accuracy: 0.86711s - loss: 0.5128 - lin_loss: 0.0108 - cat1_loss: 0.2425 - cat2_loss: 0.2594 - lin_acc: 0.7230 - cat1_categori\n",
      "Epoch 560/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 0.5271 - lin_loss: 0.0111 - cat1_loss: 0.2500 - cat2_loss: 0.2661 - lin_acc: 0.7309 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8655\n",
      "Epoch 561/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5250 - lin_loss: 0.0111 - cat1_loss: 0.2480 - cat2_loss: 0.2659 - lin_acc: 0.7281 - cat1_categorical_accuracy: 0.8797 - cat2_categorical_accuracy: 0.8677\n",
      "Epoch 562/1001\n",
      "8745/8745 [==============================] - 3s 302us/step - loss: 0.5252 - lin_loss: 0.0111 - cat1_loss: 0.2504 - cat2_loss: 0.2637 - lin_acc: 0.7294 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.8695\n",
      "Epoch 563/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5248 - lin_loss: 0.0111 - cat1_loss: 0.2497 - cat2_loss: 0.2641 - lin_acc: 0.7305 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8683\n",
      "Epoch 564/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5298 - lin_loss: 0.0110 - cat1_loss: 0.2502 - cat2_loss: 0.2686 - lin_acc: 0.7322 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 565/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5243 - lin_loss: 0.0111 - cat1_loss: 0.2493 - cat2_loss: 0.2640 - lin_acc: 0.7289 - cat1_categorical_accuracy: 0.8788 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 566/1001\n",
      "8745/8745 [==============================] - 3s 304us/step - loss: 0.5213 - lin_loss: 0.0111 - cat1_loss: 0.2475 - cat2_loss: 0.2627 - lin_acc: 0.7328 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 567/1001\n",
      "8745/8745 [==============================] - 3s 315us/step - loss: 0.5253 - lin_loss: 0.0111 - cat1_loss: 0.2493 - cat2_loss: 0.2649 - lin_acc: 0.7270 - cat1_categorical_accuracy: 0.8754 - cat2_categorical_accuracy: 0.8711\n",
      "Epoch 568/1001\n",
      "8745/8745 [==============================] - 3s 302us/step - loss: 0.5258 - lin_loss: 0.0111 - cat1_loss: 0.2501 - cat2_loss: 0.2647 - lin_acc: 0.7307 - cat1_categorical_accuracy: 0.8791 - cat2_categorical_accuracy: 0.8651\n",
      "Epoch 569/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5226 - lin_loss: 0.0111 - cat1_loss: 0.2482 - cat2_loss: 0.2634 - lin_acc: 0.7316 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 570/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5272 - lin_loss: 0.0111 - cat1_loss: 0.2493 - cat2_loss: 0.2668 - lin_acc: 0.7304 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8650\n",
      "Epoch 571/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5284 - lin_loss: 0.0110 - cat1_loss: 0.2500 - cat2_loss: 0.2674 - lin_acc: 0.7338 - cat1_categorical_accuracy: 0.8756 - cat2_categorical_accuracy: 0.8696\n",
      "Epoch 572/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 0.5245 - lin_loss: 0.0111 - cat1_loss: 0.2485 - cat2_loss: 0.2650 - lin_acc: 0.7250 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.86990s - loss: 0.5208 - lin_loss: 0.0110 - cat1_loss: 0.2474 - cat2_loss: 0.2624 - lin_acc: 0.7269 - cat1_categorical_accuracy: 0.8774 -\n",
      "Epoch 573/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5236 - lin_loss: 0.0111 - cat1_loss: 0.2505 - cat2_loss: 0.2620 - lin_acc: 0.7370 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.8708\n",
      "Epoch 574/1001\n",
      "8745/8745 [==============================] - 3s 303us/step - loss: 0.5216 - lin_loss: 0.0111 - cat1_loss: 0.2479 - cat2_loss: 0.2626 - lin_acc: 0.7308 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.87000s - loss: 0.5131 - lin_loss: 0.0111 - cat1_loss: 0.2424 - cat2_loss: 0.2596 - lin_acc: 0.7289 - cat1_categorical_accuracy: 0.8809 -\n",
      "Epoch 575/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5250 - lin_loss: 0.0110 - cat1_loss: 0.2508 - cat2_loss: 0.2631 - lin_acc: 0.7320 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.86930s - loss: 0.5220 - lin_loss: 0.0110 - cat1_loss: 0.2490 - cat2_loss: 0.2620 - lin_acc: 0.7330 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.\n",
      "Epoch 576/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5230 - lin_loss: 0.0110 - cat1_loss: 0.2480 - cat2_loss: 0.2640 - lin_acc: 0.7345 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8688\n",
      "Epoch 577/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5239 - lin_loss: 0.0110 - cat1_loss: 0.2499 - cat2_loss: 0.2630 - lin_acc: 0.7317 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 578/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5254 - lin_loss: 0.0111 - cat1_loss: 0.2493 - cat2_loss: 0.2651 - lin_acc: 0.7314 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.8704\n",
      "Epoch 579/1001\n",
      "8745/8745 [==============================] - 2s 266us/step - loss: 0.5273 - lin_loss: 0.0110 - cat1_loss: 0.2500 - cat2_loss: 0.2662 - lin_acc: 0.7316 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8668\n",
      "Epoch 580/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5244 - lin_loss: 0.0110 - cat1_loss: 0.2481 - cat2_loss: 0.2653 - lin_acc: 0.7300 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.8642\n",
      "Epoch 581/1001\n",
      "8745/8745 [==============================] - 2s 261us/step - loss: 0.5243 - lin_loss: 0.0110 - cat1_loss: 0.2482 - cat2_loss: 0.2652 - lin_acc: 0.7304 - cat1_categorical_accuracy: 0.8805 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 582/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5246 - lin_loss: 0.0110 - cat1_loss: 0.2489 - cat2_loss: 0.2647 - lin_acc: 0.7326 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8663\n",
      "Epoch 583/1001\n",
      "8745/8745 [==============================] - 2s 284us/step - loss: 0.5247 - lin_loss: 0.0110 - cat1_loss: 0.2479 - cat2_loss: 0.2658 - lin_acc: 0.7395 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 584/1001\n",
      "8745/8745 [==============================] - 2s 266us/step - loss: 0.5245 - lin_loss: 0.0110 - cat1_loss: 0.2494 - cat2_loss: 0.2641 - lin_acc: 0.7336 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.86660s - loss: 0.5230 - lin_loss: 0.0110 - cat1_loss: 0.2476 - cat2_loss: 0.2644 - lin_acc: 0.7375 - cat1_categorical_accuracy: 0.8813\n",
      "Epoch 585/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5244 - lin_loss: 0.0110 - cat1_loss: 0.2486 - cat2_loss: 0.2647 - lin_acc: 0.7345 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8693\n",
      "Epoch 586/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5223 - lin_loss: 0.0109 - cat1_loss: 0.2470 - cat2_loss: 0.2643 - lin_acc: 0.7332 - cat1_categorical_accuracy: 0.8812 - cat2_categorical_accuracy: 0.8670\n",
      "Epoch 587/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 0.5250 - lin_loss: 0.0110 - cat1_loss: 0.2507 - cat2_loss: 0.2633 - lin_acc: 0.7324 - cat1_categorical_accuracy: 0.8797 - cat2_categorical_accuracy: 0.86840s - loss: 0.5223 - lin_loss: 0.0109 - cat1_loss: 0.2439 - cat2_loss: 0.2674 - lin_acc: 0.7408 - cat1_categorical_accuracy: 0.8830 - cat\n",
      "Epoch 588/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5270 - lin_loss: 0.0111 - cat1_loss: 0.2511 - cat2_loss: 0.2648 - lin_acc: 0.7341 - cat1_categorical_accuracy: 0.8765 - cat2_categorical_accuracy: 0.8662\n",
      "Epoch 589/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5241 - lin_loss: 0.0110 - cat1_loss: 0.2482 - cat2_loss: 0.2648 - lin_acc: 0.7331 - cat1_categorical_accuracy: 0.8808 - cat2_categorical_accuracy: 0.86701s - loss: 0.5354 - lin_loss: 0.0111 - cat1_loss: 0.2534 - cat2_loss: 0.2708 - lin_acc: 0.7386 - cat1_categorical_accuracy: \n",
      "Epoch 590/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5245 - lin_loss: 0.0110 - cat1_loss: 0.2479 - cat2_loss: 0.2656 - lin_acc: 0.7332 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 591/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5252 - lin_loss: 0.0109 - cat1_loss: 0.2511 - cat2_loss: 0.2632 - lin_acc: 0.7380 - cat1_categorical_accuracy: 0.8755 - cat2_categorical_accuracy: 0.8693\n",
      "Epoch 592/1001\n",
      "8745/8745 [==============================] - 3s 300us/step - loss: 0.5254 - lin_loss: 0.0110 - cat1_loss: 0.2478 - cat2_loss: 0.2666 - lin_acc: 0.7314 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.8683\n",
      "Epoch 593/1001\n",
      "8745/8745 [==============================] - 3s 338us/step - loss: 0.5276 - lin_loss: 0.0110 - cat1_loss: 0.2497 - cat2_loss: 0.2669 - lin_acc: 0.7332 - cat1_categorical_accuracy: 0.8750 - cat2_categorical_accuracy: 0.86620s - loss: 0.5276 - lin_loss: 0.0109 - cat1_loss: 0.2502 - cat2_loss: 0.2665 - lin_acc: 0.7296 - cat1_categorical_accuracy: 0.8736 - cat2_categori - ETA: 0s - loss: 0.5323 - lin_loss: 0.0110 - cat1_loss: 0.2530 - cat2_loss: 0.2683 - lin_acc: 0.7324 - cat1_categorical_accuracy: 0.8733 - cat2_catego\n",
      "Epoch 594/1001\n",
      "8745/8745 [==============================] - 3s 335us/step - loss: 0.5222 - lin_loss: 0.0110 - cat1_loss: 0.2472 - cat2_loss: 0.2640 - lin_acc: 0.7322 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.8695\n",
      "Epoch 595/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5305 - lin_loss: 0.0109 - cat1_loss: 0.2564 - cat2_loss: 0.2631 - lin_acc: 0.7344 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8702\n",
      "Epoch 596/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 0.5276 - lin_loss: 0.0110 - cat1_loss: 0.2537 - cat2_loss: 0.2630 - lin_acc: 0.7313 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8707\n",
      "Epoch 597/1001\n",
      "8745/8745 [==============================] - 3s 333us/step - loss: 0.5225 - lin_loss: 0.0110 - cat1_loss: 0.2479 - cat2_loss: 0.2637 - lin_acc: 0.7318 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.86790s - loss: 0.5193 - lin_loss: 0.0109 - cat1_loss: 0.2493 - cat2_loss: 0.2590 - lin_acc: 0.7332 - cat1_categorical_accuracy: 0.8798 - c\n",
      "Epoch 598/1001\n",
      "8745/8745 [==============================] - 3s 359us/step - loss: 0.5259 - lin_loss: 0.0110 - cat1_loss: 0.2485 - cat2_loss: 0.2663 - lin_acc: 0.7341 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8652\n",
      "Epoch 599/1001\n",
      "8745/8745 [==============================] - 3s 322us/step - loss: 0.5232 - lin_loss: 0.0110 - cat1_loss: 0.2483 - cat2_loss: 0.2639 - lin_acc: 0.7339 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 600/1001\n",
      "8745/8745 [==============================] - 3s 339us/step - loss: 0.5214 - lin_loss: 0.0110 - cat1_loss: 0.2466 - cat2_loss: 0.2638 - lin_acc: 0.7368 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.86600s - loss: 0.5208 - lin_loss: 0.0110 - cat1_loss: 0.2468 - cat2_loss: 0.2630 - lin_acc: 0.7368 - cat1_categorical_accuracy: 0.8758 - cat2_categorical_accuracy: 0.\n",
      "Epoch 601/1001\n",
      "8745/8745 [==============================] - 3s 332us/step - loss: 0.5231 - lin_loss: 0.0110 - cat1_loss: 0.2459 - cat2_loss: 0.2662 - lin_acc: 0.7348 - cat1_categorical_accuracy: 0.8765 - cat2_categorical_accuracy: 0.8668\n",
      "Epoch 602/1001\n",
      "8745/8745 [==============================] - 3s 305us/step - loss: 0.5211 - lin_loss: 0.0110 - cat1_loss: 0.2478 - cat2_loss: 0.2622 - lin_acc: 0.7334 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.8668\n",
      "Epoch 603/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5215 - lin_loss: 0.0109 - cat1_loss: 0.2479 - cat2_loss: 0.2626 - lin_acc: 0.7312 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.8698\n",
      "Epoch 604/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5222 - lin_loss: 0.0111 - cat1_loss: 0.2471 - cat2_loss: 0.2641 - lin_acc: 0.7320 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8695\n",
      "Epoch 605/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5317 - lin_loss: 0.0109 - cat1_loss: 0.2483 - cat2_loss: 0.2724 - lin_acc: 0.7353 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8655\n",
      "Epoch 606/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5262 - lin_loss: 0.0109 - cat1_loss: 0.2502 - cat2_loss: 0.2650 - lin_acc: 0.7342 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8701\n",
      "Epoch 607/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5252 - lin_loss: 0.0110 - cat1_loss: 0.2482 - cat2_loss: 0.2660 - lin_acc: 0.7360 - cat1_categorical_accuracy: 0.8755 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 608/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5209 - lin_loss: 0.0109 - cat1_loss: 0.2477 - cat2_loss: 0.2623 - lin_acc: 0.7336 - cat1_categorical_accuracy: 0.8813 - cat2_categorical_accuracy: 0.87011s - loss: 0.5028 - lin_loss: 0.0107 - cat1_loss: 0.2394 - cat2_loss: 0.2527 - lin_acc: 0.7369 - cat1_categorical_\n",
      "Epoch 609/1001\n",
      "8745/8745 [==============================] - 3s 286us/step - loss: 0.5236 - lin_loss: 0.0110 - cat1_loss: 0.2455 - cat2_loss: 0.2672 - lin_acc: 0.7332 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.8666\n",
      "Epoch 610/1001\n",
      "8745/8745 [==============================] - 3s 304us/step - loss: 0.5195 - lin_loss: 0.0109 - cat1_loss: 0.2462 - cat2_loss: 0.2624 - lin_acc: 0.7348 - cat1_categorical_accuracy: 0.8788 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 611/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.5204 - lin_loss: 0.0109 - cat1_loss: 0.2468 - cat2_loss: 0.2626 - lin_acc: 0.7366 - cat1_categorical_accuracy: 0.8810 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 612/1001\n",
      "8745/8745 [==============================] - 3s 301us/step - loss: 0.5268 - lin_loss: 0.0109 - cat1_loss: 0.2487 - cat2_loss: 0.2672 - lin_acc: 0.7326 - cat1_categorical_accuracy: 0.8748 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 613/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5285 - lin_loss: 0.0109 - cat1_loss: 0.2484 - cat2_loss: 0.2692 - lin_acc: 0.7380 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8651\n",
      "Epoch 614/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5232 - lin_loss: 0.0109 - cat1_loss: 0.2479 - cat2_loss: 0.2644 - lin_acc: 0.7366 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8667\n",
      "Epoch 615/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5229 - lin_loss: 0.0109 - cat1_loss: 0.2490 - cat2_loss: 0.2629 - lin_acc: 0.7349 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8695\n",
      "Epoch 616/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5200 - lin_loss: 0.0109 - cat1_loss: 0.2456 - cat2_loss: 0.2635 - lin_acc: 0.7361 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8677\n",
      "Epoch 617/1001\n",
      "8745/8745 [==============================] - 2s 286us/step - loss: 0.5245 - lin_loss: 0.0109 - cat1_loss: 0.2484 - cat2_loss: 0.2653 - lin_acc: 0.7374 - cat1_categorical_accuracy: 0.8760 - cat2_categorical_accuracy: 0.8695\n",
      "Epoch 618/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 0.5212 - lin_loss: 0.0108 - cat1_loss: 0.2473 - cat2_loss: 0.2631 - lin_acc: 0.7366 - cat1_categorical_accuracy: 0.8805 - cat2_categorical_accuracy: 0.8702\n",
      "Epoch 619/1001\n",
      "8745/8745 [==============================] - 3s 312us/step - loss: 0.5233 - lin_loss: 0.0108 - cat1_loss: 0.2477 - cat2_loss: 0.2649 - lin_acc: 0.7373 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8672\n",
      "Epoch 620/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 0.5244 - lin_loss: 0.0109 - cat1_loss: 0.2492 - cat2_loss: 0.2642 - lin_acc: 0.7364 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8661\n",
      "Epoch 621/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 0.5240 - lin_loss: 0.0109 - cat1_loss: 0.2497 - cat2_loss: 0.2634 - lin_acc: 0.7376 - cat1_categorical_accuracy: 0.8786 - cat2_categorical_accuracy: 0.86681s - loss: 0.5228 - lin_loss: 0.0108 - cat1_loss: 0.2465 - cat2_loss: 0.2656 - lin_acc: 0.7373 - cat1_categorical_accuracy: 0.88\n",
      "Epoch 622/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5212 - lin_loss: 0.0108 - cat1_loss: 0.2462 - cat2_loss: 0.2642 - lin_acc: 0.7381 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8670\n",
      "Epoch 623/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5251 - lin_loss: 0.0109 - cat1_loss: 0.2472 - cat2_loss: 0.2671 - lin_acc: 0.7345 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8698\n",
      "Epoch 624/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5227 - lin_loss: 0.0109 - cat1_loss: 0.2477 - cat2_loss: 0.2642 - lin_acc: 0.7358 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8698\n",
      "Epoch 625/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5226 - lin_loss: 0.0109 - cat1_loss: 0.2484 - cat2_loss: 0.2633 - lin_acc: 0.7385 - cat1_categorical_accuracy: 0.8796 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 626/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5262 - lin_loss: 0.0108 - cat1_loss: 0.2486 - cat2_loss: 0.2667 - lin_acc: 0.7368 - cat1_categorical_accuracy: 0.8750 - cat2_categorical_accuracy: 0.8629\n",
      "Epoch 627/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5222 - lin_loss: 0.0108 - cat1_loss: 0.2474 - cat2_loss: 0.2639 - lin_acc: 0.7384 - cat1_categorical_accuracy: 0.8783 - cat2_categorical_accuracy: 0.8660\n",
      "Epoch 628/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5242 - lin_loss: 0.0108 - cat1_loss: 0.2486 - cat2_loss: 0.2648 - lin_acc: 0.7320 - cat1_categorical_accuracy: 0.8792 - cat2_categorical_accuracy: 0.8630\n",
      "Epoch 629/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5244 - lin_loss: 0.0108 - cat1_loss: 0.2480 - cat2_loss: 0.2656 - lin_acc: 0.7328 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8677\n",
      "Epoch 630/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5206 - lin_loss: 0.0108 - cat1_loss: 0.2479 - cat2_loss: 0.2619 - lin_acc: 0.7371 - cat1_categorical_accuracy: 0.8756 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 631/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5206 - lin_loss: 0.0108 - cat1_loss: 0.2472 - cat2_loss: 0.2626 - lin_acc: 0.7369 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8696\n",
      "Epoch 632/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5207 - lin_loss: 0.0108 - cat1_loss: 0.2485 - cat2_loss: 0.2614 - lin_acc: 0.7352 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 633/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5206 - lin_loss: 0.0108 - cat1_loss: 0.2481 - cat2_loss: 0.2616 - lin_acc: 0.7395 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.8708\n",
      "Epoch 634/1001\n",
      "8745/8745 [==============================] - 3s 311us/step - loss: 0.5234 - lin_loss: 0.0108 - cat1_loss: 0.2473 - cat2_loss: 0.2652 - lin_acc: 0.7381 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.86680s - loss: 0.5245 - lin_loss: 0.0108 - cat1_loss: 0.2475 - cat2_loss: 0.2662 - lin_acc: 0.7380 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: \n",
      "Epoch 635/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5186 - lin_loss: 0.0108 - cat1_loss: 0.2458 - cat2_loss: 0.2620 - lin_acc: 0.7393 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8708\n",
      "Epoch 636/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5232 - lin_loss: 0.0108 - cat1_loss: 0.2475 - cat2_loss: 0.2649 - lin_acc: 0.7416 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.8662\n",
      "Epoch 637/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5210 - lin_loss: 0.0108 - cat1_loss: 0.2479 - cat2_loss: 0.2623 - lin_acc: 0.7349 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8709\n",
      "Epoch 638/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5223 - lin_loss: 0.0108 - cat1_loss: 0.2498 - cat2_loss: 0.2617 - lin_acc: 0.7365 - cat1_categorical_accuracy: 0.8754 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 639/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5219 - lin_loss: 0.0108 - cat1_loss: 0.2476 - cat2_loss: 0.2635 - lin_acc: 0.7413 - cat1_categorical_accuracy: 0.8805 - cat2_categorical_accuracy: 0.87010s - loss: 0.5184 - lin_loss: 0.0108 - cat1_loss: 0.2440 - cat2_loss: 0.2637 - lin_acc: 0.7471 - cat1_categorical_accuracy: 0.8840 - cat2_catego\n",
      "Epoch 640/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5248 - lin_loss: 0.0108 - cat1_loss: 0.2503 - cat2_loss: 0.2638 - lin_acc: 0.7413 - cat1_categorical_accuracy: 0.8747 - cat2_categorical_accuracy: 0.8671\n",
      "Epoch 641/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5230 - lin_loss: 0.0107 - cat1_loss: 0.2470 - cat2_loss: 0.2653 - lin_acc: 0.7391 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8690\n",
      "Epoch 642/1001\n",
      "8745/8745 [==============================] - 2s 261us/step - loss: 0.5212 - lin_loss: 0.0108 - cat1_loss: 0.2485 - cat2_loss: 0.2620 - lin_acc: 0.7380 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8704\n",
      "Epoch 643/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5194 - lin_loss: 0.0108 - cat1_loss: 0.2487 - cat2_loss: 0.2599 - lin_acc: 0.7403 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 644/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5205 - lin_loss: 0.0108 - cat1_loss: 0.2475 - cat2_loss: 0.2622 - lin_acc: 0.7389 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 645/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.5242 - lin_loss: 0.0108 - cat1_loss: 0.2470 - cat2_loss: 0.2665 - lin_acc: 0.7418 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 646/1001\n",
      "8745/8745 [==============================] - 3s 316us/step - loss: 0.5220 - lin_loss: 0.0107 - cat1_loss: 0.2483 - cat2_loss: 0.2630 - lin_acc: 0.7439 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.86641s - loss: 0.5215 - lin_loss: 0.0106 - cat1_loss: 0.2532 - cat2_loss: 0.2577 - lin_acc: 0.7421 - cat1_categorical_accuracy: 0.\n",
      "Epoch 647/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5219 - lin_loss: 0.0107 - cat1_loss: 0.2486 - cat2_loss: 0.2625 - lin_acc: 0.7377 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.87020s - loss: 0.5261 - lin_loss: 0.0108 - cat1_loss: 0.2506 - cat2_loss: 0.2647 - lin_acc: 0.7406 - cat1_categorical_accuracy: 0.8757 - cat2_categorica\n",
      "Epoch 648/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5213 - lin_loss: 0.0107 - cat1_loss: 0.2473 - cat2_loss: 0.2634 - lin_acc: 0.7433 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.8676\n",
      "Epoch 649/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5227 - lin_loss: 0.0108 - cat1_loss: 0.2481 - cat2_loss: 0.2638 - lin_acc: 0.7427 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8647\n",
      "Epoch 650/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5241 - lin_loss: 0.0107 - cat1_loss: 0.2487 - cat2_loss: 0.2648 - lin_acc: 0.7385 - cat1_categorical_accuracy: 0.8806 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 651/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5227 - lin_loss: 0.0107 - cat1_loss: 0.2488 - cat2_loss: 0.2632 - lin_acc: 0.7378 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8719\n",
      "Epoch 652/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5218 - lin_loss: 0.0108 - cat1_loss: 0.2482 - cat2_loss: 0.2628 - lin_acc: 0.7404 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8640\n",
      "Epoch 653/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5205 - lin_loss: 0.0107 - cat1_loss: 0.2475 - cat2_loss: 0.2623 - lin_acc: 0.7416 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8715\n",
      "Epoch 654/1001\n",
      "8745/8745 [==============================] - 3s 315us/step - loss: 0.5236 - lin_loss: 0.0107 - cat1_loss: 0.2484 - cat2_loss: 0.2646 - lin_acc: 0.7431 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8693\n",
      "Epoch 655/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5227 - lin_loss: 0.0108 - cat1_loss: 0.2478 - cat2_loss: 0.2641 - lin_acc: 0.7440 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 656/1001\n",
      "8745/8745 [==============================] - 3s 286us/step - loss: 0.5199 - lin_loss: 0.0107 - cat1_loss: 0.2477 - cat2_loss: 0.2615 - lin_acc: 0.7428 - cat1_categorical_accuracy: 0.8822 - cat2_categorical_accuracy: 0.87032s - loss: 0.5001 - lin_loss: 0.0107 - cat1_loss: 0.2486 - cat2_loss: 0.2408 - lin_acc: 0.\n",
      "Epoch 657/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5234 - lin_loss: 0.0107 - cat1_loss: 0.2495 - cat2_loss: 0.2632 - lin_acc: 0.7369 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.86691s - loss: 0.5156 - lin_loss: 0.0107 - cat1_loss: 0.2474 - cat2_loss: 0.2575 - lin_acc: 0.7375 - cat1_categorical_accuracy\n",
      "Epoch 658/1001\n",
      "8745/8745 [==============================] - 3s 304us/step - loss: 0.5217 - lin_loss: 0.0107 - cat1_loss: 0.2485 - cat2_loss: 0.2626 - lin_acc: 0.7431 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8679\n",
      "Epoch 659/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5227 - lin_loss: 0.0106 - cat1_loss: 0.2472 - cat2_loss: 0.2648 - lin_acc: 0.7445 - cat1_categorical_accuracy: 0.8765 - cat2_categorical_accuracy: 0.8675\n",
      "Epoch 660/1001\n",
      "8745/8745 [==============================] - 2s 265us/step - loss: 0.5194 - lin_loss: 0.0108 - cat1_loss: 0.2478 - cat2_loss: 0.2608 - lin_acc: 0.7421 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 661/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.5208 - lin_loss: 0.0106 - cat1_loss: 0.2498 - cat2_loss: 0.2604 - lin_acc: 0.7383 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.8698\n",
      "Epoch 662/1001\n",
      "8745/8745 [==============================] - 3s 302us/step - loss: 0.5200 - lin_loss: 0.0107 - cat1_loss: 0.2469 - cat2_loss: 0.2624 - lin_acc: 0.7413 - cat1_categorical_accuracy: 0.8802 - cat2_categorical_accuracy: 0.8707\n",
      "Epoch 663/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 0.5244 - lin_loss: 0.0107 - cat1_loss: 0.2495 - cat2_loss: 0.2642 - lin_acc: 0.7405 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 664/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5187 - lin_loss: 0.0106 - cat1_loss: 0.2479 - cat2_loss: 0.2602 - lin_acc: 0.7434 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.8730\n",
      "Epoch 665/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5226 - lin_loss: 0.0107 - cat1_loss: 0.2482 - cat2_loss: 0.2637 - lin_acc: 0.7400 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.86910s - loss: 0.5220 - lin_loss: 0.0108 - cat1_loss: 0.2499 - cat2_loss: 0.2614 - lin_acc: 0.7405 - cat1_categorical_accuracy: 0.8792 - cat2_categori\n",
      "Epoch 666/1001\n",
      "8745/8745 [==============================] - 2s 284us/step - loss: 0.5230 - lin_loss: 0.0107 - cat1_loss: 0.2481 - cat2_loss: 0.2642 - lin_acc: 0.7404 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 667/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5221 - lin_loss: 0.0106 - cat1_loss: 0.2473 - cat2_loss: 0.2642 - lin_acc: 0.7421 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 668/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5205 - lin_loss: 0.0106 - cat1_loss: 0.2469 - cat2_loss: 0.2630 - lin_acc: 0.7429 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.87170s - loss: 0.5146 - lin_loss: 0.0106 - cat1_loss: 0.2447 - cat2_loss: 0.2593 - lin_acc: 0.7439 - cat1_categorical_accuracy: 0.8786 - cat2_catego\n",
      "Epoch 669/1001\n",
      "8745/8745 [==============================] - 2s 286us/step - loss: 0.5183 - lin_loss: 0.0107 - cat1_loss: 0.2461 - cat2_loss: 0.2616 - lin_acc: 0.7410 - cat1_categorical_accuracy: 0.8792 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 670/1001\n",
      "8745/8745 [==============================] - 3s 296us/step - loss: 0.5192 - lin_loss: 0.0106 - cat1_loss: 0.2464 - cat2_loss: 0.2622 - lin_acc: 0.7400 - cat1_categorical_accuracy: 0.8790 - cat2_categorical_accuracy: 0.87030s - loss: 0.5222 - lin_loss: 0.0106 - cat1_loss: 0.2481 - cat2_loss: 0.2634 - lin_acc: 0.7391 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy\n",
      "Epoch 671/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 0.5165 - lin_loss: 0.0107 - cat1_loss: 0.2455 - cat2_loss: 0.2603 - lin_acc: 0.7401 - cat1_categorical_accuracy: 0.8792 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 672/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5245 - lin_loss: 0.0106 - cat1_loss: 0.2486 - cat2_loss: 0.2653 - lin_acc: 0.7420 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.8627\n",
      "Epoch 673/1001\n",
      "8745/8745 [==============================] - 3s 294us/step - loss: 0.5192 - lin_loss: 0.0106 - cat1_loss: 0.2473 - cat2_loss: 0.2613 - lin_acc: 0.7409 - cat1_categorical_accuracy: 0.8816 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 674/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5207 - lin_loss: 0.0106 - cat1_loss: 0.2479 - cat2_loss: 0.2622 - lin_acc: 0.7395 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 675/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5225 - lin_loss: 0.0107 - cat1_loss: 0.2485 - cat2_loss: 0.2633 - lin_acc: 0.7396 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 676/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5216 - lin_loss: 0.0106 - cat1_loss: 0.2475 - cat2_loss: 0.2634 - lin_acc: 0.7421 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.8703\n",
      "Epoch 677/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5189 - lin_loss: 0.0106 - cat1_loss: 0.2467 - cat2_loss: 0.2616 - lin_acc: 0.7405 - cat1_categorical_accuracy: 0.8790 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 678/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5189 - lin_loss: 0.0106 - cat1_loss: 0.2461 - cat2_loss: 0.2622 - lin_acc: 0.7432 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 679/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5200 - lin_loss: 0.0106 - cat1_loss: 0.2462 - cat2_loss: 0.2632 - lin_acc: 0.7419 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8674\n",
      "Epoch 680/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5231 - lin_loss: 0.0106 - cat1_loss: 0.2476 - cat2_loss: 0.2649 - lin_acc: 0.7432 - cat1_categorical_accuracy: 0.8762 - cat2_categorical_accuracy: 0.87010s - loss: 0.5251 - lin_loss: 0.0107 - cat1_loss: 0.2524 - cat2_loss: 0.2620 - lin_acc: 0.7371 - cat1_categorical_accuracy: 0.8739 - cat2_cate\n",
      "Epoch 681/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5181 - lin_loss: 0.0106 - cat1_loss: 0.2466 - cat2_loss: 0.2610 - lin_acc: 0.7441 - cat1_categorical_accuracy: 0.8794 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 682/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5172 - lin_loss: 0.0106 - cat1_loss: 0.2458 - cat2_loss: 0.2608 - lin_acc: 0.7429 - cat1_categorical_accuracy: 0.8790 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 683/1001\n",
      "8745/8745 [==============================] - 3s 291us/step - loss: 0.5232 - lin_loss: 0.0106 - cat1_loss: 0.2500 - cat2_loss: 0.2626 - lin_acc: 0.7436 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8693\n",
      "Epoch 684/1001\n",
      "8745/8745 [==============================] - 2s 264us/step - loss: 0.5202 - lin_loss: 0.0106 - cat1_loss: 0.2463 - cat2_loss: 0.2633 - lin_acc: 0.7448 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.86680s - loss: 0.5185 - lin_loss: 0.0106 - cat1_loss: 0.2453 - cat2_loss: 0.2626 - lin_acc: 0.7464 - cat1_categorical_accuracy: 0.8793 - cat2_categorical_accuracy: 0.\n",
      "Epoch 685/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5212 - lin_loss: 0.0107 - cat1_loss: 0.2487 - cat2_loss: 0.2618 - lin_acc: 0.7425 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8698\n",
      "Epoch 686/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5222 - lin_loss: 0.0106 - cat1_loss: 0.2472 - cat2_loss: 0.2644 - lin_acc: 0.7455 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 687/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5223 - lin_loss: 0.0106 - cat1_loss: 0.2477 - cat2_loss: 0.2640 - lin_acc: 0.7420 - cat1_categorical_accuracy: 0.8794 - cat2_categorical_accuracy: 0.86700s - loss: 0.5213 - lin_loss: 0.0106 - cat1_loss: 0.2501 - cat2_loss: 0.2605 - lin_acc: 0.7418 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_\n",
      "Epoch 688/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 0.5208 - lin_loss: 0.0106 - cat1_loss: 0.2490 - cat2_loss: 0.2612 - lin_acc: 0.7402 - cat1_categorical_accuracy: 0.8747 - cat2_categorical_accuracy: 0.8724\n",
      "Epoch 689/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5185 - lin_loss: 0.0106 - cat1_loss: 0.2456 - cat2_loss: 0.2622 - lin_acc: 0.7377 - cat1_categorical_accuracy: 0.8792 - cat2_categorical_accuracy: 0.8667\n",
      "Epoch 690/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5227 - lin_loss: 0.0106 - cat1_loss: 0.2469 - cat2_loss: 0.2653 - lin_acc: 0.7408 - cat1_categorical_accuracy: 0.8804 - cat2_categorical_accuracy: 0.8676\n",
      "Epoch 691/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5214 - lin_loss: 0.0106 - cat1_loss: 0.2484 - cat2_loss: 0.2624 - lin_acc: 0.7407 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8717\n",
      "Epoch 692/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5217 - lin_loss: 0.0106 - cat1_loss: 0.2474 - cat2_loss: 0.2638 - lin_acc: 0.7431 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.86781s - loss: 0.5148 - lin_loss: 0.0106 - cat1_loss: 0.2454 - cat2_loss: 0.2587 - lin_acc: 0.7460 - cat1_\n",
      "Epoch 693/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5227 - lin_loss: 0.0106 - cat1_loss: 0.2505 - cat2_loss: 0.2617 - lin_acc: 0.7433 - cat1_categorical_accuracy: 0.8762 - cat2_categorical_accuracy: 0.8704\n",
      "Epoch 694/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5219 - lin_loss: 0.0105 - cat1_loss: 0.2468 - cat2_loss: 0.2645 - lin_acc: 0.7409 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8677\n",
      "Epoch 695/1001\n",
      "8745/8745 [==============================] - 3s 301us/step - loss: 0.5245 - lin_loss: 0.0106 - cat1_loss: 0.2490 - cat2_loss: 0.2649 - lin_acc: 0.7435 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.86721s - loss: 0.5272 - lin_loss: 0.0105 - cat1_loss: 0.2521 - cat2_loss: 0.2646 - lin_acc: 0.7365 - cat1_categorical_accuracy: 0.\n",
      "Epoch 696/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5196 - lin_loss: 0.0105 - cat1_loss: 0.2462 - cat2_loss: 0.2630 - lin_acc: 0.7481 - cat1_categorical_accuracy: 0.8794 - cat2_categorical_accuracy: 0.86921s - loss: 0.5409 - lin_loss: 0.0106 - cat1_loss: 0.2571 - cat2_loss: 0.2732 - lin_acc: 0.7355 - cat1_categorical_accuracy: 0.8744 - - ETA: 0s - loss: 0.5288 - lin_loss: 0.0105 - cat1_loss: 0.2516 - cat2_loss: 0.2667 - lin_acc: 0.7446 - cat1_categorical_accuracy: 0.8768 - cat2_categori\n",
      "Epoch 697/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5211 - lin_loss: 0.0105 - cat1_loss: 0.2469 - cat2_loss: 0.2637 - lin_acc: 0.7461 - cat1_categorical_accuracy: 0.8792 - cat2_categorical_accuracy: 0.8679\n",
      "Epoch 698/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5195 - lin_loss: 0.0105 - cat1_loss: 0.2465 - cat2_loss: 0.2625 - lin_acc: 0.7465 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.86861s - loss: 0.5099 - lin_loss: 0.0105 - cat1_loss: 0.2448 - cat2_loss: 0.2546 - lin_acc: 0.7546 - cat1_categori\n",
      "Epoch 699/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 0.5206 - lin_loss: 0.0105 - cat1_loss: 0.2496 - cat2_loss: 0.2605 - lin_acc: 0.7476 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8702\n",
      "Epoch 700/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5192 - lin_loss: 0.0106 - cat1_loss: 0.2472 - cat2_loss: 0.2615 - lin_acc: 0.7424 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8695\n",
      "Epoch 701/1001\n",
      "8745/8745 [==============================] - 2s 284us/step - loss: 0.5178 - lin_loss: 0.0106 - cat1_loss: 0.2468 - cat2_loss: 0.2605 - lin_acc: 0.7418 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 702/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5190 - lin_loss: 0.0106 - cat1_loss: 0.2474 - cat2_loss: 0.2610 - lin_acc: 0.7425 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.86711s - loss: 0.5078 - lin_loss: 0.0104 - cat1_loss: 0.2428 - cat2_loss: 0.2546 - lin_acc: 0.7492 - cat1_categorical_accuracy: 0.8769 -\n",
      "Epoch 703/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5193 - lin_loss: 0.0105 - cat1_loss: 0.2461 - cat2_loss: 0.2628 - lin_acc: 0.7435 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.8667\n",
      "Epoch 704/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5199 - lin_loss: 0.0105 - cat1_loss: 0.2470 - cat2_loss: 0.2624 - lin_acc: 0.7408 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 705/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5223 - lin_loss: 0.0105 - cat1_loss: 0.2488 - cat2_loss: 0.2630 - lin_acc: 0.7418 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8679\n",
      "Epoch 706/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.5245 - lin_loss: 0.0105 - cat1_loss: 0.2506 - cat2_loss: 0.2633 - lin_acc: 0.7471 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.8668\n",
      "Epoch 707/1001\n",
      "8745/8745 [==============================] - 3s 302us/step - loss: 0.5223 - lin_loss: 0.0105 - cat1_loss: 0.2485 - cat2_loss: 0.2633 - lin_acc: 0.7415 - cat1_categorical_accuracy: 0.8814 - cat2_categorical_accuracy: 0.8668\n",
      "Epoch 708/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5192 - lin_loss: 0.0105 - cat1_loss: 0.2474 - cat2_loss: 0.2614 - lin_acc: 0.7449 - cat1_categorical_accuracy: 0.8783 - cat2_categorical_accuracy: 0.8700\n",
      "Epoch 709/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 0.5194 - lin_loss: 0.0105 - cat1_loss: 0.2472 - cat2_loss: 0.2617 - lin_acc: 0.7440 - cat1_categorical_accuracy: 0.8752 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 710/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5209 - lin_loss: 0.0105 - cat1_loss: 0.2456 - cat2_loss: 0.2648 - lin_acc: 0.7444 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.86672s - loss: 0.5221 - lin_loss: 0.0106 - cat1_loss: 0.2360 - cat2_loss: 0.2756 - lin_acc: 0.7450 - c\n",
      "Epoch 711/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5213 - lin_loss: 0.0104 - cat1_loss: 0.2482 - cat2_loss: 0.2627 - lin_acc: 0.7413 - cat1_categorical_accuracy: 0.8790 - cat2_categorical_accuracy: 0.86850s - loss: 0.5198 - lin_loss: 0.0105 - cat1_loss: 0.2484 - cat2_loss: 0.2609 - lin_acc: 0.7423 - cat1_categorical_accuracy: 0.8759 - cat2_categori\n",
      "Epoch 712/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5200 - lin_loss: 0.0105 - cat1_loss: 0.2467 - cat2_loss: 0.2629 - lin_acc: 0.7442 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.86850s - loss: 0.5211 - lin_loss: 0.0105 - cat1_loss: 0.2468 - cat2_loss: 0.2639 - lin_acc: 0.7442 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy\n",
      "Epoch 713/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 0.5197 - lin_loss: 0.0105 - cat1_loss: 0.2466 - cat2_loss: 0.2626 - lin_acc: 0.7426 - cat1_categorical_accuracy: 0.8755 - cat2_categorical_accuracy: 0.86911s - loss: 0.4956 - lin_loss: 0.0103 - cat1_loss: 0.2431 - cat2_loss: 0.2422 - lin_acc: 0.7507 - cat1_categori\n",
      "Epoch 714/1001\n",
      "8745/8745 [==============================] - ETA: 0s - loss: 0.5276 - lin_loss: 0.0105 - cat1_loss: 0.2505 - cat2_loss: 0.2667 - lin_acc: 0.7460 - cat1_categorical_accuracy: 0.8744 - cat2_categorical_accuracy: 0.86 - 3s 288us/step - loss: 0.5259 - lin_loss: 0.0104 - cat1_loss: 0.2490 - cat2_loss: 0.2665 - lin_acc: 0.7461 - cat1_categorical_accuracy: 0.8752 - cat2_categorical_accuracy: 0.8644\n",
      "Epoch 715/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5183 - lin_loss: 0.0105 - cat1_loss: 0.2477 - cat2_loss: 0.2602 - lin_acc: 0.7441 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 716/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5209 - lin_loss: 0.0105 - cat1_loss: 0.2478 - cat2_loss: 0.2627 - lin_acc: 0.7442 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8690\n",
      "Epoch 717/1001\n",
      "8745/8745 [==============================] - 3s 300us/step - loss: 0.5180 - lin_loss: 0.0105 - cat1_loss: 0.2457 - cat2_loss: 0.2619 - lin_acc: 0.7474 - cat1_categorical_accuracy: 0.8798 - cat2_categorical_accuracy: 0.8691\n",
      "Epoch 718/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5187 - lin_loss: 0.0105 - cat1_loss: 0.2474 - cat2_loss: 0.2609 - lin_acc: 0.7425 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 719/1001\n",
      "8745/8745 [==============================] - 3s 296us/step - loss: 0.5182 - lin_loss: 0.0105 - cat1_loss: 0.2462 - cat2_loss: 0.2616 - lin_acc: 0.7425 - cat1_categorical_accuracy: 0.8742 - cat2_categorical_accuracy: 0.8666\n",
      "Epoch 720/1001\n",
      "8745/8745 [==============================] - 2s 284us/step - loss: 0.5233 - lin_loss: 0.0104 - cat1_loss: 0.2485 - cat2_loss: 0.2643 - lin_acc: 0.7433 - cat1_categorical_accuracy: 0.8803 - cat2_categorical_accuracy: 0.8696\n",
      "Epoch 721/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5187 - lin_loss: 0.0104 - cat1_loss: 0.2479 - cat2_loss: 0.2604 - lin_acc: 0.7445 - cat1_categorical_accuracy: 0.8790 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 722/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5195 - lin_loss: 0.0104 - cat1_loss: 0.2466 - cat2_loss: 0.2624 - lin_acc: 0.7455 - cat1_categorical_accuracy: 0.8800 - cat2_categorical_accuracy: 0.8677\n",
      "Epoch 723/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5212 - lin_loss: 0.0105 - cat1_loss: 0.2481 - cat2_loss: 0.2626 - lin_acc: 0.7415 - cat1_categorical_accuracy: 0.8790 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 724/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 0.5197 - lin_loss: 0.0104 - cat1_loss: 0.2474 - cat2_loss: 0.2620 - lin_acc: 0.7485 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8710\n",
      "Epoch 725/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5161 - lin_loss: 0.0104 - cat1_loss: 0.2461 - cat2_loss: 0.2597 - lin_acc: 0.7457 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.8722\n",
      "Epoch 726/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5189 - lin_loss: 0.0104 - cat1_loss: 0.2460 - cat2_loss: 0.2624 - lin_acc: 0.7477 - cat1_categorical_accuracy: 0.8800 - cat2_categorical_accuracy: 0.86771s - loss: 0.5137 - lin_loss: 0.0103 - cat1_loss: 0.2492 - cat2_loss: 0.2542 - lin_acc: 0.7648 - cat1_catego\n",
      "Epoch 727/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5216 - lin_loss: 0.0104 - cat1_loss: 0.2479 - cat2_loss: 0.2632 - lin_acc: 0.7473 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.8671\n",
      "Epoch 728/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5175 - lin_loss: 0.0104 - cat1_loss: 0.2475 - cat2_loss: 0.2595 - lin_acc: 0.7476 - cat1_categorical_accuracy: 0.8762 - cat2_categorical_accuracy: 0.8706\n",
      "Epoch 729/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5256 - lin_loss: 0.0104 - cat1_loss: 0.2474 - cat2_loss: 0.2678 - lin_acc: 0.7479 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8675\n",
      "Epoch 730/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5179 - lin_loss: 0.0104 - cat1_loss: 0.2452 - cat2_loss: 0.2623 - lin_acc: 0.7439 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8677\n",
      "Epoch 731/1001\n",
      "8745/8745 [==============================] - 3s 300us/step - loss: 0.5186 - lin_loss: 0.0104 - cat1_loss: 0.2480 - cat2_loss: 0.2602 - lin_acc: 0.7460 - cat1_categorical_accuracy: 0.8798 - cat2_categorical_accuracy: 0.8711\n",
      "Epoch 732/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5175 - lin_loss: 0.0104 - cat1_loss: 0.2450 - cat2_loss: 0.2621 - lin_acc: 0.7488 - cat1_categorical_accuracy: 0.8783 - cat2_categorical_accuracy: 0.87022s - loss: 0.4861 - lin_loss: 0.0104 - cat1_loss: 0.2439 - cat2_loss: 0.2318 - lin_acc: 0.7506 - c\n",
      "Epoch 733/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5173 - lin_loss: 0.0104 - cat1_loss: 0.2463 - cat2_loss: 0.2607 - lin_acc: 0.7455 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8691\n",
      "Epoch 734/1001\n",
      "8745/8745 [==============================] - 3s 306us/step - loss: 0.5178 - lin_loss: 0.0104 - cat1_loss: 0.2466 - cat2_loss: 0.2608 - lin_acc: 0.7456 - cat1_categorical_accuracy: 0.8765 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 735/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5166 - lin_loss: 0.0103 - cat1_loss: 0.2457 - cat2_loss: 0.2605 - lin_acc: 0.7508 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 736/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5197 - lin_loss: 0.0104 - cat1_loss: 0.2479 - cat2_loss: 0.2614 - lin_acc: 0.7466 - cat1_categorical_accuracy: 0.8794 - cat2_categorical_accuracy: 0.8707\n",
      "Epoch 737/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5191 - lin_loss: 0.0104 - cat1_loss: 0.2464 - cat2_loss: 0.2624 - lin_acc: 0.7455 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8675\n",
      "Epoch 738/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5210 - lin_loss: 0.0104 - cat1_loss: 0.2479 - cat2_loss: 0.2628 - lin_acc: 0.7489 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.8668\n",
      "Epoch 739/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5173 - lin_loss: 0.0104 - cat1_loss: 0.2464 - cat2_loss: 0.2605 - lin_acc: 0.7466 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.8704\n",
      "Epoch 740/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5175 - lin_loss: 0.0104 - cat1_loss: 0.2470 - cat2_loss: 0.2601 - lin_acc: 0.7441 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.86870s - loss: 0.5078 - lin_loss: 0.0104 - cat1_loss: 0.2401 - cat2_loss: 0.2572 - lin_acc: 0.7450 - cat1_categorical_accuracy: 0.8809 - cat2_cate\n",
      "Epoch 741/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5313 - lin_loss: 0.0104 - cat1_loss: 0.2472 - cat2_loss: 0.2737 - lin_acc: 0.7443 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8639\n",
      "Epoch 742/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5185 - lin_loss: 0.0104 - cat1_loss: 0.2479 - cat2_loss: 0.2603 - lin_acc: 0.7500 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.8720\n",
      "Epoch 743/1001\n",
      "8745/8745 [==============================] - 3s 309us/step - loss: 0.5173 - lin_loss: 0.0104 - cat1_loss: 0.2471 - cat2_loss: 0.2598 - lin_acc: 0.7457 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 744/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5182 - lin_loss: 0.0105 - cat1_loss: 0.2462 - cat2_loss: 0.2615 - lin_acc: 0.7505 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8672\n",
      "Epoch 745/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5172 - lin_loss: 0.0104 - cat1_loss: 0.2461 - cat2_loss: 0.2607 - lin_acc: 0.7450 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8710\n",
      "Epoch 746/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5188 - lin_loss: 0.0103 - cat1_loss: 0.2474 - cat2_loss: 0.2611 - lin_acc: 0.7451 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.8707\n",
      "Epoch 747/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5185 - lin_loss: 0.0103 - cat1_loss: 0.2464 - cat2_loss: 0.2617 - lin_acc: 0.7463 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 748/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5163 - lin_loss: 0.0103 - cat1_loss: 0.2469 - cat2_loss: 0.2591 - lin_acc: 0.7461 - cat1_categorical_accuracy: 0.8812 - cat2_categorical_accuracy: 0.8709\n",
      "Epoch 749/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5212 - lin_loss: 0.0104 - cat1_loss: 0.2479 - cat2_loss: 0.2630 - lin_acc: 0.7469 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 750/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5196 - lin_loss: 0.0104 - cat1_loss: 0.2464 - cat2_loss: 0.2628 - lin_acc: 0.7496 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8703\n",
      "Epoch 751/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5200 - lin_loss: 0.0104 - cat1_loss: 0.2479 - cat2_loss: 0.2617 - lin_acc: 0.7457 - cat1_categorical_accuracy: 0.8798 - cat2_categorical_accuracy: 0.8710\n",
      "Epoch 752/1001\n",
      "8745/8745 [==============================] - 3s 286us/step - loss: 0.5195 - lin_loss: 0.0104 - cat1_loss: 0.2447 - cat2_loss: 0.2644 - lin_acc: 0.7483 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.86770s - loss: 0.5104 - lin_loss: 0.0104 - cat1_loss: 0.2416 - cat2_loss: 0.2584 - lin_acc: 0.7496 - cat1_categorical_accuracy: 0.8813 - c\n",
      "Epoch 753/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5166 - lin_loss: 0.0104 - cat1_loss: 0.2464 - cat2_loss: 0.2599 - lin_acc: 0.7485 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8698\n",
      "Epoch 754/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5193 - lin_loss: 0.0103 - cat1_loss: 0.2484 - cat2_loss: 0.2606 - lin_acc: 0.7464 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.87231s - loss: 0.5025 - lin_loss: 0.0101 - cat1_loss: 0.2397 - cat2_loss: 0.2526 - lin_acc: 0.7515 - cat1_ca\n",
      "Epoch 755/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5173 - lin_loss: 0.0104 - cat1_loss: 0.2467 - cat2_loss: 0.2601 - lin_acc: 0.7428 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8659\n",
      "Epoch 756/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 3s 304us/step - loss: 0.5183 - lin_loss: 0.0103 - cat1_loss: 0.2468 - cat2_loss: 0.2613 - lin_acc: 0.7449 - cat1_categorical_accuracy: 0.8765 - cat2_categorical_accuracy: 0.86840s - loss: 0.5175 - lin_loss: 0.0103 - cat1_loss: 0.2467 - cat2_loss: 0.2606 - lin_acc: 0.7444 - cat1_categorical_accuracy: 0.8765 - cat2_categorical_accuracy: 0.86\n",
      "Epoch 757/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5160 - lin_loss: 0.0104 - cat1_loss: 0.2459 - cat2_loss: 0.2597 - lin_acc: 0.7477 - cat1_categorical_accuracy: 0.8796 - cat2_categorical_accuracy: 0.8695\n",
      "Epoch 758/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5195 - lin_loss: 0.0103 - cat1_loss: 0.2474 - cat2_loss: 0.2618 - lin_acc: 0.7475 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 759/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5216 - lin_loss: 0.0103 - cat1_loss: 0.2475 - cat2_loss: 0.2637 - lin_acc: 0.7491 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8704\n",
      "Epoch 760/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5149 - lin_loss: 0.0103 - cat1_loss: 0.2451 - cat2_loss: 0.2595 - lin_acc: 0.7476 - cat1_categorical_accuracy: 0.8765 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 761/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5183 - lin_loss: 0.0103 - cat1_loss: 0.2466 - cat2_loss: 0.2614 - lin_acc: 0.7452 - cat1_categorical_accuracy: 0.8803 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 762/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5168 - lin_loss: 0.0102 - cat1_loss: 0.2462 - cat2_loss: 0.2603 - lin_acc: 0.7498 - cat1_categorical_accuracy: 0.8805 - cat2_categorical_accuracy: 0.8714\n",
      "Epoch 763/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5174 - lin_loss: 0.0103 - cat1_loss: 0.2457 - cat2_loss: 0.2614 - lin_acc: 0.7466 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.8679\n",
      "Epoch 764/1001\n",
      "8745/8745 [==============================] - 3s 302us/step - loss: 0.5171 - lin_loss: 0.0103 - cat1_loss: 0.2464 - cat2_loss: 0.2604 - lin_acc: 0.7513 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.8674\n",
      "Epoch 765/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5173 - lin_loss: 0.0104 - cat1_loss: 0.2461 - cat2_loss: 0.2608 - lin_acc: 0.7457 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8693\n",
      "Epoch 766/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 0.5207 - lin_loss: 0.0103 - cat1_loss: 0.2486 - cat2_loss: 0.2618 - lin_acc: 0.7472 - cat1_categorical_accuracy: 0.8758 - cat2_categorical_accuracy: 0.8663\n",
      "Epoch 767/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5165 - lin_loss: 0.0103 - cat1_loss: 0.2466 - cat2_loss: 0.2597 - lin_acc: 0.7487 - cat1_categorical_accuracy: 0.8760 - cat2_categorical_accuracy: 0.8690\n",
      "Epoch 768/1001\n",
      "8745/8745 [==============================] - 3s 301us/step - loss: 0.5173 - lin_loss: 0.0103 - cat1_loss: 0.2462 - cat2_loss: 0.2608 - lin_acc: 0.7448 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 769/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5180 - lin_loss: 0.0103 - cat1_loss: 0.2461 - cat2_loss: 0.2616 - lin_acc: 0.7447 - cat1_categorical_accuracy: 0.8783 - cat2_categorical_accuracy: 0.8704\n",
      "Epoch 770/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5215 - lin_loss: 0.0102 - cat1_loss: 0.2487 - cat2_loss: 0.2625 - lin_acc: 0.7487 - cat1_categorical_accuracy: 0.8762 - cat2_categorical_accuracy: 0.86752s - loss: 0.5009 - lin_loss: 0.0101 - cat1_loss: 0.2453 - cat2_loss: 0.2456 - lin_acc: 0.7440 - cat\n",
      "Epoch 771/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5170 - lin_loss: 0.0104 - cat1_loss: 0.2466 - cat2_loss: 0.2600 - lin_acc: 0.7463 - cat1_categorical_accuracy: 0.8788 - cat2_categorical_accuracy: 0.86772s - loss: 0.5147 - lin_loss: 0.0102 - cat1_loss: 0.2525 - cat2_loss: 0.2521 - lin_acc: 0.7471 - cat1_categorical_accuracy: 0.8735 - cat2_categorical_accuracy: 0.87 - ETA: 1s - loss: 0.5092 - lin_loss: 0.0101 - cat1_loss: 0.2459 - cat2_loss: 0.2532 - lin_acc: 0.7461 - cat1_\n",
      "Epoch 772/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5179 - lin_loss: 0.0103 - cat1_loss: 0.2459 - cat2_loss: 0.2617 - lin_acc: 0.7474 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 773/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5168 - lin_loss: 0.0103 - cat1_loss: 0.2467 - cat2_loss: 0.2599 - lin_acc: 0.7474 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8680\n",
      "Epoch 774/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5190 - lin_loss: 0.0102 - cat1_loss: 0.2460 - cat2_loss: 0.2628 - lin_acc: 0.7484 - cat1_categorical_accuracy: 0.8798 - cat2_categorical_accuracy: 0.8664\n",
      "Epoch 775/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5190 - lin_loss: 0.0103 - cat1_loss: 0.2468 - cat2_loss: 0.2619 - lin_acc: 0.7477 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.8667\n",
      "Epoch 776/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5175 - lin_loss: 0.0103 - cat1_loss: 0.2467 - cat2_loss: 0.2605 - lin_acc: 0.7477 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 777/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5187 - lin_loss: 0.0103 - cat1_loss: 0.2462 - cat2_loss: 0.2622 - lin_acc: 0.7447 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8680\n",
      "Epoch 778/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5161 - lin_loss: 0.0102 - cat1_loss: 0.2463 - cat2_loss: 0.2597 - lin_acc: 0.7496 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.8680\n",
      "Epoch 779/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5200 - lin_loss: 0.0103 - cat1_loss: 0.2468 - cat2_loss: 0.2629 - lin_acc: 0.7487 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8695\n",
      "Epoch 780/1001\n",
      "8745/8745 [==============================] - 3s 304us/step - loss: 0.5188 - lin_loss: 0.0102 - cat1_loss: 0.2462 - cat2_loss: 0.2623 - lin_acc: 0.7499 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.87020s - loss: 0.5189 - lin_loss: 0.0102 - cat1_loss: 0.2465 - cat2_loss: 0.2621 - lin_acc: 0.7501 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.87\n",
      "Epoch 781/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5175 - lin_loss: 0.0104 - cat1_loss: 0.2470 - cat2_loss: 0.2602 - lin_acc: 0.7464 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.8703\n",
      "Epoch 782/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5178 - lin_loss: 0.0103 - cat1_loss: 0.2464 - cat2_loss: 0.2611 - lin_acc: 0.7481 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.86990s - loss: 0.5169 - lin_loss: 0.0103 - cat1_loss: 0.2452 - cat2_loss: 0.2614 - lin_acc: 0.7484 - cat1_categorical_accuracy: 0.8775 - c\n",
      "Epoch 783/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5161 - lin_loss: 0.0103 - cat1_loss: 0.2457 - cat2_loss: 0.2601 - lin_acc: 0.7501 - cat1_categorical_accuracy: 0.8792 - cat2_categorical_accuracy: 0.8693\n",
      "Epoch 784/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 0.5150 - lin_loss: 0.0102 - cat1_loss: 0.2453 - cat2_loss: 0.2595 - lin_acc: 0.7529 - cat1_categorical_accuracy: 0.8758 - cat2_categorical_accuracy: 0.8712\n",
      "Epoch 785/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5183 - lin_loss: 0.0103 - cat1_loss: 0.2478 - cat2_loss: 0.2603 - lin_acc: 0.7475 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 786/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5152 - lin_loss: 0.0103 - cat1_loss: 0.2445 - cat2_loss: 0.2604 - lin_acc: 0.7493 - cat1_categorical_accuracy: 0.8786 - cat2_categorical_accuracy: 0.8691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 787/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5184 - lin_loss: 0.0103 - cat1_loss: 0.2466 - cat2_loss: 0.2615 - lin_acc: 0.7457 - cat1_categorical_accuracy: 0.8783 - cat2_categorical_accuracy: 0.86800s - loss: 0.5114 - lin_loss: 0.0102 - cat1_loss: 0.2435 - cat2_loss: 0.2577 - lin_acc: 0.7487 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.87 - ETA: 0s - loss: 0.5159 - lin_loss: 0.0102 - cat1_loss: 0.2466 - cat2_loss: 0.2591 - lin_acc: 0.7475 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy - ETA: 0s - loss: 0.5177 - lin_loss: 0.0102 - cat1_loss: 0.2461 - cat2_loss: 0.2614 - lin_acc: 0.7462 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy\n",
      "Epoch 788/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5159 - lin_loss: 0.0102 - cat1_loss: 0.2448 - cat2_loss: 0.2608 - lin_acc: 0.7503 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 789/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5164 - lin_loss: 0.0103 - cat1_loss: 0.2461 - cat2_loss: 0.2600 - lin_acc: 0.7484 - cat1_categorical_accuracy: 0.8791 - cat2_categorical_accuracy: 0.8710\n",
      "Epoch 790/1001\n",
      "8745/8745 [==============================] - 3s 286us/step - loss: 0.5163 - lin_loss: 0.0102 - cat1_loss: 0.2454 - cat2_loss: 0.2606 - lin_acc: 0.7483 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.86861s - loss: 0.4966 - lin_loss: 0.0100 - cat1_loss: 0.2319 - cat2_loss: 0.2546 - lin_acc: 0.7602 - cat1_categorical_accuracy: 0.8876 - cat2_categorical_accuracy: 0. - ETA: 1s - loss: 0.5012 - lin_loss: 0.0100 - cat1_loss: 0.2323 - cat2_loss: 0.2588 - lin_acc: 0.7591 - cat1_categorical_ac - ETA: 0s - loss: 0.5104 - lin_loss: 0.0102 - cat1_loss: 0.2407 - cat2_loss: 0.2595 - lin_acc: 0.7508 - cat1_categorical_accuracy: 0.8823 - cat2_categorical_\n",
      "Epoch 791/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5184 - lin_loss: 0.0102 - cat1_loss: 0.2475 - cat2_loss: 0.2607 - lin_acc: 0.7473 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8686\n",
      "Epoch 792/1001\n",
      "8745/8745 [==============================] - 3s 296us/step - loss: 0.5157 - lin_loss: 0.0103 - cat1_loss: 0.2456 - cat2_loss: 0.2598 - lin_acc: 0.7441 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8702\n",
      "Epoch 793/1001\n",
      "8745/8745 [==============================] - 2s 286us/step - loss: 0.5177 - lin_loss: 0.0103 - cat1_loss: 0.2454 - cat2_loss: 0.2620 - lin_acc: 0.7485 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8691\n",
      "Epoch 794/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5163 - lin_loss: 0.0102 - cat1_loss: 0.2444 - cat2_loss: 0.2617 - lin_acc: 0.7468 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8683\n",
      "Epoch 795/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.5155 - lin_loss: 0.0102 - cat1_loss: 0.2455 - cat2_loss: 0.2597 - lin_acc: 0.7487 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.8707\n",
      "Epoch 796/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5170 - lin_loss: 0.0102 - cat1_loss: 0.2468 - cat2_loss: 0.2600 - lin_acc: 0.7513 - cat1_categorical_accuracy: 0.8792 - cat2_categorical_accuracy: 0.8688\n",
      "Epoch 797/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5139 - lin_loss: 0.0102 - cat1_loss: 0.2450 - cat2_loss: 0.2587 - lin_acc: 0.7484 - cat1_categorical_accuracy: 0.8796 - cat2_categorical_accuracy: 0.87200s - loss: 0.5059 - lin_loss: 0.0101 - cat1_loss: 0.2386 - cat2_loss: 0.2572 - lin_acc: 0.7496 - cat1_categorical_accuracy: 0.8822 -\n",
      "Epoch 798/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5179 - lin_loss: 0.0102 - cat1_loss: 0.2459 - cat2_loss: 0.2618 - lin_acc: 0.7521 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 799/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5179 - lin_loss: 0.0102 - cat1_loss: 0.2467 - cat2_loss: 0.2609 - lin_acc: 0.7477 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8704\n",
      "Epoch 800/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5158 - lin_loss: 0.0102 - cat1_loss: 0.2466 - cat2_loss: 0.2591 - lin_acc: 0.7483 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8693\n",
      "Epoch 801/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5182 - lin_loss: 0.0103 - cat1_loss: 0.2475 - cat2_loss: 0.2604 - lin_acc: 0.7433 - cat1_categorical_accuracy: 0.8786 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 802/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5168 - lin_loss: 0.0102 - cat1_loss: 0.2458 - cat2_loss: 0.2608 - lin_acc: 0.7484 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 803/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5182 - lin_loss: 0.0102 - cat1_loss: 0.2474 - cat2_loss: 0.2606 - lin_acc: 0.7505 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.8679\n",
      "Epoch 804/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5166 - lin_loss: 0.0102 - cat1_loss: 0.2452 - cat2_loss: 0.2611 - lin_acc: 0.7507 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8661\n",
      "Epoch 805/1001\n",
      "8745/8745 [==============================] - 3s 320us/step - loss: 0.5187 - lin_loss: 0.0102 - cat1_loss: 0.2469 - cat2_loss: 0.2616 - lin_acc: 0.7496 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 806/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5165 - lin_loss: 0.0102 - cat1_loss: 0.2463 - cat2_loss: 0.2600 - lin_acc: 0.7481 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8696\n",
      "Epoch 807/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5194 - lin_loss: 0.0102 - cat1_loss: 0.2467 - cat2_loss: 0.2625 - lin_acc: 0.7520 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8675\n",
      "Epoch 808/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.5259 - lin_loss: 0.0102 - cat1_loss: 0.2463 - cat2_loss: 0.2694 - lin_acc: 0.7482 - cat1_categorical_accuracy: 0.8826 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 809/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5168 - lin_loss: 0.0102 - cat1_loss: 0.2455 - cat2_loss: 0.2611 - lin_acc: 0.7500 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 810/1001\n",
      "8745/8745 [==============================] - 3s 291us/step - loss: 0.5161 - lin_loss: 0.0102 - cat1_loss: 0.2455 - cat2_loss: 0.2605 - lin_acc: 0.7488 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.8690\n",
      "Epoch 811/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 0.5144 - lin_loss: 0.0101 - cat1_loss: 0.2451 - cat2_loss: 0.2591 - lin_acc: 0.7489 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 812/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5211 - lin_loss: 0.0102 - cat1_loss: 0.2472 - cat2_loss: 0.2638 - lin_acc: 0.7513 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8659\n",
      "Epoch 813/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5170 - lin_loss: 0.0102 - cat1_loss: 0.2464 - cat2_loss: 0.2604 - lin_acc: 0.7491 - cat1_categorical_accuracy: 0.8799 - cat2_categorical_accuracy: 0.8675\n",
      "Epoch 814/1001\n",
      "8745/8745 [==============================] - 3s 286us/step - loss: 0.5179 - lin_loss: 0.0102 - cat1_loss: 0.2476 - cat2_loss: 0.2601 - lin_acc: 0.7460 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.87000s - loss: 0.5177 - lin_loss: 0.0101 - cat1_loss: 0.2521 - cat2_loss: 0.2555 - lin_acc: 0.7472 - cat1_categorical_accuracy: 0.8773 - cat2_\n",
      "Epoch 815/1001\n",
      "8745/8745 [==============================] - 3s 307us/step - loss: 0.5157 - lin_loss: 0.0102 - cat1_loss: 0.2451 - cat2_loss: 0.2603 - lin_acc: 0.7476 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8707\n",
      "Epoch 816/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 3s 290us/step - loss: 0.5160 - lin_loss: 0.0101 - cat1_loss: 0.2474 - cat2_loss: 0.2585 - lin_acc: 0.7507 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.86992s - loss: 0.4800 - lin_loss: 0.0098 - cat1_loss: 0.2328 - cat2_loss: 0.2374 - lin_acc: 0.75\n",
      "Epoch 817/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 0.5170 - lin_loss: 0.0102 - cat1_loss: 0.2455 - cat2_loss: 0.2612 - lin_acc: 0.7503 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.87112s - loss: 0.4977 - lin_loss: 0.0106 - cat1_loss: 0.2349 - cat2_loss: 0.2522 - lin_acc: 0.7555 - cat1_ca\n",
      "Epoch 818/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5129 - lin_loss: 0.0102 - cat1_loss: 0.2440 - cat2_loss: 0.2587 - lin_acc: 0.7484 - cat1_categorical_accuracy: 0.8805 - cat2_categorical_accuracy: 0.8661\n",
      "Epoch 819/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5182 - lin_loss: 0.0101 - cat1_loss: 0.2474 - cat2_loss: 0.2606 - lin_acc: 0.7503 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.8677\n",
      "Epoch 820/1001\n",
      "8745/8745 [==============================] - 3s 291us/step - loss: 0.5151 - lin_loss: 0.0101 - cat1_loss: 0.2452 - cat2_loss: 0.2598 - lin_acc: 0.7527 - cat1_categorical_accuracy: 0.8786 - cat2_categorical_accuracy: 0.8710\n",
      "Epoch 821/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5141 - lin_loss: 0.0102 - cat1_loss: 0.2455 - cat2_loss: 0.2584 - lin_acc: 0.7529 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8693\n",
      "Epoch 822/1001\n",
      "8745/8745 [==============================] - 3s 286us/step - loss: 0.5150 - lin_loss: 0.0101 - cat1_loss: 0.2459 - cat2_loss: 0.2589 - lin_acc: 0.7524 - cat1_categorical_accuracy: 0.8800 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 823/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5171 - lin_loss: 0.0101 - cat1_loss: 0.2472 - cat2_loss: 0.2597 - lin_acc: 0.7520 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 824/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 0.5177 - lin_loss: 0.0103 - cat1_loss: 0.2464 - cat2_loss: 0.2610 - lin_acc: 0.7481 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.86770s - loss: 0.5187 - lin_loss: 0.0103 - cat1_loss: 0.2470 - cat2_loss: 0.2614 - lin_acc: 0.7492 - cat1_categorical_accuracy: 0.8782 - cat2_\n",
      "Epoch 825/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5182 - lin_loss: 0.0102 - cat1_loss: 0.2467 - cat2_loss: 0.2613 - lin_acc: 0.7497 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.8676\n",
      "Epoch 826/1001\n",
      "8745/8745 [==============================] - 2s 285us/step - loss: 0.5149 - lin_loss: 0.0102 - cat1_loss: 0.2444 - cat2_loss: 0.2604 - lin_acc: 0.7522 - cat1_categorical_accuracy: 0.8804 - cat2_categorical_accuracy: 0.8703\n",
      "Epoch 827/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5146 - lin_loss: 0.0101 - cat1_loss: 0.2449 - cat2_loss: 0.2596 - lin_acc: 0.7509 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.86681s - loss: 0.5186 - lin_loss: 0.0103 - cat1_loss: 0.2413 - cat2_loss: 0.2670 - lin_acc: 0.7521 - cat1_categorical_accuracy\n",
      "Epoch 828/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5187 - lin_loss: 0.0102 - cat1_loss: 0.2461 - cat2_loss: 0.2624 - lin_acc: 0.7507 - cat1_categorical_accuracy: 0.8802 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 829/1001\n",
      "8745/8745 [==============================] - 3s 299us/step - loss: 0.5187 - lin_loss: 0.0101 - cat1_loss: 0.2467 - cat2_loss: 0.2619 - lin_acc: 0.7515 - cat1_categorical_accuracy: 0.8751 - cat2_categorical_accuracy: 0.8666\n",
      "Epoch 830/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5181 - lin_loss: 0.0101 - cat1_loss: 0.2455 - cat2_loss: 0.2625 - lin_acc: 0.7492 - cat1_categorical_accuracy: 0.8800 - cat2_categorical_accuracy: 0.8703\n",
      "Epoch 831/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 0.5174 - lin_loss: 0.0102 - cat1_loss: 0.2458 - cat2_loss: 0.2614 - lin_acc: 0.7473 - cat1_categorical_accuracy: 0.8790 - cat2_categorical_accuracy: 0.8652\n",
      "Epoch 832/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 0.5150 - lin_loss: 0.0101 - cat1_loss: 0.2453 - cat2_loss: 0.2597 - lin_acc: 0.7483 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 833/1001\n",
      "8745/8745 [==============================] - 3s 342us/step - loss: 0.5171 - lin_loss: 0.0101 - cat1_loss: 0.2476 - cat2_loss: 0.2594 - lin_acc: 0.7513 - cat1_categorical_accuracy: 0.8754 - cat2_categorical_accuracy: 0.8696\n",
      "Epoch 834/1001\n",
      "8745/8745 [==============================] - 3s 319us/step - loss: 0.5151 - lin_loss: 0.0101 - cat1_loss: 0.2467 - cat2_loss: 0.2583 - lin_acc: 0.7531 - cat1_categorical_accuracy: 0.8790 - cat2_categorical_accuracy: 0.86881s - loss: 0.5128 - lin_loss: 0.0103 - cat1_loss: 0.2469 - cat2_loss: 0.2556 - lin_acc: 0.7475 - cat\n",
      "Epoch 835/1001\n",
      "8745/8745 [==============================] - 3s 315us/step - loss: 0.5180 - lin_loss: 0.0101 - cat1_loss: 0.2463 - cat2_loss: 0.2616 - lin_acc: 0.7485 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8654\n",
      "Epoch 836/1001\n",
      "8745/8745 [==============================] - 3s 317us/step - loss: 0.5134 - lin_loss: 0.0101 - cat1_loss: 0.2438 - cat2_loss: 0.2594 - lin_acc: 0.7516 - cat1_categorical_accuracy: 0.8794 - cat2_categorical_accuracy: 0.8714\n",
      "Epoch 837/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5211 - lin_loss: 0.0101 - cat1_loss: 0.2485 - cat2_loss: 0.2624 - lin_acc: 0.7493 - cat1_categorical_accuracy: 0.8756 - cat2_categorical_accuracy: 0.86741s - loss: 0.5004 - lin_loss: 0.0102 - cat1_loss: 0.2432 - cat2_loss: 0.2470 - lin_acc: 0.7608 - cat1_cate\n",
      "Epoch 838/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5150 - lin_loss: 0.0101 - cat1_loss: 0.2445 - cat2_loss: 0.2604 - lin_acc: 0.7508 - cat1_categorical_accuracy: 0.8799 - cat2_categorical_accuracy: 0.8678\n",
      "Epoch 839/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5159 - lin_loss: 0.0101 - cat1_loss: 0.2459 - cat2_loss: 0.2599 - lin_acc: 0.7517 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8690\n",
      "Epoch 840/1001\n",
      "8745/8745 [==============================] - 3s 304us/step - loss: 0.5142 - lin_loss: 0.0102 - cat1_loss: 0.2449 - cat2_loss: 0.2591 - lin_acc: 0.7467 - cat1_categorical_accuracy: 0.8826 - cat2_categorical_accuracy: 0.8709\n",
      "Epoch 841/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5157 - lin_loss: 0.0102 - cat1_loss: 0.2448 - cat2_loss: 0.2607 - lin_acc: 0.7497 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 842/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5149 - lin_loss: 0.0101 - cat1_loss: 0.2454 - cat2_loss: 0.2593 - lin_acc: 0.7547 - cat1_categorical_accuracy: 0.8797 - cat2_categorical_accuracy: 0.86630s - loss: 0.5152 - lin_loss: 0.0102 - cat1_loss: 0.2455 - cat2_loss: 0.2596 - lin_acc: 0.7548 - cat1_categorical_accuracy: 0.8792 - cat2_categorical_accuracy\n",
      "Epoch 843/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5170 - lin_loss: 0.0101 - cat1_loss: 0.2459 - cat2_loss: 0.2611 - lin_acc: 0.7501 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 844/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5164 - lin_loss: 0.0101 - cat1_loss: 0.2461 - cat2_loss: 0.2603 - lin_acc: 0.7514 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 845/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5163 - lin_loss: 0.0101 - cat1_loss: 0.2469 - cat2_loss: 0.2593 - lin_acc: 0.7514 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 846/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5244 - lin_loss: 0.0101 - cat1_loss: 0.2497 - cat2_loss: 0.2646 - lin_acc: 0.7529 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8675\n",
      "Epoch 847/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5282 - lin_loss: 0.0101 - cat1_loss: 0.2456 - cat2_loss: 0.2725 - lin_acc: 0.7505 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.8660\n",
      "Epoch 848/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5168 - lin_loss: 0.0101 - cat1_loss: 0.2440 - cat2_loss: 0.2626 - lin_acc: 0.7520 - cat1_categorical_accuracy: 0.8791 - cat2_categorical_accuracy: 0.8701\n",
      "Epoch 849/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5204 - lin_loss: 0.0101 - cat1_loss: 0.2482 - cat2_loss: 0.2620 - lin_acc: 0.7487 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 850/1001\n",
      "8745/8745 [==============================] - 3s 314us/step - loss: 0.5130 - lin_loss: 0.0101 - cat1_loss: 0.2451 - cat2_loss: 0.2579 - lin_acc: 0.7532 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 851/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5125 - lin_loss: 0.0101 - cat1_loss: 0.2434 - cat2_loss: 0.2590 - lin_acc: 0.7530 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.8717\n",
      "Epoch 852/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 0.5155 - lin_loss: 0.0100 - cat1_loss: 0.2466 - cat2_loss: 0.2588 - lin_acc: 0.7543 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8703\n",
      "Epoch 853/1001\n",
      "8745/8745 [==============================] - 3s 311us/step - loss: 0.5143 - lin_loss: 0.0101 - cat1_loss: 0.2463 - cat2_loss: 0.2579 - lin_acc: 0.7524 - cat1_categorical_accuracy: 0.8797 - cat2_categorical_accuracy: 0.8717\n",
      "Epoch 854/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5149 - lin_loss: 0.0101 - cat1_loss: 0.2456 - cat2_loss: 0.2592 - lin_acc: 0.7511 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8702\n",
      "Epoch 855/1001\n",
      "8745/8745 [==============================] - 3s 324us/step - loss: 0.5143 - lin_loss: 0.0101 - cat1_loss: 0.2455 - cat2_loss: 0.2587 - lin_acc: 0.7537 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8710\n",
      "Epoch 856/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5172 - lin_loss: 0.0101 - cat1_loss: 0.2456 - cat2_loss: 0.2615 - lin_acc: 0.7499 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8670\n",
      "Epoch 857/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 0.5225 - lin_loss: 0.0101 - cat1_loss: 0.2449 - cat2_loss: 0.2675 - lin_acc: 0.7521 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.86510s - loss: 0.5202 - lin_loss: 0.0100 - cat1_loss: 0.2429 - cat2_loss: 0.2673 - lin_acc: 0.7524 - cat1_categorical_accuracy: 0.8797 - cat2_categorical_ac\n",
      "Epoch 858/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.5143 - lin_loss: 0.0101 - cat1_loss: 0.2436 - cat2_loss: 0.2606 - lin_acc: 0.7501 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 859/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5183 - lin_loss: 0.0100 - cat1_loss: 0.2450 - cat2_loss: 0.2632 - lin_acc: 0.7563 - cat1_categorical_accuracy: 0.8792 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 860/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.5175 - lin_loss: 0.0100 - cat1_loss: 0.2471 - cat2_loss: 0.2603 - lin_acc: 0.7520 - cat1_categorical_accuracy: 0.8799 - cat2_categorical_accuracy: 0.8701\n",
      "Epoch 861/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5297 - lin_loss: 0.0101 - cat1_loss: 0.2610 - cat2_loss: 0.2586 - lin_acc: 0.7548 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.8725\n",
      "Epoch 862/1001\n",
      "8745/8745 [==============================] - 3s 301us/step - loss: 0.5280 - lin_loss: 0.0101 - cat1_loss: 0.2602 - cat2_loss: 0.2577 - lin_acc: 0.7512 - cat1_categorical_accuracy: 0.8743 - cat2_categorical_accuracy: 0.87221s - loss: 0.5578 - lin_loss: 0.0101 - cat1_loss: 0.2902 - cat2_loss: 0.2575 - lin_acc: 0.7425\n",
      "Epoch 863/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5166 - lin_loss: 0.0100 - cat1_loss: 0.2461 - cat2_loss: 0.2604 - lin_acc: 0.7538 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.8727\n",
      "Epoch 864/1001\n",
      "8745/8745 [==============================] - 3s 308us/step - loss: 0.5136 - lin_loss: 0.0100 - cat1_loss: 0.2434 - cat2_loss: 0.2601 - lin_acc: 0.7505 - cat1_categorical_accuracy: 0.8805 - cat2_categorical_accuracy: 0.8672\n",
      "Epoch 865/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5116 - lin_loss: 0.0102 - cat1_loss: 0.2438 - cat2_loss: 0.2576 - lin_acc: 0.7493 - cat1_categorical_accuracy: 0.8813 - cat2_categorical_accuracy: 0.8716\n",
      "Epoch 866/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5118 - lin_loss: 0.0101 - cat1_loss: 0.2436 - cat2_loss: 0.2581 - lin_acc: 0.7512 - cat1_categorical_accuracy: 0.8804 - cat2_categorical_accuracy: 0.8710\n",
      "Epoch 867/1001\n",
      "8745/8745 [==============================] - 3s 294us/step - loss: 0.5123 - lin_loss: 0.0100 - cat1_loss: 0.2443 - cat2_loss: 0.2580 - lin_acc: 0.7536 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.8728\n",
      "Epoch 868/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5161 - lin_loss: 0.0100 - cat1_loss: 0.2449 - cat2_loss: 0.2611 - lin_acc: 0.7501 - cat1_categorical_accuracy: 0.8807 - cat2_categorical_accuracy: 0.8700\n",
      "Epoch 869/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5185 - lin_loss: 0.0101 - cat1_loss: 0.2459 - cat2_loss: 0.2625 - lin_acc: 0.7532 - cat1_categorical_accuracy: 0.8783 - cat2_categorical_accuracy: 0.8660\n",
      "Epoch 870/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5138 - lin_loss: 0.0101 - cat1_loss: 0.2440 - cat2_loss: 0.2598 - lin_acc: 0.7545 - cat1_categorical_accuracy: 0.8807 - cat2_categorical_accuracy: 0.8672\n",
      "Epoch 871/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5144 - lin_loss: 0.0101 - cat1_loss: 0.2447 - cat2_loss: 0.2597 - lin_acc: 0.7512 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 872/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5135 - lin_loss: 0.0100 - cat1_loss: 0.2446 - cat2_loss: 0.2589 - lin_acc: 0.7528 - cat1_categorical_accuracy: 0.8812 - cat2_categorical_accuracy: 0.8700\n",
      "Epoch 873/1001\n",
      "8745/8745 [==============================] - 2s 277us/step - loss: 0.5145 - lin_loss: 0.0100 - cat1_loss: 0.2444 - cat2_loss: 0.2602 - lin_acc: 0.7508 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.8676\n",
      "Epoch 874/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5168 - lin_loss: 0.0100 - cat1_loss: 0.2448 - cat2_loss: 0.2619 - lin_acc: 0.7537 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 875/1001\n",
      "8745/8745 [==============================] - 2s 275us/step - loss: 0.5147 - lin_loss: 0.0101 - cat1_loss: 0.2443 - cat2_loss: 0.2603 - lin_acc: 0.7528 - cat1_categorical_accuracy: 0.8794 - cat2_categorical_accuracy: 0.8715\n",
      "Epoch 876/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 0.5160 - lin_loss: 0.0101 - cat1_loss: 0.2454 - cat2_loss: 0.2604 - lin_acc: 0.7488 - cat1_categorical_accuracy: 0.8806 - cat2_categorical_accuracy: 0.86980s - loss: 0.5153 - lin_loss: 0.0101 - cat1_loss: 0.2462 - cat2_loss: 0.2590 - lin_acc: 0.7504 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.\n",
      "Epoch 877/1001\n",
      "8745/8745 [==============================] - 3s 301us/step - loss: 0.5139 - lin_loss: 0.0101 - cat1_loss: 0.2457 - cat2_loss: 0.2581 - lin_acc: 0.7520 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8718\n",
      "Epoch 878/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5133 - lin_loss: 0.0101 - cat1_loss: 0.2444 - cat2_loss: 0.2589 - lin_acc: 0.7538 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 879/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5156 - lin_loss: 0.0100 - cat1_loss: 0.2461 - cat2_loss: 0.2595 - lin_acc: 0.7481 - cat1_categorical_accuracy: 0.8802 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 880/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5136 - lin_loss: 0.0101 - cat1_loss: 0.2456 - cat2_loss: 0.2579 - lin_acc: 0.7529 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8717\n",
      "Epoch 881/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5199 - lin_loss: 0.0100 - cat1_loss: 0.2478 - cat2_loss: 0.2621 - lin_acc: 0.7511 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8676\n",
      "Epoch 882/1001\n",
      "8745/8745 [==============================] - 2s 284us/step - loss: 0.5154 - lin_loss: 0.0101 - cat1_loss: 0.2445 - cat2_loss: 0.2609 - lin_acc: 0.7503 - cat1_categorical_accuracy: 0.8803 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 883/1001\n",
      "8745/8745 [==============================] - 2s 284us/step - loss: 0.5146 - lin_loss: 0.0100 - cat1_loss: 0.2461 - cat2_loss: 0.2584 - lin_acc: 0.7497 - cat1_categorical_accuracy: 0.8767 - cat2_categorical_accuracy: 0.86960s - loss: 0.5162 - lin_loss: 0.0099 - cat1_loss: 0.2499 - cat2_loss: 0.2565 - lin_acc: 0.7487 - cat1_categorical_accuracy: 0.8775 - cat2_ca\n",
      "Epoch 884/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5134 - lin_loss: 0.0101 - cat1_loss: 0.2443 - cat2_loss: 0.2591 - lin_acc: 0.7549 - cat1_categorical_accuracy: 0.8802 - cat2_categorical_accuracy: 0.8704\n",
      "Epoch 885/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5157 - lin_loss: 0.0100 - cat1_loss: 0.2453 - cat2_loss: 0.2604 - lin_acc: 0.7485 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.8656\n",
      "Epoch 886/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5184 - lin_loss: 0.0100 - cat1_loss: 0.2460 - cat2_loss: 0.2624 - lin_acc: 0.7511 - cat1_categorical_accuracy: 0.8762 - cat2_categorical_accuracy: 0.8671\n",
      "Epoch 887/1001\n",
      "8745/8745 [==============================] - 2s 265us/step - loss: 0.5160 - lin_loss: 0.0100 - cat1_loss: 0.2458 - cat2_loss: 0.2602 - lin_acc: 0.7577 - cat1_categorical_accuracy: 0.8808 - cat2_categorical_accuracy: 0.8702\n",
      "Epoch 888/1001\n",
      "8745/8745 [==============================] - 3s 286us/step - loss: 0.5140 - lin_loss: 0.0100 - cat1_loss: 0.2449 - cat2_loss: 0.2591 - lin_acc: 0.7544 - cat1_categorical_accuracy: 0.8788 - cat2_categorical_accuracy: 0.8700\n",
      "Epoch 889/1001\n",
      "8745/8745 [==============================] - 3s 303us/step - loss: 0.5139 - lin_loss: 0.0100 - cat1_loss: 0.2457 - cat2_loss: 0.2581 - lin_acc: 0.7505 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8726\n",
      "Epoch 890/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5129 - lin_loss: 0.0100 - cat1_loss: 0.2434 - cat2_loss: 0.2595 - lin_acc: 0.7530 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8690\n",
      "Epoch 891/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5148 - lin_loss: 0.0101 - cat1_loss: 0.2463 - cat2_loss: 0.2585 - lin_acc: 0.7531 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.86831s - loss: 0.5088 - lin_loss: 0.0100 - cat1_loss: 0.2487 - cat2_loss: 0.2501 - lin_acc: 0.7518 - cat\n",
      "Epoch 892/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5149 - lin_loss: 0.0100 - cat1_loss: 0.2458 - cat2_loss: 0.2591 - lin_acc: 0.7511 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.86832s - loss: 0.5285 - lin_loss: 0.0103 - cat1_loss: 0.2429 - cat2_loss: 0.2752 - lin_acc: \n",
      "Epoch 893/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5175 - lin_loss: 0.0100 - cat1_loss: 0.2459 - cat2_loss: 0.2616 - lin_acc: 0.7515 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.86721s - loss: 0.5297 - lin_loss: 0.0099 - cat1_loss: 0.2549 - cat2_loss: 0.2649 - lin_acc: 0.7510 - cat1_categorical_accura\n",
      "Epoch 894/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5178 - lin_loss: 0.0100 - cat1_loss: 0.2451 - cat2_loss: 0.2628 - lin_acc: 0.7533 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8660\n",
      "Epoch 895/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5160 - lin_loss: 0.0101 - cat1_loss: 0.2466 - cat2_loss: 0.2593 - lin_acc: 0.7524 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8693\n",
      "Epoch 896/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.5164 - lin_loss: 0.0100 - cat1_loss: 0.2455 - cat2_loss: 0.2609 - lin_acc: 0.7551 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8686\n",
      "Epoch 897/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5146 - lin_loss: 0.0100 - cat1_loss: 0.2441 - cat2_loss: 0.2605 - lin_acc: 0.7529 - cat1_categorical_accuracy: 0.8799 - cat2_categorical_accuracy: 0.8679\n",
      "Epoch 898/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5170 - lin_loss: 0.0101 - cat1_loss: 0.2467 - cat2_loss: 0.2603 - lin_acc: 0.7545 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8666\n",
      "Epoch 899/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5153 - lin_loss: 0.0100 - cat1_loss: 0.2450 - cat2_loss: 0.2603 - lin_acc: 0.7501 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.8690\n",
      "Epoch 900/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5186 - lin_loss: 0.0100 - cat1_loss: 0.2459 - cat2_loss: 0.2627 - lin_acc: 0.7511 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8656\n",
      "Epoch 901/1001\n",
      "8745/8745 [==============================] - 3s 300us/step - loss: 0.5170 - lin_loss: 0.0101 - cat1_loss: 0.2461 - cat2_loss: 0.2608 - lin_acc: 0.7471 - cat1_categorical_accuracy: 0.8749 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 902/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5183 - lin_loss: 0.0100 - cat1_loss: 0.2480 - cat2_loss: 0.2603 - lin_acc: 0.7530 - cat1_categorical_accuracy: 0.8740 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 903/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5145 - lin_loss: 0.0100 - cat1_loss: 0.2459 - cat2_loss: 0.2586 - lin_acc: 0.7498 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8712\n",
      "Epoch 904/1001\n",
      "8745/8745 [==============================] - 2s 271us/step - loss: 0.5156 - lin_loss: 0.0100 - cat1_loss: 0.2452 - cat2_loss: 0.2604 - lin_acc: 0.7557 - cat1_categorical_accuracy: 0.8806 - cat2_categorical_accuracy: 0.8698\n",
      "Epoch 905/1001\n",
      "8745/8745 [==============================] - 3s 301us/step - loss: 0.5150 - lin_loss: 0.0099 - cat1_loss: 0.2458 - cat2_loss: 0.2593 - lin_acc: 0.7573 - cat1_categorical_accuracy: 0.8749 - cat2_categorical_accuracy: 0.8710\n",
      "Epoch 906/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5134 - lin_loss: 0.0100 - cat1_loss: 0.2432 - cat2_loss: 0.2602 - lin_acc: 0.7520 - cat1_categorical_accuracy: 0.8804 - cat2_categorical_accuracy: 0.87040s - loss: 0.5127 - lin_loss: 0.0100 - cat1_loss: 0.2420 - cat2_loss: 0.2607 - lin_acc: 0.7521 - cat1_categorical_accuracy: 0.8808 - cat2_categorical_accuracy: 0.87\n",
      "Epoch 907/1001\n",
      "8745/8745 [==============================] - 5s 533us/step - loss: 0.5174 - lin_loss: 0.0100 - cat1_loss: 0.2480 - cat2_loss: 0.2594 - lin_acc: 0.7539 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.8702\n",
      "Epoch 908/1001\n",
      "8745/8745 [==============================] - 3s 302us/step - loss: 0.5138 - lin_loss: 0.0100 - cat1_loss: 0.2448 - cat2_loss: 0.2590 - lin_acc: 0.7516 - cat1_categorical_accuracy: 0.8800 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 909/1001\n",
      "8745/8745 [==============================] - 4s 450us/step - loss: 0.5135 - lin_loss: 0.0099 - cat1_loss: 0.2450 - cat2_loss: 0.2586 - lin_acc: 0.7562 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.87232s - loss: 0.5162 - lin_loss: 0.0096 - cat1_loss: 0.23\n",
      "Epoch 910/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 4s 458us/step - loss: 0.5145 - lin_loss: 0.0100 - cat1_loss: 0.2451 - cat2_loss: 0.2594 - lin_acc: 0.7537 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 911/1001\n",
      "8745/8745 [==============================] - 3s 326us/step - loss: 0.5155 - lin_loss: 0.0100 - cat1_loss: 0.2453 - cat2_loss: 0.2603 - lin_acc: 0.7559 - cat1_categorical_accuracy: 0.8784 - cat2_categorical_accuracy: 0.87032s - loss: 0.5447 - lin_loss: 0.0103 - cat1_loss: 0.2574 - cat2_loss: 0.2770 - lin_acc: 0.7396 -\n",
      "Epoch 912/1001\n",
      "8745/8745 [==============================] - 3s 318us/step - loss: 0.5138 - lin_loss: 0.0100 - cat1_loss: 0.2442 - cat2_loss: 0.2596 - lin_acc: 0.7524 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8696\n",
      "Epoch 913/1001\n",
      "8745/8745 [==============================] - 3s 378us/step - loss: 0.5148 - lin_loss: 0.0100 - cat1_loss: 0.2451 - cat2_loss: 0.2597 - lin_acc: 0.7515 - cat1_categorical_accuracy: 0.8790 - cat2_categorical_accuracy: 0.86942s - loss: 0.5134 - lin_loss: 0.0100 - cat1_loss: 0.2372 - cat2_loss: 0.2662 - lin_acc: 0.7484 - cat1_cate\n",
      "Epoch 914/1001\n",
      "8745/8745 [==============================] - ETA: 0s - loss: 0.5127 - lin_loss: 0.0099 - cat1_loss: 0.2451 - cat2_loss: 0.2577 - lin_acc: 0.7562 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.86 - 3s 322us/step - loss: 0.5128 - lin_loss: 0.0099 - cat1_loss: 0.2452 - cat2_loss: 0.2577 - lin_acc: 0.7561 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8696\n",
      "Epoch 915/1001\n",
      "8745/8745 [==============================] - 3s 294us/step - loss: 0.5207 - lin_loss: 0.0100 - cat1_loss: 0.2462 - cat2_loss: 0.2644 - lin_acc: 0.7545 - cat1_categorical_accuracy: 0.8754 - cat2_categorical_accuracy: 0.8679\n",
      "Epoch 916/1001\n",
      "8745/8745 [==============================] - 3s 310us/step - loss: 0.5175 - lin_loss: 0.0100 - cat1_loss: 0.2449 - cat2_loss: 0.2626 - lin_acc: 0.7562 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.87162s - loss: 0.5050 - lin_loss: 0.0105 - cat1_loss: 0.2368 - cat2_loss: 0.2576 - lin\n",
      "Epoch 917/1001\n",
      "8745/8745 [==============================] - 3s 356us/step - loss: 0.5118 - lin_loss: 0.0100 - cat1_loss: 0.2445 - cat2_loss: 0.2574 - lin_acc: 0.7539 - cat1_categorical_accuracy: 0.8762 - cat2_categorical_accuracy: 0.8722\n",
      "Epoch 918/1001\n",
      "8745/8745 [==============================] - 3s 349us/step - loss: 0.5136 - lin_loss: 0.0099 - cat1_loss: 0.2439 - cat2_loss: 0.2598 - lin_acc: 0.7559 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.87160s - loss: 0.5146 - lin_loss: 0.0098 - cat1_loss: 0.2426 - cat2_loss: 0.2621 - lin_acc: 0.7584 - cat1_categorical_accuracy: 0.8789 - c\n",
      "Epoch 919/1001\n",
      "8745/8745 [==============================] - 4s 407us/step - loss: 0.5144 - lin_loss: 0.0099 - cat1_loss: 0.2446 - cat2_loss: 0.2598 - lin_acc: 0.7537 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 920/1001\n",
      "8745/8745 [==============================] - 4s 442us/step - loss: 0.5148 - lin_loss: 0.0100 - cat1_loss: 0.2442 - cat2_loss: 0.2606 - lin_acc: 0.7507 - cat1_categorical_accuracy: 0.8811 - cat2_categorical_accuracy: 0.87001s - loss: 0.5147 - lin_loss: 0.0100 - cat1_loss: 0.2467 - cat2_loss: 0.2579 - lin_acc: 0.7542 - cat1_categorical_accuracy: 0.88\n",
      "Epoch 921/1001\n",
      "8745/8745 [==============================] - 4s 422us/step - loss: 0.5145 - lin_loss: 0.0099 - cat1_loss: 0.2448 - cat2_loss: 0.2597 - lin_acc: 0.7543 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 922/1001\n",
      "8745/8745 [==============================] - 3s 310us/step - loss: 0.5125 - lin_loss: 0.0100 - cat1_loss: 0.2447 - cat2_loss: 0.2578 - lin_acc: 0.7548 - cat1_categorical_accuracy: 0.8752 - cat2_categorical_accuracy: 0.87170s - loss: 0.5109 - lin_loss: 0.0099 - cat1_loss: 0.2425 - cat2_loss: 0.2585 - lin_acc: 0.7564 - cat1_categorical_accuracy: 0.8776 - cat2_categori\n",
      "Epoch 923/1001\n",
      "8745/8745 [==============================] - 3s 355us/step - loss: 0.5145 - lin_loss: 0.0099 - cat1_loss: 0.2449 - cat2_loss: 0.2598 - lin_acc: 0.7536 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.8700\n",
      "Epoch 924/1001\n",
      "8745/8745 [==============================] - 4s 405us/step - loss: 0.5135 - lin_loss: 0.0099 - cat1_loss: 0.2446 - cat2_loss: 0.2589 - lin_acc: 0.7513 - cat1_categorical_accuracy: 0.8786 - cat2_categorical_accuracy: 0.8688\n",
      "Epoch 925/1001\n",
      "8745/8745 [==============================] - 3s 335us/step - loss: 0.5162 - lin_loss: 0.0100 - cat1_loss: 0.2463 - cat2_loss: 0.2599 - lin_acc: 0.7496 - cat1_categorical_accuracy: 0.8763 - cat2_categorical_accuracy: 0.8671\n",
      "Epoch 926/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5141 - lin_loss: 0.0100 - cat1_loss: 0.2453 - cat2_loss: 0.2589 - lin_acc: 0.7541 - cat1_categorical_accuracy: 0.8799 - cat2_categorical_accuracy: 0.8709\n",
      "Epoch 927/1001\n",
      "8745/8745 [==============================] - 3s 291us/step - loss: 0.5120 - lin_loss: 0.0099 - cat1_loss: 0.2435 - cat2_loss: 0.2586 - lin_acc: 0.7535 - cat1_categorical_accuracy: 0.8792 - cat2_categorical_accuracy: 0.8698\n",
      "Epoch 928/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5134 - lin_loss: 0.0099 - cat1_loss: 0.2452 - cat2_loss: 0.2583 - lin_acc: 0.7541 - cat1_categorical_accuracy: 0.8747 - cat2_categorical_accuracy: 0.8662\n",
      "Epoch 929/1001\n",
      "8745/8745 [==============================] - 3s 296us/step - loss: 0.5141 - lin_loss: 0.0099 - cat1_loss: 0.2457 - cat2_loss: 0.2585 - lin_acc: 0.7579 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.86980s - loss: 0.5093 - lin_loss: 0.0099 - cat1_loss: 0.2409 - cat2_loss: 0.2586 - lin_acc: 0.7573 - cat1_categorical_accuracy: 0.8815 - cat\n",
      "Epoch 930/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5128 - lin_loss: 0.0099 - cat1_loss: 0.2444 - cat2_loss: 0.2585 - lin_acc: 0.7555 - cat1_categorical_accuracy: 0.8799 - cat2_categorical_accuracy: 0.87001s - loss: 0.5214 - lin_loss: 0.0099 - cat1_loss: 0.2494 - cat2_loss: 0.2620 - lin_acc: 0.7408 - cat1_categorical_\n",
      "Epoch 931/1001\n",
      "8745/8745 [==============================] - 3s 316us/step - loss: 0.5131 - lin_loss: 0.0099 - cat1_loss: 0.2441 - cat2_loss: 0.2591 - lin_acc: 0.7555 - cat1_categorical_accuracy: 0.8788 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 932/1001\n",
      "8745/8745 [==============================] - 3s 319us/step - loss: 0.5180 - lin_loss: 0.0100 - cat1_loss: 0.2448 - cat2_loss: 0.2632 - lin_acc: 0.7513 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.8698\n",
      "Epoch 933/1001\n",
      "8745/8745 [==============================] - 3s 344us/step - loss: 0.5131 - lin_loss: 0.0099 - cat1_loss: 0.2455 - cat2_loss: 0.2577 - lin_acc: 0.7577 - cat1_categorical_accuracy: 0.8750 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 934/1001\n",
      "8745/8745 [==============================] - 3s 296us/step - loss: 0.5143 - lin_loss: 0.0099 - cat1_loss: 0.2442 - cat2_loss: 0.2602 - lin_acc: 0.7573 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 935/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 0.5139 - lin_loss: 0.0099 - cat1_loss: 0.2451 - cat2_loss: 0.2589 - lin_acc: 0.7559 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8715\n",
      "Epoch 936/1001\n",
      "8745/8745 [==============================] - 3s 310us/step - loss: 0.5128 - lin_loss: 0.0100 - cat1_loss: 0.2447 - cat2_loss: 0.2581 - lin_acc: 0.7531 - cat1_categorical_accuracy: 0.8835 - cat2_categorical_accuracy: 0.8720\n",
      "Epoch 937/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.5116 - lin_loss: 0.0100 - cat1_loss: 0.2442 - cat2_loss: 0.2575 - lin_acc: 0.7495 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8688\n",
      "Epoch 938/1001\n",
      "8745/8745 [==============================] - 3s 293us/step - loss: 0.5130 - lin_loss: 0.0099 - cat1_loss: 0.2449 - cat2_loss: 0.2581 - lin_acc: 0.7547 - cat1_categorical_accuracy: 0.8758 - cat2_categorical_accuracy: 0.86911s - loss: 0.5116 - lin_loss: 0.0101 - cat1_loss: 0.2410 - cat2_loss: 0.2606 - lin_acc: 0.7518 - cat1_categori\n",
      "Epoch 939/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5134 - lin_loss: 0.0100 - cat1_loss: 0.2444 - cat2_loss: 0.2590 - lin_acc: 0.7519 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8712\n",
      "Epoch 940/1001\n",
      "8745/8745 [==============================] - 3s 349us/step - loss: 0.5148 - lin_loss: 0.0099 - cat1_loss: 0.2456 - cat2_loss: 0.2592 - lin_acc: 0.7540 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.86760s - loss: 0.5139 - lin_loss: 0.0100 - cat1_loss: 0.2436 - cat2_loss: 0.2603 - lin_acc: 0.7574 - cat1_categorical_accuracy: 0.8780 - c\n",
      "Epoch 941/1001\n",
      "8745/8745 [==============================] - 2s 272us/step - loss: 0.5147 - lin_loss: 0.0099 - cat1_loss: 0.2458 - cat2_loss: 0.2590 - lin_acc: 0.7527 - cat1_categorical_accuracy: 0.8766 - cat2_categorical_accuracy: 0.8693\n",
      "Epoch 942/1001\n",
      "8745/8745 [==============================] - 3s 314us/step - loss: 0.5152 - lin_loss: 0.0099 - cat1_loss: 0.2441 - cat2_loss: 0.2613 - lin_acc: 0.7548 - cat1_categorical_accuracy: 0.8779 - cat2_categorical_accuracy: 0.86941s - loss: 0.5102 - lin_loss: 0.0098 - cat1_loss: 0.2425 - cat2_loss: 0.2579 - lin_acc: 0.7561 - cat\n",
      "Epoch 943/1001\n",
      "8745/8745 [==============================] - 3s 288us/step - loss: 0.5127 - lin_loss: 0.0100 - cat1_loss: 0.2443 - cat2_loss: 0.2584 - lin_acc: 0.7547 - cat1_categorical_accuracy: 0.8788 - cat2_categorical_accuracy: 0.8694\n",
      "Epoch 944/1001\n",
      "8745/8745 [==============================] - 3s 290us/step - loss: 0.5169 - lin_loss: 0.0099 - cat1_loss: 0.2475 - cat2_loss: 0.2595 - lin_acc: 0.7559 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 945/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 0.5130 - lin_loss: 0.0099 - cat1_loss: 0.2449 - cat2_loss: 0.2583 - lin_acc: 0.7553 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 946/1001\n",
      "8745/8745 [==============================] - 2s 284us/step - loss: 0.5149 - lin_loss: 0.0100 - cat1_loss: 0.2454 - cat2_loss: 0.2595 - lin_acc: 0.7527 - cat1_categorical_accuracy: 0.8792 - cat2_categorical_accuracy: 0.86871s - loss: 0.5057 - lin_loss: 0.0101 - cat1_loss: 0.2369 - cat2_loss: 0.2587 - lin_acc: 0.7480 - cat1_categorical_ac\n",
      "Epoch 947/1001\n",
      "8745/8745 [==============================] - 3s 294us/step - loss: 0.5142 - lin_loss: 0.0099 - cat1_loss: 0.2449 - cat2_loss: 0.2594 - lin_acc: 0.7563 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.8688\n",
      "Epoch 948/1001\n",
      "8745/8745 [==============================] - 3s 297us/step - loss: 0.5134 - lin_loss: 0.0099 - cat1_loss: 0.2451 - cat2_loss: 0.2584 - lin_acc: 0.7543 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.8716\n",
      "Epoch 949/1001\n",
      "8745/8745 [==============================] - 3s 309us/step - loss: 0.5130 - lin_loss: 0.0099 - cat1_loss: 0.2455 - cat2_loss: 0.2576 - lin_acc: 0.7522 - cat1_categorical_accuracy: 0.8806 - cat2_categorical_accuracy: 0.8709\n",
      "Epoch 950/1001\n",
      "8745/8745 [==============================] - 3s 300us/step - loss: 0.5143 - lin_loss: 0.0099 - cat1_loss: 0.2452 - cat2_loss: 0.2592 - lin_acc: 0.7539 - cat1_categorical_accuracy: 0.8758 - cat2_categorical_accuracy: 0.8701\n",
      "Epoch 951/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5153 - lin_loss: 0.0099 - cat1_loss: 0.2466 - cat2_loss: 0.2588 - lin_acc: 0.7567 - cat1_categorical_accuracy: 0.8798 - cat2_categorical_accuracy: 0.87020s - loss: 0.5157 - lin_loss: 0.0099 - cat1_loss: 0.2476 - cat2_loss: 0.2582 - lin_acc: 0.7565 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.87\n",
      "Epoch 952/1001\n",
      "8745/8745 [==============================] - 3s 320us/step - loss: 0.5126 - lin_loss: 0.0099 - cat1_loss: 0.2441 - cat2_loss: 0.2586 - lin_acc: 0.7528 - cat1_categorical_accuracy: 0.8783 - cat2_categorical_accuracy: 0.8711\n",
      "Epoch 953/1001\n",
      "8745/8745 [==============================] - 3s 314us/step - loss: 0.5165 - lin_loss: 0.0099 - cat1_loss: 0.2446 - cat2_loss: 0.2620 - lin_acc: 0.7525 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.8685\n",
      "Epoch 954/1001\n",
      "8745/8745 [==============================] - 3s 304us/step - loss: 0.5161 - lin_loss: 0.0099 - cat1_loss: 0.2468 - cat2_loss: 0.2594 - lin_acc: 0.7531 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 955/1001\n",
      "8745/8745 [==============================] - 3s 304us/step - loss: 0.5133 - lin_loss: 0.0099 - cat1_loss: 0.2449 - cat2_loss: 0.2585 - lin_acc: 0.7529 - cat1_categorical_accuracy: 0.8794 - cat2_categorical_accuracy: 0.8690\n",
      "Epoch 956/1001\n",
      "8745/8745 [==============================] - 3s 300us/step - loss: 0.5153 - lin_loss: 0.0099 - cat1_loss: 0.2449 - cat2_loss: 0.2605 - lin_acc: 0.7563 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.8686\n",
      "Epoch 957/1001\n",
      "8745/8745 [==============================] - 2s 282us/step - loss: 0.5135 - lin_loss: 0.0099 - cat1_loss: 0.2444 - cat2_loss: 0.2592 - lin_acc: 0.7557 - cat1_categorical_accuracy: 0.8799 - cat2_categorical_accuracy: 0.8695\n",
      "Epoch 958/1001\n",
      "8745/8745 [==============================] - 3s 301us/step - loss: 0.5115 - lin_loss: 0.0099 - cat1_loss: 0.2441 - cat2_loss: 0.2574 - lin_acc: 0.7557 - cat1_categorical_accuracy: 0.8810 - cat2_categorical_accuracy: 0.8724\n",
      "Epoch 959/1001\n",
      "8745/8745 [==============================] - 3s 312us/step - loss: 0.5131 - lin_loss: 0.0099 - cat1_loss: 0.2448 - cat2_loss: 0.2585 - lin_acc: 0.7539 - cat1_categorical_accuracy: 0.8786 - cat2_categorical_accuracy: 0.8701\n",
      "Epoch 960/1001\n",
      "8745/8745 [==============================] - 2s 262us/step - loss: 0.5123 - lin_loss: 0.0099 - cat1_loss: 0.2455 - cat2_loss: 0.2569 - lin_acc: 0.7548 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.8719\n",
      "Epoch 961/1001\n",
      "8745/8745 [==============================] - 3s 354us/step - loss: 0.5111 - lin_loss: 0.0099 - cat1_loss: 0.2439 - cat2_loss: 0.2574 - lin_acc: 0.7560 - cat1_categorical_accuracy: 0.8799 - cat2_categorical_accuracy: 0.87221s - loss: 0.5107 - lin_loss: 0.0098 - cat1_loss: 0.2461 - cat2_loss: 0.2548 - lin_acc: 0.7595 - cat1_categorical_accuracy\n",
      "Epoch 962/1001\n",
      "8745/8745 [==============================] - 4s 464us/step - loss: 0.5142 - lin_loss: 0.0099 - cat1_loss: 0.2444 - cat2_loss: 0.2599 - lin_acc: 0.7504 - cat1_categorical_accuracy: 0.8790 - cat2_categorical_accuracy: 0.86923s - loss: 0.5030 - lin_loss: 0.0098 - cat1_loss: 0.2405 - cat2_loss: 0.2528 -\n",
      "Epoch 963/1001\n",
      "8745/8745 [==============================] - 3s 324us/step - loss: 0.5142 - lin_loss: 0.0099 - cat1_loss: 0.2459 - cat2_loss: 0.2584 - lin_acc: 0.7536 - cat1_categorical_accuracy: 0.8773 - cat2_categorical_accuracy: 0.8699\n",
      "Epoch 964/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5149 - lin_loss: 0.0099 - cat1_loss: 0.2447 - cat2_loss: 0.2603 - lin_acc: 0.7512 - cat1_categorical_accuracy: 0.8791 - cat2_categorical_accuracy: 0.8700\n",
      "Epoch 965/1001\n",
      "8745/8745 [==============================] - 3s 313us/step - loss: 0.5143 - lin_loss: 0.0099 - cat1_loss: 0.2465 - cat2_loss: 0.2580 - lin_acc: 0.7532 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8671\n",
      "Epoch 966/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5133 - lin_loss: 0.0098 - cat1_loss: 0.2442 - cat2_loss: 0.2593 - lin_acc: 0.7570 - cat1_categorical_accuracy: 0.8796 - cat2_categorical_accuracy: 0.8682\n",
      "Epoch 967/1001\n",
      "8745/8745 [==============================] - 3s 318us/step - loss: 0.5149 - lin_loss: 0.0099 - cat1_loss: 0.2443 - cat2_loss: 0.2607 - lin_acc: 0.7559 - cat1_categorical_accuracy: 0.8790 - cat2_categorical_accuracy: 0.8693\n",
      "Epoch 968/1001\n",
      "8745/8745 [==============================] - 3s 307us/step - loss: 0.5132 - lin_loss: 0.0099 - cat1_loss: 0.2450 - cat2_loss: 0.2583 - lin_acc: 0.7554 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.86770s - loss: 0.5139 - lin_loss: 0.0099 - cat1_loss: 0.2426 - cat2_loss: 0.2614 - lin_acc: 0.7562 - cat1_categorical_accuracy: 0.8782 - cat2_categorical_accura - ETA: 0s - loss: 0.5138 - lin_loss: 0.0099 - cat1_loss: 0.2455 - cat2_loss: 0.2584 - lin_acc: 0.7560 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.\n",
      "Epoch 969/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 3s 286us/step - loss: 0.5139 - lin_loss: 0.0099 - cat1_loss: 0.2447 - cat2_loss: 0.2594 - lin_acc: 0.7549 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.86981s - loss: 0.4890 - lin_loss: 0.0098 - cat1_loss: 0.2343 - cat2_loss: 0.2448 - lin_acc: 0.7588 - cat1_categorica\n",
      "Epoch 970/1001\n",
      "8745/8745 [==============================] - 2s 280us/step - loss: 0.5122 - lin_loss: 0.0099 - cat1_loss: 0.2441 - cat2_loss: 0.2581 - lin_acc: 0.7563 - cat1_categorical_accuracy: 0.8772 - cat2_categorical_accuracy: 0.87070s - loss: 0.5183 - lin_loss: 0.0099 - cat1_loss: 0.2517 - cat2_loss: 0.2568 - lin_acc: 0.7549 - cat1_categorical_accuracy: 0.8743 - cat2_cate\n",
      "Epoch 971/1001\n",
      "8745/8745 [==============================] - 3s 287us/step - loss: 0.5138 - lin_loss: 0.0099 - cat1_loss: 0.2445 - cat2_loss: 0.2594 - lin_acc: 0.7520 - cat1_categorical_accuracy: 0.8760 - cat2_categorical_accuracy: 0.87091s - loss: 0.5144 - lin_loss: 0.0100 - cat1_loss: 0.2460 - cat2_loss: 0.2583 - lin_acc: 0.7507 - cat1_categori\n",
      "Epoch 972/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5137 - lin_loss: 0.0099 - cat1_loss: 0.2438 - cat2_loss: 0.2600 - lin_acc: 0.7530 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 973/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5145 - lin_loss: 0.0100 - cat1_loss: 0.2445 - cat2_loss: 0.2600 - lin_acc: 0.7511 - cat1_categorical_accuracy: 0.8799 - cat2_categorical_accuracy: 0.8683\n",
      "Epoch 974/1001\n",
      "8745/8745 [==============================] - 2s 283us/step - loss: 0.5136 - lin_loss: 0.0099 - cat1_loss: 0.2450 - cat2_loss: 0.2587 - lin_acc: 0.7583 - cat1_categorical_accuracy: 0.8764 - cat2_categorical_accuracy: 0.8669\n",
      "Epoch 975/1001\n",
      "8745/8745 [==============================] - 2s 266us/step - loss: 0.5134 - lin_loss: 0.0099 - cat1_loss: 0.2456 - cat2_loss: 0.2579 - lin_acc: 0.7551 - cat1_categorical_accuracy: 0.8804 - cat2_categorical_accuracy: 0.8701\n",
      "Epoch 976/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5131 - lin_loss: 0.0099 - cat1_loss: 0.2438 - cat2_loss: 0.2594 - lin_acc: 0.7547 - cat1_categorical_accuracy: 0.8789 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 977/1001\n",
      "8745/8745 [==============================] - 3s 295us/step - loss: 0.5113 - lin_loss: 0.0098 - cat1_loss: 0.2430 - cat2_loss: 0.2584 - lin_acc: 0.7573 - cat1_categorical_accuracy: 0.8800 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 978/1001\n",
      "8745/8745 [==============================] - 2s 278us/step - loss: 0.5153 - lin_loss: 0.0099 - cat1_loss: 0.2467 - cat2_loss: 0.2586 - lin_acc: 0.7549 - cat1_categorical_accuracy: 0.8759 - cat2_categorical_accuracy: 0.8679\n",
      "Epoch 979/1001\n",
      "8745/8745 [==============================] - 2s 284us/step - loss: 0.5155 - lin_loss: 0.0098 - cat1_loss: 0.2452 - cat2_loss: 0.2605 - lin_acc: 0.7569 - cat1_categorical_accuracy: 0.8775 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 980/1001\n",
      "8745/8745 [==============================] - 2s 270us/step - loss: 0.5128 - lin_loss: 0.0099 - cat1_loss: 0.2444 - cat2_loss: 0.2585 - lin_acc: 0.7552 - cat1_categorical_accuracy: 0.8774 - cat2_categorical_accuracy: 0.86801s - loss: 0.5160 - lin_loss: 0.0098 - cat1_loss: 0.2467 - cat2_loss: 0.2595 - lin_acc: 0.7617 - cat1_categorical_\n",
      "Epoch 981/1001\n",
      "8745/8745 [==============================] - 3s 290us/step - loss: 0.5113 - lin_loss: 0.0099 - cat1_loss: 0.2458 - cat2_loss: 0.2557 - lin_acc: 0.7508 - cat1_categorical_accuracy: 0.8798 - cat2_categorical_accuracy: 0.8711\n",
      "Epoch 982/1001\n",
      "8745/8745 [==============================] - 2s 284us/step - loss: 0.5141 - lin_loss: 0.0098 - cat1_loss: 0.2448 - cat2_loss: 0.2595 - lin_acc: 0.7568 - cat1_categorical_accuracy: 0.8758 - cat2_categorical_accuracy: 0.86901s - loss: 0.5060 - lin_loss: 0.0097 - cat1_loss: 0.2449 - cat2_loss: 0.2514 - lin_acc: 0.7691 - cat1_\n",
      "Epoch 983/1001\n",
      "8745/8745 [==============================] - 2s 265us/step - loss: 0.5129 - lin_loss: 0.0098 - cat1_loss: 0.2451 - cat2_loss: 0.2580 - lin_acc: 0.7571 - cat1_categorical_accuracy: 0.8778 - cat2_categorical_accuracy: 0.8690\n",
      "Epoch 984/1001\n",
      "8745/8745 [==============================] - 3s 296us/step - loss: 0.5143 - lin_loss: 0.0098 - cat1_loss: 0.2452 - cat2_loss: 0.2592 - lin_acc: 0.7592 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8698\n",
      "Epoch 985/1001\n",
      "8745/8745 [==============================] - 2s 281us/step - loss: 0.5113 - lin_loss: 0.0099 - cat1_loss: 0.2442 - cat2_loss: 0.2572 - lin_acc: 0.7509 - cat1_categorical_accuracy: 0.8794 - cat2_categorical_accuracy: 0.8695\n",
      "Epoch 986/1001\n",
      "8745/8745 [==============================] - 2s 267us/step - loss: 0.5137 - lin_loss: 0.0099 - cat1_loss: 0.2447 - cat2_loss: 0.2591 - lin_acc: 0.7555 - cat1_categorical_accuracy: 0.8783 - cat2_categorical_accuracy: 0.86831s - loss: 0.5036 - lin_loss: 0.0099 - cat1_loss: 0.2359 - cat2_loss: 0.2578 - lin_acc: 0.7584 - cat1_categorical_accuracy: \n",
      "Epoch 987/1001\n",
      "8745/8745 [==============================] - 3s 298us/step - loss: 0.5126 - lin_loss: 0.0098 - cat1_loss: 0.2443 - cat2_loss: 0.2585 - lin_acc: 0.7572 - cat1_categorical_accuracy: 0.8776 - cat2_categorical_accuracy: 0.8692\n",
      "Epoch 988/1001\n",
      "8745/8745 [==============================] - 2s 276us/step - loss: 0.5137 - lin_loss: 0.0099 - cat1_loss: 0.2447 - cat2_loss: 0.2591 - lin_acc: 0.7522 - cat1_categorical_accuracy: 0.8791 - cat2_categorical_accuracy: 0.86901s - loss: 0.5109 - lin_loss: 0.0099 - cat1_loss: 0.2454 - cat2_loss: 0.2556 - lin_acc: 0.7495 - cat1_categorical_ac\n",
      "Epoch 989/1001\n",
      "8745/8745 [==============================] - 3s 296us/step - loss: 0.5152 - lin_loss: 0.0099 - cat1_loss: 0.2445 - cat2_loss: 0.2608 - lin_acc: 0.7569 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.86950s - loss: 0.5109 - lin_loss: 0.0099 - cat1_loss: 0.2434 - cat2_loss: 0.2576 - lin_acc: 0.7566 - cat1_categorical_accuracy: 0.8798 - cat2_categorical_accuracy: 0.87 - ETA: 0s - loss: 0.5117 - lin_loss: 0.0099 - cat1_loss: 0.2445 - cat2_loss: 0.2572 - lin_acc: 0.7561 - cat1_categorical_accuracy: 0.8791 - cat2_catego\n",
      "Epoch 990/1001\n",
      "8745/8745 [==============================] - 2s 286us/step - loss: 0.5177 - lin_loss: 0.0098 - cat1_loss: 0.2446 - cat2_loss: 0.2633 - lin_acc: 0.7520 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8696\n",
      "Epoch 991/1001\n",
      "8745/8745 [==============================] - 2s 273us/step - loss: 0.5132 - lin_loss: 0.0099 - cat1_loss: 0.2429 - cat2_loss: 0.2604 - lin_acc: 0.7514 - cat1_categorical_accuracy: 0.8799 - cat2_categorical_accuracy: 0.8709\n",
      "Epoch 992/1001\n",
      "8745/8745 [==============================] - 2s 274us/step - loss: 0.5123 - lin_loss: 0.0098 - cat1_loss: 0.2452 - cat2_loss: 0.2574 - lin_acc: 0.7504 - cat1_categorical_accuracy: 0.8768 - cat2_categorical_accuracy: 0.8691\n",
      "Epoch 993/1001\n",
      "8745/8745 [==============================] - 3s 292us/step - loss: 0.5125 - lin_loss: 0.0099 - cat1_loss: 0.2453 - cat2_loss: 0.2572 - lin_acc: 0.7584 - cat1_categorical_accuracy: 0.8757 - cat2_categorical_accuracy: 0.8706\n",
      "Epoch 994/1001\n",
      "8745/8745 [==============================] - 2s 268us/step - loss: 0.5123 - lin_loss: 0.0098 - cat1_loss: 0.2446 - cat2_loss: 0.2579 - lin_acc: 0.7545 - cat1_categorical_accuracy: 0.8756 - cat2_categorical_accuracy: 0.87241s - loss: 0.5210 - lin_loss: 0.0098 - cat1_loss: 0.2516 - cat2_loss: 0.2596 - lin_acc: 0.7490 - cat1_categorical_accuracy: 0.8720 -\n",
      "Epoch 995/1001\n",
      "8745/8745 [==============================] - 3s 289us/step - loss: 0.5112 - lin_loss: 0.0099 - cat1_loss: 0.2436 - cat2_loss: 0.2577 - lin_acc: 0.7513 - cat1_categorical_accuracy: 0.8797 - cat2_categorical_accuracy: 0.8695\n",
      "Epoch 996/1001\n",
      "8745/8745 [==============================] - 2s 279us/step - loss: 0.5123 - lin_loss: 0.0098 - cat1_loss: 0.2440 - cat2_loss: 0.2584 - lin_acc: 0.7585 - cat1_categorical_accuracy: 0.8787 - cat2_categorical_accuracy: 0.8687\n",
      "Epoch 997/1001\n",
      "8745/8745 [==============================] - 2s 258us/step - loss: 0.5122 - lin_loss: 0.0098 - cat1_loss: 0.2432 - cat2_loss: 0.2592 - lin_acc: 0.7567 - cat1_categorical_accuracy: 0.8780 - cat2_categorical_accuracy: 0.8707\n",
      "Epoch 998/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 3s 307us/step - loss: 0.5141 - lin_loss: 0.0098 - cat1_loss: 0.2442 - cat2_loss: 0.2601 - lin_acc: 0.7546 - cat1_categorical_accuracy: 0.8781 - cat2_categorical_accuracy: 0.8722\n",
      "Epoch 999/1001\n",
      "8745/8745 [==============================] - 3s 291us/step - loss: 0.5129 - lin_loss: 0.0098 - cat1_loss: 0.2444 - cat2_loss: 0.2587 - lin_acc: 0.7499 - cat1_categorical_accuracy: 0.8771 - cat2_categorical_accuracy: 0.8671\n",
      "Epoch 1000/1001\n",
      "8745/8745 [==============================] - 2s 269us/step - loss: 0.5163 - lin_loss: 0.0098 - cat1_loss: 0.2448 - cat2_loss: 0.2616 - lin_acc: 0.7548 - cat1_categorical_accuracy: 0.8770 - cat2_categorical_accuracy: 0.8684\n",
      "Epoch 1001/1001\n",
      "8745/8745 [==============================] - 3s 379us/step - loss: 0.5133 - lin_loss: 0.0098 - cat1_loss: 0.2428 - cat2_loss: 0.2606 - lin_acc: 0.7585 - cat1_categorical_accuracy: 0.8795 - cat2_categorical_accuracy: 0.86902s - loss: 0.5017 - lin_loss: 0.0096 - cat1_loss: 0.2227 - cat2_loss: 0.2693 - lin_acc: 0.7812 - cat1_categorical_accuracy: 0.8989 - cat2_categorical_accuracy: 0.87 - ETA: 2s - loss: 0.5020 - lin_loss: 0.0095 - cat1_loss: 0.2269 - cat2_loss: 0.2655 - lin_acc: 0.7714 - cat1_categorical_accuracy: 0. - ETA: 1s - loss: 0.5207 - lin_loss: 0.0096 - cat1_loss: 0.2378 - cat2_loss: 0.2733 - lin_acc: 0.7620 - cat1_categori\n",
      "../linkPrediction/dataframes/apnea\\apnea-model-article-1000_2008-2015.pkl\n",
      "../linkPrediction/dataframes/apnea\\apnea-X_test-article_2008-2015.pkl\n",
      "../linkPrediction/dataframes/apnea\\apnea-y_test-article_2008-2015.pkl\n"
     ]
    }
   ],
   "source": [
    "feature_names = {\n",
    "# 'author':[0,6,22,9,10,11,12,25,26,27,28]\n",
    "'article': [1,7,23,13,14,15,16,29,30,31,32]\n",
    "# 'degree': [2,8,24,17,18,19,20,33,34,35,36],\n",
    "# 'citation': [3,21,37],\n",
    "# 'pref': [4,8,24],\n",
    "# 'cm': [5,8,24]\n",
    "}\n",
    "names1 = set(['author','article','degree'])\n",
    "names2 = set(['citation','pref','cm'])\n",
    "X = ut.load_data(datapath, domain[select_domain], \"X-features\", times)\n",
    "y = ut.load_data(datapath, domain[select_domain], \"y-features\", times)\n",
    "for name,feature in feature_names.items():\n",
    "    if name in names1:\n",
    "        param = [0.3,64,1001,name,times]\n",
    "        print(name,\"---------------------------------------------------------------------------------\")\n",
    "        X_test, y_test = lstm_forecast(X[:,:,feature],param)\n",
    "        ut.save_data(X_test, datapath, domain[select_domain], \"X_test-\"+name, times)\n",
    "        ut.save_data(y_test, datapath, domain[select_domain], \"y_test-\"+name, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "citation ---------------------------------------------------------------------------------\n",
      "(131006, 7, 3) (131006, 3)\n",
      "Epoch 1/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 8.8304e-05 - acc: 0.9989\n",
      "Epoch 2/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 5.4576e-05 - acc: 0.9976\n",
      "Epoch 3/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 4.7644e-05 - acc: 1.0000\n",
      "Epoch 4/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 4.3998e-05 - acc: 0.9957\n",
      "Epoch 5/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 4.1869e-05 - acc: 0.9982\n",
      "Epoch 6/1001\n",
      "91704/91704 [==============================] - 5s 51us/step - loss: 4.0307e-05 - acc: 0.9993\n",
      "Epoch 7/1001\n",
      "91704/91704 [==============================] - 5s 51us/step - loss: 3.9497e-05 - acc: 1.0000\n",
      "Epoch 8/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.7565e-05 - acc: 1.0000\n",
      "Epoch 9/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.8019e-05 - acc: 0.9947\n",
      "Epoch 10/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 3.6962e-05 - acc: 1.0000\n",
      "Epoch 11/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 3.6529e-05 - acc: 1.0000\n",
      "Epoch 12/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 3.6236e-05 - acc: 1.0000\n",
      "Epoch 13/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 3.5754e-05 - acc: 1.0000\n",
      "Epoch 14/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 3.5678e-05 - acc: 0.9999\n",
      "Epoch 15/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.5222e-05 - acc: 0.9999\n",
      "Epoch 16/1001\n",
      "91704/91704 [==============================] - 5s 51us/step - loss: 3.4478e-05 - acc: 0.9999\n",
      "Epoch 17/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 3.4170e-05 - acc: 0.9999\n",
      "Epoch 18/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.4127e-05 - acc: 0.9994\n",
      "Epoch 19/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 3.3333e-05 - acc: 0.9999\n",
      "Epoch 20/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.3269e-05 - acc: 1.0000\n",
      "Epoch 21/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.3449e-05 - acc: 0.9999\n",
      "Epoch 22/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 3.2967e-05 - acc: 0.9999\n",
      "Epoch 23/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.2505e-05 - acc: 1.0000\n",
      "Epoch 24/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 3.2433e-05 - acc: 0.9999\n",
      "Epoch 25/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 3.2619e-05 - acc: 0.9999\n",
      "Epoch 26/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.2030e-05 - acc: 0.9999\n",
      "Epoch 27/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.1852e-05 - acc: 0.9999\n",
      "Epoch 28/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.2039e-05 - acc: 0.9999\n",
      "Epoch 29/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.1656e-05 - acc: 1.0000\n",
      "Epoch 30/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.1363e-05 - acc: 1.0000\n",
      "Epoch 31/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 3.1294e-05 - acc: 1.0000\n",
      "Epoch 32/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 3.1583e-05 - acc: 1.0000\n",
      "Epoch 33/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.1079e-05 - acc: 1.0000\n",
      "Epoch 34/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.0967e-05 - acc: 1.0000\n",
      "Epoch 35/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 3.0876e-05 - acc: 1.0000\n",
      "Epoch 36/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.0593e-05 - acc: 1.0000\n",
      "Epoch 37/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.0449e-05 - acc: 1.0000\n",
      "Epoch 38/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 3.0556e-05 - acc: 1.0000\n",
      "Epoch 39/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 3.0080e-05 - acc: 1.0000\n",
      "Epoch 40/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.0309e-05 - acc: 1.0000\n",
      "Epoch 41/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.9896e-05 - acc: 1.0000\n",
      "Epoch 42/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.9783e-05 - acc: 1.0000\n",
      "Epoch 43/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.9734e-05 - acc: 1.0000\n",
      "Epoch 44/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.9434e-05 - acc: 1.0000\n",
      "Epoch 45/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.9383e-05 - acc: 1.0000\n",
      "Epoch 46/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.9140e-05 - acc: 1.0000\n",
      "Epoch 47/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.9263e-05 - acc: 1.0000\n",
      "Epoch 48/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.9275e-05 - acc: 1.0000\n",
      "Epoch 49/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.8888e-05 - acc: 1.0000\n",
      "Epoch 50/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8845e-05 - acc: 1.0000\n",
      "Epoch 51/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.8984e-05 - acc: 1.0000\n",
      "Epoch 52/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.8592e-05 - acc: 1.0000\n",
      "Epoch 53/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8886e-05 - acc: 1.0000\n",
      "Epoch 54/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8734e-05 - acc: 1.0000\n",
      "Epoch 55/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8223e-05 - acc: 1.0000\n",
      "Epoch 56/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8436e-05 - acc: 1.0000: \n",
      "Epoch 57/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.8340e-05 - acc: 1.0000\n",
      "Epoch 58/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.8220e-05 - acc: 1.0000\n",
      "Epoch 59/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7744e-05 - acc: 1.0000\n",
      "Epoch 60/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8116e-05 - acc: 1.0000\n",
      "Epoch 61/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7744e-05 - acc: 1.0000\n",
      "Epoch 62/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7824e-05 - acc: 1.0000\n",
      "Epoch 63/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7715e-05 - acc: 1.0000\n",
      "Epoch 64/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8034e-05 - acc: 1.0000\n",
      "Epoch 65/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.7507e-05 - acc: 1.0000\n",
      "Epoch 66/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.7605e-05 - acc: 1.0000\n",
      "Epoch 67/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.7355e-05 - acc: 1.0000\n",
      "Epoch 68/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7498e-05 - acc: 1.0000\n",
      "Epoch 69/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.7208e-05 - acc: 1.0000\n",
      "Epoch 70/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.7327e-05 - acc: 1.0000\n",
      "Epoch 71/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7249e-05 - acc: 1.0000\n",
      "Epoch 72/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6968e-05 - acc: 1.0000\n",
      "Epoch 73/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7180e-05 - acc: 1.0000\n",
      "Epoch 74/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7279e-05 - acc: 1.0000\n",
      "Epoch 75/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6869e-05 - acc: 1.0000\n",
      "Epoch 76/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6908e-05 - acc: 1.0000\n",
      "Epoch 77/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6809e-05 - acc: 1.0000\n",
      "Epoch 78/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6908e-05 - acc: 1.0000\n",
      "Epoch 79/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7092e-05 - acc: 1.0000\n",
      "Epoch 80/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.6714e-05 - acc: 1.0000\n",
      "Epoch 81/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.6617e-05 - acc: 1.0000\n",
      "Epoch 82/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6558e-05 - acc: 1.0000\n",
      "Epoch 83/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6558e-05 - acc: 1.0000\n",
      "Epoch 84/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6638e-05 - acc: 1.0000\n",
      "Epoch 85/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6275e-05 - acc: 1.0000\n",
      "Epoch 86/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.6754e-05 - acc: 1.0000\n",
      "Epoch 87/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.6182e-05 - acc: 1.0000\n",
      "Epoch 88/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.6903e-05 - acc: 1.0000\n",
      "Epoch 89/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6087e-05 - acc: 1.0000\n",
      "Epoch 90/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6132e-05 - acc: 1.0000\n",
      "Epoch 91/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6226e-05 - acc: 1.0000\n",
      "Epoch 92/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.6270e-05 - acc: 1.0000\n",
      "Epoch 93/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.6655e-05 - acc: 1.0000\n",
      "Epoch 94/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.5753e-05 - acc: 1.0000\n",
      "Epoch 95/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.6007e-05 - acc: 1.0000\n",
      "Epoch 96/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6008e-05 - acc: 1.0000\n",
      "Epoch 97/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.6079e-05 - acc: 1.0000\n",
      "Epoch 98/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.5896e-05 - acc: 1.0000\n",
      "Epoch 99/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.5641e-05 - acc: 1.0000\n",
      "Epoch 100/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5655e-05 - acc: 1.0000\n",
      "Epoch 101/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5571e-05 - acc: 1.0000\n",
      "../linkPrediction/dataframes/obesity\\obesity-model-citation-100_2008-2015.pkl\n",
      "Epoch 102/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5682e-05 - acc: 1.0000\n",
      "Epoch 103/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5532e-05 - acc: 1.0000\n",
      "Epoch 104/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.5406e-05 - acc: 1.0000\n",
      "Epoch 105/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.6246e-05 - acc: 1.0000\n",
      "Epoch 106/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5186e-05 - acc: 1.0000\n",
      "Epoch 107/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5218e-05 - acc: 1.0000\n",
      "Epoch 108/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5141e-05 - acc: 1.0000\n",
      "Epoch 109/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.5296e-05 - acc: 1.0000\n",
      "Epoch 110/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5086e-05 - acc: 1.0000\n",
      "Epoch 111/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.5087e-05 - acc: 1.0000\n",
      "Epoch 112/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.5024e-05 - acc: 1.0000\n",
      "Epoch 113/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.5241e-05 - acc: 1.0000\n",
      "Epoch 114/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.4851e-05 - acc: 1.0000\n",
      "Epoch 115/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.4749e-05 - acc: 1.0000\n",
      "Epoch 116/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5105e-05 - acc: 1.0000\n",
      "Epoch 117/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4738e-05 - acc: 1.0000\n",
      "Epoch 118/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4707e-05 - acc: 1.0000\n",
      "Epoch 119/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.4566e-05 - acc: 1.0000\n",
      "Epoch 120/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4614e-05 - acc: 1.0000\n",
      "Epoch 121/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4428e-05 - acc: 1.0000\n",
      "Epoch 122/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4383e-05 - acc: 1.0000\n",
      "Epoch 123/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4516e-05 - acc: 1.0000\n",
      "Epoch 124/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4272e-05 - acc: 1.0000\n",
      "Epoch 125/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4338e-05 - acc: 1.0000\n",
      "Epoch 126/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4212e-05 - acc: 1.0000\n",
      "Epoch 127/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4539e-05 - acc: 1.0000\n",
      "Epoch 128/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4069e-05 - acc: 1.0000\n",
      "Epoch 129/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.3875e-05 - acc: 1.0000\n",
      "Epoch 130/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.3999e-05 - acc: 1.0000\n",
      "Epoch 131/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4124e-05 - acc: 1.0000\n",
      "Epoch 132/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.4081e-05 - acc: 1.0000\n",
      "Epoch 133/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.3952e-05 - acc: 1.0000\n",
      "Epoch 134/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.3913e-05 - acc: 1.0000\n",
      "Epoch 135/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.3784e-05 - acc: 1.0000\n",
      "Epoch 136/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.3694e-05 - acc: 1.0000\n",
      "Epoch 137/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.3855e-05 - acc: 1.0000\n",
      "Epoch 138/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.3927e-05 - acc: 1.0000\n",
      "Epoch 139/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.3668e-05 - acc: 1.0000\n",
      "Epoch 140/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.3576e-05 - acc: 1.0000\n",
      "Epoch 141/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.3536e-05 - acc: 1.0000\n",
      "Epoch 142/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.3508e-05 - acc: 1.0000\n",
      "Epoch 143/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.3593e-05 - acc: 1.0000\n",
      "Epoch 144/1001\n",
      "91704/91704 [==============================] - 6s 62us/step - loss: 2.3347e-05 - acc: 1.0000\n",
      "Epoch 145/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.3471e-05 - acc: 1.0000\n",
      "Epoch 146/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.3326e-05 - acc: 1.0000\n",
      "Epoch 147/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.3400e-05 - acc: 1.0000\n",
      "Epoch 148/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.3234e-05 - acc: 1.0000\n",
      "Epoch 149/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.3476e-05 - acc: 1.0000\n",
      "Epoch 150/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.3560e-05 - acc: 1.0000\n",
      "Epoch 151/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.3054e-05 - acc: 1.0000\n",
      "Epoch 152/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.3126e-05 - acc: 1.0000\n",
      "Epoch 153/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.3207e-05 - acc: 1.0000\n",
      "Epoch 154/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.3061e-05 - acc: 1.0000\n",
      "Epoch 155/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.2992e-05 - acc: 1.0000\n",
      "Epoch 156/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.3061e-05 - acc: 1.0000\n",
      "Epoch 157/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.3002e-05 - acc: 1.0000\n",
      "Epoch 158/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.2851e-05 - acc: 1.0000\n",
      "Epoch 159/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.2866e-05 - acc: 1.0000\n",
      "Epoch 160/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.2965e-05 - acc: 1.0000\n",
      "Epoch 161/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.2808e-05 - acc: 1.0000\n",
      "Epoch 162/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.2774e-05 - acc: 1.0000\n",
      "Epoch 163/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.2856e-05 - acc: 1.0000\n",
      "Epoch 164/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.2748e-05 - acc: 1.0000\n",
      "Epoch 165/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.2919e-05 - acc: 1.0000\n",
      "Epoch 166/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.2659e-05 - acc: 1.0000\n",
      "Epoch 167/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.2630e-05 - acc: 1.0000\n",
      "Epoch 168/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.2646e-05 - acc: 1.0000\n",
      "Epoch 169/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.2358e-05 - acc: 1.0000\n",
      "Epoch 170/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.2625e-05 - acc: 1.0000\n",
      "Epoch 171/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.2507e-05 - acc: 1.0000\n",
      "Epoch 172/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.2362e-05 - acc: 1.0000\n",
      "Epoch 173/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.2461e-05 - acc: 0.9998\n",
      "Epoch 174/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.2415e-05 - acc: 1.0000\n",
      "Epoch 175/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.2441e-05 - acc: 1.0000\n",
      "Epoch 176/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.2576e-05 - acc: 1.0000\n",
      "Epoch 177/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.2265e-05 - acc: 1.0000\n",
      "Epoch 178/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.2311e-05 - acc: 1.0000\n",
      "Epoch 179/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.2286e-05 - acc: 1.0000\n",
      "Epoch 180/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.2086e-05 - acc: 1.0000\n",
      "Epoch 181/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.2857e-05 - acc: 1.0000\n",
      "Epoch 182/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.1903e-05 - acc: 1.0000\n",
      "Epoch 183/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.2037e-05 - acc: 1.0000\n",
      "Epoch 184/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1966e-05 - acc: 1.0000\n",
      "Epoch 185/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.2012e-05 - acc: 1.0000\n",
      "Epoch 186/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.1926e-05 - acc: 1.0000\n",
      "Epoch 187/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.2344e-05 - acc: 1.0000\n",
      "Epoch 188/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1927e-05 - acc: 1.0000\n",
      "Epoch 189/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1899e-05 - acc: 1.0000\n",
      "Epoch 190/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.1873e-05 - acc: 1.0000\n",
      "Epoch 191/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.1904e-05 - acc: 1.0000\n",
      "Epoch 192/1001\n",
      "91704/91704 [==============================] - 6s 61us/step - loss: 2.1977e-05 - acc: 0.9996\n",
      "Epoch 193/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1769e-05 - acc: 1.0000\n",
      "Epoch 194/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.1743e-05 - acc: 1.0000\n",
      "Epoch 195/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.1837e-05 - acc: 1.0000\n",
      "Epoch 196/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1541e-05 - acc: 1.0000\n",
      "Epoch 197/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.2409e-05 - acc: 1.0000\n",
      "Epoch 198/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.1747e-05 - acc: 1.0000\n",
      "Epoch 199/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1529e-05 - acc: 1.0000\n",
      "Epoch 200/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1550e-05 - acc: 1.0000\n",
      "Epoch 201/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1720e-05 - acc: 1.0000\n",
      "Epoch 202/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.1495e-05 - acc: 1.0000\n",
      "Epoch 203/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.1587e-05 - acc: 1.0000\n",
      "Epoch 204/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.1583e-05 - acc: 1.0000\n",
      "Epoch 205/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.1495e-05 - acc: 1.0000\n",
      "Epoch 206/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.1554e-05 - acc: 1.0000\n",
      "Epoch 207/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1456e-05 - acc: 1.0000\n",
      "Epoch 208/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.1511e-05 - acc: 1.0000\n",
      "Epoch 209/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.1322e-05 - acc: 1.0000\n",
      "Epoch 210/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1496e-05 - acc: 1.0000\n",
      "Epoch 211/1001\n",
      "91704/91704 [==============================] - 5s 60us/step - loss: 2.1452e-05 - acc: 1.0000\n",
      "Epoch 212/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.1292e-05 - acc: 1.0000\n",
      "Epoch 213/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.1154e-05 - acc: 1.0000\n",
      "Epoch 214/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1361e-05 - acc: 1.0000\n",
      "Epoch 215/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1263e-05 - acc: 1.0000\n",
      "Epoch 216/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.1147e-05 - acc: 1.0000\n",
      "Epoch 217/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.1360e-05 - acc: 1.0000\n",
      "Epoch 218/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.1956e-05 - acc: 1.0000\n",
      "Epoch 219/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.1112e-05 - acc: 1.0000\n",
      "Epoch 220/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.1169e-05 - acc: 1.0000\n",
      "Epoch 221/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.1560e-05 - acc: 1.0000\n",
      "Epoch 222/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.1040e-05 - acc: 1.0000\n",
      "Epoch 223/1001\n",
      "91704/91704 [==============================] - 5s 60us/step - loss: 2.1691e-05 - acc: 1.0000\n",
      "Epoch 224/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.1017e-05 - acc: 0.9997\n",
      "Epoch 225/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0975e-05 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.1053e-05 - acc: 1.0000\n",
      "Epoch 227/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.1049e-05 - acc: 1.0000\n",
      "Epoch 228/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0989e-05 - acc: 1.0000\n",
      "Epoch 229/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1197e-05 - acc: 1.0000\n",
      "Epoch 230/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.1026e-05 - acc: 1.0000\n",
      "Epoch 231/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0851e-05 - acc: 1.0000\n",
      "Epoch 232/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1192e-05 - acc: 1.0000\n",
      "Epoch 233/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.1382e-05 - acc: 1.0000\n",
      "Epoch 234/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.0798e-05 - acc: 1.0000\n",
      "Epoch 235/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0964e-05 - acc: 1.0000\n",
      "Epoch 236/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.1073e-05 - acc: 1.0000\n",
      "Epoch 237/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.0967e-05 - acc: 1.0000\n",
      "Epoch 238/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0944e-05 - acc: 1.0000\n",
      "Epoch 239/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0906e-05 - acc: 1.0000\n",
      "Epoch 240/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0975e-05 - acc: 1.0000\n",
      "Epoch 241/1001\n",
      "91704/91704 [==============================] - 6s 61us/step - loss: 2.0934e-05 - acc: 1.0000\n",
      "Epoch 242/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.0741e-05 - acc: 1.0000\n",
      "Epoch 243/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.1274e-05 - acc: 1.0000\n",
      "Epoch 244/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0563e-05 - acc: 1.0000\n",
      "Epoch 245/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0658e-05 - acc: 1.0000\n",
      "Epoch 246/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0623e-05 - acc: 1.0000\n",
      "Epoch 247/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.0772e-05 - acc: 1.0000\n",
      "Epoch 248/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.0851e-05 - acc: 1.0000\n",
      "Epoch 249/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.1049e-05 - acc: 1.0000\n",
      "Epoch 250/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.0599e-05 - acc: 1.0000\n",
      "Epoch 251/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0723e-05 - acc: 1.0000\n",
      "Epoch 252/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0595e-05 - acc: 1.0000\n",
      "Epoch 253/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0726e-05 - acc: 1.0000\n",
      "Epoch 254/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0683e-05 - acc: 1.0000\n",
      "Epoch 255/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0763e-05 - acc: 1.0000\n",
      "Epoch 256/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0613e-05 - acc: 1.0000\n",
      "Epoch 257/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0501e-05 - acc: 1.0000\n",
      "Epoch 258/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.1052e-05 - acc: 1.0000\n",
      "Epoch 259/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0884e-05 - acc: 1.0000\n",
      "Epoch 260/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.0420e-05 - acc: 1.0000\n",
      "Epoch 261/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0471e-05 - acc: 1.0000\n",
      "Epoch 262/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0490e-05 - acc: 1.0000\n",
      "Epoch 263/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.0615e-05 - acc: 1.0000\n",
      "Epoch 264/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.0576e-05 - acc: 1.0000\n",
      "Epoch 265/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.0491e-05 - acc: 1.0000\n",
      "Epoch 266/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0391e-05 - acc: 1.0000\n",
      "Epoch 267/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0841e-05 - acc: 1.0000\n",
      "Epoch 268/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0477e-05 - acc: 0.9999\n",
      "Epoch 269/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0658e-05 - acc: 1.0000\n",
      "Epoch 270/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0513e-05 - acc: 1.0000\n",
      "Epoch 271/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0397e-05 - acc: 1.0000\n",
      "Epoch 272/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0608e-05 - acc: 1.0000\n",
      "Epoch 273/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0340e-05 - acc: 1.0000\n",
      "Epoch 274/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.0444e-05 - acc: 1.0000\n",
      "Epoch 275/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0299e-05 - acc: 1.0000\n",
      "Epoch 276/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.0339e-05 - acc: 1.0000\n",
      "Epoch 277/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.0507e-05 - acc: 1.0000\n",
      "Epoch 278/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0294e-05 - acc: 1.0000\n",
      "Epoch 279/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0448e-05 - acc: 1.0000\n",
      "Epoch 280/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0503e-05 - acc: 1.0000\n",
      "Epoch 281/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0202e-05 - acc: 1.0000\n",
      "Epoch 282/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.0322e-05 - acc: 1.0000\n",
      "Epoch 283/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.0208e-05 - acc: 1.0000\n",
      "Epoch 284/1001\n",
      "91704/91704 [==============================] - 6s 63us/step - loss: 2.0345e-05 - acc: 1.0000\n",
      "Epoch 285/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.0463e-05 - acc: 1.0000\n",
      "Epoch 286/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0090e-05 - acc: 1.0000\n",
      "Epoch 287/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.0530e-05 - acc: 1.0000\n",
      "Epoch 288/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0068e-05 - acc: 1.0000\n",
      "Epoch 289/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.0193e-05 - acc: 1.0000\n",
      "Epoch 290/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.0112e-05 - acc: 1.0000\n",
      "Epoch 291/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0124e-05 - acc: 1.0000\n",
      "Epoch 292/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0440e-05 - acc: 1.0000\n",
      "Epoch 293/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9994e-05 - acc: 1.0000\n",
      "Epoch 294/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0143e-05 - acc: 1.0000\n",
      "Epoch 295/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0020e-05 - acc: 1.0000\n",
      "Epoch 296/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0016e-05 - acc: 1.0000\n",
      "Epoch 297/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0041e-05 - acc: 1.0000\n",
      "Epoch 298/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.0387e-05 - acc: 1.0000\n",
      "Epoch 299/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.0120e-05 - acc: 1.0000\n",
      "Epoch 300/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.9907e-05 - acc: 1.0000\n",
      "Epoch 301/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.0527e-05 - acc: 1.0000\n",
      "Epoch 302/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.0085e-05 - acc: 1.0000\n",
      "Epoch 303/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.9875e-05 - acc: 1.0000\n",
      "Epoch 304/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0114e-05 - acc: 1.0000: 0s - loss: 2.00\n",
      "Epoch 305/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9822e-05 - acc: 1.0000\n",
      "Epoch 306/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.0594e-05 - acc: 1.0000\n",
      "Epoch 307/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.9825e-05 - acc: 1.0000\n",
      "Epoch 308/1001\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 1.9910e-05 - acc: 1.000 - 5s 55us/step - loss: 1.9908e-05 - acc: 1.0000\n",
      "Epoch 309/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.0037e-05 - acc: 1.0000\n",
      "Epoch 310/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9803e-05 - acc: 1.0000\n",
      "Epoch 311/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.9915e-05 - acc: 1.0000\n",
      "Epoch 312/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9919e-05 - acc: 1.0000\n",
      "Epoch 313/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.9912e-05 - acc: 1.0000\n",
      "Epoch 314/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9813e-05 - acc: 1.0000\n",
      "Epoch 315/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9897e-05 - acc: 1.0000\n",
      "Epoch 316/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.0165e-05 - acc: 1.0000\n",
      "Epoch 317/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9946e-05 - acc: 1.0000\n",
      "Epoch 318/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0226e-05 - acc: 1.0000\n",
      "Epoch 319/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0200e-05 - acc: 1.0000\n",
      "Epoch 320/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9732e-05 - acc: 1.0000\n",
      "Epoch 321/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9814e-05 - acc: 1.0000\n",
      "Epoch 322/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9957e-05 - acc: 1.0000\n",
      "Epoch 323/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0032e-05 - acc: 1.0000\n",
      "Epoch 324/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9705e-05 - acc: 1.0000\n",
      "Epoch 325/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0605e-05 - acc: 1.0000\n",
      "Epoch 326/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.9767e-05 - acc: 1.0000\n",
      "Epoch 327/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9824e-05 - acc: 1.0000\n",
      "Epoch 328/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9710e-05 - acc: 1.0000\n",
      "Epoch 329/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.9764e-05 - acc: 1.0000\n",
      "Epoch 330/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.0138e-05 - acc: 1.0000\n",
      "Epoch 331/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9983e-05 - acc: 1.0000\n",
      "Epoch 332/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.9989e-05 - acc: 1.0000\n",
      "Epoch 333/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9563e-05 - acc: 1.0000\n",
      "Epoch 334/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9849e-05 - acc: 1.0000\n",
      "Epoch 335/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9723e-05 - acc: 1.0000\n",
      "Epoch 336/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.9580e-05 - acc: 1.0000\n",
      "Epoch 337/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.0017e-05 - acc: 1.0000\n",
      "Epoch 338/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9610e-05 - acc: 0.9999\n",
      "Epoch 339/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9868e-05 - acc: 1.0000\n",
      "Epoch 340/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9656e-05 - acc: 1.0000\n",
      "Epoch 341/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9626e-05 - acc: 1.0000\n",
      "Epoch 342/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.9723e-05 - acc: 1.0000\n",
      "Epoch 343/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.9718e-05 - acc: 1.0000\n",
      "Epoch 344/1001\n",
      "91704/91704 [==============================] - 6s 62us/step - loss: 1.9789e-05 - acc: 1.0000\n",
      "Epoch 345/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9397e-05 - acc: 1.0000\n",
      "Epoch 346/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9618e-05 - acc: 1.0000\n",
      "Epoch 347/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9826e-05 - acc: 1.0000\n",
      "Epoch 348/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9594e-05 - acc: 1.0000\n",
      "Epoch 349/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9525e-05 - acc: 1.0000\n",
      "Epoch 350/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9901e-05 - acc: 1.0000\n",
      "Epoch 351/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9479e-05 - acc: 1.0000\n",
      "Epoch 352/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9658e-05 - acc: 1.0000\n",
      "Epoch 353/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.9492e-05 - acc: 1.0000\n",
      "Epoch 354/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.9481e-05 - acc: 1.0000\n",
      "Epoch 355/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9592e-05 - acc: 1.0000\n",
      "Epoch 356/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.9507e-05 - acc: 1.0000\n",
      "Epoch 357/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9563e-05 - acc: 1.0000\n",
      "Epoch 358/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9598e-05 - acc: 1.0000\n",
      "Epoch 359/1001\n",
      "91704/91704 [==============================] - 6s 60us/step - loss: 1.9580e-05 - acc: 1.0000\n",
      "Epoch 360/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9466e-05 - acc: 1.0000\n",
      "Epoch 361/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9475e-05 - acc: 1.0000\n",
      "Epoch 362/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9586e-05 - acc: 1.0000\n",
      "Epoch 363/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9683e-05 - acc: 1.0000\n",
      "Epoch 364/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9424e-05 - acc: 1.0000\n",
      "Epoch 365/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9810e-05 - acc: 1.0000\n",
      "Epoch 366/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.9309e-05 - acc: 1.0000\n",
      "Epoch 367/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9534e-05 - acc: 1.0000\n",
      "Epoch 368/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9432e-05 - acc: 1.0000\n",
      "Epoch 369/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.9388e-05 - acc: 1.0000\n",
      "Epoch 370/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9520e-05 - acc: 1.0000\n",
      "Epoch 371/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9267e-05 - acc: 1.0000\n",
      "Epoch 372/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9329e-05 - acc: 1.0000\n",
      "Epoch 373/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9639e-05 - acc: 1.0000\n",
      "Epoch 374/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9296e-05 - acc: 1.0000\n",
      "Epoch 375/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9416e-05 - acc: 1.0000\n",
      "Epoch 376/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9305e-05 - acc: 1.0000\n",
      "Epoch 377/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 1.9451e-05 - acc: 1.0000\n",
      "Epoch 378/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.9664e-05 - acc: 1.0000\n",
      "Epoch 379/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.9342e-05 - acc: 1.0000\n",
      "Epoch 380/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.9303e-05 - acc: 1.0000\n",
      "Epoch 381/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9460e-05 - acc: 1.0000\n",
      "Epoch 382/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.9249e-05 - acc: 1.0000\n",
      "Epoch 383/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.9223e-05 - acc: 1.0000\n",
      "Epoch 384/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9447e-05 - acc: 1.0000\n",
      "Epoch 385/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9348e-05 - acc: 1.0000\n",
      "Epoch 386/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9142e-05 - acc: 1.0000\n",
      "Epoch 387/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.9375e-05 - acc: 1.0000\n",
      "Epoch 388/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9199e-05 - acc: 1.0000\n",
      "Epoch 389/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.9673e-05 - acc: 1.0000\n",
      "Epoch 390/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9138e-05 - acc: 1.0000\n",
      "Epoch 391/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9314e-05 - acc: 1.0000\n",
      "Epoch 392/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.9260e-05 - acc: 1.0000\n",
      "Epoch 393/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.9208e-05 - acc: 1.0000\n",
      "Epoch 394/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9199e-05 - acc: 1.0000\n",
      "Epoch 395/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.9821e-05 - acc: 1.0000\n",
      "Epoch 396/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.9199e-05 - acc: 1.0000\n",
      "Epoch 397/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9241e-05 - acc: 1.0000\n",
      "Epoch 398/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9242e-05 - acc: 1.0000\n",
      "Epoch 399/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9065e-05 - acc: 1.0000\n",
      "Epoch 400/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9120e-05 - acc: 1.0000\n",
      "Epoch 401/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9172e-05 - acc: 1.0000\n",
      "Epoch 402/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.9570e-05 - acc: 1.0000\n",
      "Epoch 403/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9164e-05 - acc: 1.0000\n",
      "Epoch 404/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.9145e-05 - acc: 1.0000\n",
      "Epoch 405/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9317e-05 - acc: 1.0000\n",
      "Epoch 406/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8936e-05 - acc: 1.0000\n",
      "Epoch 407/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9231e-05 - acc: 1.0000\n",
      "Epoch 408/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9073e-05 - acc: 1.0000\n",
      "Epoch 409/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.9228e-05 - acc: 1.0000\n",
      "Epoch 410/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9078e-05 - acc: 1.0000\n",
      "Epoch 411/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9115e-05 - acc: 1.0000\n",
      "Epoch 412/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9049e-05 - acc: 1.0000\n",
      "Epoch 413/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9230e-05 - acc: 1.0000\n",
      "Epoch 414/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0319e-05 - acc: 1.0000\n",
      "Epoch 415/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.0464e-05 - acc: 1.0000\n",
      "Epoch 416/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9808e-05 - acc: 1.0000\n",
      "Epoch 417/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9309e-05 - acc: 1.0000\n",
      "Epoch 418/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9237e-05 - acc: 1.0000\n",
      "Epoch 419/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.9129e-05 - acc: 1.0000\n",
      "Epoch 420/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9120e-05 - acc: 1.0000\n",
      "Epoch 421/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9414e-05 - acc: 1.0000\n",
      "Epoch 422/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.9013e-05 - acc: 1.0000\n",
      "Epoch 423/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8977e-05 - acc: 1.0000\n",
      "Epoch 424/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9059e-05 - acc: 1.0000\n",
      "Epoch 425/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9078e-05 - acc: 1.0000\n",
      "Epoch 426/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9022e-05 - acc: 1.0000\n",
      "Epoch 427/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.8995e-05 - acc: 1.0000\n",
      "Epoch 428/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8948e-05 - acc: 1.0000\n",
      "Epoch 429/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8944e-05 - acc: 1.0000\n",
      "Epoch 430/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9012e-05 - acc: 1.0000\n",
      "Epoch 431/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8863e-05 - acc: 1.0000\n",
      "Epoch 432/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8988e-05 - acc: 1.0000\n",
      "Epoch 433/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8932e-05 - acc: 1.0000\n",
      "Epoch 434/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8982e-05 - acc: 1.0000\n",
      "Epoch 435/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8976e-05 - acc: 1.0000\n",
      "Epoch 436/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8934e-05 - acc: 1.0000\n",
      "Epoch 437/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9230e-05 - acc: 1.0000\n",
      "Epoch 438/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8821e-05 - acc: 1.0000\n",
      "Epoch 439/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9185e-05 - acc: 1.0000\n",
      "Epoch 440/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8821e-05 - acc: 1.0000\n",
      "Epoch 441/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9114e-05 - acc: 1.0000\n",
      "Epoch 442/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8824e-05 - acc: 1.0000\n",
      "Epoch 443/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8794e-05 - acc: 1.0000\n",
      "Epoch 444/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9008e-05 - acc: 1.0000\n",
      "Epoch 445/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8956e-05 - acc: 1.0000\n",
      "Epoch 446/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8798e-05 - acc: 1.0000\n",
      "Epoch 447/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8857e-05 - acc: 1.0000\n",
      "Epoch 448/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9273e-05 - acc: 1.0000\n",
      "Epoch 449/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8792e-05 - acc: 1.0000\n",
      "Epoch 450/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8857e-05 - acc: 1.0000\n",
      "Epoch 451/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.8763e-05 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8738e-05 - acc: 1.0000: 0s - loss: 1.8682e-05 - acc: 1\n",
      "Epoch 453/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9044e-05 - acc: 1.0000\n",
      "Epoch 454/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8675e-05 - acc: 1.0000\n",
      "Epoch 455/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9221e-05 - acc: 1.0000\n",
      "Epoch 456/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.8800e-05 - acc: 1.0000: 1\n",
      "Epoch 457/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8865e-05 - acc: 1.0000\n",
      "Epoch 458/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9119e-05 - acc: 1.0000\n",
      "Epoch 459/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.8685e-05 - acc: 1.0000\n",
      "Epoch 460/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8764e-05 - acc: 1.0000\n",
      "Epoch 461/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8800e-05 - acc: 1.0000\n",
      "Epoch 462/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.8856e-05 - acc: 1.0000: 1s - loss: 1\n",
      "Epoch 463/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8780e-05 - acc: 1.0000\n",
      "Epoch 464/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8763e-05 - acc: 1.0000\n",
      "Epoch 465/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8866e-05 - acc: 1.0000\n",
      "Epoch 466/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8654e-05 - acc: 1.0000\n",
      "Epoch 467/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8669e-05 - acc: 1.0000\n",
      "Epoch 468/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9017e-05 - acc: 1.0000: 0s - loss: 1.8753e-05 - a\n",
      "Epoch 469/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8746e-05 - acc: 0.9999\n",
      "Epoch 470/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8673e-05 - acc: 1.0000\n",
      "Epoch 471/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.9033e-05 - acc: 1.0000\n",
      "Epoch 472/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8745e-05 - acc: 1.0000\n",
      "Epoch 473/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8761e-05 - acc: 1.0000\n",
      "Epoch 474/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8666e-05 - acc: 1.0000\n",
      "Epoch 475/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.8624e-05 - acc: 1.0000\n",
      "Epoch 476/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9011e-05 - acc: 1.0000\n",
      "Epoch 477/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8582e-05 - acc: 1.0000\n",
      "Epoch 478/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8677e-05 - acc: 1.0000\n",
      "Epoch 479/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8634e-05 - acc: 1.0000\n",
      "Epoch 480/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8657e-05 - acc: 1.0000\n",
      "Epoch 481/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8707e-05 - acc: 1.0000\n",
      "Epoch 482/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8621e-05 - acc: 1.0000\n",
      "Epoch 483/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8649e-05 - acc: 1.0000\n",
      "Epoch 484/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8905e-05 - acc: 0.9998\n",
      "Epoch 485/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8470e-05 - acc: 1.0000\n",
      "Epoch 486/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8633e-05 - acc: 1.0000\n",
      "Epoch 487/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8799e-05 - acc: 1.0000\n",
      "Epoch 488/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8616e-05 - acc: 1.0000\n",
      "Epoch 489/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.8670e-05 - acc: 1.0000\n",
      "Epoch 490/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8757e-05 - acc: 1.0000\n",
      "Epoch 491/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8617e-05 - acc: 1.0000\n",
      "Epoch 492/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8572e-05 - acc: 1.0000\n",
      "Epoch 493/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8641e-05 - acc: 1.0000\n",
      "Epoch 494/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9080e-05 - acc: 0.9999\n",
      "Epoch 495/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8360e-05 - acc: 1.0000\n",
      "Epoch 496/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8615e-05 - acc: 1.0000\n",
      "Epoch 497/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8627e-05 - acc: 1.0000\n",
      "Epoch 498/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8536e-05 - acc: 1.0000\n",
      "Epoch 499/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 1.8573e-05 - acc: 1.0000\n",
      "Epoch 500/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8446e-05 - acc: 1.0000\n",
      "Epoch 501/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8634e-05 - acc: 1.0000\n",
      "../linkPrediction/dataframes/obesity\\obesity-model-citation-500_2008-2015.pkl\n",
      "Epoch 502/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.8815e-05 - acc: 1.0000\n",
      "Epoch 503/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8569e-05 - acc: 1.0000\n",
      "Epoch 504/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8640e-05 - acc: 1.0000\n",
      "Epoch 505/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8531e-05 - acc: 1.0000\n",
      "Epoch 506/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8520e-05 - acc: 1.0000\n",
      "Epoch 507/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8600e-05 - acc: 1.0000: 0s - loss: 1.8569e-05 - \n",
      "Epoch 508/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8623e-05 - acc: 1.0000\n",
      "Epoch 509/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8624e-05 - acc: 1.0000\n",
      "Epoch 510/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8408e-05 - acc: 1.0000\n",
      "Epoch 511/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8630e-05 - acc: 1.0000\n",
      "Epoch 512/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8650e-05 - acc: 1.0000\n",
      "Epoch 513/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8722e-05 - acc: 1.0000\n",
      "Epoch 514/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8524e-05 - acc: 1.0000\n",
      "Epoch 515/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.8434e-05 - acc: 1.0000\n",
      "Epoch 516/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8650e-05 - acc: 1.0000\n",
      "Epoch 517/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8844e-05 - acc: 1.0000\n",
      "Epoch 518/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8351e-05 - acc: 1.0000\n",
      "Epoch 519/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.9042e-05 - acc: 1.0000\n",
      "Epoch 520/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8464e-05 - acc: 1.0000\n",
      "Epoch 521/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8462e-05 - acc: 1.0000\n",
      "Epoch 522/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8516e-05 - acc: 1.0000\n",
      "Epoch 523/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8537e-05 - acc: 1.0000\n",
      "Epoch 524/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8537e-05 - acc: 1.0000\n",
      "Epoch 525/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8437e-05 - acc: 1.0000\n",
      "Epoch 526/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8541e-05 - acc: 1.0000\n",
      "Epoch 527/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8556e-05 - acc: 1.0000\n",
      "Epoch 528/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8370e-05 - acc: 1.0000\n",
      "Epoch 529/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8380e-05 - acc: 1.0000\n",
      "Epoch 530/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8381e-05 - acc: 1.0000\n",
      "Epoch 531/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8656e-05 - acc: 1.0000\n",
      "Epoch 532/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8506e-05 - acc: 1.0000\n",
      "Epoch 533/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8395e-05 - acc: 1.0000\n",
      "Epoch 534/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8514e-05 - acc: 1.0000\n",
      "Epoch 535/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8338e-05 - acc: 1.0000\n",
      "Epoch 536/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8565e-05 - acc: 1.0000\n",
      "Epoch 537/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8479e-05 - acc: 1.0000\n",
      "Epoch 538/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8292e-05 - acc: 1.0000\n",
      "Epoch 539/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.8423e-05 - acc: 1.0000\n",
      "Epoch 540/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8260e-05 - acc: 1.0000: 0s - loss: 1.8348e-\n",
      "Epoch 541/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8412e-05 - acc: 1.0000\n",
      "Epoch 542/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.8361e-05 - acc: 1.0000\n",
      "Epoch 543/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8386e-05 - acc: 1.0000\n",
      "Epoch 544/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8494e-05 - acc: 1.0000\n",
      "Epoch 545/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8399e-05 - acc: 1.0000\n",
      "Epoch 546/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8381e-05 - acc: 1.0000\n",
      "Epoch 547/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8401e-05 - acc: 1.0000\n",
      "Epoch 548/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8578e-05 - acc: 1.0000\n",
      "Epoch 549/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8307e-05 - acc: 1.0000\n",
      "Epoch 550/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8330e-05 - acc: 1.0000\n",
      "Epoch 551/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8259e-05 - acc: 1.0000\n",
      "Epoch 552/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8291e-05 - acc: 1.0000\n",
      "Epoch 553/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8795e-05 - acc: 1.0000\n",
      "Epoch 554/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8420e-05 - acc: 1.0000\n",
      "Epoch 555/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.8239e-05 - acc: 1.0000\n",
      "Epoch 556/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8237e-05 - acc: 1.0000\n",
      "Epoch 557/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8266e-05 - acc: 1.0000\n",
      "Epoch 558/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8264e-05 - acc: 1.0000\n",
      "Epoch 559/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8400e-05 - acc: 1.0000\n",
      "Epoch 560/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8207e-05 - acc: 1.0000\n",
      "Epoch 561/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.8332e-05 - acc: 1.0000\n",
      "Epoch 562/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.8269e-05 - acc: 1.0000\n",
      "Epoch 563/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8400e-05 - acc: 1.0000\n",
      "Epoch 564/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8328e-05 - acc: 1.0000\n",
      "Epoch 565/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8147e-05 - acc: 1.0000\n",
      "Epoch 566/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8208e-05 - acc: 1.0000\n",
      "Epoch 567/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8095e-05 - acc: 1.0000\n",
      "Epoch 568/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.8401e-05 - acc: 1.0000\n",
      "Epoch 569/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8327e-05 - acc: 1.0000\n",
      "Epoch 570/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8274e-05 - acc: 1.0000\n",
      "Epoch 571/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8224e-05 - acc: 1.0000\n",
      "Epoch 572/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8272e-05 - acc: 1.0000\n",
      "Epoch 573/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8139e-05 - acc: 1.0000: 1s - loss: 1\n",
      "Epoch 574/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8350e-05 - acc: 1.0000\n",
      "Epoch 575/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8231e-05 - acc: 1.0000\n",
      "Epoch 576/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8214e-05 - acc: 1.0000\n",
      "Epoch 577/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8282e-05 - acc: 1.0000\n",
      "Epoch 578/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8090e-05 - acc: 1.0000\n",
      "Epoch 579/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8241e-05 - acc: 1.0000\n",
      "Epoch 580/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8237e-05 - acc: 1.0000\n",
      "Epoch 581/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.8250e-05 - acc: 1.0000\n",
      "Epoch 582/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8157e-05 - acc: 1.0000\n",
      "Epoch 583/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8138e-05 - acc: 1.0000\n",
      "Epoch 584/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8421e-05 - acc: 1.0000\n",
      "Epoch 585/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8217e-05 - acc: 1.0000\n",
      "Epoch 586/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8138e-05 - acc: 1.0000\n",
      "Epoch 587/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8130e-05 - acc: 1.0000\n",
      "Epoch 588/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8218e-05 - acc: 1.0000\n",
      "Epoch 589/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8737e-05 - acc: 1.0000\n",
      "Epoch 590/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8166e-05 - acc: 1.0000\n",
      "Epoch 591/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8130e-05 - acc: 1.0000\n",
      "Epoch 592/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8152e-05 - acc: 1.0000\n",
      "Epoch 593/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8270e-05 - acc: 1.0000\n",
      "Epoch 594/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8064e-05 - acc: 1.0000\n",
      "Epoch 595/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.8097e-05 - acc: 1.0000\n",
      "Epoch 596/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8095e-05 - acc: 1.0000\n",
      "Epoch 597/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8357e-05 - acc: 1.0000\n",
      "Epoch 598/1001\n",
      "91704/91704 [==============================] - 6s 62us/step - loss: 1.8093e-05 - acc: 1.0000\n",
      "Epoch 599/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.8118e-05 - acc: 1.0000\n",
      "Epoch 600/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8147e-05 - acc: 1.0000\n",
      "Epoch 601/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8114e-05 - acc: 1.0000\n",
      "Epoch 602/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 1.8059e-05 - acc: 1.0000\n",
      "Epoch 603/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8111e-05 - acc: 1.0000\n",
      "Epoch 604/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8097e-05 - acc: 1.0000\n",
      "Epoch 605/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.8129e-05 - acc: 1.0000\n",
      "Epoch 606/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8018e-05 - acc: 1.0000\n",
      "Epoch 607/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.8328e-05 - acc: 1.0000\n",
      "Epoch 608/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7922e-05 - acc: 1.0000\n",
      "Epoch 609/1001\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 1.8048e-05 - acc: 1.000 - 5s 55us/step - loss: 1.8060e-05 - acc: 1.0000\n",
      "Epoch 610/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8000e-05 - acc: 1.0000\n",
      "Epoch 611/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8095e-05 - acc: 1.0000\n",
      "Epoch 612/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8091e-05 - acc: 1.0000\n",
      "Epoch 613/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8268e-05 - acc: 1.0000\n",
      "Epoch 614/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8192e-05 - acc: 1.0000\n",
      "Epoch 615/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7888e-05 - acc: 1.0000\n",
      "Epoch 616/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8057e-05 - acc: 1.0000\n",
      "Epoch 617/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8050e-05 - acc: 1.0000\n",
      "Epoch 618/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.8029e-05 - acc: 1.0000\n",
      "Epoch 619/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8082e-05 - acc: 1.0000\n",
      "Epoch 620/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7947e-05 - acc: 1.0000\n",
      "Epoch 621/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7934e-05 - acc: 1.0000\n",
      "Epoch 622/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8066e-05 - acc: 1.0000\n",
      "Epoch 623/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7982e-05 - acc: 1.0000\n",
      "Epoch 624/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8033e-05 - acc: 1.0000\n",
      "Epoch 625/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8003e-05 - acc: 1.0000\n",
      "Epoch 626/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8049e-05 - acc: 1.0000\n",
      "Epoch 627/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7923e-05 - acc: 1.0000\n",
      "Epoch 628/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8040e-05 - acc: 1.0000\n",
      "Epoch 629/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7921e-05 - acc: 1.0000\n",
      "Epoch 630/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8053e-05 - acc: 1.0000\n",
      "Epoch 631/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7876e-05 - acc: 1.0000\n",
      "Epoch 632/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7932e-05 - acc: 1.0000\n",
      "Epoch 633/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.8129e-05 - acc: 1.0000\n",
      "Epoch 634/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7824e-05 - acc: 1.0000\n",
      "Epoch 635/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8013e-05 - acc: 1.0000\n",
      "Epoch 636/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8020e-05 - acc: 1.0000\n",
      "Epoch 637/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7937e-05 - acc: 1.0000\n",
      "Epoch 638/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7966e-05 - acc: 1.0000\n",
      "Epoch 639/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7911e-05 - acc: 1.0000\n",
      "Epoch 640/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7970e-05 - acc: 1.0000\n",
      "Epoch 641/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7977e-05 - acc: 1.0000\n",
      "Epoch 642/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.7925e-05 - acc: 1.0000\n",
      "Epoch 643/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7936e-05 - acc: 1.0000\n",
      "Epoch 644/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7955e-05 - acc: 1.0000\n",
      "Epoch 645/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7848e-05 - acc: 1.0000\n",
      "Epoch 646/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7756e-05 - acc: 1.0000\n",
      "Epoch 647/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8014e-05 - acc: 1.0000\n",
      "Epoch 648/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7891e-05 - acc: 1.0000\n",
      "Epoch 649/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7926e-05 - acc: 1.0000\n",
      "Epoch 650/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.9073e-05 - acc: 1.0000\n",
      "Epoch 651/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8242e-05 - acc: 1.0000\n",
      "Epoch 652/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8455e-05 - acc: 1.0000\n",
      "Epoch 653/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8005e-05 - acc: 1.0000\n",
      "Epoch 654/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8139e-05 - acc: 1.0000\n",
      "Epoch 655/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7979e-05 - acc: 1.0000\n",
      "Epoch 656/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.8002e-05 - acc: 1.0000\n",
      "Epoch 657/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8074e-05 - acc: 1.0000\n",
      "Epoch 658/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7996e-05 - acc: 1.0000\n",
      "Epoch 659/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7974e-05 - acc: 1.0000\n",
      "Epoch 660/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8179e-05 - acc: 1.0000\n",
      "Epoch 661/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7995e-05 - acc: 1.0000\n",
      "Epoch 662/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7914e-05 - acc: 1.0000\n",
      "Epoch 663/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.8091e-05 - acc: 1.0000\n",
      "Epoch 664/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7960e-05 - acc: 1.0000\n",
      "Epoch 665/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7812e-05 - acc: 1.0000\n",
      "Epoch 666/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.7887e-05 - acc: 1.0000\n",
      "Epoch 667/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7946e-05 - acc: 1.0000\n",
      "Epoch 668/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8181e-05 - acc: 1.0000\n",
      "Epoch 669/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7726e-05 - acc: 1.0000\n",
      "Epoch 670/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.8163e-05 - acc: 1.0000\n",
      "Epoch 671/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7859e-05 - acc: 1.0000\n",
      "Epoch 672/1001\n",
      "91704/91704 [==============================] - 6s 61us/step - loss: 1.7954e-05 - acc: 1.0000\n",
      "Epoch 673/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7862e-05 - acc: 1.0000\n",
      "Epoch 674/1001\n",
      "91704/91704 [==============================] - 8s 89us/step - loss: 1.7842e-05 - acc: 1.0000\n",
      "Epoch 675/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.7882e-05 - acc: 1.0000\n",
      "Epoch 676/1001\n",
      "91704/91704 [==============================] - 6s 63us/step - loss: 1.7909e-05 - acc: 1.0000\n",
      "Epoch 677/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7798e-05 - acc: 1.0000\n",
      "Epoch 678/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7745e-05 - acc: 1.0000\n",
      "Epoch 679/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7816e-05 - acc: 1.0000\n",
      "Epoch 680/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7874e-05 - acc: 1.0000\n",
      "Epoch 681/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.7831e-05 - acc: 1.0000\n",
      "Epoch 682/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7793e-05 - acc: 1.0000\n",
      "Epoch 683/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7936e-05 - acc: 1.0000\n",
      "Epoch 684/1001\n",
      "91704/91704 [==============================] - 5s 60us/step - loss: 1.7931e-05 - acc: 1.0000\n",
      "Epoch 685/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.7730e-05 - acc: 1.0000\n",
      "Epoch 686/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 1.7912e-05 - acc: 1.0000\n",
      "Epoch 687/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 1.7784e-05 - acc: 1.0000\n",
      "Epoch 688/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7771e-05 - acc: 1.0000\n",
      "Epoch 689/1001\n",
      "91704/91704 [==============================] - 5s 60us/step - loss: 1.7707e-05 - acc: 1.0000\n",
      "Epoch 690/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7669e-05 - acc: 1.0000\n",
      "Epoch 691/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7692e-05 - acc: 1.0000\n",
      "Epoch 692/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7845e-05 - acc: 1.0000\n",
      "Epoch 693/1001\n",
      "91704/91704 [==============================] - 6s 62us/step - loss: 1.7834e-05 - acc: 1.0000\n",
      "Epoch 694/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.7815e-05 - acc: 1.0000\n",
      "Epoch 695/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7799e-05 - acc: 1.0000\n",
      "Epoch 696/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 1.7641e-05 - acc: 1.0000\n",
      "Epoch 697/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.7755e-05 - acc: 1.0000\n",
      "Epoch 698/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7782e-05 - acc: 1.0000\n",
      "Epoch 699/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 1.7734e-05 - acc: 1.0000\n",
      "Epoch 700/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.7678e-05 - acc: 1.0000\n",
      "Epoch 701/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7679e-05 - acc: 1.0000\n",
      "Epoch 702/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7573e-05 - acc: 1.0000\n",
      "Epoch 703/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7758e-05 - acc: 1.0000\n",
      "Epoch 704/1001\n",
      "91704/91704 [==============================] - 6s 63us/step - loss: 1.7658e-05 - acc: 1.0000\n",
      "Epoch 705/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.7703e-05 - acc: 1.0000\n",
      "Epoch 706/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7752e-05 - acc: 1.0000\n",
      "Epoch 707/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7629e-05 - acc: 1.0000\n",
      "Epoch 708/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 1.7774e-05 - acc: 1.0000\n",
      "Epoch 709/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7542e-05 - acc: 1.0000\n",
      "Epoch 710/1001\n",
      "91704/91704 [==============================] - 6s 60us/step - loss: 1.7700e-05 - acc: 1.0000\n",
      "Epoch 711/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7706e-05 - acc: 1.0000\n",
      "Epoch 712/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7637e-05 - acc: 1.0000\n",
      "Epoch 713/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7704e-05 - acc: 1.0000\n",
      "Epoch 714/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7654e-05 - acc: 1.0000\n",
      "Epoch 715/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7610e-05 - acc: 1.0000\n",
      "Epoch 716/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7657e-05 - acc: 1.0000\n",
      "Epoch 717/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7619e-05 - acc: 1.0000\n",
      "Epoch 718/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7640e-05 - acc: 1.0000\n",
      "Epoch 719/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7736e-05 - acc: 1.0000\n",
      "Epoch 720/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7533e-05 - acc: 1.0000\n",
      "Epoch 721/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7676e-05 - acc: 1.0000\n",
      "Epoch 722/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7761e-05 - acc: 1.0000\n",
      "Epoch 723/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7530e-05 - acc: 1.0000\n",
      "Epoch 724/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7606e-05 - acc: 1.0000\n",
      "Epoch 725/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7550e-05 - acc: 1.0000\n",
      "Epoch 726/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7706e-05 - acc: 1.0000\n",
      "Epoch 727/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7580e-05 - acc: 0.9999\n",
      "Epoch 728/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7539e-05 - acc: 1.0000\n",
      "Epoch 729/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7797e-05 - acc: 1.0000\n",
      "Epoch 730/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7490e-05 - acc: 1.0000\n",
      "Epoch 731/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7659e-05 - acc: 1.0000\n",
      "Epoch 732/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7645e-05 - acc: 1.0000\n",
      "Epoch 733/1001\n",
      "91704/91704 [==============================] - 6s 60us/step - loss: 1.7616e-05 - acc: 1.0000\n",
      "Epoch 734/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7687e-05 - acc: 1.0000\n",
      "Epoch 735/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 1.7606e-05 - acc: 1.0000\n",
      "Epoch 736/1001\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 1.7547e-05 - acc: 1.000 - 5s 54us/step - loss: 1.7548e-05 - acc: 1.0000\n",
      "Epoch 737/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7824e-05 - acc: 1.0000\n",
      "Epoch 738/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7601e-05 - acc: 1.0000\n",
      "Epoch 739/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7609e-05 - acc: 1.0000\n",
      "Epoch 740/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7603e-05 - acc: 1.0000\n",
      "Epoch 741/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7455e-05 - acc: 1.0000\n",
      "Epoch 742/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7665e-05 - acc: 1.0000\n",
      "Epoch 743/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7520e-05 - acc: 1.0000\n",
      "Epoch 744/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7548e-05 - acc: 1.0000\n",
      "Epoch 745/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7601e-05 - acc: 1.0000\n",
      "Epoch 746/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7536e-05 - acc: 1.0000\n",
      "Epoch 747/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7513e-05 - acc: 1.0000\n",
      "Epoch 748/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7506e-05 - acc: 1.0000\n",
      "Epoch 749/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7682e-05 - acc: 1.0000\n",
      "Epoch 750/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7653e-05 - acc: 1.0000\n",
      "Epoch 751/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7526e-05 - acc: 1.0000\n",
      "Epoch 752/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7422e-05 - acc: 1.0000\n",
      "Epoch 753/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7627e-05 - acc: 1.0000\n",
      "Epoch 754/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7459e-05 - acc: 1.0000\n",
      "Epoch 755/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7568e-05 - acc: 1.0000\n",
      "Epoch 756/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7530e-05 - acc: 1.0000\n",
      "Epoch 757/1001\n",
      "91704/91704 [==============================] - 6s 61us/step - loss: 1.7584e-05 - acc: 1.0000\n",
      "Epoch 758/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7564e-05 - acc: 1.0000\n",
      "Epoch 759/1001\n",
      "91704/91704 [==============================] - 5s 60us/step - loss: 1.7672e-05 - acc: 1.0000\n",
      "Epoch 760/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7627e-05 - acc: 1.0000\n",
      "Epoch 761/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7481e-05 - acc: 1.0000\n",
      "Epoch 762/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7434e-05 - acc: 1.0000\n",
      "Epoch 763/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7510e-05 - acc: 1.0000\n",
      "Epoch 764/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7443e-05 - acc: 1.0000\n",
      "Epoch 765/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7421e-05 - acc: 1.0000\n",
      "Epoch 766/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7712e-05 - acc: 1.0000\n",
      "Epoch 767/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7593e-05 - acc: 1.0000\n",
      "Epoch 768/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7561e-05 - acc: 1.0000\n",
      "Epoch 769/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7480e-05 - acc: 1.0000\n",
      "Epoch 770/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7728e-05 - acc: 1.0000\n",
      "Epoch 771/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7556e-05 - acc: 1.0000\n",
      "Epoch 772/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7376e-05 - acc: 1.0000\n",
      "Epoch 773/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.7442e-05 - acc: 1.0000\n",
      "Epoch 774/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7456e-05 - acc: 1.0000\n",
      "Epoch 775/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7536e-05 - acc: 1.0000\n",
      "Epoch 776/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7623e-05 - acc: 1.0000\n",
      "Epoch 777/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7429e-05 - acc: 1.0000\n",
      "Epoch 778/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7619e-05 - acc: 1.0000\n",
      "Epoch 779/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7383e-05 - acc: 1.0000\n",
      "Epoch 780/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7427e-05 - acc: 1.0000\n",
      "Epoch 781/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7472e-05 - acc: 1.0000\n",
      "Epoch 782/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7523e-05 - acc: 1.0000\n",
      "Epoch 783/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7459e-05 - acc: 1.0000\n",
      "Epoch 784/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7397e-05 - acc: 1.0000\n",
      "Epoch 785/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7375e-05 - acc: 1.0000\n",
      "Epoch 786/1001\n",
      "91704/91704 [==============================] - 6s 60us/step - loss: 1.7441e-05 - acc: 1.0000\n",
      "Epoch 787/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7462e-05 - acc: 1.0000\n",
      "Epoch 788/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7482e-05 - acc: 1.0000\n",
      "Epoch 789/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7470e-05 - acc: 1.0000\n",
      "Epoch 790/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7366e-05 - acc: 1.0000\n",
      "Epoch 791/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7423e-05 - acc: 1.0000\n",
      "Epoch 792/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7420e-05 - acc: 1.0000\n",
      "Epoch 793/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7478e-05 - acc: 1.0000\n",
      "Epoch 794/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7342e-05 - acc: 1.0000\n",
      "Epoch 795/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7354e-05 - acc: 1.0000\n",
      "Epoch 796/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7399e-05 - acc: 1.0000\n",
      "Epoch 797/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7389e-05 - acc: 1.0000\n",
      "Epoch 798/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7285e-05 - acc: 1.0000\n",
      "Epoch 799/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7383e-05 - acc: 1.0000\n",
      "Epoch 800/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7407e-05 - acc: 1.0000\n",
      "Epoch 801/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7308e-05 - acc: 1.0000\n",
      "Epoch 802/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7242e-05 - acc: 1.0000\n",
      "Epoch 803/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7343e-05 - acc: 1.0000\n",
      "Epoch 804/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.7277e-05 - acc: 1.0000\n",
      "Epoch 805/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7372e-05 - acc: 1.0000\n",
      "Epoch 806/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7245e-05 - acc: 1.0000\n",
      "Epoch 807/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7416e-05 - acc: 1.0000\n",
      "Epoch 808/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7255e-05 - acc: 1.0000\n",
      "Epoch 809/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 1.7513e-05 - acc: 1.0000\n",
      "Epoch 810/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7269e-05 - acc: 1.0000\n",
      "Epoch 811/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7449e-05 - acc: 1.0000\n",
      "Epoch 812/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7266e-05 - acc: 1.0000: 0s - loss: 1.7284e-05 - acc: 1.000\n",
      "Epoch 813/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7357e-05 - acc: 1.0000\n",
      "Epoch 814/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7321e-05 - acc: 1.0000\n",
      "Epoch 815/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7226e-05 - acc: 1.0000\n",
      "Epoch 816/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7330e-05 - acc: 1.0000\n",
      "Epoch 817/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7271e-05 - acc: 1.0000\n",
      "Epoch 818/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7377e-05 - acc: 1.0000\n",
      "Epoch 819/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7412e-05 - acc: 1.0000\n",
      "Epoch 820/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7180e-05 - acc: 1.0000\n",
      "Epoch 821/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7246e-05 - acc: 1.0000\n",
      "Epoch 822/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7350e-05 - acc: 1.0000\n",
      "Epoch 823/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7143e-05 - acc: 1.0000\n",
      "Epoch 824/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7270e-05 - acc: 1.0000\n",
      "Epoch 825/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7273e-05 - acc: 1.0000\n",
      "Epoch 826/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7249e-05 - acc: 1.0000\n",
      "Epoch 827/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7254e-05 - acc: 1.0000\n",
      "Epoch 828/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7166e-05 - acc: 1.0000\n",
      "Epoch 829/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7251e-05 - acc: 1.0000\n",
      "Epoch 830/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7135e-05 - acc: 1.0000\n",
      "Epoch 831/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7320e-05 - acc: 1.0000\n",
      "Epoch 832/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7176e-05 - acc: 1.0000\n",
      "Epoch 833/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7390e-05 - acc: 1.0000\n",
      "Epoch 834/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 1.7125e-05 - acc: 1.0000\n",
      "Epoch 835/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7199e-05 - acc: 1.0000\n",
      "Epoch 836/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7283e-05 - acc: 1.0000\n",
      "Epoch 837/1001\n",
      "91704/91704 [==============================] - 6s 61us/step - loss: 1.7138e-05 - acc: 1.0000\n",
      "Epoch 838/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.7273e-05 - acc: 1.0000\n",
      "Epoch 839/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.7198e-05 - acc: 1.0000\n",
      "Epoch 840/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7169e-05 - acc: 1.0000\n",
      "Epoch 841/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 1.7102e-05 - acc: 1.0000\n",
      "Epoch 842/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7256e-05 - acc: 1.0000\n",
      "Epoch 843/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7172e-05 - acc: 1.0000\n",
      "Epoch 844/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7209e-05 - acc: 1.0000\n",
      "Epoch 845/1001\n",
      "91704/91704 [==============================] - 6s 61us/step - loss: 1.7187e-05 - acc: 1.0000\n",
      "Epoch 846/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 1.7251e-05 - acc: 1.0000\n",
      "Epoch 847/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7033e-05 - acc: 1.0000\n",
      "Epoch 848/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.7151e-05 - acc: 1.0000\n",
      "Epoch 849/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 1.7108e-05 - acc: 1.0000\n",
      "Epoch 850/1001\n",
      "91704/91704 [==============================] - 6s 62us/step - loss: 1.7371e-05 - acc: 1.0000\n",
      "Epoch 851/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 1.7136e-05 - acc: 1.0000\n",
      "Epoch 852/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 1.7465e-05 - acc: 1.0000\n",
      "Epoch 853/1001\n",
      "91704/91704 [==============================] - 6s 64us/step - loss: 1.7158e-05 - acc: 1.0000\n",
      "Epoch 854/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.7065e-05 - acc: 1.0000\n",
      "Epoch 855/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.7181e-05 - acc: 1.0000\n",
      "Epoch 856/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7102e-05 - acc: 1.0000\n",
      "Epoch 857/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.7095e-05 - acc: 1.0000\n",
      "Epoch 858/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.7323e-05 - acc: 1.0000\n",
      "Epoch 859/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.6945e-05 - acc: 1.0000\n",
      "Epoch 860/1001\n",
      "91704/91704 [==============================] - 9s 94us/step - loss: 1.7036e-05 - acc: 1.0000\n",
      "Epoch 861/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.7126e-05 - acc: 1.0000\n",
      "Epoch 862/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7246e-05 - acc: 1.0000\n",
      "Epoch 863/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.7031e-05 - acc: 1.0000\n",
      "Epoch 864/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.7211e-05 - acc: 1.0000\n",
      "Epoch 865/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7065e-05 - acc: 1.0000\n",
      "Epoch 866/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7002e-05 - acc: 1.0000\n",
      "Epoch 867/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7038e-05 - acc: 1.0000\n",
      "Epoch 868/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7083e-05 - acc: 1.0000\n",
      "Epoch 869/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.7040e-05 - acc: 1.0000\n",
      "Epoch 870/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.7132e-05 - acc: 1.0000\n",
      "Epoch 871/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.7020e-05 - acc: 1.0000\n",
      "Epoch 872/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7106e-05 - acc: 1.0000\n",
      "Epoch 873/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.7166e-05 - acc: 1.0000\n",
      "Epoch 874/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.7074e-05 - acc: 1.0000\n",
      "Epoch 875/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7146e-05 - acc: 1.0000\n",
      "Epoch 876/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.6988e-05 - acc: 1.0000\n",
      "Epoch 877/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7285e-05 - acc: 1.0000\n",
      "Epoch 878/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7164e-05 - acc: 1.0000\n",
      "Epoch 879/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.7023e-05 - acc: 1.0000\n",
      "Epoch 880/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.7079e-05 - acc: 1.0000\n",
      "Epoch 881/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.7165e-05 - acc: 1.0000\n",
      "Epoch 882/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.7083e-05 - acc: 1.0000\n",
      "Epoch 883/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.7007e-05 - acc: 1.0000\n",
      "Epoch 884/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.6993e-05 - acc: 1.0000\n",
      "Epoch 885/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7034e-05 - acc: 1.0000\n",
      "Epoch 886/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7045e-05 - acc: 1.0000\n",
      "Epoch 887/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7138e-05 - acc: 1.0000\n",
      "Epoch 888/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.6955e-05 - acc: 1.0000\n",
      "Epoch 889/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.7011e-05 - acc: 1.0000\n",
      "Epoch 890/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.7243e-05 - acc: 1.0000\n",
      "Epoch 891/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.7084e-05 - acc: 1.0000\n",
      "Epoch 892/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.6914e-05 - acc: 1.0000\n",
      "Epoch 893/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.7457e-05 - acc: 1.0000\n",
      "Epoch 894/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.6961e-05 - acc: 1.0000\n",
      "Epoch 895/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7010e-05 - acc: 1.0000\n",
      "Epoch 896/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.6998e-05 - acc: 1.0000\n",
      "Epoch 897/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.6996e-05 - acc: 1.0000\n",
      "Epoch 898/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7084e-05 - acc: 1.0000\n",
      "Epoch 899/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.7026e-05 - acc: 1.0000\n",
      "Epoch 900/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 1.6978e-05 - acc: 1.0000\n",
      "Epoch 901/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.6906e-05 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 902/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.7043e-05 - acc: 1.0000\n",
      "Epoch 903/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.7005e-05 - acc: 1.0000\n",
      "Epoch 904/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7095e-05 - acc: 1.0000\n",
      "Epoch 905/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7132e-05 - acc: 1.0000\n",
      "Epoch 906/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.6862e-05 - acc: 1.0000\n",
      "Epoch 907/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.7102e-05 - acc: 1.0000\n",
      "Epoch 908/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.6952e-05 - acc: 1.0000: 1s -\n",
      "Epoch 909/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.7113e-05 - acc: 1.0000\n",
      "Epoch 910/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.6869e-05 - acc: 1.0000\n",
      "Epoch 911/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.7049e-05 - acc: 1.0000\n",
      "Epoch 912/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.6912e-05 - acc: 1.0000\n",
      "Epoch 913/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.7011e-05 - acc: 1.0000\n",
      "Epoch 914/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7049e-05 - acc: 1.0000\n",
      "Epoch 915/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.7048e-05 - acc: 1.0000\n",
      "Epoch 916/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.6894e-05 - acc: 1.0000\n",
      "Epoch 917/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.6984e-05 - acc: 1.0000\n",
      "Epoch 918/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 1.6866e-05 - acc: 1.0000\n",
      "Epoch 919/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.6959e-05 - acc: 1.0000\n",
      "Epoch 920/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7122e-05 - acc: 1.0000\n",
      "Epoch 921/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.7032e-05 - acc: 1.0000\n",
      "Epoch 922/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.7048e-05 - acc: 1.0000\n",
      "Epoch 923/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.6866e-05 - acc: 1.0000\n",
      "Epoch 924/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.6969e-05 - acc: 1.0000\n",
      "Epoch 925/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.6823e-05 - acc: 1.0000\n",
      "Epoch 926/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 1.6940e-05 - acc: 1.0000\n",
      "Epoch 927/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.6895e-05 - acc: 1.0000\n",
      "Epoch 928/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.6900e-05 - acc: 1.0000\n",
      "Epoch 929/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7052e-05 - acc: 1.0000\n",
      "Epoch 930/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.6921e-05 - acc: 1.0000\n",
      "Epoch 931/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.6875e-05 - acc: 1.0000\n",
      "Epoch 932/1001\n",
      "91704/91704 [==============================] - 9s 95us/step - loss: 1.6836e-05 - acc: 1.0000\n",
      "Epoch 933/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7039e-05 - acc: 1.0000\n",
      "Epoch 934/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.6902e-05 - acc: 1.0000\n",
      "Epoch 935/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.6922e-05 - acc: 1.0000\n",
      "Epoch 936/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.6835e-05 - acc: 1.0000\n",
      "Epoch 937/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.6866e-05 - acc: 1.0000\n",
      "Epoch 938/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 1.6976e-05 - acc: 1.0000\n",
      "Epoch 939/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.6858e-05 - acc: 1.0000\n",
      "Epoch 940/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 1.6970e-05 - acc: 1.0000\n",
      "Epoch 941/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 1.6836e-05 - acc: 1.0000\n",
      "Epoch 942/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.6895e-05 - acc: 1.0000\n",
      "Epoch 943/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.6915e-05 - acc: 1.0000\n",
      "Epoch 944/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 1.6841e-05 - acc: 1.0000\n",
      "Epoch 945/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 1.6931e-05 - acc: 1.0000\n",
      "Epoch 946/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.6845e-05 - acc: 1.0000\n",
      "Epoch 947/1001\n",
      "91704/91704 [==============================] - 7s 80us/step - loss: 1.6972e-05 - acc: 1.0000\n",
      "Epoch 948/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.7004e-05 - acc: 1.0000\n",
      "Epoch 949/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.6853e-05 - acc: 1.0000\n",
      "Epoch 950/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 1.6784e-05 - acc: 1.0000\n",
      "Epoch 951/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.6855e-05 - acc: 1.0000\n",
      "Epoch 952/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.7001e-05 - acc: 1.0000\n",
      "Epoch 953/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.6855e-05 - acc: 1.0000\n",
      "Epoch 954/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 1.6815e-05 - acc: 1.0000\n",
      "Epoch 955/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.6884e-05 - acc: 1.0000\n",
      "Epoch 956/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.7009e-05 - acc: 1.0000\n",
      "Epoch 957/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 1.6840e-05 - acc: 1.0000\n",
      "Epoch 958/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.6950e-05 - acc: 1.0000\n",
      "Epoch 959/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.6788e-05 - acc: 1.0000\n",
      "Epoch 960/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.6845e-05 - acc: 1.0000\n",
      "Epoch 961/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.6878e-05 - acc: 1.0000\n",
      "Epoch 962/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 1.6712e-05 - acc: 1.0000\n",
      "Epoch 963/1001\n",
      "91704/91704 [==============================] - 8s 88us/step - loss: 1.6881e-05 - acc: 1.0000\n",
      "Epoch 964/1001\n",
      "91704/91704 [==============================] - 8s 85us/step - loss: 1.6745e-05 - acc: 1.0000\n",
      "Epoch 965/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 1.6864e-05 - acc: 1.0000\n",
      "Epoch 966/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 1.6880e-05 - acc: 1.0000\n",
      "Epoch 967/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.6822e-05 - acc: 1.0000\n",
      "Epoch 968/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 1.6847e-05 - acc: 1.0000\n",
      "Epoch 969/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.6721e-05 - acc: 1.0000\n",
      "Epoch 970/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.6885e-05 - acc: 1.0000\n",
      "Epoch 971/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.6736e-05 - acc: 1.0000\n",
      "Epoch 972/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 1.6895e-05 - acc: 1.0000\n",
      "Epoch 973/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.6886e-05 - acc: 1.0000\n",
      "Epoch 974/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 1.6833e-05 - acc: 1.0000\n",
      "Epoch 975/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 1.6859e-05 - acc: 1.0000\n",
      "Epoch 976/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 1.6842e-05 - acc: 1.0000\n",
      "Epoch 977/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 1.6797e-05 - acc: 1.0000\n",
      "Epoch 978/1001\n",
      "91704/91704 [==============================] - 7s 80us/step - loss: 1.6808e-05 - acc: 1.0000\n",
      "Epoch 979/1001\n",
      "91704/91704 [==============================] - 7s 82us/step - loss: 1.6718e-05 - acc: 1.0000\n",
      "Epoch 980/1001\n",
      "91704/91704 [==============================] - 8s 90us/step - loss: 1.6819e-05 - acc: 1.0000\n",
      "Epoch 981/1001\n",
      "91704/91704 [==============================] - 8s 85us/step - loss: 1.6730e-05 - acc: 1.0000\n",
      "Epoch 982/1001\n",
      "91704/91704 [==============================] - 9s 95us/step - loss: 1.6738e-05 - acc: 1.0000\n",
      "Epoch 983/1001\n",
      "91704/91704 [==============================] - 10s 107us/step - loss: 1.6832e-05 - acc: 1.0000\n",
      "Epoch 984/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 1.6898e-05 - acc: 1.0000\n",
      "Epoch 985/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.6969e-05 - acc: 1.0000\n",
      "Epoch 986/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.6719e-05 - acc: 1.0000\n",
      "Epoch 987/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.6800e-05 - acc: 1.0000\n",
      "Epoch 988/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.6819e-05 - acc: 1.0000\n",
      "Epoch 989/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.6708e-05 - acc: 1.0000\n",
      "Epoch 990/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 1.6773e-05 - acc: 1.0000\n",
      "Epoch 991/1001\n",
      "91704/91704 [==============================] - 7s 81us/step - loss: 1.6824e-05 - acc: 1.0000\n",
      "Epoch 992/1001\n",
      "91704/91704 [==============================] - 8s 87us/step - loss: 1.6787e-05 - acc: 1.0000\n",
      "Epoch 993/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.6794e-05 - acc: 1.0000\n",
      "Epoch 994/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.6786e-05 - acc: 1.0000\n",
      "Epoch 995/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 1.6780e-05 - acc: 1.0000\n",
      "Epoch 996/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.6730e-05 - acc: 1.0000\n",
      "Epoch 997/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 1.6747e-05 - acc: 1.0000\n",
      "Epoch 998/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.6705e-05 - acc: 1.0000\n",
      "Epoch 999/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 1.6818e-05 - acc: 1.0000\n",
      "Epoch 1000/1001\n",
      "91704/91704 [==============================] - 8s 88us/step - loss: 1.6790e-05 - acc: 1.0000\n",
      "Epoch 1001/1001\n",
      "91704/91704 [==============================] - 7s 80us/step - loss: 1.6864e-05 - acc: 1.0000\n",
      "../linkPrediction/dataframes/obesity\\obesity-model-citation-1000_2008-2015.pkl\n",
      "../linkPrediction/dataframes/obesity\\obesity-X_test-citation_2008-2015.pkl\n",
      "../linkPrediction/dataframes/obesity\\obesity-y_test-citation_2008-2015.pkl\n",
      "pref ---------------------------------------------------------------------------------\n",
      "(131006, 7, 3) (131006, 3)\n",
      "Epoch 1/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 4.7287e-04 - acc: 0.6995\n",
      "Epoch 2/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.2385e-04 - acc: 0.7080\n",
      "Epoch 3/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 2.0943e-04 - acc: 0.7095\n",
      "Epoch 4/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.0536e-04 - acc: 0.7112\n",
      "Epoch 5/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.0226e-04 - acc: 0.7114\n",
      "Epoch 6/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.0048e-04 - acc: 0.7100\n",
      "Epoch 7/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.9527e-04 - acc: 0.7150\n",
      "Epoch 8/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.9190e-04 - acc: 0.7135\n",
      "Epoch 9/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.8779e-04 - acc: 0.7151\n",
      "Epoch 10/1001\n",
      "91704/91704 [==============================] - 6s 64us/step - loss: 1.8160e-04 - acc: 0.7166\n",
      "Epoch 11/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.7710e-04 - acc: 0.7191\n",
      "Epoch 12/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.7376e-04 - acc: 0.7174\n",
      "Epoch 13/1001\n",
      "91704/91704 [==============================] - 6s 64us/step - loss: 1.7051e-04 - acc: 0.7185\n",
      "Epoch 14/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.6861e-04 - acc: 0.7199\n",
      "Epoch 15/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.6513e-04 - acc: 0.7185\n",
      "Epoch 16/1001\n",
      "91704/91704 [==============================] - 6s 64us/step - loss: 1.6386e-04 - acc: 0.7211\n",
      "Epoch 17/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.6157e-04 - acc: 0.7192\n",
      "Epoch 18/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.6212e-04 - acc: 0.7229\n",
      "Epoch 19/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.5835e-04 - acc: 0.7202\n",
      "Epoch 20/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.5842e-04 - acc: 0.7227\n",
      "Epoch 21/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.5634e-04 - acc: 0.7238\n",
      "Epoch 22/1001\n",
      "91704/91704 [==============================] - 6s 64us/step - loss: 1.5430e-04 - acc: 0.7250\n",
      "Epoch 23/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.5466e-04 - acc: 0.7237\n",
      "Epoch 24/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.5260e-04 - acc: 0.7240\n",
      "Epoch 25/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.5237e-04 - acc: 0.7231\n",
      "Epoch 26/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.5140e-04 - acc: 0.7260\n",
      "Epoch 27/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.5009e-04 - acc: 0.7234\n",
      "Epoch 28/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.4944e-04 - acc: 0.7267\n",
      "Epoch 29/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.4741e-04 - acc: 0.7253\n",
      "Epoch 30/1001\n",
      "91704/91704 [==============================] - 6s 64us/step - loss: 1.4557e-04 - acc: 0.7254\n",
      "Epoch 31/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.4478e-04 - acc: 0.7267\n",
      "Epoch 32/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.4587e-04 - acc: 0.7258\n",
      "Epoch 33/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.4415e-04 - acc: 0.7270\n",
      "Epoch 34/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.4359e-04 - acc: 0.7248\n",
      "Epoch 35/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.4133e-04 - acc: 0.7280\n",
      "Epoch 36/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.4300e-04 - acc: 0.7284\n",
      "Epoch 37/1001\n",
      "91704/91704 [==============================] - 6s 64us/step - loss: 1.4060e-04 - acc: 0.7280\n",
      "Epoch 38/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.4040e-04 - acc: 0.7263\n",
      "Epoch 39/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.4105e-04 - acc: 0.7258\n",
      "Epoch 40/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.3997e-04 - acc: 0.7260: 0s - loss: 1.4001e-04 - acc:\n",
      "Epoch 41/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.3799e-04 - acc: 0.7245\n",
      "Epoch 42/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.3744e-04 - acc: 0.7273\n",
      "Epoch 43/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.3762e-04 - acc: 0.7261\n",
      "Epoch 44/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.3678e-04 - acc: 0.7260\n",
      "Epoch 45/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.3705e-04 - acc: 0.7283\n",
      "Epoch 46/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.3570e-04 - acc: 0.7290\n",
      "Epoch 47/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.3569e-04 - acc: 0.7296\n",
      "Epoch 48/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.3521e-04 - acc: 0.7262\n",
      "Epoch 49/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.3487e-04 - acc: 0.7282\n",
      "Epoch 50/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 1.3363e-04 - acc: 0.7274\n",
      "Epoch 51/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.3283e-04 - acc: 0.7304\n",
      "Epoch 52/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.3185e-04 - acc: 0.7285\n",
      "Epoch 53/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 1.3366e-04 - acc: 0.7292\n",
      "Epoch 54/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.3233e-04 - acc: 0.7252\n",
      "Epoch 55/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.3136e-04 - acc: 0.7283\n",
      "Epoch 56/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.3126e-04 - acc: 0.7284\n",
      "Epoch 57/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.3089e-04 - acc: 0.7277\n",
      "Epoch 58/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.3046e-04 - acc: 0.7289\n",
      "Epoch 59/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.2883e-04 - acc: 0.7288\n",
      "Epoch 60/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.2798e-04 - acc: 0.7287\n",
      "Epoch 61/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.2821e-04 - acc: 0.7306\n",
      "Epoch 62/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.2923e-04 - acc: 0.7303\n",
      "Epoch 63/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.2838e-04 - acc: 0.7306\n",
      "Epoch 64/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.2653e-04 - acc: 0.7312\n",
      "Epoch 65/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.2675e-04 - acc: 0.7301\n",
      "Epoch 66/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.2688e-04 - acc: 0.7300\n",
      "Epoch 67/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 1.2600e-04 - acc: 0.7308\n",
      "Epoch 68/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.2636e-04 - acc: 0.7299\n",
      "Epoch 69/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.2556e-04 - acc: 0.7295\n",
      "Epoch 70/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.2493e-04 - acc: 0.7278\n",
      "Epoch 71/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.2614e-04 - acc: 0.7301\n",
      "Epoch 72/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.2538e-04 - acc: 0.7327\n",
      "Epoch 73/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.2333e-04 - acc: 0.7304\n",
      "Epoch 74/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.2497e-04 - acc: 0.7294\n",
      "Epoch 75/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.2320e-04 - acc: 0.7305\n",
      "Epoch 76/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.2427e-04 - acc: 0.7312\n",
      "Epoch 77/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.2292e-04 - acc: 0.7315\n",
      "Epoch 78/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.2218e-04 - acc: 0.7320\n",
      "Epoch 79/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.2232e-04 - acc: 0.7299\n",
      "Epoch 80/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.2270e-04 - acc: 0.7299\n",
      "Epoch 81/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.2210e-04 - acc: 0.7316\n",
      "Epoch 82/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.2216e-04 - acc: 0.7289\n",
      "Epoch 83/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 1.2219e-04 - acc: 0.7306\n",
      "Epoch 84/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.2202e-04 - acc: 0.7288\n",
      "Epoch 85/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.2106e-04 - acc: 0.7301\n",
      "Epoch 86/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.2104e-04 - acc: 0.7305\n",
      "Epoch 87/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.2116e-04 - acc: 0.7314\n",
      "Epoch 88/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.2170e-04 - acc: 0.7280\n",
      "Epoch 89/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 1.1995e-04 - acc: 0.7309\n",
      "Epoch 90/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.2074e-04 - acc: 0.7305\n",
      "Epoch 91/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.1993e-04 - acc: 0.7318\n",
      "Epoch 92/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.2027e-04 - acc: 0.7309\n",
      "Epoch 93/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 1.2037e-04 - acc: 0.7285\n",
      "Epoch 94/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.1919e-04 - acc: 0.7295\n",
      "Epoch 95/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.1884e-04 - acc: 0.7292\n",
      "Epoch 96/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 1.1888e-04 - acc: 0.7284\n",
      "Epoch 97/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.1997e-04 - acc: 0.7275\n",
      "Epoch 98/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.1829e-04 - acc: 0.7313\n",
      "Epoch 99/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.1785e-04 - acc: 0.7322\n",
      "Epoch 100/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.1774e-04 - acc: 0.7313\n",
      "Epoch 101/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.1788e-04 - acc: 0.7316\n",
      "../linkPrediction/dataframes/obesity\\obesity-model-pref-100_2008-2015.pkl\n",
      "Epoch 102/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.1786e-04 - acc: 0.7310\n",
      "Epoch 103/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 1.1699e-04 - acc: 0.7292\n",
      "Epoch 104/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.1778e-04 - acc: 0.7309\n",
      "Epoch 105/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.1688e-04 - acc: 0.7297\n",
      "Epoch 106/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 1.1787e-04 - acc: 0.7303\n",
      "Epoch 107/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.1668e-04 - acc: 0.7310\n",
      "Epoch 108/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.1608e-04 - acc: 0.7302\n",
      "Epoch 109/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.1533e-04 - acc: 0.7324\n",
      "Epoch 110/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.1678e-04 - acc: 0.7313\n",
      "Epoch 111/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.1552e-04 - acc: 0.7323\n",
      "Epoch 112/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.1504e-04 - acc: 0.7300\n",
      "Epoch 113/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.1574e-04 - acc: 0.7308\n",
      "Epoch 114/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.1564e-04 - acc: 0.7300\n",
      "Epoch 115/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.1472e-04 - acc: 0.7329\n",
      "Epoch 116/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.1469e-04 - acc: 0.7328\n",
      "Epoch 117/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.1417e-04 - acc: 0.7298\n",
      "Epoch 118/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.1430e-04 - acc: 0.7303\n",
      "Epoch 119/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.1465e-04 - acc: 0.7322\n",
      "Epoch 120/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.1340e-04 - acc: 0.7325\n",
      "Epoch 121/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 1.1345e-04 - acc: 0.7323\n",
      "Epoch 122/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.1315e-04 - acc: 0.7322\n",
      "Epoch 123/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.1308e-04 - acc: 0.7316\n",
      "Epoch 124/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.1243e-04 - acc: 0.7330\n",
      "Epoch 125/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 1.1276e-04 - acc: 0.7333\n",
      "Epoch 126/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.1200e-04 - acc: 0.7317\n",
      "Epoch 127/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 1.1170e-04 - acc: 0.7333\n",
      "Epoch 128/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.1220e-04 - acc: 0.7318\n",
      "Epoch 129/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.1231e-04 - acc: 0.7319\n",
      "Epoch 130/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.1158e-04 - acc: 0.7315\n",
      "Epoch 131/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.1149e-04 - acc: 0.7330\n",
      "Epoch 132/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.1157e-04 - acc: 0.7317\n",
      "Epoch 133/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.1034e-04 - acc: 0.7310\n",
      "Epoch 134/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.1142e-04 - acc: 0.7315\n",
      "Epoch 135/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.1039e-04 - acc: 0.7324\n",
      "Epoch 136/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.1030e-04 - acc: 0.7330\n",
      "Epoch 137/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.1043e-04 - acc: 0.7339\n",
      "Epoch 138/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.1059e-04 - acc: 0.7328\n",
      "Epoch 139/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.1087e-04 - acc: 0.7323\n",
      "Epoch 140/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.0994e-04 - acc: 0.7311\n",
      "Epoch 141/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.0935e-04 - acc: 0.7335\n",
      "Epoch 142/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0876e-04 - acc: 0.7327\n",
      "Epoch 143/1001\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 1.0880e-04 - acc: 0.731 - 6s 67us/step - loss: 1.0883e-04 - acc: 0.7312\n",
      "Epoch 144/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0947e-04 - acc: 0.7297\n",
      "Epoch 145/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.0900e-04 - acc: 0.7326\n",
      "Epoch 146/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.1000e-04 - acc: 0.7317\n",
      "Epoch 147/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.0781e-04 - acc: 0.7311\n",
      "Epoch 148/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.0860e-04 - acc: 0.7329\n",
      "Epoch 149/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.0827e-04 - acc: 0.7296\n",
      "Epoch 150/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0782e-04 - acc: 0.7321\n",
      "Epoch 151/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0742e-04 - acc: 0.7311\n",
      "Epoch 152/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0832e-04 - acc: 0.7332\n",
      "Epoch 153/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0785e-04 - acc: 0.7320\n",
      "Epoch 154/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0684e-04 - acc: 0.7325\n",
      "Epoch 155/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.0692e-04 - acc: 0.7311\n",
      "Epoch 156/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.0853e-04 - acc: 0.7320\n",
      "Epoch 157/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.0667e-04 - acc: 0.7332\n",
      "Epoch 158/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.0649e-04 - acc: 0.7325\n",
      "Epoch 159/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.0696e-04 - acc: 0.7309\n",
      "Epoch 160/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.0616e-04 - acc: 0.7310\n",
      "Epoch 161/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.0667e-04 - acc: 0.7318\n",
      "Epoch 162/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.0626e-04 - acc: 0.7328\n",
      "Epoch 163/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.0558e-04 - acc: 0.7318\n",
      "Epoch 164/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0615e-04 - acc: 0.7307\n",
      "Epoch 165/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.0613e-04 - acc: 0.7316\n",
      "Epoch 166/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.0579e-04 - acc: 0.7323\n",
      "Epoch 167/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.0562e-04 - acc: 0.7315\n",
      "Epoch 168/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.0575e-04 - acc: 0.7302\n",
      "Epoch 169/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0598e-04 - acc: 0.7316\n",
      "Epoch 170/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.0525e-04 - acc: 0.7330\n",
      "Epoch 171/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.0484e-04 - acc: 0.7326\n",
      "Epoch 172/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0502e-04 - acc: 0.7320\n",
      "Epoch 173/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0499e-04 - acc: 0.7320\n",
      "Epoch 174/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.0404e-04 - acc: 0.7311\n",
      "Epoch 175/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0433e-04 - acc: 0.7305\n",
      "Epoch 176/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0408e-04 - acc: 0.7329\n",
      "Epoch 177/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 1.0448e-04 - acc: 0.7309\n",
      "Epoch 178/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 1.0380e-04 - acc: 0.7325: 1s - los\n",
      "Epoch 179/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.0421e-04 - acc: 0.7304\n",
      "Epoch 180/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.0311e-04 - acc: 0.7301\n",
      "Epoch 181/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.0446e-04 - acc: 0.7283\n",
      "Epoch 182/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.0310e-04 - acc: 0.7317\n",
      "Epoch 183/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.0380e-04 - acc: 0.7302\n",
      "Epoch 184/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.0310e-04 - acc: 0.7307\n",
      "Epoch 185/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 1.0313e-04 - acc: 0.7319\n",
      "Epoch 186/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.0285e-04 - acc: 0.7329\n",
      "Epoch 187/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.0290e-04 - acc: 0.7315\n",
      "Epoch 188/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.0366e-04 - acc: 0.7312\n",
      "Epoch 189/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 1.0262e-04 - acc: 0.7311\n",
      "Epoch 190/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.0400e-04 - acc: 0.7290\n",
      "Epoch 191/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.0339e-04 - acc: 0.7302\n",
      "Epoch 192/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 1.0252e-04 - acc: 0.7301\n",
      "Epoch 193/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0335e-04 - acc: 0.7302\n",
      "Epoch 194/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.0171e-04 - acc: 0.7306\n",
      "Epoch 195/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.0286e-04 - acc: 0.7309\n",
      "Epoch 196/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.0256e-04 - acc: 0.7297\n",
      "Epoch 197/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.0304e-04 - acc: 0.7328\n",
      "Epoch 198/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0184e-04 - acc: 0.7318\n",
      "Epoch 199/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.0218e-04 - acc: 0.7310\n",
      "Epoch 200/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.0158e-04 - acc: 0.7289\n",
      "Epoch 201/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.0242e-04 - acc: 0.7295\n",
      "Epoch 202/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.0123e-04 - acc: 0.7291\n",
      "Epoch 203/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.0237e-04 - acc: 0.7318\n",
      "Epoch 204/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.0283e-04 - acc: 0.7299\n",
      "Epoch 205/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.0172e-04 - acc: 0.7304\n",
      "Epoch 206/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.0121e-04 - acc: 0.7304\n",
      "Epoch 207/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.0172e-04 - acc: 0.7305\n",
      "Epoch 208/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 1.0065e-04 - acc: 0.7312\n",
      "Epoch 209/1001\n",
      "91704/91704 [==============================] - 9s 96us/step - loss: 1.0114e-04 - acc: 0.7310\n",
      "Epoch 210/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 1.0148e-04 - acc: 0.7296\n",
      "Epoch 211/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.0099e-04 - acc: 0.7302\n",
      "Epoch 212/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 1.0122e-04 - acc: 0.7295\n",
      "Epoch 213/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.0123e-04 - acc: 0.7298\n",
      "Epoch 214/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 1.0144e-04 - acc: 0.7306\n",
      "Epoch 215/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.0104e-04 - acc: 0.7299: 1s - \n",
      "Epoch 216/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.0154e-04 - acc: 0.7302\n",
      "Epoch 217/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.9918e-05 - acc: 0.7312\n",
      "Epoch 218/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.0091e-04 - acc: 0.7302\n",
      "Epoch 219/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.0094e-04 - acc: 0.7310\n",
      "Epoch 220/1001\n",
      "91704/91704 [==============================] - 8s 85us/step - loss: 1.0011e-04 - acc: 0.7317\n",
      "Epoch 221/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 1.0074e-04 - acc: 0.7284\n",
      "Epoch 222/1001\n",
      "91704/91704 [==============================] - 11s 115us/step - loss: 1.0115e-04 - acc: 0.7306\n",
      "Epoch 223/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 1.0056e-04 - acc: 0.7279\n",
      "Epoch 224/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 1.0015e-04 - acc: 0.7309\n",
      "Epoch 225/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 1.0009e-04 - acc: 0.7309\n",
      "Epoch 226/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.9806e-05 - acc: 0.7294\n",
      "Epoch 227/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.9466e-05 - acc: 0.7306\n",
      "Epoch 228/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 1.0102e-04 - acc: 0.7299\n",
      "Epoch 229/1001\n",
      "91704/91704 [==============================] - 8s 83us/step - loss: 9.9398e-05 - acc: 0.7307\n",
      "Epoch 230/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.0010e-04 - acc: 0.7309\n",
      "Epoch 231/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 9.9030e-05 - acc: 0.7308\n",
      "Epoch 232/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 9.9603e-05 - acc: 0.7316\n",
      "Epoch 233/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.9199e-05 - acc: 0.7294\n",
      "Epoch 234/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.9666e-05 - acc: 0.7301\n",
      "Epoch 235/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 1.0008e-04 - acc: 0.7311\n",
      "Epoch 236/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.8190e-05 - acc: 0.7335\n",
      "Epoch 237/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.8554e-05 - acc: 0.7295\n",
      "Epoch 238/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.8662e-05 - acc: 0.7305\n",
      "Epoch 239/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.8437e-05 - acc: 0.7307\n",
      "Epoch 240/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 9.9137e-05 - acc: 0.7278\n",
      "Epoch 241/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.9082e-05 - acc: 0.7304\n",
      "Epoch 242/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 9.7738e-05 - acc: 0.7296\n",
      "Epoch 243/1001\n",
      "91704/91704 [==============================] - 8s 84us/step - loss: 9.9120e-05 - acc: 0.7303\n",
      "Epoch 244/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.7781e-05 - acc: 0.7299\n",
      "Epoch 245/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 9.7919e-05 - acc: 0.7302\n",
      "Epoch 246/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.7725e-05 - acc: 0.7288\n",
      "Epoch 247/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.8466e-05 - acc: 0.7298\n",
      "Epoch 248/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 9.8079e-05 - acc: 0.7311\n",
      "Epoch 249/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.7609e-05 - acc: 0.7313\n",
      "Epoch 250/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 9.7877e-05 - acc: 0.7297\n",
      "Epoch 251/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 9.6904e-05 - acc: 0.7305\n",
      "Epoch 252/1001\n",
      "91704/91704 [==============================] - 8s 85us/step - loss: 9.7255e-05 - acc: 0.7312\n",
      "Epoch 253/1001\n",
      "91704/91704 [==============================] - 8s 90us/step - loss: 9.7641e-05 - acc: 0.7312\n",
      "Epoch 254/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 9.7272e-05 - acc: 0.7303\n",
      "Epoch 255/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.7328e-05 - acc: 0.7307\n",
      "Epoch 256/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.7178e-05 - acc: 0.7305\n",
      "Epoch 257/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 9.6815e-05 - acc: 0.7296\n",
      "Epoch 258/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 9.6630e-05 - acc: 0.7298\n",
      "Epoch 259/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 9.6977e-05 - acc: 0.7314\n",
      "Epoch 260/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 9.6891e-05 - acc: 0.7305\n",
      "Epoch 261/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.6055e-05 - acc: 0.7305\n",
      "Epoch 262/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 9.6585e-05 - acc: 0.7293\n",
      "Epoch 263/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 9.6445e-05 - acc: 0.7295: 1s\n",
      "Epoch 264/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 9.6884e-05 - acc: 0.7295\n",
      "Epoch 265/1001\n",
      "91704/91704 [==============================] - 7s 79us/step - loss: 9.7190e-05 - acc: 0.7302\n",
      "Epoch 266/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.5850e-05 - acc: 0.7291\n",
      "Epoch 267/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.6456e-05 - acc: 0.7295\n",
      "Epoch 268/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.6304e-05 - acc: 0.7302\n",
      "Epoch 269/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.6053e-05 - acc: 0.7302\n",
      "Epoch 270/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 9.5912e-05 - acc: 0.7297\n",
      "Epoch 271/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.5929e-05 - acc: 0.7303\n",
      "Epoch 272/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.5885e-05 - acc: 0.7298\n",
      "Epoch 273/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 9.5524e-05 - acc: 0.7303\n",
      "Epoch 274/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.6212e-05 - acc: 0.7316\n",
      "Epoch 275/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 9.5754e-05 - acc: 0.7325\n",
      "Epoch 276/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 9.5475e-05 - acc: 0.7303\n",
      "Epoch 277/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 9.5038e-05 - acc: 0.7297\n",
      "Epoch 278/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 9.5716e-05 - acc: 0.7305\n",
      "Epoch 279/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.5501e-05 - acc: 0.7302\n",
      "Epoch 280/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.6395e-05 - acc: 0.7309\n",
      "Epoch 281/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 9.4773e-05 - acc: 0.7299\n",
      "Epoch 282/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.4965e-05 - acc: 0.7292\n",
      "Epoch 283/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 9.5662e-05 - acc: 0.7312\n",
      "Epoch 284/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 9.5156e-05 - acc: 0.7307\n",
      "Epoch 285/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.4528e-05 - acc: 0.7305\n",
      "Epoch 286/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.5233e-05 - acc: 0.7319: 1s\n",
      "Epoch 287/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.5344e-05 - acc: 0.7304\n",
      "Epoch 288/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 9.4721e-05 - acc: 0.7316\n",
      "Epoch 289/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 9.4127e-05 - acc: 0.7312\n",
      "Epoch 290/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 9.4043e-05 - acc: 0.7303\n",
      "Epoch 291/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.5153e-05 - acc: 0.7308\n",
      "Epoch 292/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.4273e-05 - acc: 0.7299\n",
      "Epoch 293/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.4347e-05 - acc: 0.7306\n",
      "Epoch 294/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 9.4698e-05 - acc: 0.7298\n",
      "Epoch 295/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 9.4362e-05 - acc: 0.7292\n",
      "Epoch 296/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.5244e-05 - acc: 0.7301\n",
      "Epoch 297/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 9.4046e-05 - acc: 0.7322\n",
      "Epoch 298/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 9.4365e-05 - acc: 0.7304\n",
      "Epoch 299/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 9.3431e-05 - acc: 0.7294\n",
      "Epoch 300/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.3992e-05 - acc: 0.7292\n",
      "Epoch 301/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.3907e-05 - acc: 0.7318\n",
      "Epoch 302/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 9.3980e-05 - acc: 0.7314\n",
      "Epoch 303/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 9.3802e-05 - acc: 0.7314\n",
      "Epoch 304/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.3708e-05 - acc: 0.7298\n",
      "Epoch 305/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 9.3997e-05 - acc: 0.7311\n",
      "Epoch 306/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.4122e-05 - acc: 0.7311\n",
      "Epoch 307/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.3068e-05 - acc: 0.7313\n",
      "Epoch 308/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.3355e-05 - acc: 0.7292\n",
      "Epoch 309/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 9.3689e-05 - acc: 0.7327\n",
      "Epoch 310/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.3939e-05 - acc: 0.7299\n",
      "Epoch 311/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.3542e-05 - acc: 0.7302\n",
      "Epoch 312/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.2423e-05 - acc: 0.7302\n",
      "Epoch 313/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 9.3205e-05 - acc: 0.7304\n",
      "Epoch 314/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.3156e-05 - acc: 0.7295\n",
      "Epoch 315/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 9.3168e-05 - acc: 0.7291\n",
      "Epoch 316/1001\n",
      "91704/91704 [==============================] - 8s 91us/step - loss: 9.3742e-05 - acc: 0.7294: 1s - loss: 9.3902e-05 - acc: 0.729 - ETA: 1s - \n",
      "Epoch 317/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 9.2470e-05 - acc: 0.7290\n",
      "Epoch 318/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.5812e-05 - acc: 0.7282\n",
      "Epoch 319/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.2485e-05 - acc: 0.7304\n",
      "Epoch 320/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.3423e-05 - acc: 0.7271\n",
      "Epoch 321/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.2179e-05 - acc: 0.7301\n",
      "Epoch 322/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.3042e-05 - acc: 0.7285\n",
      "Epoch 323/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 9.2254e-05 - acc: 0.7289\n",
      "Epoch 324/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.2859e-05 - acc: 0.7320\n",
      "Epoch 325/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 9.2309e-05 - acc: 0.7298\n",
      "Epoch 326/1001\n",
      "91704/91704 [==============================] - 7s 81us/step - loss: 9.2415e-05 - acc: 0.7321\n",
      "Epoch 327/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 9.3029e-05 - acc: 0.7315\n",
      "Epoch 328/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.2130e-05 - acc: 0.7307\n",
      "Epoch 329/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.1766e-05 - acc: 0.7307\n",
      "Epoch 330/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.2796e-05 - acc: 0.7275\n",
      "Epoch 331/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.1609e-05 - acc: 0.7303\n",
      "Epoch 332/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 9.2156e-05 - acc: 0.7311\n",
      "Epoch 333/1001\n",
      "91704/91704 [==============================] - 7s 80us/step - loss: 9.1900e-05 - acc: 0.7313\n",
      "Epoch 334/1001\n",
      "91704/91704 [==============================] - 8s 91us/step - loss: 9.2609e-05 - acc: 0.7302\n",
      "Epoch 335/1001\n",
      "91704/91704 [==============================] - 8s 84us/step - loss: 9.2551e-05 - acc: 0.7278\n",
      "Epoch 336/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.1404e-05 - acc: 0.7290\n",
      "Epoch 337/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.2049e-05 - acc: 0.7304\n",
      "Epoch 338/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 9.1802e-05 - acc: 0.7304\n",
      "Epoch 339/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.1233e-05 - acc: 0.7310\n",
      "Epoch 340/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 9.1764e-05 - acc: 0.7314\n",
      "Epoch 341/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.1719e-05 - acc: 0.7312\n",
      "Epoch 342/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 9.1060e-05 - acc: 0.7297\n",
      "Epoch 343/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 9.1955e-05 - acc: 0.7300\n",
      "Epoch 344/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.1240e-05 - acc: 0.7308\n",
      "Epoch 345/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 9.1405e-05 - acc: 0.7283\n",
      "Epoch 346/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.1563e-05 - acc: 0.7299\n",
      "Epoch 347/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.0935e-05 - acc: 0.7308\n",
      "Epoch 348/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.1879e-05 - acc: 0.7312\n",
      "Epoch 349/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.1013e-05 - acc: 0.7298\n",
      "Epoch 350/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.0637e-05 - acc: 0.7314\n",
      "Epoch 351/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 9.1262e-05 - acc: 0.7295\n",
      "Epoch 352/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.1062e-05 - acc: 0.7316\n",
      "Epoch 353/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 9.1124e-05 - acc: 0.7313\n",
      "Epoch 354/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.1112e-05 - acc: 0.7296\n",
      "Epoch 355/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 9.3771e-05 - acc: 0.7295\n",
      "Epoch 356/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.1476e-05 - acc: 0.7297\n",
      "Epoch 357/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.0602e-05 - acc: 0.7298\n",
      "Epoch 358/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.0514e-05 - acc: 0.7310\n",
      "Epoch 359/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.0904e-05 - acc: 0.7305\n",
      "Epoch 360/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.1655e-05 - acc: 0.7296\n",
      "Epoch 361/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.0596e-05 - acc: 0.7309\n",
      "Epoch 362/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.0446e-05 - acc: 0.7315\n",
      "Epoch 363/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 9.0461e-05 - acc: 0.7311\n",
      "Epoch 364/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 9.0083e-05 - acc: 0.7319\n",
      "Epoch 365/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 9.2475e-05 - acc: 0.7290\n",
      "Epoch 366/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 9.0473e-05 - acc: 0.7307\n",
      "Epoch 367/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 8.9710e-05 - acc: 0.7313\n",
      "Epoch 368/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.0925e-05 - acc: 0.7300\n",
      "Epoch 369/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 9.1027e-05 - acc: 0.7289\n",
      "Epoch 370/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.9997e-05 - acc: 0.7309\n",
      "Epoch 371/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 8.9668e-05 - acc: 0.7295\n",
      "Epoch 372/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.9593e-05 - acc: 0.7302\n",
      "Epoch 373/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 8.9804e-05 - acc: 0.7298\n",
      "Epoch 374/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 9.0533e-05 - acc: 0.7292\n",
      "Epoch 375/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.9454e-05 - acc: 0.7316\n",
      "Epoch 376/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.0330e-05 - acc: 0.7306\n",
      "Epoch 377/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 9.0392e-05 - acc: 0.7288\n",
      "Epoch 378/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.9212e-05 - acc: 0.7306\n",
      "Epoch 379/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.0219e-05 - acc: 0.7287\n",
      "Epoch 380/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 9.1477e-05 - acc: 0.7311\n",
      "Epoch 381/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.9152e-05 - acc: 0.7319\n",
      "Epoch 382/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.9344e-05 - acc: 0.7304\n",
      "Epoch 383/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.9828e-05 - acc: 0.7334\n",
      "Epoch 384/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.9172e-05 - acc: 0.7312\n",
      "Epoch 385/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.9761e-05 - acc: 0.7296\n",
      "Epoch 386/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.9224e-05 - acc: 0.7299\n",
      "Epoch 387/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.9632e-05 - acc: 0.7311\n",
      "Epoch 388/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.9169e-05 - acc: 0.7301\n",
      "Epoch 389/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.9677e-05 - acc: 0.7294\n",
      "Epoch 390/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.0305e-05 - acc: 0.7296\n",
      "Epoch 391/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.0121e-05 - acc: 0.7288\n",
      "Epoch 392/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.8687e-05 - acc: 0.7303\n",
      "Epoch 393/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.9520e-05 - acc: 0.7325\n",
      "Epoch 394/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.9293e-05 - acc: 0.7309\n",
      "Epoch 395/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.9028e-05 - acc: 0.7289\n",
      "Epoch 396/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.9316e-05 - acc: 0.7305\n",
      "Epoch 397/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.8976e-05 - acc: 0.7298\n",
      "Epoch 398/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.8663e-05 - acc: 0.7305\n",
      "Epoch 399/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.9783e-05 - acc: 0.7317\n",
      "Epoch 400/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.9240e-05 - acc: 0.7308\n",
      "Epoch 401/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.8840e-05 - acc: 0.7316\n",
      "Epoch 402/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.8579e-05 - acc: 0.7310\n",
      "Epoch 403/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.8549e-05 - acc: 0.7317\n",
      "Epoch 404/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.8877e-05 - acc: 0.7313\n",
      "Epoch 405/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.8752e-05 - acc: 0.7312\n",
      "Epoch 406/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.9604e-05 - acc: 0.7308\n",
      "Epoch 407/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.8453e-05 - acc: 0.7318\n",
      "Epoch 408/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.8312e-05 - acc: 0.7319\n",
      "Epoch 409/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 9.0098e-05 - acc: 0.7294\n",
      "Epoch 410/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.9795e-05 - acc: 0.7324\n",
      "Epoch 411/1001\n",
      "91704/91704 [==============================] - 7s 81us/step - loss: 8.8969e-05 - acc: 0.7304\n",
      "Epoch 412/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.8415e-05 - acc: 0.7324\n",
      "Epoch 413/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.8445e-05 - acc: 0.7307\n",
      "Epoch 414/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.8288e-05 - acc: 0.7315\n",
      "Epoch 415/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.8219e-05 - acc: 0.7323\n",
      "Epoch 416/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.9039e-05 - acc: 0.7324\n",
      "Epoch 417/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.8426e-05 - acc: 0.7316\n",
      "Epoch 418/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.7926e-05 - acc: 0.7314\n",
      "Epoch 419/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.7845e-05 - acc: 0.7320\n",
      "Epoch 420/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.8251e-05 - acc: 0.7305\n",
      "Epoch 421/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.8076e-05 - acc: 0.7318\n",
      "Epoch 422/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.8227e-05 - acc: 0.7312\n",
      "Epoch 423/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.7922e-05 - acc: 0.7317\n",
      "Epoch 424/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.9897e-05 - acc: 0.7322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 9.0901e-05 - acc: 0.7315\n",
      "Epoch 426/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 8.8017e-05 - acc: 0.7312\n",
      "Epoch 427/1001\n",
      "91704/91704 [==============================] - 7s 79us/step - loss: 8.7784e-05 - acc: 0.7309\n",
      "Epoch 428/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.7469e-05 - acc: 0.7322\n",
      "Epoch 429/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.7661e-05 - acc: 0.7320\n",
      "Epoch 430/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.8585e-05 - acc: 0.7315\n",
      "Epoch 431/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.7719e-05 - acc: 0.7317\n",
      "Epoch 432/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 9.2869e-05 - acc: 0.7310\n",
      "Epoch 433/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.8807e-05 - acc: 0.7303\n",
      "Epoch 434/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.8011e-05 - acc: 0.7305\n",
      "Epoch 435/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.7526e-05 - acc: 0.7312\n",
      "Epoch 436/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.7611e-05 - acc: 0.7298\n",
      "Epoch 437/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.7561e-05 - acc: 0.7311\n",
      "Epoch 438/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.7570e-05 - acc: 0.7304\n",
      "Epoch 439/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.8858e-05 - acc: 0.7320\n",
      "Epoch 440/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.8139e-05 - acc: 0.7302\n",
      "Epoch 441/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.7207e-05 - acc: 0.7325\n",
      "Epoch 442/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.7945e-05 - acc: 0.7310\n",
      "Epoch 443/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.7224e-05 - acc: 0.7326\n",
      "Epoch 444/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.7441e-05 - acc: 0.7302\n",
      "Epoch 445/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.7857e-05 - acc: 0.7321\n",
      "Epoch 446/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 9.0713e-05 - acc: 0.7304\n",
      "Epoch 447/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.7554e-05 - acc: 0.7297\n",
      "Epoch 448/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.6557e-05 - acc: 0.7314\n",
      "Epoch 449/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.7527e-05 - acc: 0.7307\n",
      "Epoch 450/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.7864e-05 - acc: 0.7316\n",
      "Epoch 451/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.7665e-05 - acc: 0.7307\n",
      "Epoch 452/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.7228e-05 - acc: 0.7312\n",
      "Epoch 453/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.7577e-05 - acc: 0.7303\n",
      "Epoch 454/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.7539e-05 - acc: 0.7315\n",
      "Epoch 455/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.9720e-05 - acc: 0.7283\n",
      "Epoch 456/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.7509e-05 - acc: 0.7302\n",
      "Epoch 457/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.6877e-05 - acc: 0.7306\n",
      "Epoch 458/1001\n",
      "91704/91704 [==============================] - 7s 79us/step - loss: 8.7103e-05 - acc: 0.7297\n",
      "Epoch 459/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.7563e-05 - acc: 0.7296\n",
      "Epoch 460/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.7117e-05 - acc: 0.7321\n",
      "Epoch 461/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.7997e-05 - acc: 0.7315\n",
      "Epoch 462/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.7768e-05 - acc: 0.7304\n",
      "Epoch 463/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.6903e-05 - acc: 0.7296\n",
      "Epoch 464/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.7369e-05 - acc: 0.7312\n",
      "Epoch 465/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.7446e-05 - acc: 0.7305\n",
      "Epoch 466/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.7030e-05 - acc: 0.7312\n",
      "Epoch 467/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.6774e-05 - acc: 0.7316\n",
      "Epoch 468/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.6987e-05 - acc: 0.7301\n",
      "Epoch 469/1001\n",
      "91704/91704 [==============================] - 7s 81us/step - loss: 8.7259e-05 - acc: 0.7305\n",
      "Epoch 470/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.6857e-05 - acc: 0.7299\n",
      "Epoch 471/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.6661e-05 - acc: 0.7309\n",
      "Epoch 472/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.6889e-05 - acc: 0.7306\n",
      "Epoch 473/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.7380e-05 - acc: 0.7321\n",
      "Epoch 474/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.7977e-05 - acc: 0.7320\n",
      "Epoch 475/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.6410e-05 - acc: 0.7316\n",
      "Epoch 476/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.7232e-05 - acc: 0.7319\n",
      "Epoch 477/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.7260e-05 - acc: 0.7315\n",
      "Epoch 478/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.7273e-05 - acc: 0.7311\n",
      "Epoch 479/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.6758e-05 - acc: 0.7326\n",
      "Epoch 480/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.6739e-05 - acc: 0.7321\n",
      "Epoch 481/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.6361e-05 - acc: 0.7299\n",
      "Epoch 482/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.6737e-05 - acc: 0.7304\n",
      "Epoch 483/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 8.7026e-05 - acc: 0.7307\n",
      "Epoch 484/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.6956e-05 - acc: 0.7299\n",
      "Epoch 485/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.6521e-05 - acc: 0.7318\n",
      "Epoch 486/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.6654e-05 - acc: 0.7301\n",
      "Epoch 487/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.7382e-05 - acc: 0.7296\n",
      "Epoch 488/1001\n",
      "91704/91704 [==============================] - 9s 101us/step - loss: 8.6274e-05 - acc: 0.7302 1s - lo\n",
      "Epoch 489/1001\n",
      "91704/91704 [==============================] - 8s 85us/step - loss: 8.6756e-05 - acc: 0.7301\n",
      "Epoch 490/1001\n",
      "91704/91704 [==============================] - 7s 80us/step - loss: 8.6794e-05 - acc: 0.7320\n",
      "Epoch 491/1001\n",
      "91704/91704 [==============================] - 9s 93us/step - loss: 8.6381e-05 - acc: 0.7310\n",
      "Epoch 492/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.6537e-05 - acc: 0.7285\n",
      "Epoch 493/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.8363e-05 - acc: 0.7304\n",
      "Epoch 494/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.6418e-05 - acc: 0.7314\n",
      "Epoch 495/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.6092e-05 - acc: 0.7311\n",
      "Epoch 496/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.7395e-05 - acc: 0.7312\n",
      "Epoch 497/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.6698e-05 - acc: 0.7313\n",
      "Epoch 498/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.6363e-05 - acc: 0.7302\n",
      "Epoch 499/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.6097e-05 - acc: 0.7296\n",
      "Epoch 500/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.6966e-05 - acc: 0.7314\n",
      "Epoch 501/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.6202e-05 - acc: 0.7310\n",
      "../linkPrediction/dataframes/obesity\\obesity-model-pref-500_2008-2015.pkl\n",
      "Epoch 502/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.6275e-05 - acc: 0.7315\n",
      "Epoch 503/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.7194e-05 - acc: 0.7306\n",
      "Epoch 504/1001\n",
      "91704/91704 [==============================] - 7s 81us/step - loss: 8.5823e-05 - acc: 0.7315\n",
      "Epoch 505/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.6072e-05 - acc: 0.7308\n",
      "Epoch 506/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.6238e-05 - acc: 0.7314\n",
      "Epoch 507/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.6337e-05 - acc: 0.7330\n",
      "Epoch 508/1001\n",
      "91704/91704 [==============================] - 7s 80us/step - loss: 8.6015e-05 - acc: 0.7317\n",
      "Epoch 509/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.6216e-05 - acc: 0.7314\n",
      "Epoch 510/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.6535e-05 - acc: 0.7310\n",
      "Epoch 511/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.5353e-05 - acc: 0.7304\n",
      "Epoch 512/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.6156e-05 - acc: 0.7331\n",
      "Epoch 513/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.6418e-05 - acc: 0.7308\n",
      "Epoch 514/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.6335e-05 - acc: 0.7328\n",
      "Epoch 515/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.5605e-05 - acc: 0.7313\n",
      "Epoch 516/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.6200e-05 - acc: 0.7302\n",
      "Epoch 517/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.6353e-05 - acc: 0.7308\n",
      "Epoch 518/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.6327e-05 - acc: 0.7315\n",
      "Epoch 519/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.6070e-05 - acc: 0.7328\n",
      "Epoch 520/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.6253e-05 - acc: 0.7308\n",
      "Epoch 521/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.6313e-05 - acc: 0.7306\n",
      "Epoch 522/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.6041e-05 - acc: 0.7319\n",
      "Epoch 523/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.6080e-05 - acc: 0.7323\n",
      "Epoch 524/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.5523e-05 - acc: 0.7313\n",
      "Epoch 525/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.7735e-05 - acc: 0.7308\n",
      "Epoch 526/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.6448e-05 - acc: 0.7309: 0s - loss: 8.6204e-05 - ac\n",
      "Epoch 527/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.5231e-05 - acc: 0.7332\n",
      "Epoch 528/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.5825e-05 - acc: 0.7295\n",
      "Epoch 529/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.6320e-05 - acc: 0.7318\n",
      "Epoch 530/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.5486e-05 - acc: 0.7314\n",
      "Epoch 531/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.5983e-05 - acc: 0.7305\n",
      "Epoch 532/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.5763e-05 - acc: 0.7324\n",
      "Epoch 533/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.5567e-05 - acc: 0.7302\n",
      "Epoch 534/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.5913e-05 - acc: 0.7313\n",
      "Epoch 535/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.5656e-05 - acc: 0.7304\n",
      "Epoch 536/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.5821e-05 - acc: 0.7318\n",
      "Epoch 537/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.5499e-05 - acc: 0.7304\n",
      "Epoch 538/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.6348e-05 - acc: 0.7297\n",
      "Epoch 539/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.5951e-05 - acc: 0.7322\n",
      "Epoch 540/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.5266e-05 - acc: 0.7310\n",
      "Epoch 541/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.5451e-05 - acc: 0.7301\n",
      "Epoch 542/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.7836e-05 - acc: 0.7330\n",
      "Epoch 543/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.4926e-05 - acc: 0.7323\n",
      "Epoch 544/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.5079e-05 - acc: 0.7318\n",
      "Epoch 545/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.5577e-05 - acc: 0.7328\n",
      "Epoch 546/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 8.5280e-05 - acc: 0.7303\n",
      "Epoch 547/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.5723e-05 - acc: 0.7314\n",
      "Epoch 548/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.5272e-05 - acc: 0.7316\n",
      "Epoch 549/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.5687e-05 - acc: 0.7312\n",
      "Epoch 550/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.4852e-05 - acc: 0.7294\n",
      "Epoch 551/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.5235e-05 - acc: 0.7304\n",
      "Epoch 552/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.5159e-05 - acc: 0.7315\n",
      "Epoch 553/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.5919e-05 - acc: 0.7320\n",
      "Epoch 554/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.5183e-05 - acc: 0.7309\n",
      "Epoch 555/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.5170e-05 - acc: 0.7330\n",
      "Epoch 556/1001\n",
      "91704/91704 [==============================] - 7s 81us/step - loss: 8.5011e-05 - acc: 0.7303\n",
      "Epoch 557/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.4901e-05 - acc: 0.7307\n",
      "Epoch 558/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.6025e-05 - acc: 0.7308\n",
      "Epoch 559/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.5459e-05 - acc: 0.7294\n",
      "Epoch 560/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.4994e-05 - acc: 0.7311\n",
      "Epoch 561/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.5140e-05 - acc: 0.7317\n",
      "Epoch 562/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.5262e-05 - acc: 0.7324\n",
      "Epoch 563/1001\n",
      "91704/91704 [==============================] - 7s 80us/step - loss: 8.5391e-05 - acc: 0.7309\n",
      "Epoch 564/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.4882e-05 - acc: 0.7313\n",
      "Epoch 565/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.4506e-05 - acc: 0.7337\n",
      "Epoch 566/1001\n",
      "91704/91704 [==============================] - 11s 123us/step - loss: 8.5298e-05 - acc: 0.7317\n",
      "Epoch 567/1001\n",
      "91704/91704 [==============================] - 10s 114us/step - loss: 8.4823e-05 - acc: 0.7305\n",
      "Epoch 568/1001\n",
      "91704/91704 [==============================] - 8s 84us/step - loss: 8.5798e-05 - acc: 0.7304\n",
      "Epoch 569/1001\n",
      "91704/91704 [==============================] - 8s 89us/step - loss: 8.5144e-05 - acc: 0.7319\n",
      "Epoch 570/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.4203e-05 - acc: 0.7317\n",
      "Epoch 571/1001\n",
      "91704/91704 [==============================] - 8s 85us/step - loss: 8.5159e-05 - acc: 0.7302\n",
      "Epoch 572/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.5691e-05 - acc: 0.7311\n",
      "Epoch 573/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.4776e-05 - acc: 0.7303\n",
      "Epoch 574/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 8s 84us/step - loss: 8.4763e-05 - acc: 0.7310\n",
      "Epoch 575/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.5355e-05 - acc: 0.7314\n",
      "Epoch 576/1001\n",
      "91704/91704 [==============================] - 9s 96us/step - loss: 8.5234e-05 - acc: 0.7315: - ETA: \n",
      "Epoch 577/1001\n",
      "91704/91704 [==============================] - 8s 85us/step - loss: 8.4567e-05 - acc: 0.7300\n",
      "Epoch 578/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.5222e-05 - acc: 0.7311\n",
      "Epoch 579/1001\n",
      "91704/91704 [==============================] - 8s 90us/step - loss: 8.5164e-05 - acc: 0.7325\n",
      "Epoch 580/1001\n",
      "91704/91704 [==============================] - 13s 141us/step - loss: 8.4524e-05 - acc: 0.7327\n",
      "Epoch 581/1001\n",
      "91704/91704 [==============================] - 9s 98us/step - loss: 8.5847e-05 - acc: 0.7307\n",
      "Epoch 582/1001\n",
      "91704/91704 [==============================] - 11s 116us/step - loss: 8.4845e-05 - acc: 0.7321\n",
      "Epoch 583/1001\n",
      "91704/91704 [==============================] - 8s 85us/step - loss: 8.5510e-05 - acc: 0.7300\n",
      "Epoch 584/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 8.4502e-05 - acc: 0.7305\n",
      "Epoch 585/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.4980e-05 - acc: 0.7319\n",
      "Epoch 586/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.5140e-05 - acc: 0.7314\n",
      "Epoch 587/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 8.5014e-05 - acc: 0.7300\n",
      "Epoch 588/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.5713e-05 - acc: 0.7319\n",
      "Epoch 589/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.4169e-05 - acc: 0.7305\n",
      "Epoch 590/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.4592e-05 - acc: 0.7317\n",
      "Epoch 591/1001\n",
      "91704/91704 [==============================] - 7s 79us/step - loss: 8.5208e-05 - acc: 0.7305\n",
      "Epoch 592/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.4221e-05 - acc: 0.7329\n",
      "Epoch 593/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.4841e-05 - acc: 0.7287\n",
      "Epoch 594/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.5297e-05 - acc: 0.7323\n",
      "Epoch 595/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.4038e-05 - acc: 0.7314\n",
      "Epoch 596/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.4343e-05 - acc: 0.7320\n",
      "Epoch 597/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 8.5665e-05 - acc: 0.7305\n",
      "Epoch 598/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.4542e-05 - acc: 0.7324\n",
      "Epoch 599/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.4199e-05 - acc: 0.7304\n",
      "Epoch 600/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.4308e-05 - acc: 0.7319\n",
      "Epoch 601/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.4333e-05 - acc: 0.7313\n",
      "Epoch 602/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.4703e-05 - acc: 0.7305\n",
      "Epoch 603/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.4759e-05 - acc: 0.7316\n",
      "Epoch 604/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.4111e-05 - acc: 0.7308\n",
      "Epoch 605/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.4472e-05 - acc: 0.7325\n",
      "Epoch 606/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.4658e-05 - acc: 0.7298\n",
      "Epoch 607/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.4641e-05 - acc: 0.7318\n",
      "Epoch 608/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.4516e-05 - acc: 0.7325\n",
      "Epoch 609/1001\n",
      "91704/91704 [==============================] - 7s 81us/step - loss: 8.4322e-05 - acc: 0.7314\n",
      "Epoch 610/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 8.4921e-05 - acc: 0.7332\n",
      "Epoch 611/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.4026e-05 - acc: 0.7311\n",
      "Epoch 612/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.5220e-05 - acc: 0.7330\n",
      "Epoch 613/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.4370e-05 - acc: 0.7307\n",
      "Epoch 614/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.4265e-05 - acc: 0.7306\n",
      "Epoch 615/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.4281e-05 - acc: 0.7311\n",
      "Epoch 616/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.4665e-05 - acc: 0.7318\n",
      "Epoch 617/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.5085e-05 - acc: 0.7295\n",
      "Epoch 618/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.4328e-05 - acc: 0.7316\n",
      "Epoch 619/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.4221e-05 - acc: 0.7311\n",
      "Epoch 620/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.4128e-05 - acc: 0.7309\n",
      "Epoch 621/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.4507e-05 - acc: 0.7315\n",
      "Epoch 622/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.4562e-05 - acc: 0.7321\n",
      "Epoch 623/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.4155e-05 - acc: 0.7306\n",
      "Epoch 624/1001\n",
      "91704/91704 [==============================] - 7s 81us/step - loss: 8.4082e-05 - acc: 0.7306\n",
      "Epoch 625/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.4113e-05 - acc: 0.7305\n",
      "Epoch 626/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.4348e-05 - acc: 0.7309\n",
      "Epoch 627/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.4627e-05 - acc: 0.7311\n",
      "Epoch 628/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.3919e-05 - acc: 0.7322\n",
      "Epoch 629/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.4572e-05 - acc: 0.7322: 0s - loss: 8.4553e-05 - acc: 0.732 - ETA: 0s - loss: 8.4534e-0\n",
      "Epoch 630/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.4135e-05 - acc: 0.7317\n",
      "Epoch 631/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.4258e-05 - acc: 0.7314\n",
      "Epoch 632/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.3932e-05 - acc: 0.7321\n",
      "Epoch 633/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.5377e-05 - acc: 0.7321\n",
      "Epoch 634/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.3741e-05 - acc: 0.7324\n",
      "Epoch 635/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.3899e-05 - acc: 0.7315\n",
      "Epoch 636/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.4135e-05 - acc: 0.7313\n",
      "Epoch 637/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.4066e-05 - acc: 0.7320\n",
      "Epoch 638/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.4077e-05 - acc: 0.7328\n",
      "Epoch 639/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.4060e-05 - acc: 0.7302\n",
      "Epoch 640/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.4216e-05 - acc: 0.7311\n",
      "Epoch 641/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.3697e-05 - acc: 0.7309\n",
      "Epoch 642/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.3999e-05 - acc: 0.7323\n",
      "Epoch 643/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.4014e-05 - acc: 0.7319\n",
      "Epoch 644/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.4225e-05 - acc: 0.7321\n",
      "Epoch 645/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.3968e-05 - acc: 0.7334\n",
      "Epoch 646/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.3448e-05 - acc: 0.7303\n",
      "Epoch 647/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 8.4515e-05 - acc: 0.7323\n",
      "Epoch 648/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.3869e-05 - acc: 0.7318\n",
      "Epoch 649/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.3834e-05 - acc: 0.7312\n",
      "Epoch 650/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.4075e-05 - acc: 0.7317\n",
      "Epoch 651/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.3726e-05 - acc: 0.7309\n",
      "Epoch 652/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.3420e-05 - acc: 0.7312\n",
      "Epoch 653/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.4425e-05 - acc: 0.7311\n",
      "Epoch 654/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.4092e-05 - acc: 0.7318\n",
      "Epoch 655/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.3825e-05 - acc: 0.7296\n",
      "Epoch 656/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.4073e-05 - acc: 0.7320\n",
      "Epoch 657/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.4248e-05 - acc: 0.7314\n",
      "Epoch 658/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.3916e-05 - acc: 0.7318\n",
      "Epoch 659/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.3467e-05 - acc: 0.7297\n",
      "Epoch 660/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.3823e-05 - acc: 0.7310\n",
      "Epoch 661/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.3716e-05 - acc: 0.7309\n",
      "Epoch 662/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.3673e-05 - acc: 0.7321\n",
      "Epoch 663/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.4224e-05 - acc: 0.7314\n",
      "Epoch 664/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.3340e-05 - acc: 0.7310\n",
      "Epoch 665/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.4159e-05 - acc: 0.7311\n",
      "Epoch 666/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.3693e-05 - acc: 0.7321\n",
      "Epoch 667/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.3748e-05 - acc: 0.7299\n",
      "Epoch 668/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.3261e-05 - acc: 0.7318\n",
      "Epoch 669/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.4394e-05 - acc: 0.7323\n",
      "Epoch 670/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.3936e-05 - acc: 0.7324\n",
      "Epoch 671/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.3626e-05 - acc: 0.7317\n",
      "Epoch 672/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3294e-05 - acc: 0.7325\n",
      "Epoch 673/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.3965e-05 - acc: 0.7320\n",
      "Epoch 674/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.4095e-05 - acc: 0.7319\n",
      "Epoch 675/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.3414e-05 - acc: 0.7325\n",
      "Epoch 676/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.4046e-05 - acc: 0.7315\n",
      "Epoch 677/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.3335e-05 - acc: 0.7332\n",
      "Epoch 678/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.4100e-05 - acc: 0.7313\n",
      "Epoch 679/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.3611e-05 - acc: 0.7324\n",
      "Epoch 680/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 8.3243e-05 - acc: 0.7309\n",
      "Epoch 681/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.4186e-05 - acc: 0.7303\n",
      "Epoch 682/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.3984e-05 - acc: 0.7296\n",
      "Epoch 683/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.3014e-05 - acc: 0.7316\n",
      "Epoch 684/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.3752e-05 - acc: 0.7306\n",
      "Epoch 685/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.3365e-05 - acc: 0.7317\n",
      "Epoch 686/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.3691e-05 - acc: 0.7314: 1s \n",
      "Epoch 687/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.4061e-05 - acc: 0.7290\n",
      "Epoch 688/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.2931e-05 - acc: 0.7328\n",
      "Epoch 689/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3359e-05 - acc: 0.7324\n",
      "Epoch 690/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.3724e-05 - acc: 0.7316\n",
      "Epoch 691/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.3893e-05 - acc: 0.7319\n",
      "Epoch 692/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.3495e-05 - acc: 0.7308\n",
      "Epoch 693/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.3730e-05 - acc: 0.7288\n",
      "Epoch 694/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3486e-05 - acc: 0.7315\n",
      "Epoch 695/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.3796e-05 - acc: 0.7317\n",
      "Epoch 696/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.3393e-05 - acc: 0.7317\n",
      "Epoch 697/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2970e-05 - acc: 0.7321\n",
      "Epoch 698/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.3343e-05 - acc: 0.7316\n",
      "Epoch 699/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3318e-05 - acc: 0.7320\n",
      "Epoch 700/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3545e-05 - acc: 0.7308\n",
      "Epoch 701/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.3571e-05 - acc: 0.7309\n",
      "Epoch 702/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 8.3316e-05 - acc: 0.7313\n",
      "Epoch 703/1001\n",
      "91704/91704 [==============================] - 8s 83us/step - loss: 8.3754e-05 - acc: 0.7300\n",
      "Epoch 704/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2954e-05 - acc: 0.7310\n",
      "Epoch 705/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3926e-05 - acc: 0.7313\n",
      "Epoch 706/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.3056e-05 - acc: 0.7314\n",
      "Epoch 707/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.3543e-05 - acc: 0.7323\n",
      "Epoch 708/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.3216e-05 - acc: 0.7319\n",
      "Epoch 709/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.3067e-05 - acc: 0.7313\n",
      "Epoch 710/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3730e-05 - acc: 0.7322\n",
      "Epoch 711/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.3451e-05 - acc: 0.7306\n",
      "Epoch 712/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3519e-05 - acc: 0.7312\n",
      "Epoch 713/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3161e-05 - acc: 0.7310\n",
      "Epoch 714/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3430e-05 - acc: 0.7322\n",
      "Epoch 715/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3600e-05 - acc: 0.7304\n",
      "Epoch 716/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 8.3455e-05 - acc: 0.7307\n",
      "Epoch 717/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.3075e-05 - acc: 0.7303\n",
      "Epoch 718/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3420e-05 - acc: 0.7327\n",
      "Epoch 719/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.4071e-05 - acc: 0.7316\n",
      "Epoch 720/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.3355e-05 - acc: 0.7323\n",
      "Epoch 721/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.2777e-05 - acc: 0.7312\n",
      "Epoch 722/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2823e-05 - acc: 0.7309\n",
      "Epoch 723/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3339e-05 - acc: 0.7310\n",
      "Epoch 724/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3251e-05 - acc: 0.7293\n",
      "Epoch 725/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.2563e-05 - acc: 0.7322\n",
      "Epoch 726/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.2526e-05 - acc: 0.7328\n",
      "Epoch 727/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3992e-05 - acc: 0.7323\n",
      "Epoch 728/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 8.3111e-05 - acc: 0.7308\n",
      "Epoch 729/1001\n",
      "91704/91704 [==============================] - 8s 90us/step - loss: 8.3369e-05 - acc: 0.7311\n",
      "Epoch 730/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.2791e-05 - acc: 0.7326\n",
      "Epoch 731/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.2781e-05 - acc: 0.7330\n",
      "Epoch 732/1001\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 8.2874e-05 - acc: 0.731 - 7s 74us/step - loss: 8.2913e-05 - acc: 0.7314\n",
      "Epoch 733/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.3415e-05 - acc: 0.7322\n",
      "Epoch 734/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.2682e-05 - acc: 0.7312\n",
      "Epoch 735/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3501e-05 - acc: 0.7310\n",
      "Epoch 736/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.2942e-05 - acc: 0.7319\n",
      "Epoch 737/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.3188e-05 - acc: 0.7327\n",
      "Epoch 738/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2741e-05 - acc: 0.7323\n",
      "Epoch 739/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.2800e-05 - acc: 0.7300\n",
      "Epoch 740/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.3150e-05 - acc: 0.7319\n",
      "Epoch 741/1001\n",
      "91704/91704 [==============================] - 7s 81us/step - loss: 8.3583e-05 - acc: 0.7308\n",
      "Epoch 742/1001\n",
      "91704/91704 [==============================] - 8s 86us/step - loss: 8.2686e-05 - acc: 0.7304\n",
      "Epoch 743/1001\n",
      "91704/91704 [==============================] - 9s 97us/step - loss: 8.4017e-05 - acc: 0.7322\n",
      "Epoch 744/1001\n",
      "91704/91704 [==============================] - 8s 87us/step - loss: 8.3103e-05 - acc: 0.7303\n",
      "Epoch 745/1001\n",
      "91704/91704 [==============================] - 8s 88us/step - loss: 8.2322e-05 - acc: 0.7312\n",
      "Epoch 746/1001\n",
      "91704/91704 [==============================] - 8s 84us/step - loss: 8.2782e-05 - acc: 0.7340\n",
      "Epoch 747/1001\n",
      "91704/91704 [==============================] - 9s 93us/step - loss: 8.2613e-05 - acc: 0.7320\n",
      "Epoch 748/1001\n",
      "91704/91704 [==============================] - 9s 94us/step - loss: 8.3043e-05 - acc: 0.7302\n",
      "Epoch 749/1001\n",
      "91704/91704 [==============================] - 9s 96us/step - loss: 8.3057e-05 - acc: 0.7324\n",
      "Epoch 750/1001\n",
      "91704/91704 [==============================] - 8s 88us/step - loss: 8.2391e-05 - acc: 0.7312\n",
      "Epoch 751/1001\n",
      "91704/91704 [==============================] - 8s 92us/step - loss: 8.2967e-05 - acc: 0.7306\n",
      "Epoch 752/1001\n",
      "91704/91704 [==============================] - 9s 102us/step - loss: 8.3384e-05 - acc: 0.7303\n",
      "Epoch 753/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.3135e-05 - acc: 0.7304\n",
      "Epoch 754/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.3009e-05 - acc: 0.7323\n",
      "Epoch 755/1001\n",
      "91704/91704 [==============================] - 8s 88us/step - loss: 8.2444e-05 - acc: 0.7319\n",
      "Epoch 756/1001\n",
      "91704/91704 [==============================] - 10s 107us/step - loss: 8.2554e-05 - acc: 0.7307\n",
      "Epoch 757/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.2626e-05 - acc: 0.7317\n",
      "Epoch 758/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.2748e-05 - acc: 0.7294\n",
      "Epoch 759/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.2894e-05 - acc: 0.7304\n",
      "Epoch 760/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2810e-05 - acc: 0.7317\n",
      "Epoch 761/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2870e-05 - acc: 0.7325\n",
      "Epoch 762/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.2968e-05 - acc: 0.7311\n",
      "Epoch 763/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.2279e-05 - acc: 0.7323\n",
      "Epoch 764/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2750e-05 - acc: 0.7307\n",
      "Epoch 765/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2533e-05 - acc: 0.7313\n",
      "Epoch 766/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.2907e-05 - acc: 0.7302\n",
      "Epoch 767/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.2534e-05 - acc: 0.7308\n",
      "Epoch 768/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2514e-05 - acc: 0.7304\n",
      "Epoch 769/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.3143e-05 - acc: 0.7309\n",
      "Epoch 770/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1943e-05 - acc: 0.7319\n",
      "Epoch 771/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.3266e-05 - acc: 0.7320\n",
      "Epoch 772/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2343e-05 - acc: 0.7306\n",
      "Epoch 773/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.2532e-05 - acc: 0.7322\n",
      "Epoch 774/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.2898e-05 - acc: 0.7315: 0s - loss: 8.2964e-05 - acc: \n",
      "Epoch 775/1001\n",
      "91704/91704 [==============================] - 8s 85us/step - loss: 8.2133e-05 - acc: 0.7314\n",
      "Epoch 776/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.2102e-05 - acc: 0.7319\n",
      "Epoch 777/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.2547e-05 - acc: 0.7311\n",
      "Epoch 778/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.2511e-05 - acc: 0.7327\n",
      "Epoch 779/1001\n",
      "91704/91704 [==============================] - 8s 83us/step - loss: 8.2502e-05 - acc: 0.7310\n",
      "Epoch 780/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.3068e-05 - acc: 0.7295\n",
      "Epoch 781/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2341e-05 - acc: 0.7319\n",
      "Epoch 782/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.2240e-05 - acc: 0.7318\n",
      "Epoch 783/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.2436e-05 - acc: 0.7304\n",
      "Epoch 784/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2257e-05 - acc: 0.7312\n",
      "Epoch 785/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.2397e-05 - acc: 0.7322\n",
      "Epoch 786/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2629e-05 - acc: 0.7306\n",
      "Epoch 787/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.2545e-05 - acc: 0.7311\n",
      "Epoch 788/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.2991e-05 - acc: 0.7315\n",
      "Epoch 789/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.2483e-05 - acc: 0.7301\n",
      "Epoch 790/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.2044e-05 - acc: 0.7321\n",
      "Epoch 791/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.2126e-05 - acc: 0.7313\n",
      "Epoch 792/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2783e-05 - acc: 0.7316\n",
      "Epoch 793/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1921e-05 - acc: 0.7326\n",
      "Epoch 794/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.2501e-05 - acc: 0.7331\n",
      "Epoch 795/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.2260e-05 - acc: 0.7311\n",
      "Epoch 796/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.2349e-05 - acc: 0.7318\n",
      "Epoch 797/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 8.1971e-05 - acc: 0.7324\n",
      "Epoch 798/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 8.2496e-05 - acc: 0.7321\n",
      "Epoch 799/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.1572e-05 - acc: 0.7314\n",
      "Epoch 800/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.2261e-05 - acc: 0.7320\n",
      "Epoch 801/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2637e-05 - acc: 0.7314\n",
      "Epoch 802/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.2102e-05 - acc: 0.7327\n",
      "Epoch 803/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.3219e-05 - acc: 0.7314\n",
      "Epoch 804/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1711e-05 - acc: 0.7305\n",
      "Epoch 805/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.2191e-05 - acc: 0.7325\n",
      "Epoch 806/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 8.2274e-05 - acc: 0.7321\n",
      "Epoch 807/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.1864e-05 - acc: 0.7312\n",
      "Epoch 808/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.3013e-05 - acc: 0.7300\n",
      "Epoch 809/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 8.1846e-05 - acc: 0.7332\n",
      "Epoch 810/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.1945e-05 - acc: 0.7314\n",
      "Epoch 811/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.2500e-05 - acc: 0.7317\n",
      "Epoch 812/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.2100e-05 - acc: 0.7325\n",
      "Epoch 813/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2094e-05 - acc: 0.7305\n",
      "Epoch 814/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.2916e-05 - acc: 0.7327\n",
      "Epoch 815/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.2004e-05 - acc: 0.7315\n",
      "Epoch 816/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1863e-05 - acc: 0.7306\n",
      "Epoch 817/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.2040e-05 - acc: 0.7313\n",
      "Epoch 818/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.2341e-05 - acc: 0.7321\n",
      "Epoch 819/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.1837e-05 - acc: 0.7328\n",
      "Epoch 820/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.2919e-05 - acc: 0.7309\n",
      "Epoch 821/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.2472e-05 - acc: 0.7314\n",
      "Epoch 822/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.2246e-05 - acc: 0.7314\n",
      "Epoch 823/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.1966e-05 - acc: 0.7332\n",
      "Epoch 824/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.2466e-05 - acc: 0.7314\n",
      "Epoch 825/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.2365e-05 - acc: 0.7315\n",
      "Epoch 826/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2317e-05 - acc: 0.7321\n",
      "Epoch 827/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.2004e-05 - acc: 0.7311\n",
      "Epoch 828/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.1385e-05 - acc: 0.7325\n",
      "Epoch 829/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.2384e-05 - acc: 0.7308\n",
      "Epoch 830/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1927e-05 - acc: 0.7314\n",
      "Epoch 831/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1947e-05 - acc: 0.7298\n",
      "Epoch 832/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2393e-05 - acc: 0.7326\n",
      "Epoch 833/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2359e-05 - acc: 0.7316\n",
      "Epoch 834/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1634e-05 - acc: 0.7317\n",
      "Epoch 835/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2748e-05 - acc: 0.7317\n",
      "Epoch 836/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1534e-05 - acc: 0.7321\n",
      "Epoch 837/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.2062e-05 - acc: 0.7311\n",
      "Epoch 838/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.2021e-05 - acc: 0.7318\n",
      "Epoch 839/1001\n",
      "91704/91704 [==============================] - 11s 117us/step - loss: 8.1450e-05 - acc: 0.7326\n",
      "Epoch 840/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 8.2266e-05 - acc: 0.7305\n",
      "Epoch 841/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.1917e-05 - acc: 0.7316\n",
      "Epoch 842/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 8.1611e-05 - acc: 0.7315\n",
      "Epoch 843/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1622e-05 - acc: 0.7314\n",
      "Epoch 844/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1920e-05 - acc: 0.7327\n",
      "Epoch 845/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1854e-05 - acc: 0.7314\n",
      "Epoch 846/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.1676e-05 - acc: 0.7314\n",
      "Epoch 847/1001\n",
      "91704/91704 [==============================] - 8s 89us/step - loss: 8.1773e-05 - acc: 0.7311\n",
      "Epoch 848/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1589e-05 - acc: 0.7318\n",
      "Epoch 849/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.2087e-05 - acc: 0.7314\n",
      "Epoch 850/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.1583e-05 - acc: 0.7316\n",
      "Epoch 851/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.2199e-05 - acc: 0.7318: 1s - \n",
      "Epoch 852/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1801e-05 - acc: 0.7321\n",
      "Epoch 853/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1230e-05 - acc: 0.7298\n",
      "Epoch 854/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1705e-05 - acc: 0.7312\n",
      "Epoch 855/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1599e-05 - acc: 0.7309\n",
      "Epoch 856/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1951e-05 - acc: 0.7318\n",
      "Epoch 857/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.1740e-05 - acc: 0.7321\n",
      "Epoch 858/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.1629e-05 - acc: 0.7316\n",
      "Epoch 859/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.1968e-05 - acc: 0.7307\n",
      "Epoch 860/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.1619e-05 - acc: 0.7330\n",
      "Epoch 861/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1815e-05 - acc: 0.7320\n",
      "Epoch 862/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.2589e-05 - acc: 0.7319\n",
      "Epoch 863/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1711e-05 - acc: 0.7305\n",
      "Epoch 864/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1082e-05 - acc: 0.7307\n",
      "Epoch 865/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1570e-05 - acc: 0.7324\n",
      "Epoch 866/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1689e-05 - acc: 0.7310\n",
      "Epoch 867/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1518e-05 - acc: 0.7315\n",
      "Epoch 868/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.1718e-05 - acc: 0.7325\n",
      "Epoch 869/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1568e-05 - acc: 0.7322\n",
      "Epoch 870/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.1800e-05 - acc: 0.7319\n",
      "Epoch 871/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.1422e-05 - acc: 0.7329\n",
      "Epoch 872/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1679e-05 - acc: 0.7320\n",
      "Epoch 873/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1604e-05 - acc: 0.7316\n",
      "Epoch 874/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.1025e-05 - acc: 0.7323\n",
      "Epoch 875/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.2040e-05 - acc: 0.7323\n",
      "Epoch 876/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.1658e-05 - acc: 0.7317\n",
      "Epoch 877/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.1281e-05 - acc: 0.7324\n",
      "Epoch 878/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1702e-05 - acc: 0.7318\n",
      "Epoch 879/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.2043e-05 - acc: 0.7330\n",
      "Epoch 880/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1353e-05 - acc: 0.7324\n",
      "Epoch 881/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.1923e-05 - acc: 0.7290\n",
      "Epoch 882/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1331e-05 - acc: 0.7326\n",
      "Epoch 883/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.1947e-05 - acc: 0.7314\n",
      "Epoch 884/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.1187e-05 - acc: 0.7319\n",
      "Epoch 885/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1382e-05 - acc: 0.7324\n",
      "Epoch 886/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1271e-05 - acc: 0.7324\n",
      "Epoch 887/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.0956e-05 - acc: 0.7337\n",
      "Epoch 888/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1484e-05 - acc: 0.7313\n",
      "Epoch 889/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.1699e-05 - acc: 0.7324\n",
      "Epoch 890/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1476e-05 - acc: 0.7339\n",
      "Epoch 891/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.1592e-05 - acc: 0.7318\n",
      "Epoch 892/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1714e-05 - acc: 0.7324\n",
      "Epoch 893/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1737e-05 - acc: 0.7310\n",
      "Epoch 894/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1914e-05 - acc: 0.7316\n",
      "Epoch 895/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1281e-05 - acc: 0.7323\n",
      "Epoch 896/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1295e-05 - acc: 0.7311\n",
      "Epoch 897/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1344e-05 - acc: 0.7321\n",
      "Epoch 898/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.1759e-05 - acc: 0.7316\n",
      "Epoch 899/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.1559e-05 - acc: 0.7297\n",
      "Epoch 900/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1395e-05 - acc: 0.7313\n",
      "Epoch 901/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.2592e-05 - acc: 0.7314\n",
      "Epoch 902/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.0908e-05 - acc: 0.7299\n",
      "Epoch 903/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1802e-05 - acc: 0.7328\n",
      "Epoch 904/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1978e-05 - acc: 0.7318\n",
      "Epoch 905/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1259e-05 - acc: 0.7324\n",
      "Epoch 906/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1094e-05 - acc: 0.7320: 1s - \n",
      "Epoch 907/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1493e-05 - acc: 0.7321\n",
      "Epoch 908/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1136e-05 - acc: 0.7315\n",
      "Epoch 909/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1238e-05 - acc: 0.7326\n",
      "Epoch 910/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.1736e-05 - acc: 0.7332\n",
      "Epoch 911/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.1272e-05 - acc: 0.7311\n",
      "Epoch 912/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1730e-05 - acc: 0.7325\n",
      "Epoch 913/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.1235e-05 - acc: 0.7319\n",
      "Epoch 914/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1256e-05 - acc: 0.7319\n",
      "Epoch 915/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.1453e-05 - acc: 0.7321\n",
      "Epoch 916/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1779e-05 - acc: 0.7313\n",
      "Epoch 917/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.1211e-05 - acc: 0.7323\n",
      "Epoch 918/1001\n",
      "91704/91704 [==============================] - 9s 96us/step - loss: 8.1088e-05 - acc: 0.7315\n",
      "Epoch 919/1001\n",
      "91704/91704 [==============================] - 10s 108us/step - loss: 8.1446e-05 - acc: 0.7339\n",
      "Epoch 920/1001\n",
      "91704/91704 [==============================] - 8s 92us/step - loss: 8.1405e-05 - acc: 0.7329\n",
      "Epoch 921/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.1943e-05 - acc: 0.7327\n",
      "Epoch 922/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.1571e-05 - acc: 0.7321\n",
      "Epoch 923/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.1569e-05 - acc: 0.7299\n",
      "Epoch 924/1001\n",
      "91704/91704 [==============================] - 7s 81us/step - loss: 8.1515e-05 - acc: 0.7314\n",
      "Epoch 925/1001\n",
      "91704/91704 [==============================] - 8s 83us/step - loss: 8.1069e-05 - acc: 0.7322: 2s - loss: 8.1393e-05\n",
      "Epoch 926/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.1556e-05 - acc: 0.7314\n",
      "Epoch 927/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.2586e-05 - acc: 0.7325\n",
      "Epoch 928/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.0957e-05 - acc: 0.7318\n",
      "Epoch 929/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.0792e-05 - acc: 0.7320\n",
      "Epoch 930/1001\n",
      "91704/91704 [==============================] - 8s 87us/step - loss: 8.1548e-05 - acc: 0.7317\n",
      "Epoch 931/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.1235e-05 - acc: 0.7332\n",
      "Epoch 932/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.1517e-05 - acc: 0.7304\n",
      "Epoch 933/1001\n",
      "91704/91704 [==============================] - 8s 87us/step - loss: 8.1065e-05 - acc: 0.7326\n",
      "Epoch 934/1001\n",
      "91704/91704 [==============================] - 7s 79us/step - loss: 8.0756e-05 - acc: 0.7320: 1s - loss: 8.10\n",
      "Epoch 935/1001\n",
      "91704/91704 [==============================] - 7s 80us/step - loss: 8.2226e-05 - acc: 0.7326\n",
      "Epoch 936/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.1429e-05 - acc: 0.7310\n",
      "Epoch 937/1001\n",
      "91704/91704 [==============================] - 7s 81us/step - loss: 8.1254e-05 - acc: 0.7309\n",
      "Epoch 938/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.1621e-05 - acc: 0.7315\n",
      "Epoch 939/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 8.1071e-05 - acc: 0.7327\n",
      "Epoch 940/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.0845e-05 - acc: 0.7314\n",
      "Epoch 941/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.1447e-05 - acc: 0.7316\n",
      "Epoch 942/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.0984e-05 - acc: 0.7312\n",
      "Epoch 943/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.0974e-05 - acc: 0.7321\n",
      "Epoch 944/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1198e-05 - acc: 0.7321\n",
      "Epoch 945/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1546e-05 - acc: 0.7311\n",
      "Epoch 946/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.0754e-05 - acc: 0.7321\n",
      "Epoch 947/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1270e-05 - acc: 0.7312\n",
      "Epoch 948/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1478e-05 - acc: 0.7330\n",
      "Epoch 949/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.0964e-05 - acc: 0.7317\n",
      "Epoch 950/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.1071e-05 - acc: 0.7303\n",
      "Epoch 951/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.1111e-05 - acc: 0.7326\n",
      "Epoch 952/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.0937e-05 - acc: 0.7307\n",
      "Epoch 953/1001\n",
      "91704/91704 [==============================] - 10s 110us/step - loss: 8.0792e-05 - acc: 0.7329\n",
      "Epoch 954/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 8.1667e-05 - acc: 0.7320\n",
      "Epoch 955/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.0883e-05 - acc: 0.7318\n",
      "Epoch 956/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1005e-05 - acc: 0.7318\n",
      "Epoch 957/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1719e-05 - acc: 0.7318\n",
      "Epoch 958/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.1531e-05 - acc: 0.7325\n",
      "Epoch 959/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.0634e-05 - acc: 0.7318\n",
      "Epoch 960/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.1094e-05 - acc: 0.7315\n",
      "Epoch 961/1001\n",
      "91704/91704 [==============================] - 8s 82us/step - loss: 8.1411e-05 - acc: 0.7325\n",
      "Epoch 962/1001\n",
      "91704/91704 [==============================] - 8s 84us/step - loss: 8.0661e-05 - acc: 0.7324\n",
      "Epoch 963/1001\n",
      "91704/91704 [==============================] - 7s 82us/step - loss: 8.0868e-05 - acc: 0.7323\n",
      "Epoch 964/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 8.1128e-05 - acc: 0.7330\n",
      "Epoch 965/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.0983e-05 - acc: 0.7316\n",
      "Epoch 966/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.0888e-05 - acc: 0.7311\n",
      "Epoch 967/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1043e-05 - acc: 0.7327\n",
      "Epoch 968/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.1072e-05 - acc: 0.7320\n",
      "Epoch 969/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.1355e-05 - acc: 0.7309\n",
      "Epoch 970/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.0851e-05 - acc: 0.7306\n",
      "Epoch 971/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1091e-05 - acc: 0.7316\n",
      "Epoch 972/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.1405e-05 - acc: 0.7314\n",
      "Epoch 973/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.0404e-05 - acc: 0.7313\n",
      "Epoch 974/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.0855e-05 - acc: 0.7323\n",
      "Epoch 975/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.0918e-05 - acc: 0.7309\n",
      "Epoch 976/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.1970e-05 - acc: 0.7310\n",
      "Epoch 977/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 8.0696e-05 - acc: 0.7317\n",
      "Epoch 978/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.0386e-05 - acc: 0.7321\n",
      "Epoch 979/1001\n",
      "91704/91704 [==============================] - 8s 82us/step - loss: 8.0912e-05 - acc: 0.7325\n",
      "Epoch 980/1001\n",
      "91704/91704 [==============================] - 8s 88us/step - loss: 8.0421e-05 - acc: 0.7319\n",
      "Epoch 981/1001\n",
      "91704/91704 [==============================] - 9s 102us/step - loss: 8.1088e-05 - acc: 0.7317\n",
      "Epoch 982/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.0762e-05 - acc: 0.7315\n",
      "Epoch 983/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 8.1058e-05 - acc: 0.7314\n",
      "Epoch 984/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 8.0724e-05 - acc: 0.7313\n",
      "Epoch 985/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.0799e-05 - acc: 0.7321\n",
      "Epoch 986/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 8.1482e-05 - acc: 0.7314\n",
      "Epoch 987/1001\n",
      "91704/91704 [==============================] - 7s 79us/step - loss: 8.0630e-05 - acc: 0.7330\n",
      "Epoch 988/1001\n",
      "91704/91704 [==============================] - 7s 79us/step - loss: 8.0414e-05 - acc: 0.7316\n",
      "Epoch 989/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.1880e-05 - acc: 0.7321\n",
      "Epoch 990/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.0620e-05 - acc: 0.7321\n",
      "Epoch 991/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.0994e-05 - acc: 0.7330\n",
      "Epoch 992/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 8.0228e-05 - acc: 0.7332\n",
      "Epoch 993/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.0959e-05 - acc: 0.7332\n",
      "Epoch 994/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 8.0779e-05 - acc: 0.7315\n",
      "Epoch 995/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.0223e-05 - acc: 0.7318\n",
      "Epoch 996/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 8.0394e-05 - acc: 0.7325\n",
      "Epoch 997/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 8.0794e-05 - acc: 0.7319\n",
      "Epoch 998/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 8.0574e-05 - acc: 0.7315\n",
      "Epoch 999/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.1895e-05 - acc: 0.7320\n",
      "Epoch 1000/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 8.0702e-05 - acc: 0.7336\n",
      "Epoch 1001/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 8.0529e-05 - acc: 0.7310\n",
      "../linkPrediction/dataframes/obesity\\obesity-model-pref-1000_2008-2015.pkl\n",
      "../linkPrediction/dataframes/obesity\\obesity-X_test-pref_2008-2015.pkl\n",
      "../linkPrediction/dataframes/obesity\\obesity-y_test-pref_2008-2015.pkl\n",
      "cm ---------------------------------------------------------------------------------\n",
      "(131006, 7, 3) (131006, 3)\n",
      "Epoch 1/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 6.2809e-04 - acc: 0.6550\n",
      "Epoch 2/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 3.9832e-04 - acc: 0.6654\n",
      "Epoch 3/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.8711e-04 - acc: 0.6659\n",
      "Epoch 4/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 3.8018e-04 - acc: 0.6683\n",
      "Epoch 5/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 3.7791e-04 - acc: 0.6697\n",
      "Epoch 6/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.7308e-04 - acc: 0.6700\n",
      "Epoch 7/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.7111e-04 - acc: 0.6699\n",
      "Epoch 8/1001\n",
      "91704/91704 [==============================] - 5s 51us/step - loss: 3.6724e-04 - acc: 0.6695\n",
      "Epoch 9/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.6700e-04 - acc: 0.6691\n",
      "Epoch 10/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.6560e-04 - acc: 0.6682\n",
      "Epoch 11/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.6577e-04 - acc: 0.6674\n",
      "Epoch 12/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.6104e-04 - acc: 0.6721\n",
      "Epoch 13/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 3.6083e-04 - acc: 0.6664\n",
      "Epoch 14/1001\n",
      "91704/91704 [==============================] - 6s 62us/step - loss: 3.5557e-04 - acc: 0.6700\n",
      "Epoch 15/1001\n",
      "91704/91704 [==============================] - 5s 60us/step - loss: 3.5624e-04 - acc: 0.6727\n",
      "Epoch 16/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 3.5252e-04 - acc: 0.6754\n",
      "Epoch 17/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 3.4984e-04 - acc: 0.6720\n",
      "Epoch 18/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 3.4935e-04 - acc: 0.6721\n",
      "Epoch 19/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 3.4525e-04 - acc: 0.6772\n",
      "Epoch 20/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.4372e-04 - acc: 0.6751\n",
      "Epoch 21/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 3.4167e-04 - acc: 0.6765\n",
      "Epoch 22/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.4035e-04 - acc: 0.6756\n",
      "Epoch 23/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.3745e-04 - acc: 0.6793\n",
      "Epoch 24/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.3502e-04 - acc: 0.6763\n",
      "Epoch 25/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.3366e-04 - acc: 0.6814\n",
      "Epoch 26/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.3100e-04 - acc: 0.6789\n",
      "Epoch 27/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.3017e-04 - acc: 0.6772\n",
      "Epoch 28/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 3.2963e-04 - acc: 0.6785\n",
      "Epoch 29/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.2672e-04 - acc: 0.6784\n",
      "Epoch 30/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 3.2545e-04 - acc: 0.6772\n",
      "Epoch 31/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 3.2386e-04 - acc: 0.6804\n",
      "Epoch 32/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.2237e-04 - acc: 0.6788\n",
      "Epoch 33/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.2222e-04 - acc: 0.6827\n",
      "Epoch 34/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.2156e-04 - acc: 0.6809\n",
      "Epoch 35/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.2136e-04 - acc: 0.6796\n",
      "Epoch 36/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.1809e-04 - acc: 0.6805\n",
      "Epoch 37/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.1693e-04 - acc: 0.6809\n",
      "Epoch 38/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.1556e-04 - acc: 0.6821\n",
      "Epoch 39/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.1571e-04 - acc: 0.6815\n",
      "Epoch 40/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.1488e-04 - acc: 0.6806\n",
      "Epoch 41/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 3.1363e-04 - acc: 0.6806\n",
      "Epoch 42/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.1326e-04 - acc: 0.6817\n",
      "Epoch 43/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.1183e-04 - acc: 0.6824\n",
      "Epoch 44/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 3.1019e-04 - acc: 0.6843\n",
      "Epoch 45/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 3.0924e-04 - acc: 0.6823\n",
      "Epoch 46/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.0984e-04 - acc: 0.6815\n",
      "Epoch 47/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.0771e-04 - acc: 0.6814\n",
      "Epoch 48/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.0771e-04 - acc: 0.6835\n",
      "Epoch 49/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.0683e-04 - acc: 0.6843\n",
      "Epoch 50/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.0564e-04 - acc: 0.6841\n",
      "Epoch 51/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.0535e-04 - acc: 0.6819\n",
      "Epoch 52/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.0447e-04 - acc: 0.6843\n",
      "Epoch 53/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 3.0370e-04 - acc: 0.6821\n",
      "Epoch 54/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 3.0276e-04 - acc: 0.6856\n",
      "Epoch 55/1001\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 3.0156e-04 - acc: 0.683 - 5s 53us/step - loss: 3.0178e-04 - acc: 0.6838\n",
      "Epoch 56/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.0198e-04 - acc: 0.6838\n",
      "Epoch 57/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 3.0244e-04 - acc: 0.6846\n",
      "Epoch 58/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 3.0031e-04 - acc: 0.6834\n",
      "Epoch 59/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.9962e-04 - acc: 0.6819\n",
      "Epoch 60/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 3.0038e-04 - acc: 0.6851\n",
      "Epoch 61/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.9959e-04 - acc: 0.6868\n",
      "Epoch 62/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.9925e-04 - acc: 0.6853\n",
      "Epoch 63/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.9805e-04 - acc: 0.6842\n",
      "Epoch 64/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.9845e-04 - acc: 0.6836\n",
      "Epoch 65/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.9704e-04 - acc: 0.6863\n",
      "Epoch 66/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.9656e-04 - acc: 0.6856\n",
      "Epoch 67/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.9643e-04 - acc: 0.6853\n",
      "Epoch 68/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.9578e-04 - acc: 0.6869\n",
      "Epoch 69/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.9631e-04 - acc: 0.6872\n",
      "Epoch 70/1001\n",
      "91704/91704 [==============================] - 6s 61us/step - loss: 2.9625e-04 - acc: 0.6883\n",
      "Epoch 71/1001\n",
      "91704/91704 [==============================] - 6s 60us/step - loss: 2.9380e-04 - acc: 0.6865\n",
      "Epoch 72/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.9488e-04 - acc: 0.6863\n",
      "Epoch 73/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.9519e-04 - acc: 0.6863\n",
      "Epoch 74/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.9452e-04 - acc: 0.6856\n",
      "Epoch 75/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.9371e-04 - acc: 0.6849\n",
      "Epoch 76/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.9399e-04 - acc: 0.6832\n",
      "Epoch 77/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.9298e-04 - acc: 0.6861\n",
      "Epoch 78/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.9282e-04 - acc: 0.6849\n",
      "Epoch 79/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.9288e-04 - acc: 0.6873\n",
      "Epoch 80/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.9263e-04 - acc: 0.6859\n",
      "Epoch 81/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.9282e-04 - acc: 0.6878\n",
      "Epoch 82/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.9168e-04 - acc: 0.6855\n",
      "Epoch 83/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.9081e-04 - acc: 0.6870\n",
      "Epoch 84/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.9087e-04 - acc: 0.6849\n",
      "Epoch 85/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.9076e-04 - acc: 0.6880\n",
      "Epoch 86/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.8954e-04 - acc: 0.6869\n",
      "Epoch 87/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.8984e-04 - acc: 0.6865\n",
      "Epoch 88/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.8961e-04 - acc: 0.6859\n",
      "Epoch 89/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.9003e-04 - acc: 0.6845\n",
      "Epoch 90/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.8921e-04 - acc: 0.6868\n",
      "Epoch 91/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.8842e-04 - acc: 0.6850\n",
      "Epoch 92/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.9027e-04 - acc: 0.6869\n",
      "Epoch 93/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.8828e-04 - acc: 0.6871\n",
      "Epoch 94/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.8841e-04 - acc: 0.6843\n",
      "Epoch 95/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8739e-04 - acc: 0.6859\n",
      "Epoch 96/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.8753e-04 - acc: 0.6862\n",
      "Epoch 97/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.8682e-04 - acc: 0.6858\n",
      "Epoch 98/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8804e-04 - acc: 0.6883\n",
      "Epoch 99/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.8699e-04 - acc: 0.6851\n",
      "Epoch 100/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8675e-04 - acc: 0.6859\n",
      "Epoch 101/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8674e-04 - acc: 0.6865\n",
      "../linkPrediction/dataframes/obesity\\obesity-model-cm-100_2008-2015.pkl\n",
      "Epoch 102/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8495e-04 - acc: 0.6867\n",
      "Epoch 103/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8523e-04 - acc: 0.6864\n",
      "Epoch 104/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.8535e-04 - acc: 0.6861\n",
      "Epoch 105/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.8516e-04 - acc: 0.6877\n",
      "Epoch 106/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8465e-04 - acc: 0.6876\n",
      "Epoch 107/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.8456e-04 - acc: 0.6882\n",
      "Epoch 108/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8414e-04 - acc: 0.6887\n",
      "Epoch 109/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8459e-04 - acc: 0.6884\n",
      "Epoch 110/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.8450e-04 - acc: 0.6874\n",
      "Epoch 111/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.8332e-04 - acc: 0.6884\n",
      "Epoch 112/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8288e-04 - acc: 0.6884: 0s - loss: 2.8406e-04 - ac\n",
      "Epoch 113/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8421e-04 - acc: 0.6885\n",
      "Epoch 114/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.8287e-04 - acc: 0.6881\n",
      "Epoch 115/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.8295e-04 - acc: 0.6856\n",
      "Epoch 116/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.8245e-04 - acc: 0.6887\n",
      "Epoch 117/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.8205e-04 - acc: 0.6869\n",
      "Epoch 118/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.8198e-04 - acc: 0.6875\n",
      "Epoch 119/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8175e-04 - acc: 0.6876\n",
      "Epoch 120/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.8225e-04 - acc: 0.6856\n",
      "Epoch 121/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8120e-04 - acc: 0.6882\n",
      "Epoch 122/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.8070e-04 - acc: 0.6863\n",
      "Epoch 123/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.8082e-04 - acc: 0.6857\n",
      "Epoch 124/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.8012e-04 - acc: 0.6882\n",
      "Epoch 125/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.8084e-04 - acc: 0.6881\n",
      "Epoch 126/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.8054e-04 - acc: 0.6870\n",
      "Epoch 127/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.8114e-04 - acc: 0.6873\n",
      "Epoch 128/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7935e-04 - acc: 0.6887\n",
      "Epoch 129/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7876e-04 - acc: 0.6881\n",
      "Epoch 130/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.7950e-04 - acc: 0.6866\n",
      "Epoch 131/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.7984e-04 - acc: 0.6872\n",
      "Epoch 132/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7878e-04 - acc: 0.6873\n",
      "Epoch 133/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7952e-04 - acc: 0.6863\n",
      "Epoch 134/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.7806e-04 - acc: 0.6875\n",
      "Epoch 135/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7906e-04 - acc: 0.6877\n",
      "Epoch 136/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.7933e-04 - acc: 0.6882\n",
      "Epoch 137/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7860e-04 - acc: 0.6847\n",
      "Epoch 138/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 2.7807e-04 - acc: 0.6879\n",
      "Epoch 139/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7846e-04 - acc: 0.6859\n",
      "Epoch 140/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.7691e-04 - acc: 0.6866\n",
      "Epoch 141/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7787e-04 - acc: 0.6846: 0s - loss: 2.7921e-04 \n",
      "Epoch 142/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7669e-04 - acc: 0.6875\n",
      "Epoch 143/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7660e-04 - acc: 0.6864\n",
      "Epoch 144/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.7690e-04 - acc: 0.6897\n",
      "Epoch 145/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7662e-04 - acc: 0.6849\n",
      "Epoch 146/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.7567e-04 - acc: 0.6871\n",
      "Epoch 147/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7586e-04 - acc: 0.6858\n",
      "Epoch 148/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7573e-04 - acc: 0.6871\n",
      "Epoch 149/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.7541e-04 - acc: 0.6882\n",
      "Epoch 150/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7536e-04 - acc: 0.6864\n",
      "Epoch 151/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7603e-04 - acc: 0.6868\n",
      "Epoch 152/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7568e-04 - acc: 0.6867\n",
      "Epoch 153/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7456e-04 - acc: 0.6878\n",
      "Epoch 154/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7463e-04 - acc: 0.6889\n",
      "Epoch 155/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7463e-04 - acc: 0.6876\n",
      "Epoch 156/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7479e-04 - acc: 0.6870\n",
      "Epoch 157/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7415e-04 - acc: 0.6872\n",
      "Epoch 158/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7393e-04 - acc: 0.6876\n",
      "Epoch 159/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7405e-04 - acc: 0.6861\n",
      "Epoch 160/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.7334e-04 - acc: 0.6872\n",
      "Epoch 161/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7419e-04 - acc: 0.6881\n",
      "Epoch 162/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.7477e-04 - acc: 0.6877\n",
      "Epoch 163/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7326e-04 - acc: 0.6868\n",
      "Epoch 164/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7351e-04 - acc: 0.6866\n",
      "Epoch 165/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.7433e-04 - acc: 0.6862\n",
      "Epoch 166/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.7345e-04 - acc: 0.6876\n",
      "Epoch 167/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7341e-04 - acc: 0.6883\n",
      "Epoch 168/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7279e-04 - acc: 0.6900\n",
      "Epoch 169/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7294e-04 - acc: 0.6869\n",
      "Epoch 170/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7144e-04 - acc: 0.6889\n",
      "Epoch 171/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7174e-04 - acc: 0.6881\n",
      "Epoch 172/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7293e-04 - acc: 0.6872\n",
      "Epoch 173/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7225e-04 - acc: 0.6878\n",
      "Epoch 174/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7221e-04 - acc: 0.6875\n",
      "Epoch 175/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.7187e-04 - acc: 0.6874\n",
      "Epoch 176/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.7122e-04 - acc: 0.6881\n",
      "Epoch 177/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7210e-04 - acc: 0.6886\n",
      "Epoch 178/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7127e-04 - acc: 0.6865\n",
      "Epoch 179/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7207e-04 - acc: 0.6866\n",
      "Epoch 180/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7035e-04 - acc: 0.6878\n",
      "Epoch 181/1001\n",
      "91704/91704 [==============================] - 5s 52us/step - loss: 2.7087e-04 - acc: 0.6881\n",
      "Epoch 182/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7021e-04 - acc: 0.6883\n",
      "Epoch 183/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.7031e-04 - acc: 0.6891\n",
      "Epoch 184/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.7080e-04 - acc: 0.6874\n",
      "Epoch 185/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.7080e-04 - acc: 0.6876\n",
      "Epoch 186/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 2.6948e-04 - acc: 0.6892: 0s - loss: 2.6892e-04 -\n",
      "Epoch 187/1001\n",
      "91704/91704 [==============================] - 6s 61us/step - loss: 2.6947e-04 - acc: 0.6885\n",
      "Epoch 188/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.7000e-04 - acc: 0.6879\n",
      "Epoch 189/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.7042e-04 - acc: 0.6886\n",
      "Epoch 190/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.6953e-04 - acc: 0.6886\n",
      "Epoch 191/1001\n",
      "91704/91704 [==============================] - 7s 79us/step - loss: 2.6935e-04 - acc: 0.6882\n",
      "Epoch 192/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.6850e-04 - acc: 0.6908\n",
      "Epoch 193/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6975e-04 - acc: 0.6890\n",
      "Epoch 194/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.6878e-04 - acc: 0.6887\n",
      "Epoch 195/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6829e-04 - acc: 0.6908: 0s - loss: 2.6866e-04 - acc\n",
      "Epoch 196/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6876e-04 - acc: 0.6892\n",
      "Epoch 197/1001\n",
      "91704/91704 [==============================] - 6s 62us/step - loss: 2.6841e-04 - acc: 0.6892\n",
      "Epoch 198/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6819e-04 - acc: 0.6899\n",
      "Epoch 199/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6810e-04 - acc: 0.6887\n",
      "Epoch 200/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6819e-04 - acc: 0.6891\n",
      "Epoch 201/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.6823e-04 - acc: 0.6904\n",
      "Epoch 202/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6804e-04 - acc: 0.6894\n",
      "Epoch 203/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6832e-04 - acc: 0.6887\n",
      "Epoch 204/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6716e-04 - acc: 0.6879\n",
      "Epoch 205/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6789e-04 - acc: 0.6895\n",
      "Epoch 206/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6815e-04 - acc: 0.6890\n",
      "Epoch 207/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6805e-04 - acc: 0.6909\n",
      "Epoch 208/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6779e-04 - acc: 0.6887\n",
      "Epoch 209/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6695e-04 - acc: 0.6891\n",
      "Epoch 210/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6699e-04 - acc: 0.6904\n",
      "Epoch 211/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.6741e-04 - acc: 0.6898\n",
      "Epoch 212/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6670e-04 - acc: 0.6897\n",
      "Epoch 213/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6689e-04 - acc: 0.6894\n",
      "Epoch 214/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.6603e-04 - acc: 0.6888\n",
      "Epoch 215/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6625e-04 - acc: 0.6896\n",
      "Epoch 216/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6501e-04 - acc: 0.6897\n",
      "Epoch 217/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6663e-04 - acc: 0.6906\n",
      "Epoch 218/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6568e-04 - acc: 0.6898\n",
      "Epoch 219/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6470e-04 - acc: 0.6905\n",
      "Epoch 220/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6634e-04 - acc: 0.6885\n",
      "Epoch 221/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.6516e-04 - acc: 0.6887\n",
      "Epoch 222/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6600e-04 - acc: 0.6889\n",
      "Epoch 223/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6449e-04 - acc: 0.6887\n",
      "Epoch 224/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.6537e-04 - acc: 0.6896\n",
      "Epoch 225/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.6549e-04 - acc: 0.6889\n",
      "Epoch 226/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6470e-04 - acc: 0.6890\n",
      "Epoch 227/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.6475e-04 - acc: 0.6887\n",
      "Epoch 228/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6497e-04 - acc: 0.6877\n",
      "Epoch 229/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6450e-04 - acc: 0.6892\n",
      "Epoch 230/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6442e-04 - acc: 0.6906\n",
      "Epoch 231/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6441e-04 - acc: 0.6892\n",
      "Epoch 232/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6442e-04 - acc: 0.6882\n",
      "Epoch 233/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6443e-04 - acc: 0.6883\n",
      "Epoch 234/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6333e-04 - acc: 0.6896\n",
      "Epoch 235/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6445e-04 - acc: 0.6885\n",
      "Epoch 236/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6389e-04 - acc: 0.6905\n",
      "Epoch 237/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.6354e-04 - acc: 0.6905\n",
      "Epoch 238/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.6501e-04 - acc: 0.6865\n",
      "Epoch 239/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.6350e-04 - acc: 0.6884\n",
      "Epoch 240/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.6354e-04 - acc: 0.6897\n",
      "Epoch 241/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.6383e-04 - acc: 0.6892\n",
      "Epoch 242/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6304e-04 - acc: 0.6901\n",
      "Epoch 243/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6238e-04 - acc: 0.6904\n",
      "Epoch 244/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6332e-04 - acc: 0.6888\n",
      "Epoch 245/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6249e-04 - acc: 0.6896\n",
      "Epoch 246/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6351e-04 - acc: 0.6903\n",
      "Epoch 247/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6294e-04 - acc: 0.6885\n",
      "Epoch 248/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6212e-04 - acc: 0.6889\n",
      "Epoch 249/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6319e-04 - acc: 0.6885\n",
      "Epoch 250/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.6321e-04 - acc: 0.6891\n",
      "Epoch 251/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6259e-04 - acc: 0.6904\n",
      "Epoch 252/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6260e-04 - acc: 0.6880\n",
      "Epoch 253/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.6223e-04 - acc: 0.6893\n",
      "Epoch 254/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.6230e-04 - acc: 0.6898\n",
      "Epoch 255/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6135e-04 - acc: 0.6905\n",
      "Epoch 256/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6162e-04 - acc: 0.6904\n",
      "Epoch 257/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6246e-04 - acc: 0.6899\n",
      "Epoch 258/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6124e-04 - acc: 0.6897\n",
      "Epoch 259/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.6234e-04 - acc: 0.6902\n",
      "Epoch 260/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6178e-04 - acc: 0.6907\n",
      "Epoch 261/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6234e-04 - acc: 0.6889\n",
      "Epoch 262/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6089e-04 - acc: 0.6900\n",
      "Epoch 263/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6078e-04 - acc: 0.6897\n",
      "Epoch 264/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.6123e-04 - acc: 0.6900\n",
      "Epoch 265/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6079e-04 - acc: 0.6910\n",
      "Epoch 266/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6164e-04 - acc: 0.6893\n",
      "Epoch 267/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.6085e-04 - acc: 0.6882\n",
      "Epoch 268/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6163e-04 - acc: 0.6900\n",
      "Epoch 269/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6012e-04 - acc: 0.6896\n",
      "Epoch 270/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6053e-04 - acc: 0.6902\n",
      "Epoch 271/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6014e-04 - acc: 0.6894\n",
      "Epoch 272/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6109e-04 - acc: 0.6900\n",
      "Epoch 273/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.6094e-04 - acc: 0.6900\n",
      "Epoch 274/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6034e-04 - acc: 0.6889\n",
      "Epoch 275/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5993e-04 - acc: 0.6907\n",
      "Epoch 276/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5992e-04 - acc: 0.6890\n",
      "Epoch 277/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.6034e-04 - acc: 0.6893\n",
      "Epoch 278/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6021e-04 - acc: 0.6895\n",
      "Epoch 279/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5976e-04 - acc: 0.6881\n",
      "Epoch 280/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.6050e-04 - acc: 0.6879\n",
      "Epoch 281/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5981e-04 - acc: 0.6896\n",
      "Epoch 282/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5949e-04 - acc: 0.6903\n",
      "Epoch 283/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5970e-04 - acc: 0.6900\n",
      "Epoch 284/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.6017e-04 - acc: 0.6901\n",
      "Epoch 285/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5849e-04 - acc: 0.6907\n",
      "Epoch 286/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5993e-04 - acc: 0.6911\n",
      "Epoch 287/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5989e-04 - acc: 0.6911\n",
      "Epoch 288/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5947e-04 - acc: 0.6893\n",
      "Epoch 289/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5853e-04 - acc: 0.6885\n",
      "Epoch 290/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5975e-04 - acc: 0.6902\n",
      "Epoch 291/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5865e-04 - acc: 0.6911\n",
      "Epoch 292/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.6019e-04 - acc: 0.6908\n",
      "Epoch 293/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5873e-04 - acc: 0.6900\n",
      "Epoch 294/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5887e-04 - acc: 0.6901\n",
      "Epoch 295/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5875e-04 - acc: 0.6904\n",
      "Epoch 296/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5868e-04 - acc: 0.6897\n",
      "Epoch 297/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5880e-04 - acc: 0.6897\n",
      "Epoch 298/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5847e-04 - acc: 0.6905\n",
      "Epoch 299/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5916e-04 - acc: 0.6888\n",
      "Epoch 300/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5806e-04 - acc: 0.6906\n",
      "Epoch 301/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5868e-04 - acc: 0.6894\n",
      "Epoch 302/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5848e-04 - acc: 0.6911\n",
      "Epoch 303/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5811e-04 - acc: 0.6892\n",
      "Epoch 304/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.5728e-04 - acc: 0.6904\n",
      "Epoch 305/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5964e-04 - acc: 0.6887\n",
      "Epoch 306/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5864e-04 - acc: 0.6913\n",
      "Epoch 307/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.5809e-04 - acc: 0.6899\n",
      "Epoch 308/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.5866e-04 - acc: 0.6898\n",
      "Epoch 309/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5728e-04 - acc: 0.6902\n",
      "Epoch 310/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5840e-04 - acc: 0.6906\n",
      "Epoch 311/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5732e-04 - acc: 0.6888\n",
      "Epoch 312/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5815e-04 - acc: 0.6897\n",
      "Epoch 313/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5823e-04 - acc: 0.6896\n",
      "Epoch 314/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5716e-04 - acc: 0.6897\n",
      "Epoch 315/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5787e-04 - acc: 0.6903\n",
      "Epoch 316/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5688e-04 - acc: 0.6901\n",
      "Epoch 317/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5725e-04 - acc: 0.6903\n",
      "Epoch 318/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5683e-04 - acc: 0.6900\n",
      "Epoch 319/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5783e-04 - acc: 0.6895\n",
      "Epoch 320/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.5669e-04 - acc: 0.6900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5720e-04 - acc: 0.6910\n",
      "Epoch 322/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5733e-04 - acc: 0.6880\n",
      "Epoch 323/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5758e-04 - acc: 0.6904\n",
      "Epoch 324/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5698e-04 - acc: 0.6896\n",
      "Epoch 325/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5644e-04 - acc: 0.6886\n",
      "Epoch 326/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5710e-04 - acc: 0.6884\n",
      "Epoch 327/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5727e-04 - acc: 0.6895\n",
      "Epoch 328/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5713e-04 - acc: 0.6913\n",
      "Epoch 329/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5588e-04 - acc: 0.6912\n",
      "Epoch 330/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5696e-04 - acc: 0.6911\n",
      "Epoch 331/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5670e-04 - acc: 0.6910\n",
      "Epoch 332/1001\n",
      "91704/91704 [==============================] - 6s 61us/step - loss: 2.5687e-04 - acc: 0.6896\n",
      "Epoch 333/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5622e-04 - acc: 0.6896\n",
      "Epoch 334/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5683e-04 - acc: 0.6893\n",
      "Epoch 335/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5577e-04 - acc: 0.6887\n",
      "Epoch 336/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5594e-04 - acc: 0.6892\n",
      "Epoch 337/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5664e-04 - acc: 0.6891\n",
      "Epoch 338/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5560e-04 - acc: 0.6897\n",
      "Epoch 339/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5685e-04 - acc: 0.6874\n",
      "Epoch 340/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5648e-04 - acc: 0.6892\n",
      "Epoch 341/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5553e-04 - acc: 0.6879\n",
      "Epoch 342/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5624e-04 - acc: 0.6890\n",
      "Epoch 343/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.5622e-04 - acc: 0.6905\n",
      "Epoch 344/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5562e-04 - acc: 0.6898\n",
      "Epoch 345/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.5518e-04 - acc: 0.6903\n",
      "Epoch 346/1001\n",
      "91704/91704 [==============================] - 6s 61us/step - loss: 2.5575e-04 - acc: 0.6888\n",
      "Epoch 347/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.5538e-04 - acc: 0.6895\n",
      "Epoch 348/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5516e-04 - acc: 0.6899\n",
      "Epoch 349/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5479e-04 - acc: 0.6887\n",
      "Epoch 350/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5614e-04 - acc: 0.6898\n",
      "Epoch 351/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5668e-04 - acc: 0.6913\n",
      "Epoch 352/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5475e-04 - acc: 0.6893\n",
      "Epoch 353/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5443e-04 - acc: 0.6901\n",
      "Epoch 354/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5545e-04 - acc: 0.6918\n",
      "Epoch 355/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5503e-04 - acc: 0.6869\n",
      "Epoch 356/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.5482e-04 - acc: 0.6893\n",
      "Epoch 357/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5526e-04 - acc: 0.6914\n",
      "Epoch 358/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5517e-04 - acc: 0.6906\n",
      "Epoch 359/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5462e-04 - acc: 0.6889\n",
      "Epoch 360/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5420e-04 - acc: 0.6892\n",
      "Epoch 361/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.5438e-04 - acc: 0.6872\n",
      "Epoch 362/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.5438e-04 - acc: 0.6913\n",
      "Epoch 363/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5446e-04 - acc: 0.6900\n",
      "Epoch 364/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5426e-04 - acc: 0.6885\n",
      "Epoch 365/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5429e-04 - acc: 0.6884\n",
      "Epoch 366/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5423e-04 - acc: 0.6877\n",
      "Epoch 367/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5397e-04 - acc: 0.6908\n",
      "Epoch 368/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5436e-04 - acc: 0.6900\n",
      "Epoch 369/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.5420e-04 - acc: 0.6884\n",
      "Epoch 370/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5380e-04 - acc: 0.6911\n",
      "Epoch 371/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5448e-04 - acc: 0.6906\n",
      "Epoch 372/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5444e-04 - acc: 0.6906\n",
      "Epoch 373/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5414e-04 - acc: 0.6898\n",
      "Epoch 374/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.5336e-04 - acc: 0.6887\n",
      "Epoch 375/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5398e-04 - acc: 0.6879\n",
      "Epoch 376/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5332e-04 - acc: 0.6891\n",
      "Epoch 377/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5390e-04 - acc: 0.6891\n",
      "Epoch 378/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.5357e-04 - acc: 0.6881\n",
      "Epoch 379/1001\n",
      "91704/91704 [==============================] - 6s 62us/step - loss: 2.5305e-04 - acc: 0.6900\n",
      "Epoch 380/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5346e-04 - acc: 0.6893\n",
      "Epoch 381/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.5417e-04 - acc: 0.6898\n",
      "Epoch 382/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.5356e-04 - acc: 0.6880\n",
      "Epoch 383/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5387e-04 - acc: 0.6889\n",
      "Epoch 384/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5337e-04 - acc: 0.6899\n",
      "Epoch 385/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.5351e-04 - acc: 0.6896\n",
      "Epoch 386/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 2.5344e-04 - acc: 0.6898\n",
      "Epoch 387/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5390e-04 - acc: 0.6900\n",
      "Epoch 388/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5360e-04 - acc: 0.6898\n",
      "Epoch 389/1001\n",
      "91704/91704 [==============================] - 6s 62us/step - loss: 2.5297e-04 - acc: 0.6896\n",
      "Epoch 390/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.5338e-04 - acc: 0.6895\n",
      "Epoch 391/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5209e-04 - acc: 0.6888\n",
      "Epoch 392/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5262e-04 - acc: 0.6895\n",
      "Epoch 393/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5279e-04 - acc: 0.6905\n",
      "Epoch 394/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5273e-04 - acc: 0.6906\n",
      "Epoch 395/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5280e-04 - acc: 0.6904\n",
      "Epoch 396/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5271e-04 - acc: 0.6868\n",
      "Epoch 397/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.5292e-04 - acc: 0.6906\n",
      "Epoch 398/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5217e-04 - acc: 0.6902\n",
      "Epoch 399/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5268e-04 - acc: 0.6892\n",
      "Epoch 400/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5229e-04 - acc: 0.6899\n",
      "Epoch 401/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5173e-04 - acc: 0.6887\n",
      "Epoch 402/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.5313e-04 - acc: 0.6905\n",
      "Epoch 403/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5249e-04 - acc: 0.6888\n",
      "Epoch 404/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5214e-04 - acc: 0.6897\n",
      "Epoch 405/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5199e-04 - acc: 0.6895\n",
      "Epoch 406/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5227e-04 - acc: 0.6896\n",
      "Epoch 407/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5200e-04 - acc: 0.6902\n",
      "Epoch 408/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5236e-04 - acc: 0.6895\n",
      "Epoch 409/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5214e-04 - acc: 0.6901\n",
      "Epoch 410/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5228e-04 - acc: 0.6896\n",
      "Epoch 411/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5271e-04 - acc: 0.6876\n",
      "Epoch 412/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5111e-04 - acc: 0.6892\n",
      "Epoch 413/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5210e-04 - acc: 0.6891\n",
      "Epoch 414/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5184e-04 - acc: 0.6893\n",
      "Epoch 415/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.5248e-04 - acc: 0.6879\n",
      "Epoch 416/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5204e-04 - acc: 0.6910\n",
      "Epoch 417/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5157e-04 - acc: 0.6899\n",
      "Epoch 418/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5186e-04 - acc: 0.6888\n",
      "Epoch 419/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.5141e-04 - acc: 0.6883\n",
      "Epoch 420/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5240e-04 - acc: 0.6895\n",
      "Epoch 421/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5132e-04 - acc: 0.6904\n",
      "Epoch 422/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.5141e-04 - acc: 0.6902\n",
      "Epoch 423/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.5056e-04 - acc: 0.6889\n",
      "Epoch 424/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5196e-04 - acc: 0.6880\n",
      "Epoch 425/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.5111e-04 - acc: 0.6893\n",
      "Epoch 426/1001\n",
      "91704/91704 [==============================] - 6s 62us/step - loss: 2.5155e-04 - acc: 0.6897\n",
      "Epoch 427/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5101e-04 - acc: 0.6892\n",
      "Epoch 428/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5063e-04 - acc: 0.6896\n",
      "Epoch 429/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5109e-04 - acc: 0.6889\n",
      "Epoch 430/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5207e-04 - acc: 0.6884\n",
      "Epoch 431/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5128e-04 - acc: 0.6883\n",
      "Epoch 432/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.5124e-04 - acc: 0.6887\n",
      "Epoch 433/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5039e-04 - acc: 0.6887\n",
      "Epoch 434/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5142e-04 - acc: 0.6888\n",
      "Epoch 435/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5114e-04 - acc: 0.6882\n",
      "Epoch 436/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5074e-04 - acc: 0.6907\n",
      "Epoch 437/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5101e-04 - acc: 0.6889: 0s - loss: 2.5189e-04 - acc: \n",
      "Epoch 438/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5073e-04 - acc: 0.6876\n",
      "Epoch 439/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5131e-04 - acc: 0.6909\n",
      "Epoch 440/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5061e-04 - acc: 0.6892\n",
      "Epoch 441/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5037e-04 - acc: 0.6916\n",
      "Epoch 442/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5020e-04 - acc: 0.6880\n",
      "Epoch 443/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5047e-04 - acc: 0.6890\n",
      "Epoch 444/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5050e-04 - acc: 0.6897\n",
      "Epoch 445/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.5101e-04 - acc: 0.6898\n",
      "Epoch 446/1001\n",
      "91704/91704 [==============================] - 6s 63us/step - loss: 2.5094e-04 - acc: 0.6902\n",
      "Epoch 447/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5035e-04 - acc: 0.6892\n",
      "Epoch 448/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5068e-04 - acc: 0.6889: 0s - loss: 2.5203e-04 - acc: 0. - ETA: 0s - loss: 2.5113e-04\n",
      "Epoch 449/1001\n",
      "91704/91704 [==============================] - 6s 62us/step - loss: 2.4964e-04 - acc: 0.6890\n",
      "Epoch 450/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.5049e-04 - acc: 0.6898\n",
      "Epoch 451/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5040e-04 - acc: 0.6895\n",
      "Epoch 452/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4988e-04 - acc: 0.6879\n",
      "Epoch 453/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.5004e-04 - acc: 0.6904\n",
      "Epoch 454/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5010e-04 - acc: 0.6884\n",
      "Epoch 455/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5138e-04 - acc: 0.6900\n",
      "Epoch 456/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5047e-04 - acc: 0.6910\n",
      "Epoch 457/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4997e-04 - acc: 0.6892\n",
      "Epoch 458/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5027e-04 - acc: 0.6907\n",
      "Epoch 459/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4978e-04 - acc: 0.6877\n",
      "Epoch 460/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.5020e-04 - acc: 0.6899\n",
      "Epoch 461/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 2.5002e-04 - acc: 0.6895\n",
      "Epoch 462/1001\n",
      "91704/91704 [==============================] - 6s 60us/step - loss: 2.4972e-04 - acc: 0.6900\n",
      "Epoch 463/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4962e-04 - acc: 0.6907\n",
      "Epoch 464/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.5034e-04 - acc: 0.6886\n",
      "Epoch 465/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.5015e-04 - acc: 0.6905\n",
      "Epoch 466/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4965e-04 - acc: 0.6884\n",
      "Epoch 467/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4976e-04 - acc: 0.6898\n",
      "Epoch 468/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5024e-04 - acc: 0.6880\n",
      "Epoch 469/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4968e-04 - acc: 0.6878\n",
      "Epoch 470/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.5010e-04 - acc: 0.6896\n",
      "Epoch 471/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4907e-04 - acc: 0.6887\n",
      "Epoch 472/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.5019e-04 - acc: 0.6876\n",
      "Epoch 473/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4990e-04 - acc: 0.6904\n",
      "Epoch 474/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4915e-04 - acc: 0.6904\n",
      "Epoch 475/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.4964e-04 - acc: 0.6891\n",
      "Epoch 476/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4987e-04 - acc: 0.6895\n",
      "Epoch 477/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.4958e-04 - acc: 0.6889\n",
      "Epoch 478/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.4865e-04 - acc: 0.6885\n",
      "Epoch 479/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4893e-04 - acc: 0.6890\n",
      "Epoch 480/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4970e-04 - acc: 0.6890\n",
      "Epoch 481/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4872e-04 - acc: 0.6896\n",
      "Epoch 482/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.4958e-04 - acc: 0.6884\n",
      "Epoch 483/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4847e-04 - acc: 0.6884\n",
      "Epoch 484/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4920e-04 - acc: 0.6883\n",
      "Epoch 485/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4907e-04 - acc: 0.6900\n",
      "Epoch 486/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4899e-04 - acc: 0.6891\n",
      "Epoch 487/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4813e-04 - acc: 0.6911\n",
      "Epoch 488/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.4913e-04 - acc: 0.6913\n",
      "Epoch 489/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4883e-04 - acc: 0.6904\n",
      "Epoch 490/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4813e-04 - acc: 0.6910\n",
      "Epoch 491/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4914e-04 - acc: 0.6886\n",
      "Epoch 492/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4888e-04 - acc: 0.6886\n",
      "Epoch 493/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4847e-04 - acc: 0.6898\n",
      "Epoch 494/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4863e-04 - acc: 0.6878\n",
      "Epoch 495/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4900e-04 - acc: 0.6896\n",
      "Epoch 496/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.4809e-04 - acc: 0.6905\n",
      "Epoch 497/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4907e-04 - acc: 0.6893\n",
      "Epoch 498/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4815e-04 - acc: 0.6890\n",
      "Epoch 499/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4829e-04 - acc: 0.6895\n",
      "Epoch 500/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4765e-04 - acc: 0.6916\n",
      "Epoch 501/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4865e-04 - acc: 0.6903\n",
      "../linkPrediction/dataframes/obesity\\obesity-model-cm-500_2008-2015.pkl\n",
      "Epoch 502/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4855e-04 - acc: 0.6902\n",
      "Epoch 503/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4848e-04 - acc: 0.6895\n",
      "Epoch 504/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4831e-04 - acc: 0.6898\n",
      "Epoch 505/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4911e-04 - acc: 0.6874\n",
      "Epoch 506/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4849e-04 - acc: 0.6909\n",
      "Epoch 507/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4759e-04 - acc: 0.6904\n",
      "Epoch 508/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4819e-04 - acc: 0.6892\n",
      "Epoch 509/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4844e-04 - acc: 0.6907\n",
      "Epoch 510/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4826e-04 - acc: 0.6896\n",
      "Epoch 511/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4767e-04 - acc: 0.6873\n",
      "Epoch 512/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.4785e-04 - acc: 0.6887\n",
      "Epoch 513/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4776e-04 - acc: 0.6904\n",
      "Epoch 514/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4813e-04 - acc: 0.6893\n",
      "Epoch 515/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4666e-04 - acc: 0.6886\n",
      "Epoch 516/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4759e-04 - acc: 0.6901\n",
      "Epoch 517/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4743e-04 - acc: 0.6894\n",
      "Epoch 518/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4809e-04 - acc: 0.6903\n",
      "Epoch 519/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.4828e-04 - acc: 0.6894\n",
      "Epoch 520/1001\n",
      "91704/91704 [==============================] - 6s 61us/step - loss: 2.4692e-04 - acc: 0.6891\n",
      "Epoch 521/1001\n",
      "91704/91704 [==============================] - 6s 63us/step - loss: 2.4714e-04 - acc: 0.6905\n",
      "Epoch 522/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4785e-04 - acc: 0.6893\n",
      "Epoch 523/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4753e-04 - acc: 0.6892\n",
      "Epoch 524/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.4768e-04 - acc: 0.6892\n",
      "Epoch 525/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4777e-04 - acc: 0.6889\n",
      "Epoch 526/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4706e-04 - acc: 0.6891\n",
      "Epoch 527/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4785e-04 - acc: 0.6884\n",
      "Epoch 528/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4763e-04 - acc: 0.6896\n",
      "Epoch 529/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4706e-04 - acc: 0.6901\n",
      "Epoch 530/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4717e-04 - acc: 0.6883\n",
      "Epoch 531/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4786e-04 - acc: 0.6874\n",
      "Epoch 532/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4728e-04 - acc: 0.6915\n",
      "Epoch 533/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4799e-04 - acc: 0.6897: 0s - loss: 2.4935e-04 - acc: 0.\n",
      "Epoch 534/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4833e-04 - acc: 0.6897\n",
      "Epoch 535/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4679e-04 - acc: 0.6892\n",
      "Epoch 536/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4688e-04 - acc: 0.6903\n",
      "Epoch 537/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4688e-04 - acc: 0.6870\n",
      "Epoch 538/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.4753e-04 - acc: 0.6880\n",
      "Epoch 539/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4680e-04 - acc: 0.6909\n",
      "Epoch 540/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4706e-04 - acc: 0.6906\n",
      "Epoch 541/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4721e-04 - acc: 0.6880\n",
      "Epoch 542/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4687e-04 - acc: 0.6904\n",
      "Epoch 543/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 2.4707e-04 - acc: 0.6901\n",
      "Epoch 544/1001\n",
      "91704/91704 [==============================] - 6s 61us/step - loss: 2.4718e-04 - acc: 0.6883\n",
      "Epoch 545/1001\n",
      "91704/91704 [==============================] - 8s 85us/step - loss: 2.4678e-04 - acc: 0.6892\n",
      "Epoch 546/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4625e-04 - acc: 0.6904\n",
      "Epoch 547/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4704e-04 - acc: 0.6906\n",
      "Epoch 548/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4785e-04 - acc: 0.6871\n",
      "Epoch 549/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4711e-04 - acc: 0.6910\n",
      "Epoch 550/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.4675e-04 - acc: 0.6908\n",
      "Epoch 551/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4627e-04 - acc: 0.6894\n",
      "Epoch 552/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4670e-04 - acc: 0.6908\n",
      "Epoch 553/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4650e-04 - acc: 0.6904\n",
      "Epoch 554/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4613e-04 - acc: 0.6894\n",
      "Epoch 555/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4629e-04 - acc: 0.6906\n",
      "Epoch 556/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4623e-04 - acc: 0.6905\n",
      "Epoch 557/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4858e-04 - acc: 0.6887\n",
      "Epoch 558/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4790e-04 - acc: 0.6910\n",
      "Epoch 559/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4599e-04 - acc: 0.6902\n",
      "Epoch 560/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4593e-04 - acc: 0.6898\n",
      "Epoch 561/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4685e-04 - acc: 0.6909\n",
      "Epoch 562/1001\n",
      "91704/91704 [==============================] - 6s 60us/step - loss: 2.4822e-04 - acc: 0.6894\n",
      "Epoch 563/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4512e-04 - acc: 0.6920\n",
      "Epoch 564/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4722e-04 - acc: 0.6894\n",
      "Epoch 565/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4521e-04 - acc: 0.6890\n",
      "Epoch 566/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.4629e-04 - acc: 0.6909\n",
      "Epoch 567/1001\n",
      "91704/91704 [==============================] - 6s 60us/step - loss: 2.4581e-04 - acc: 0.6894\n",
      "Epoch 568/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4553e-04 - acc: 0.6903\n",
      "Epoch 569/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4672e-04 - acc: 0.6899\n",
      "Epoch 570/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4648e-04 - acc: 0.6896\n",
      "Epoch 571/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4564e-04 - acc: 0.6914\n",
      "Epoch 572/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4657e-04 - acc: 0.6887\n",
      "Epoch 573/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4683e-04 - acc: 0.6893\n",
      "Epoch 574/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4546e-04 - acc: 0.6894\n",
      "Epoch 575/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4669e-04 - acc: 0.6888\n",
      "Epoch 576/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4556e-04 - acc: 0.6912\n",
      "Epoch 577/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4629e-04 - acc: 0.6889\n",
      "Epoch 578/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4618e-04 - acc: 0.6893\n",
      "Epoch 579/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4485e-04 - acc: 0.6883\n",
      "Epoch 580/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.4595e-04 - acc: 0.6902\n",
      "Epoch 581/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4642e-04 - acc: 0.6903\n",
      "Epoch 582/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4618e-04 - acc: 0.6906: 1\n",
      "Epoch 583/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4618e-04 - acc: 0.6911\n",
      "Epoch 584/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4657e-04 - acc: 0.6906\n",
      "Epoch 585/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4596e-04 - acc: 0.6897\n",
      "Epoch 586/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4621e-04 - acc: 0.6919\n",
      "Epoch 587/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4541e-04 - acc: 0.6904\n",
      "Epoch 588/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4590e-04 - acc: 0.6898\n",
      "Epoch 589/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4526e-04 - acc: 0.6905\n",
      "Epoch 590/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.4661e-04 - acc: 0.6885\n",
      "Epoch 591/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4537e-04 - acc: 0.6893\n",
      "Epoch 592/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.4582e-04 - acc: 0.6900\n",
      "Epoch 593/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4538e-04 - acc: 0.6885\n",
      "Epoch 594/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4522e-04 - acc: 0.6902\n",
      "Epoch 595/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4608e-04 - acc: 0.6887\n",
      "Epoch 596/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4616e-04 - acc: 0.6878\n",
      "Epoch 597/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4636e-04 - acc: 0.6899\n",
      "Epoch 598/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4581e-04 - acc: 0.6905\n",
      "Epoch 599/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4492e-04 - acc: 0.6887\n",
      "Epoch 600/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4507e-04 - acc: 0.6902\n",
      "Epoch 601/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4563e-04 - acc: 0.6896\n",
      "Epoch 602/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4515e-04 - acc: 0.6901\n",
      "Epoch 603/1001\n",
      "91704/91704 [==============================] - 5s 56us/step - loss: 2.4539e-04 - acc: 0.6895\n",
      "Epoch 604/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4511e-04 - acc: 0.6902\n",
      "Epoch 605/1001\n",
      "91704/91704 [==============================] - 6s 61us/step - loss: 2.4469e-04 - acc: 0.6899\n",
      "Epoch 606/1001\n",
      "91704/91704 [==============================] - 5s 57us/step - loss: 2.4502e-04 - acc: 0.6893\n",
      "Epoch 607/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4512e-04 - acc: 0.6901\n",
      "Epoch 608/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4548e-04 - acc: 0.6897\n",
      "Epoch 609/1001\n",
      "91704/91704 [==============================] - 5s 59us/step - loss: 2.4534e-04 - acc: 0.6898\n",
      "Epoch 610/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4473e-04 - acc: 0.6894\n",
      "Epoch 611/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4482e-04 - acc: 0.6893\n",
      "Epoch 612/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4615e-04 - acc: 0.6904\n",
      "Epoch 613/1001\n",
      "91704/91704 [==============================] - 5s 53us/step - loss: 2.4455e-04 - acc: 0.6893\n",
      "Epoch 614/1001\n",
      "91704/91704 [==============================] - 5s 58us/step - loss: 2.4454e-04 - acc: 0.6897\n",
      "Epoch 615/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4444e-04 - acc: 0.6903\n",
      "Epoch 616/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4492e-04 - acc: 0.6890\n",
      "Epoch 617/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4545e-04 - acc: 0.6890\n",
      "Epoch 618/1001\n",
      "91704/91704 [==============================] - 8s 85us/step - loss: 2.4452e-04 - acc: 0.6888\n",
      "Epoch 619/1001\n",
      "91704/91704 [==============================] - 5s 55us/step - loss: 2.4542e-04 - acc: 0.6892\n",
      "Epoch 620/1001\n",
      "91704/91704 [==============================] - 5s 54us/step - loss: 2.4471e-04 - acc: 0.6886\n",
      "Epoch 621/1001\n",
      "91704/91704 [==============================] - 6s 62us/step - loss: 2.4451e-04 - acc: 0.6912: 1s - loss:\n",
      "Epoch 622/1001\n",
      "91704/91704 [==============================] - 10s 112us/step - loss: 2.4450e-04 - acc: 0.6892\n",
      "Epoch 623/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 2.4431e-04 - acc: 0.6888\n",
      "Epoch 624/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4484e-04 - acc: 0.6905\n",
      "Epoch 625/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 2.4511e-04 - acc: 0.6911\n",
      "Epoch 626/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 2.4441e-04 - acc: 0.6897\n",
      "Epoch 627/1001\n",
      "91704/91704 [==============================] - 7s 76us/step - loss: 2.4453e-04 - acc: 0.6897\n",
      "Epoch 628/1001\n",
      "91704/91704 [==============================] - 10s 112us/step - loss: 2.4365e-04 - acc: 0.6892\n",
      "Epoch 629/1001\n",
      "91704/91704 [==============================] - 8s 83us/step - loss: 2.4454e-04 - acc: 0.6900\n",
      "Epoch 630/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4499e-04 - acc: 0.6889\n",
      "Epoch 631/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4453e-04 - acc: 0.6893\n",
      "Epoch 632/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 2.4497e-04 - acc: 0.6877\n",
      "Epoch 633/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4421e-04 - acc: 0.6895\n",
      "Epoch 634/1001\n",
      "91704/91704 [==============================] - 7s 78us/step - loss: 2.4434e-04 - acc: 0.6920\n",
      "Epoch 635/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 2.4456e-04 - acc: 0.6909\n",
      "Epoch 636/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4372e-04 - acc: 0.6909\n",
      "Epoch 637/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4323e-04 - acc: 0.6894\n",
      "Epoch 638/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4542e-04 - acc: 0.6887\n",
      "Epoch 639/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4344e-04 - acc: 0.6892\n",
      "Epoch 640/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4388e-04 - acc: 0.6887\n",
      "Epoch 641/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4464e-04 - acc: 0.6887\n",
      "Epoch 642/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 2.4503e-04 - acc: 0.6893\n",
      "Epoch 643/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4453e-04 - acc: 0.6884\n",
      "Epoch 644/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4340e-04 - acc: 0.6893\n",
      "Epoch 645/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4383e-04 - acc: 0.6896\n",
      "Epoch 646/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 2.4420e-04 - acc: 0.6906\n",
      "Epoch 647/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4428e-04 - acc: 0.6884\n",
      "Epoch 648/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4416e-04 - acc: 0.6907\n",
      "Epoch 649/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4373e-04 - acc: 0.6902\n",
      "Epoch 650/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4421e-04 - acc: 0.6904\n",
      "Epoch 651/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 2.4350e-04 - acc: 0.6912\n",
      "Epoch 652/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4414e-04 - acc: 0.6898\n",
      "Epoch 653/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4400e-04 - acc: 0.6902\n",
      "Epoch 654/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4455e-04 - acc: 0.6896\n",
      "Epoch 655/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4394e-04 - acc: 0.6904\n",
      "Epoch 656/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4364e-04 - acc: 0.6890\n",
      "Epoch 657/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4305e-04 - acc: 0.6897\n",
      "Epoch 658/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4305e-04 - acc: 0.6891\n",
      "Epoch 659/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4426e-04 - acc: 0.6882\n",
      "Epoch 660/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4353e-04 - acc: 0.6908\n",
      "Epoch 661/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4361e-04 - acc: 0.6899\n",
      "Epoch 662/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4367e-04 - acc: 0.6893\n",
      "Epoch 663/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4309e-04 - acc: 0.6897\n",
      "Epoch 664/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4368e-04 - acc: 0.6893\n",
      "Epoch 665/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4443e-04 - acc: 0.6914\n",
      "Epoch 666/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 2.4353e-04 - acc: 0.6899\n",
      "Epoch 667/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4311e-04 - acc: 0.6897\n",
      "Epoch 668/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 2.4401e-04 - acc: 0.6897\n",
      "Epoch 669/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4388e-04 - acc: 0.6898\n",
      "Epoch 670/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4495e-04 - acc: 0.6911\n",
      "Epoch 671/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 2.4302e-04 - acc: 0.6890\n",
      "Epoch 672/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4334e-04 - acc: 0.6895\n",
      "Epoch 673/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 2.4320e-04 - acc: 0.6906\n",
      "Epoch 674/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4315e-04 - acc: 0.6900\n",
      "Epoch 675/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4413e-04 - acc: 0.6886\n",
      "Epoch 676/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4440e-04 - acc: 0.6896\n",
      "Epoch 677/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4287e-04 - acc: 0.6886\n",
      "Epoch 678/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4337e-04 - acc: 0.6893\n",
      "Epoch 679/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4288e-04 - acc: 0.6892\n",
      "Epoch 680/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4287e-04 - acc: 0.6904\n",
      "Epoch 681/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4382e-04 - acc: 0.6891\n",
      "Epoch 682/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4347e-04 - acc: 0.6899\n",
      "Epoch 683/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4344e-04 - acc: 0.6896\n",
      "Epoch 684/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4327e-04 - acc: 0.6888\n",
      "Epoch 685/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4322e-04 - acc: 0.6892\n",
      "Epoch 686/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4258e-04 - acc: 0.6902\n",
      "Epoch 687/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4245e-04 - acc: 0.6893\n",
      "Epoch 688/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4322e-04 - acc: 0.6895\n",
      "Epoch 689/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4318e-04 - acc: 0.6876\n",
      "Epoch 690/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4381e-04 - acc: 0.6902\n",
      "Epoch 691/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4272e-04 - acc: 0.6899\n",
      "Epoch 692/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4188e-04 - acc: 0.6891\n",
      "Epoch 693/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 2.4389e-04 - acc: 0.6883\n",
      "Epoch 694/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4210e-04 - acc: 0.6897\n",
      "Epoch 695/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4276e-04 - acc: 0.6902\n",
      "Epoch 696/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4316e-04 - acc: 0.6888\n",
      "Epoch 697/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4233e-04 - acc: 0.6889\n",
      "Epoch 698/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4280e-04 - acc: 0.6891\n",
      "Epoch 699/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4304e-04 - acc: 0.6886\n",
      "Epoch 700/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4337e-04 - acc: 0.6888\n",
      "Epoch 701/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4196e-04 - acc: 0.6897\n",
      "Epoch 702/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4289e-04 - acc: 0.6900\n",
      "Epoch 703/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4336e-04 - acc: 0.6890\n",
      "Epoch 704/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4216e-04 - acc: 0.6898: 1s - loss: 2.\n",
      "Epoch 705/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4293e-04 - acc: 0.6907\n",
      "Epoch 706/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.4251e-04 - acc: 0.6893\n",
      "Epoch 707/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4235e-04 - acc: 0.6895\n",
      "Epoch 708/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4335e-04 - acc: 0.6886\n",
      "Epoch 709/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4223e-04 - acc: 0.6906\n",
      "Epoch 710/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4260e-04 - acc: 0.6900\n",
      "Epoch 711/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 2.4317e-04 - acc: 0.6887\n",
      "Epoch 712/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4194e-04 - acc: 0.6904\n",
      "Epoch 713/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4197e-04 - acc: 0.6907\n",
      "Epoch 714/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4263e-04 - acc: 0.6904\n",
      "Epoch 715/1001\n",
      "91704/91704 [==============================] - 8s 91us/step - loss: 2.4269e-04 - acc: 0.6889\n",
      "Epoch 716/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4290e-04 - acc: 0.6889\n",
      "Epoch 717/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4288e-04 - acc: 0.6895\n",
      "Epoch 718/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4334e-04 - acc: 0.6902\n",
      "Epoch 719/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4164e-04 - acc: 0.6908\n",
      "Epoch 720/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4318e-04 - acc: 0.6896\n",
      "Epoch 721/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4239e-04 - acc: 0.6903\n",
      "Epoch 722/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4307e-04 - acc: 0.6910\n",
      "Epoch 723/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4231e-04 - acc: 0.6893\n",
      "Epoch 724/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.4353e-04 - acc: 0.6891\n",
      "Epoch 725/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4143e-04 - acc: 0.6885\n",
      "Epoch 726/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4241e-04 - acc: 0.6893\n",
      "Epoch 727/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4185e-04 - acc: 0.6900\n",
      "Epoch 728/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4195e-04 - acc: 0.6884\n",
      "Epoch 729/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4219e-04 - acc: 0.6886\n",
      "Epoch 730/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4193e-04 - acc: 0.6893\n",
      "Epoch 731/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4187e-04 - acc: 0.6898\n",
      "Epoch 732/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4283e-04 - acc: 0.6900\n",
      "Epoch 733/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4218e-04 - acc: 0.6901\n",
      "Epoch 734/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 2.4130e-04 - acc: 0.6908\n",
      "Epoch 735/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4205e-04 - acc: 0.6893\n",
      "Epoch 736/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4197e-04 - acc: 0.6904\n",
      "Epoch 737/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4217e-04 - acc: 0.6912\n",
      "Epoch 738/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4206e-04 - acc: 0.6901\n",
      "Epoch 739/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4172e-04 - acc: 0.6886\n",
      "Epoch 740/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4204e-04 - acc: 0.6899\n",
      "Epoch 741/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4221e-04 - acc: 0.6893\n",
      "Epoch 742/1001\n",
      "91704/91704 [==============================] - 8s 83us/step - loss: 2.4170e-04 - acc: 0.6902\n",
      "Epoch 743/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4237e-04 - acc: 0.6897\n",
      "Epoch 744/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 2.4186e-04 - acc: 0.6891\n",
      "Epoch 745/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4182e-04 - acc: 0.6889\n",
      "Epoch 746/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4136e-04 - acc: 0.6882\n",
      "Epoch 747/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.4167e-04 - acc: 0.6889\n",
      "Epoch 748/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4175e-04 - acc: 0.6911\n",
      "Epoch 749/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4234e-04 - acc: 0.6884\n",
      "Epoch 750/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4152e-04 - acc: 0.6889\n",
      "Epoch 751/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4223e-04 - acc: 0.6899\n",
      "Epoch 752/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 2.4322e-04 - acc: 0.6884\n",
      "Epoch 753/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4108e-04 - acc: 0.6904\n",
      "Epoch 754/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4134e-04 - acc: 0.6889\n",
      "Epoch 755/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4105e-04 - acc: 0.6889\n",
      "Epoch 756/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4152e-04 - acc: 0.6908\n",
      "Epoch 757/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4128e-04 - acc: 0.6906\n",
      "Epoch 758/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4205e-04 - acc: 0.6901\n",
      "Epoch 759/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4138e-04 - acc: 0.6884\n",
      "Epoch 760/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4084e-04 - acc: 0.6894\n",
      "Epoch 761/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4170e-04 - acc: 0.6890\n",
      "Epoch 762/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4124e-04 - acc: 0.6882\n",
      "Epoch 763/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4164e-04 - acc: 0.6878\n",
      "Epoch 764/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4135e-04 - acc: 0.6878\n",
      "Epoch 765/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 2.4110e-04 - acc: 0.6901\n",
      "Epoch 766/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 2.4100e-04 - acc: 0.6908\n",
      "Epoch 767/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4151e-04 - acc: 0.6890\n",
      "Epoch 768/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4217e-04 - acc: 0.6905\n",
      "Epoch 769/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4147e-04 - acc: 0.6896\n",
      "Epoch 770/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4167e-04 - acc: 0.6899\n",
      "Epoch 771/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4112e-04 - acc: 0.6896\n",
      "Epoch 772/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4063e-04 - acc: 0.6892\n",
      "Epoch 773/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4178e-04 - acc: 0.6892\n",
      "Epoch 774/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4064e-04 - acc: 0.6892\n",
      "Epoch 775/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4161e-04 - acc: 0.6885\n",
      "Epoch 776/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4086e-04 - acc: 0.6895\n",
      "Epoch 777/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4090e-04 - acc: 0.6916\n",
      "Epoch 778/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4117e-04 - acc: 0.6876\n",
      "Epoch 779/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4168e-04 - acc: 0.6876\n",
      "Epoch 780/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4111e-04 - acc: 0.6902\n",
      "Epoch 781/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4153e-04 - acc: 0.6895\n",
      "Epoch 782/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4163e-04 - acc: 0.6902\n",
      "Epoch 783/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4059e-04 - acc: 0.6887\n",
      "Epoch 784/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4107e-04 - acc: 0.6893\n",
      "Epoch 785/1001\n",
      "91704/91704 [==============================] - 7s 80us/step - loss: 2.4090e-04 - acc: 0.6903\n",
      "Epoch 786/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 2.4330e-04 - acc: 0.6881\n",
      "Epoch 787/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4009e-04 - acc: 0.6901\n",
      "Epoch 788/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4036e-04 - acc: 0.6874\n",
      "Epoch 789/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 2.4077e-04 - acc: 0.6907\n",
      "Epoch 790/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 2.4081e-04 - acc: 0.6903\n",
      "Epoch 791/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4060e-04 - acc: 0.6900\n",
      "Epoch 792/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4055e-04 - acc: 0.6896\n",
      "Epoch 793/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4123e-04 - acc: 0.6903\n",
      "Epoch 794/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4054e-04 - acc: 0.6897\n",
      "Epoch 795/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4024e-04 - acc: 0.6897\n",
      "Epoch 796/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4065e-04 - acc: 0.6898\n",
      "Epoch 797/1001\n",
      "91704/91704 [==============================] - 10s 111us/step - loss: 2.4065e-04 - acc: 0.6890\n",
      "Epoch 798/1001\n",
      "91704/91704 [==============================] - 8s 92us/step - loss: 2.4055e-04 - acc: 0.6904\n",
      "Epoch 799/1001\n",
      "91704/91704 [==============================] - 7s 82us/step - loss: 2.4043e-04 - acc: 0.6909\n",
      "Epoch 800/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4082e-04 - acc: 0.6892\n",
      "Epoch 801/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4060e-04 - acc: 0.6908\n",
      "Epoch 802/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4072e-04 - acc: 0.6922\n",
      "Epoch 803/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 2.4106e-04 - acc: 0.6895\n",
      "Epoch 804/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4030e-04 - acc: 0.6886\n",
      "Epoch 805/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4076e-04 - acc: 0.6893\n",
      "Epoch 806/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4083e-04 - acc: 0.6872\n",
      "Epoch 807/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4045e-04 - acc: 0.6896\n",
      "Epoch 808/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4095e-04 - acc: 0.6906\n",
      "Epoch 809/1001\n",
      "91704/91704 [==============================] - 7s 74us/step - loss: 2.4044e-04 - acc: 0.6899\n",
      "Epoch 810/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4063e-04 - acc: 0.6904\n",
      "Epoch 811/1001\n",
      "91704/91704 [==============================] - 8s 88us/step - loss: 2.4016e-04 - acc: 0.6887\n",
      "Epoch 812/1001\n",
      "91704/91704 [==============================] - 8s 83us/step - loss: 2.4044e-04 - acc: 0.6886\n",
      "Epoch 813/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4125e-04 - acc: 0.6893\n",
      "Epoch 814/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3980e-04 - acc: 0.6900\n",
      "Epoch 815/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3965e-04 - acc: 0.6904\n",
      "Epoch 816/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4040e-04 - acc: 0.6904\n",
      "Epoch 817/1001\n",
      "91704/91704 [==============================] - 7s 80us/step - loss: 2.4063e-04 - acc: 0.6900\n",
      "Epoch 818/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 2.4020e-04 - acc: 0.6919\n",
      "Epoch 819/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4012e-04 - acc: 0.6896\n",
      "Epoch 820/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 2.3963e-04 - acc: 0.6891\n",
      "Epoch 821/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4001e-04 - acc: 0.6891\n",
      "Epoch 822/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 2.4010e-04 - acc: 0.6904\n",
      "Epoch 823/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 2.3972e-04 - acc: 0.6898\n",
      "Epoch 824/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3973e-04 - acc: 0.6890\n",
      "Epoch 825/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4033e-04 - acc: 0.6893\n",
      "Epoch 826/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4155e-04 - acc: 0.6894\n",
      "Epoch 827/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.3977e-04 - acc: 0.6882\n",
      "Epoch 828/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 2.3977e-04 - acc: 0.6887\n",
      "Epoch 829/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4024e-04 - acc: 0.6891\n",
      "Epoch 830/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4007e-04 - acc: 0.6896\n",
      "Epoch 831/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4136e-04 - acc: 0.6909\n",
      "Epoch 832/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4017e-04 - acc: 0.6889\n",
      "Epoch 833/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3999e-04 - acc: 0.6906\n",
      "Epoch 834/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3907e-04 - acc: 0.6907\n",
      "Epoch 835/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 2.4097e-04 - acc: 0.6878\n",
      "Epoch 836/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3975e-04 - acc: 0.6895\n",
      "Epoch 837/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3957e-04 - acc: 0.6899\n",
      "Epoch 838/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4006e-04 - acc: 0.6905\n",
      "Epoch 839/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4027e-04 - acc: 0.6892\n",
      "Epoch 840/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4123e-04 - acc: 0.6892\n",
      "Epoch 841/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 2.3936e-04 - acc: 0.6886\n",
      "Epoch 842/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.4000e-04 - acc: 0.6886\n",
      "Epoch 843/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3950e-04 - acc: 0.6890\n",
      "Epoch 844/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.3991e-04 - acc: 0.6891\n",
      "Epoch 845/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3971e-04 - acc: 0.6905\n",
      "Epoch 846/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3839e-04 - acc: 0.6892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 847/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 2.4056e-04 - acc: 0.6881\n",
      "Epoch 848/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3950e-04 - acc: 0.6883\n",
      "Epoch 849/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3896e-04 - acc: 0.6899\n",
      "Epoch 850/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4026e-04 - acc: 0.6900\n",
      "Epoch 851/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3974e-04 - acc: 0.6906\n",
      "Epoch 852/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4049e-04 - acc: 0.6909\n",
      "Epoch 853/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3836e-04 - acc: 0.6897\n",
      "Epoch 854/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3947e-04 - acc: 0.6894\n",
      "Epoch 855/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3991e-04 - acc: 0.6886\n",
      "Epoch 856/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.4010e-04 - acc: 0.6898\n",
      "Epoch 857/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4051e-04 - acc: 0.6894\n",
      "Epoch 858/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4014e-04 - acc: 0.6907\n",
      "Epoch 859/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3905e-04 - acc: 0.6904\n",
      "Epoch 860/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3942e-04 - acc: 0.6892: 1s - loss: 2.\n",
      "Epoch 861/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 2.3950e-04 - acc: 0.6889\n",
      "Epoch 862/1001\n",
      "91704/91704 [==============================] - 6s 65us/step - loss: 2.3935e-04 - acc: 0.6880\n",
      "Epoch 863/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3856e-04 - acc: 0.6914\n",
      "Epoch 864/1001\n",
      "91704/91704 [==============================] - 7s 77us/step - loss: 2.4039e-04 - acc: 0.6900\n",
      "Epoch 865/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3900e-04 - acc: 0.6907\n",
      "Epoch 866/1001\n",
      "91704/91704 [==============================] - 8s 84us/step - loss: 2.3937e-04 - acc: 0.6895\n",
      "Epoch 867/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 2.3951e-04 - acc: 0.6902\n",
      "Epoch 868/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.3903e-04 - acc: 0.6904\n",
      "Epoch 869/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.4031e-04 - acc: 0.6902\n",
      "Epoch 870/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3955e-04 - acc: 0.6900\n",
      "Epoch 871/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4005e-04 - acc: 0.6900\n",
      "Epoch 872/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3929e-04 - acc: 0.6913\n",
      "Epoch 873/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3890e-04 - acc: 0.6891\n",
      "Epoch 874/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3978e-04 - acc: 0.6896: 1s - loss: 2\n",
      "Epoch 875/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.4020e-04 - acc: 0.6906\n",
      "Epoch 876/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3878e-04 - acc: 0.6899\n",
      "Epoch 877/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3896e-04 - acc: 0.6901\n",
      "Epoch 878/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3934e-04 - acc: 0.6884\n",
      "Epoch 879/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3889e-04 - acc: 0.6908\n",
      "Epoch 880/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 2.3891e-04 - acc: 0.6919\n",
      "Epoch 881/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3964e-04 - acc: 0.6891\n",
      "Epoch 882/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3895e-04 - acc: 0.6904\n",
      "Epoch 883/1001\n",
      "91704/91704 [==============================] - 7s 75us/step - loss: 2.3918e-04 - acc: 0.6887\n",
      "Epoch 884/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3880e-04 - acc: 0.6879\n",
      "Epoch 885/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.4004e-04 - acc: 0.6895\n",
      "Epoch 886/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3929e-04 - acc: 0.6895\n",
      "Epoch 887/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3880e-04 - acc: 0.6918\n",
      "Epoch 888/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3826e-04 - acc: 0.6887\n",
      "Epoch 889/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3904e-04 - acc: 0.6911\n",
      "Epoch 890/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3892e-04 - acc: 0.6910\n",
      "Epoch 891/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3883e-04 - acc: 0.6886\n",
      "Epoch 892/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3886e-04 - acc: 0.6910\n",
      "Epoch 893/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3902e-04 - acc: 0.6894\n",
      "Epoch 894/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 2.3891e-04 - acc: 0.6913\n",
      "Epoch 895/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 2.3871e-04 - acc: 0.6907\n",
      "Epoch 896/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3877e-04 - acc: 0.6905\n",
      "Epoch 897/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3998e-04 - acc: 0.6893\n",
      "Epoch 898/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.3901e-04 - acc: 0.6899\n",
      "Epoch 899/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3898e-04 - acc: 0.6904\n",
      "Epoch 900/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3856e-04 - acc: 0.6902\n",
      "Epoch 901/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 2.3867e-04 - acc: 0.6900\n",
      "Epoch 902/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3969e-04 - acc: 0.6893\n",
      "Epoch 903/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3967e-04 - acc: 0.6898\n",
      "Epoch 904/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3806e-04 - acc: 0.6887\n",
      "Epoch 905/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3940e-04 - acc: 0.6900\n",
      "Epoch 906/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3899e-04 - acc: 0.6901\n",
      "Epoch 907/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3805e-04 - acc: 0.6884\n",
      "Epoch 908/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3903e-04 - acc: 0.6890\n",
      "Epoch 909/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3888e-04 - acc: 0.6896\n",
      "Epoch 910/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3836e-04 - acc: 0.6900\n",
      "Epoch 911/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3828e-04 - acc: 0.6887\n",
      "Epoch 912/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3915e-04 - acc: 0.6882\n",
      "Epoch 913/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3970e-04 - acc: 0.6906\n",
      "Epoch 914/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3824e-04 - acc: 0.6909\n",
      "Epoch 915/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3929e-04 - acc: 0.6898\n",
      "Epoch 916/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3849e-04 - acc: 0.6911\n",
      "Epoch 917/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3936e-04 - acc: 0.6908\n",
      "Epoch 918/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3847e-04 - acc: 0.6915\n",
      "Epoch 919/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3813e-04 - acc: 0.6897\n",
      "Epoch 920/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3922e-04 - acc: 0.6906\n",
      "Epoch 921/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3846e-04 - acc: 0.6904\n",
      "Epoch 922/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3901e-04 - acc: 0.6896\n",
      "Epoch 923/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3826e-04 - acc: 0.6890\n",
      "Epoch 924/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3821e-04 - acc: 0.6898\n",
      "Epoch 925/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3864e-04 - acc: 0.6896\n",
      "Epoch 926/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3827e-04 - acc: 0.6909\n",
      "Epoch 927/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3837e-04 - acc: 0.6890\n",
      "Epoch 928/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3866e-04 - acc: 0.6901\n",
      "Epoch 929/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3877e-04 - acc: 0.6911\n",
      "Epoch 930/1001\n",
      "91704/91704 [==============================] - 9s 93us/step - loss: 2.3826e-04 - acc: 0.6900\n",
      "Epoch 931/1001\n",
      "91704/91704 [==============================] - 8s 90us/step - loss: 2.4010e-04 - acc: 0.6896\n",
      "Epoch 932/1001\n",
      "91704/91704 [==============================] - 8s 89us/step - loss: 2.3800e-04 - acc: 0.6879\n",
      "Epoch 933/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3764e-04 - acc: 0.6895\n",
      "Epoch 934/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3744e-04 - acc: 0.6911\n",
      "Epoch 935/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 2.3826e-04 - acc: 0.6896\n",
      "Epoch 936/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3846e-04 - acc: 0.6907\n",
      "Epoch 937/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.3854e-04 - acc: 0.6892\n",
      "Epoch 938/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 2.3848e-04 - acc: 0.6903\n",
      "Epoch 939/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3816e-04 - acc: 0.6907\n",
      "Epoch 940/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3808e-04 - acc: 0.6898\n",
      "Epoch 941/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.3834e-04 - acc: 0.6909\n",
      "Epoch 942/1001\n",
      "91704/91704 [==============================] - 9s 96us/step - loss: 2.3842e-04 - acc: 0.6900\n",
      "Epoch 943/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3690e-04 - acc: 0.6913\n",
      "Epoch 944/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.3825e-04 - acc: 0.6917\n",
      "Epoch 945/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3750e-04 - acc: 0.6905\n",
      "Epoch 946/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3864e-04 - acc: 0.6905\n",
      "Epoch 947/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3902e-04 - acc: 0.6899\n",
      "Epoch 948/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3847e-04 - acc: 0.6905\n",
      "Epoch 949/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3740e-04 - acc: 0.6900\n",
      "Epoch 950/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3940e-04 - acc: 0.6913\n",
      "Epoch 951/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3795e-04 - acc: 0.6903\n",
      "Epoch 952/1001\n",
      "91704/91704 [==============================] - 6s 71us/step - loss: 2.3740e-04 - acc: 0.6906\n",
      "Epoch 953/1001\n",
      "91704/91704 [==============================] - 7s 71us/step - loss: 2.3765e-04 - acc: 0.6915\n",
      "Epoch 954/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 2.3776e-04 - acc: 0.6908\n",
      "Epoch 955/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3782e-04 - acc: 0.6914\n",
      "Epoch 956/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3762e-04 - acc: 0.6907\n",
      "Epoch 957/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3845e-04 - acc: 0.6897\n",
      "Epoch 958/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3879e-04 - acc: 0.6924\n",
      "Epoch 959/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3739e-04 - acc: 0.6907\n",
      "Epoch 960/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3907e-04 - acc: 0.6894\n",
      "Epoch 961/1001\n",
      "91704/91704 [==============================] - 7s 72us/step - loss: 2.3765e-04 - acc: 0.6910\n",
      "Epoch 962/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3928e-04 - acc: 0.6913\n",
      "Epoch 963/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3783e-04 - acc: 0.6903\n",
      "Epoch 964/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3762e-04 - acc: 0.6898\n",
      "Epoch 965/1001\n",
      "91704/91704 [==============================] - 7s 79us/step - loss: 2.3915e-04 - acc: 0.6902\n",
      "Epoch 966/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3716e-04 - acc: 0.6905: 0s - loss: 2.3641e-\n",
      "Epoch 967/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3901e-04 - acc: 0.6897\n",
      "Epoch 968/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3745e-04 - acc: 0.6889\n",
      "Epoch 969/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3737e-04 - acc: 0.6911\n",
      "Epoch 970/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3781e-04 - acc: 0.6905\n",
      "Epoch 971/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3701e-04 - acc: 0.6897\n",
      "Epoch 972/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3823e-04 - acc: 0.6892\n",
      "Epoch 973/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.3809e-04 - acc: 0.6906\n",
      "Epoch 974/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3737e-04 - acc: 0.6908: 1s - loss: 2\n",
      "Epoch 975/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3727e-04 - acc: 0.6898\n",
      "Epoch 976/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3764e-04 - acc: 0.6907\n",
      "Epoch 977/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3714e-04 - acc: 0.6909\n",
      "Epoch 978/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3713e-04 - acc: 0.6900\n",
      "Epoch 979/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3854e-04 - acc: 0.6890\n",
      "Epoch 980/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3729e-04 - acc: 0.6905\n",
      "Epoch 981/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3715e-04 - acc: 0.6907\n",
      "Epoch 982/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.3794e-04 - acc: 0.6903\n",
      "Epoch 983/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3695e-04 - acc: 0.6919\n",
      "Epoch 984/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3833e-04 - acc: 0.6863\n",
      "Epoch 985/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3714e-04 - acc: 0.6902\n",
      "Epoch 986/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3688e-04 - acc: 0.6892\n",
      "Epoch 987/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3820e-04 - acc: 0.6906\n",
      "Epoch 988/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3782e-04 - acc: 0.6900\n",
      "Epoch 989/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3803e-04 - acc: 0.6913\n",
      "Epoch 990/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3988e-04 - acc: 0.6895\n",
      "Epoch 991/1001\n",
      "91704/91704 [==============================] - 6s 68us/step - loss: 2.3766e-04 - acc: 0.6893\n",
      "Epoch 992/1001\n",
      "91704/91704 [==============================] - 7s 73us/step - loss: 2.3753e-04 - acc: 0.6912\n",
      "Epoch 993/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3664e-04 - acc: 0.6896\n",
      "Epoch 994/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3779e-04 - acc: 0.6900\n",
      "Epoch 995/1001\n",
      "91704/91704 [==============================] - 6s 70us/step - loss: 2.3738e-04 - acc: 0.6913\n",
      "Epoch 996/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3730e-04 - acc: 0.6897\n",
      "Epoch 997/1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 9s 94us/step - loss: 2.3927e-04 - acc: 0.6892\n",
      "Epoch 998/1001\n",
      "91704/91704 [==============================] - 6s 69us/step - loss: 2.3893e-04 - acc: 0.6921\n",
      "Epoch 999/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3632e-04 - acc: 0.6914\n",
      "Epoch 1000/1001\n",
      "91704/91704 [==============================] - 6s 67us/step - loss: 2.3630e-04 - acc: 0.6904\n",
      "Epoch 1001/1001\n",
      "91704/91704 [==============================] - 6s 66us/step - loss: 2.3693e-04 - acc: 0.6919\n",
      "../linkPrediction/dataframes/obesity\\obesity-model-cm-1000_2008-2015.pkl\n",
      "../linkPrediction/dataframes/obesity\\obesity-X_test-cm_2008-2015.pkl\n",
      "../linkPrediction/dataframes/obesity\\obesity-y_test-cm_2008-2015.pkl\n"
     ]
    }
   ],
   "source": [
    "feature_names = {\n",
    "'author':[0,6,22,9,10,11,12,25,26,27,28],\n",
    "'article': [1,7,23,13,14,15,16,29,30,31,32],\n",
    "'degree': [2,8,24,17,18,19,20,33,34,35,36],\n",
    "'citation': [3,21,37],\n",
    "'pref': [4,8,24],\n",
    "'cm': [5,8,24]\n",
    "}\n",
    "names1 = set(['author','article','degree'])\n",
    "names2 = set(['citation','pref','cm'])\n",
    "X = ut.load_data(datapath, domain[select_domain], \"X-features\", times)\n",
    "y = ut.load_data(datapath, domain[select_domain], \"y-features\", times)\n",
    "for name,feature in feature_names.items():\n",
    "    if name in names2:\n",
    "        param = [0.3,64,1001,name,times]\n",
    "        print(name,\"---------------------------------------------------------------------------------\")\n",
    "        X_test, y_test = lstm_forecast(X[:,:,feature],param)\n",
    "        ut.save_data(X_test, datapath, domain[select_domain], \"X_test-\"+name, times)\n",
    "        ut.save_data(y_test, datapath, domain[select_domain], \"y_test-\"+name, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 403 403 12494 12494 0 1093 1093\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "12494 12494\n",
      "../linkPrediction/dataframes/apnea\n",
      "article (12494, 7, 11) --------------------------------------------------------------------\n",
      "(12494, 11) (12494,)\n",
      "[12494, 11, 1]\n",
      "(8745, 11) (8745,)\n",
      "Train on 8745 samples, validate on 3749 samples\n",
      "Epoch 1/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 1.9983 - acc: 0.6758 - val_loss: 0.9149 - val_acc: 0.8672\n",
      "Epoch 2/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.8194 - acc: 0.8799 - val_loss: 0.6187 - val_acc: 0.8717\n",
      "Epoch 3/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.6407 - acc: 0.8701 - val_loss: 0.5270 - val_acc: 0.8866\n",
      "Epoch 4/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.5319 - acc: 0.8829 - val_loss: 0.5310 - val_acc: 0.8866\n",
      "Epoch 5/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.5727 - acc: 0.8751 - val_loss: 0.5259 - val_acc: 0.8909\n",
      "Epoch 6/500\n",
      "8745/8745 [==============================] - 0s 22us/step - loss: 0.4881 - acc: 0.8776 - val_loss: 0.4755 - val_acc: 0.8866\n",
      "Epoch 7/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.4659 - acc: 0.8868 - val_loss: 0.5215 - val_acc: 0.8749\n",
      "Epoch 8/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.4712 - acc: 0.8855 - val_loss: 0.4571 - val_acc: 0.8818\n",
      "Epoch 9/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.4191 - acc: 0.8878 - val_loss: 0.4244 - val_acc: 0.8962\n",
      "Epoch 10/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.4381 - acc: 0.8874 - val_loss: 0.4393 - val_acc: 0.8840\n",
      "Epoch 11/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.4324 - acc: 0.8842 - val_loss: 0.4279 - val_acc: 0.8970\n",
      "Epoch 12/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.4309 - acc: 0.8869 - val_loss: 0.4516 - val_acc: 0.8938\n",
      "Epoch 13/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.4518 - acc: 0.8843 - val_loss: 0.4743 - val_acc: 0.8792\n",
      "Epoch 14/500\n",
      "8745/8745 [==============================] - 0s 9us/step - loss: 0.4320 - acc: 0.8848 - val_loss: 0.4174 - val_acc: 0.8968\n",
      "Epoch 15/500\n",
      "8745/8745 [==============================] - 0s 9us/step - loss: 0.4015 - acc: 0.8901 - val_loss: 0.3977 - val_acc: 0.8938\n",
      "Epoch 16/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.4086 - acc: 0.8919 - val_loss: 0.4022 - val_acc: 0.8944\n",
      "Epoch 17/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.4387 - acc: 0.8889 - val_loss: 0.3833 - val_acc: 0.8917\n",
      "Epoch 18/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.3843 - acc: 0.8911 - val_loss: 0.4035 - val_acc: 0.8957\n",
      "Epoch 19/500\n",
      "8745/8745 [==============================] - 0s 22us/step - loss: 0.3683 - acc: 0.8927 - val_loss: 0.4949 - val_acc: 0.8733\n",
      "Epoch 20/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.4251 - acc: 0.8846 - val_loss: 0.4934 - val_acc: 0.8869\n",
      "Epoch 21/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.4027 - acc: 0.8850 - val_loss: 0.3547 - val_acc: 0.8962\n",
      "Epoch 22/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.3810 - acc: 0.8917 - val_loss: 0.3652 - val_acc: 0.8952\n",
      "Epoch 23/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3653 - acc: 0.8929 - val_loss: 0.3579 - val_acc: 0.8952\n",
      "Epoch 24/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.3613 - acc: 0.8950 - val_loss: 0.3838 - val_acc: 0.8930\n",
      "Epoch 25/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3626 - acc: 0.8932 - val_loss: 0.3806 - val_acc: 0.9000\n",
      "Epoch 26/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.3840 - acc: 0.8872 - val_loss: 0.3857 - val_acc: 0.8898\n",
      "Epoch 27/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.3600 - acc: 0.8930 - val_loss: 0.3657 - val_acc: 0.8962\n",
      "Epoch 28/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.3539 - acc: 0.8925 - val_loss: 0.3778 - val_acc: 0.8880\n",
      "Epoch 29/500\n",
      "8745/8745 [==============================] - 0s 21us/step - loss: 0.3453 - acc: 0.8937 - val_loss: 0.3826 - val_acc: 0.8992\n",
      "Epoch 30/500\n",
      "8745/8745 [==============================] - 0s 24us/step - loss: 0.3639 - acc: 0.8927 - val_loss: 0.3429 - val_acc: 0.8992\n",
      "Epoch 31/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.3509 - acc: 0.8930 - val_loss: 0.3648 - val_acc: 0.8906\n",
      "Epoch 32/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.3935 - acc: 0.8906 - val_loss: 0.3657 - val_acc: 0.8986\n",
      "Epoch 33/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.3543 - acc: 0.8932 - val_loss: 0.3482 - val_acc: 0.8936\n",
      "Epoch 34/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.3342 - acc: 0.8946 - val_loss: 0.3545 - val_acc: 0.8989\n",
      "Epoch 35/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.3270 - acc: 0.8947 - val_loss: 0.3328 - val_acc: 0.8954\n",
      "Epoch 36/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3292 - acc: 0.8939 - val_loss: 0.3631 - val_acc: 0.8976\n",
      "Epoch 37/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.3374 - acc: 0.8932 - val_loss: 0.3253 - val_acc: 0.8973\n",
      "Epoch 38/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.3249 - acc: 0.8951 - val_loss: 0.3526 - val_acc: 0.8973\n",
      "Epoch 39/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.3381 - acc: 0.8933 - val_loss: 0.3838 - val_acc: 0.8888\n",
      "Epoch 40/500\n",
      "8745/8745 [==============================] - 0s 22us/step - loss: 0.3337 - acc: 0.8941 - val_loss: 0.3569 - val_acc: 0.8941\n",
      "Epoch 41/500\n",
      "8745/8745 [==============================] - 0s 23us/step - loss: 0.3333 - acc: 0.8914 - val_loss: 0.3593 - val_acc: 0.8914\n",
      "Epoch 42/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.3308 - acc: 0.8937 - val_loss: 0.3119 - val_acc: 0.8992\n",
      "Epoch 43/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.3250 - acc: 0.8924 - val_loss: 0.3217 - val_acc: 0.8994\n",
      "Epoch 44/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.3239 - acc: 0.8935 - val_loss: 0.3222 - val_acc: 0.8952\n",
      "Epoch 45/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.3132 - acc: 0.8967 - val_loss: 0.3299 - val_acc: 0.9000\n",
      "Epoch 46/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.3315 - acc: 0.8954 - val_loss: 0.3147 - val_acc: 0.8968\n",
      "Epoch 47/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.3254 - acc: 0.8934 - val_loss: 0.3334 - val_acc: 0.8952\n",
      "Epoch 48/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3129 - acc: 0.8972 - val_loss: 0.3186 - val_acc: 0.8973\n",
      "Epoch 49/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.3207 - acc: 0.8959 - val_loss: 0.3372 - val_acc: 0.8957\n",
      "Epoch 50/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3182 - acc: 0.8941 - val_loss: 0.3286 - val_acc: 0.8973\n",
      "Epoch 51/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.3173 - acc: 0.8955 - val_loss: 0.3395 - val_acc: 0.9016\n",
      "Epoch 52/500\n",
      "8745/8745 [==============================] - 0s 22us/step - loss: 0.3351 - acc: 0.8940 - val_loss: 0.3100 - val_acc: 0.8989\n",
      "Epoch 53/500\n",
      "8745/8745 [==============================] - 0s 24us/step - loss: 0.3159 - acc: 0.8950 - val_loss: 0.3374 - val_acc: 0.8914\n",
      "Epoch 54/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.3145 - acc: 0.8947 - val_loss: 0.3232 - val_acc: 0.9008\n",
      "Epoch 55/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.3216 - acc: 0.8955 - val_loss: 0.3608 - val_acc: 0.8896\n",
      "Epoch 56/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.3277 - acc: 0.8937 - val_loss: 0.3278 - val_acc: 0.9000\n",
      "Epoch 57/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.3242 - acc: 0.8946 - val_loss: 0.3317 - val_acc: 0.9000\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.3097 - acc: 0.8957 - val_loss: 0.3273 - val_acc: 0.8997\n",
      "Epoch 59/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3104 - acc: 0.8959 - val_loss: 0.3171 - val_acc: 0.9010\n",
      "Epoch 60/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3212 - acc: 0.8949 - val_loss: 0.3624 - val_acc: 0.9021\n",
      "Epoch 61/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3151 - acc: 0.8974 - val_loss: 0.3225 - val_acc: 0.9008\n",
      "Epoch 62/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3140 - acc: 0.8942 - val_loss: 0.3259 - val_acc: 0.8962\n",
      "Epoch 63/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.3132 - acc: 0.8950 - val_loss: 0.3158 - val_acc: 0.8994\n",
      "Epoch 64/500\n",
      "8745/8745 [==============================] - 0s 23us/step - loss: 0.3007 - acc: 0.8962 - val_loss: 0.3152 - val_acc: 0.9002\n",
      "Epoch 65/500\n",
      "8745/8745 [==============================] - 0s 24us/step - loss: 0.3128 - acc: 0.8939 - val_loss: 0.3268 - val_acc: 0.9013\n",
      "Epoch 66/500\n",
      "8745/8745 [==============================] - 0s 22us/step - loss: 0.3247 - acc: 0.8945 - val_loss: 0.3173 - val_acc: 0.9002\n",
      "Epoch 67/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.3060 - acc: 0.8958 - val_loss: 0.3146 - val_acc: 0.9008\n",
      "Epoch 68/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.3055 - acc: 0.8963 - val_loss: 0.3020 - val_acc: 0.9008\n",
      "Epoch 69/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.3038 - acc: 0.8959 - val_loss: 0.3153 - val_acc: 0.8968\n",
      "Epoch 70/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3059 - acc: 0.8961 - val_loss: 0.3135 - val_acc: 0.9018\n",
      "Epoch 71/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3070 - acc: 0.8966 - val_loss: 0.3089 - val_acc: 0.8989\n",
      "Epoch 72/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.3072 - acc: 0.8969 - val_loss: 0.3118 - val_acc: 0.9005\n",
      "Epoch 73/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.3028 - acc: 0.8956 - val_loss: 0.3175 - val_acc: 0.8973\n",
      "Epoch 74/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2966 - acc: 0.8982 - val_loss: 0.3119 - val_acc: 0.9005\n",
      "Epoch 75/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.3066 - acc: 0.8963 - val_loss: 0.3323 - val_acc: 0.8997\n",
      "Epoch 76/500\n",
      "8745/8745 [==============================] - 0s 21us/step - loss: 0.3106 - acc: 0.8945 - val_loss: 0.3190 - val_acc: 0.8965\n",
      "Epoch 77/500\n",
      "8745/8745 [==============================] - 0s 25us/step - loss: 0.3140 - acc: 0.8942 - val_loss: 0.3014 - val_acc: 0.8992\n",
      "Epoch 78/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.3033 - acc: 0.8948 - val_loss: 0.3076 - val_acc: 0.8989\n",
      "Epoch 79/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2985 - acc: 0.8973 - val_loss: 0.3175 - val_acc: 0.9018\n",
      "Epoch 80/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.3112 - acc: 0.8967 - val_loss: 0.3215 - val_acc: 0.9002\n",
      "Epoch 81/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.3006 - acc: 0.8961 - val_loss: 0.3126 - val_acc: 0.8986\n",
      "Epoch 82/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.3103 - acc: 0.8954 - val_loss: 0.3105 - val_acc: 0.8984\n",
      "Epoch 83/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3086 - acc: 0.8950 - val_loss: 0.3095 - val_acc: 0.9005\n",
      "Epoch 84/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.3078 - acc: 0.8957 - val_loss: 0.3244 - val_acc: 0.9002\n",
      "Epoch 85/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.3053 - acc: 0.8964 - val_loss: 0.3062 - val_acc: 0.8994\n",
      "Epoch 86/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.3043 - acc: 0.8957 - val_loss: 0.3126 - val_acc: 0.8986\n",
      "Epoch 87/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.3076 - acc: 0.8963 - val_loss: 0.3097 - val_acc: 0.9013\n",
      "Epoch 88/500\n",
      "8745/8745 [==============================] - 0s 23us/step - loss: 0.3026 - acc: 0.8959 - val_loss: 0.3042 - val_acc: 0.9005\n",
      "Epoch 89/500\n",
      "8745/8745 [==============================] - 0s 26us/step - loss: 0.3042 - acc: 0.8972 - val_loss: 0.3086 - val_acc: 0.9021\n",
      "Epoch 90/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2970 - acc: 0.8977 - val_loss: 0.3083 - val_acc: 0.9008\n",
      "Epoch 91/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3036 - acc: 0.8966 - val_loss: 0.3093 - val_acc: 0.9018\n",
      "Epoch 92/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2966 - acc: 0.8974 - val_loss: 0.3024 - val_acc: 0.9010\n",
      "Epoch 93/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2976 - acc: 0.8964 - val_loss: 0.3149 - val_acc: 0.8986\n",
      "Epoch 94/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2996 - acc: 0.8963 - val_loss: 0.2992 - val_acc: 0.9005\n",
      "Epoch 95/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2968 - acc: 0.8967 - val_loss: 0.3048 - val_acc: 0.9005\n",
      "Epoch 96/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2962 - acc: 0.8969 - val_loss: 0.2997 - val_acc: 0.9010\n",
      "Epoch 97/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3062 - acc: 0.8969 - val_loss: 0.3059 - val_acc: 0.9013\n",
      "Epoch 98/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.3046 - acc: 0.8967 - val_loss: 0.3400 - val_acc: 0.8970\n",
      "Epoch 99/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.3086 - acc: 0.8959 - val_loss: 0.3062 - val_acc: 0.9021\n",
      "Epoch 100/500\n",
      "8745/8745 [==============================] - 0s 22us/step - loss: 0.3017 - acc: 0.8978 - val_loss: 0.2994 - val_acc: 0.9000\n",
      "Epoch 101/500\n",
      "8745/8745 [==============================] - 0s 25us/step - loss: 0.2966 - acc: 0.8967 - val_loss: 0.3131 - val_acc: 0.8970\n",
      "Epoch 102/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.2956 - acc: 0.8985 - val_loss: 0.2980 - val_acc: 0.9010\n",
      "Epoch 103/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2997 - acc: 0.8979 - val_loss: 0.3104 - val_acc: 0.9002\n",
      "Epoch 104/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2972 - acc: 0.8979 - val_loss: 0.3081 - val_acc: 0.8992\n",
      "Epoch 105/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2967 - acc: 0.8958 - val_loss: 0.3036 - val_acc: 0.9010\n",
      "Epoch 106/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3041 - acc: 0.8965 - val_loss: 0.3087 - val_acc: 0.8986\n",
      "Epoch 107/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.3051 - acc: 0.8959 - val_loss: 0.3179 - val_acc: 0.8981\n",
      "Epoch 108/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.3040 - acc: 0.8967 - val_loss: 0.3054 - val_acc: 0.8986\n",
      "Epoch 109/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2977 - acc: 0.8970 - val_loss: 0.3015 - val_acc: 0.8970\n",
      "Epoch 110/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2962 - acc: 0.8978 - val_loss: 0.2979 - val_acc: 0.9018\n",
      "Epoch 111/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2948 - acc: 0.8970 - val_loss: 0.2981 - val_acc: 0.9016\n",
      "Epoch 112/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2967 - acc: 0.8969 - val_loss: 0.3134 - val_acc: 0.9016\n",
      "Epoch 113/500\n",
      "8745/8745 [==============================] - 0s 24us/step - loss: 0.3083 - acc: 0.8962 - val_loss: 0.3275 - val_acc: 0.8930\n",
      "Epoch 114/500\n",
      "8745/8745 [==============================] - 0s 21us/step - loss: 0.2982 - acc: 0.8964 - val_loss: 0.3042 - val_acc: 0.8978\n",
      "Epoch 115/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2957 - acc: 0.8971 - val_loss: 0.3083 - val_acc: 0.9018\n",
      "Epoch 116/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.3053 - acc: 0.8959 - val_loss: 0.3054 - val_acc: 0.9016\n",
      "Epoch 117/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2974 - acc: 0.8962 - val_loss: 0.3128 - val_acc: 0.9005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.3002 - acc: 0.8966 - val_loss: 0.3082 - val_acc: 0.9013\n",
      "Epoch 119/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2943 - acc: 0.8969 - val_loss: 0.3080 - val_acc: 0.8992\n",
      "Epoch 120/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2969 - acc: 0.8971 - val_loss: 0.2984 - val_acc: 0.9016\n",
      "Epoch 121/500\n",
      "8745/8745 [==============================] - 0s 10us/step - loss: 0.3004 - acc: 0.8956 - val_loss: 0.3051 - val_acc: 0.9008\n",
      "Epoch 122/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2972 - acc: 0.8965 - val_loss: 0.3071 - val_acc: 0.9008\n",
      "Epoch 123/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2991 - acc: 0.8971 - val_loss: 0.3089 - val_acc: 0.8997\n",
      "Epoch 124/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2990 - acc: 0.8965 - val_loss: 0.3169 - val_acc: 0.8984\n",
      "Epoch 125/500\n",
      "8745/8745 [==============================] - 0s 21us/step - loss: 0.3042 - acc: 0.8943 - val_loss: 0.3048 - val_acc: 0.8989\n",
      "Epoch 126/500\n",
      "8745/8745 [==============================] - 0s 22us/step - loss: 0.2988 - acc: 0.8958 - val_loss: 0.3046 - val_acc: 0.9000\n",
      "Epoch 127/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.3024 - acc: 0.8962 - val_loss: 0.3108 - val_acc: 0.9016\n",
      "Epoch 128/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2951 - acc: 0.8969 - val_loss: 0.3037 - val_acc: 0.8997\n",
      "Epoch 129/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2936 - acc: 0.8971 - val_loss: 0.2990 - val_acc: 0.8997\n",
      "Epoch 130/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2936 - acc: 0.8979 - val_loss: 0.3044 - val_acc: 0.9002\n",
      "Epoch 131/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2941 - acc: 0.8969 - val_loss: 0.2992 - val_acc: 0.9000\n",
      "Epoch 132/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2935 - acc: 0.8970 - val_loss: 0.3325 - val_acc: 0.8994\n",
      "Epoch 133/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.3028 - acc: 0.8961 - val_loss: 0.3016 - val_acc: 0.9010\n",
      "Epoch 134/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2940 - acc: 0.8966 - val_loss: 0.2999 - val_acc: 0.9005\n",
      "Epoch 135/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2938 - acc: 0.8965 - val_loss: 0.2967 - val_acc: 0.9013\n",
      "Epoch 136/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2949 - acc: 0.8970 - val_loss: 0.3033 - val_acc: 0.9016\n",
      "Epoch 137/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2930 - acc: 0.8975 - val_loss: 0.2965 - val_acc: 0.9002\n",
      "Epoch 138/500\n",
      "8745/8745 [==============================] - 0s 23us/step - loss: 0.2973 - acc: 0.8962 - val_loss: 0.2975 - val_acc: 0.9005\n",
      "Epoch 139/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2942 - acc: 0.8972 - val_loss: 0.3054 - val_acc: 0.9010\n",
      "Epoch 140/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2922 - acc: 0.8979 - val_loss: 0.2983 - val_acc: 0.9010\n",
      "Epoch 141/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2929 - acc: 0.8969 - val_loss: 0.3012 - val_acc: 0.9005\n",
      "Epoch 142/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2933 - acc: 0.8962 - val_loss: 0.3033 - val_acc: 0.9005\n",
      "Epoch 143/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2947 - acc: 0.8965 - val_loss: 0.3024 - val_acc: 0.8992\n",
      "Epoch 144/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2955 - acc: 0.8964 - val_loss: 0.3121 - val_acc: 0.9005\n",
      "Epoch 145/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2992 - acc: 0.8975 - val_loss: 0.2995 - val_acc: 0.9010\n",
      "Epoch 146/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.2917 - acc: 0.8972 - val_loss: 0.3021 - val_acc: 0.8989\n",
      "Epoch 147/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2930 - acc: 0.8970 - val_loss: 0.2973 - val_acc: 0.9008\n",
      "Epoch 148/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2915 - acc: 0.8975 - val_loss: 0.3000 - val_acc: 0.8992\n",
      "Epoch 149/500\n",
      "8745/8745 [==============================] - 0s 24us/step - loss: 0.2940 - acc: 0.8974 - val_loss: 0.3115 - val_acc: 0.8978\n",
      "Epoch 150/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2940 - acc: 0.8975 - val_loss: 0.2975 - val_acc: 0.9010\n",
      "Epoch 151/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2936 - acc: 0.8975 - val_loss: 0.2983 - val_acc: 0.9016\n",
      "Epoch 152/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2956 - acc: 0.8963 - val_loss: 0.3018 - val_acc: 0.9013\n",
      "Epoch 153/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2917 - acc: 0.8980 - val_loss: 0.2998 - val_acc: 0.9008\n",
      "Epoch 154/500\n",
      "8745/8745 [==============================] - 0s 9us/step - loss: 0.2920 - acc: 0.8971 - val_loss: 0.3000 - val_acc: 0.9010\n",
      "Epoch 155/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2900 - acc: 0.8986 - val_loss: 0.2959 - val_acc: 0.9021\n",
      "Epoch 156/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2911 - acc: 0.8975 - val_loss: 0.2998 - val_acc: 0.8981\n",
      "Epoch 157/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2977 - acc: 0.8948 - val_loss: 0.3015 - val_acc: 0.9005\n",
      "Epoch 158/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.2915 - acc: 0.8970 - val_loss: 0.2944 - val_acc: 0.9018\n",
      "Epoch 159/500\n",
      "8745/8745 [==============================] - 0s 26us/step - loss: 0.2902 - acc: 0.8979 - val_loss: 0.3021 - val_acc: 0.9010\n",
      "Epoch 160/500\n",
      "8745/8745 [==============================] - 0s 24us/step - loss: 0.2964 - acc: 0.8975 - val_loss: 0.3040 - val_acc: 0.8994\n",
      "Epoch 161/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2944 - acc: 0.8981 - val_loss: 0.3010 - val_acc: 0.9005\n",
      "Epoch 162/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2994 - acc: 0.8961 - val_loss: 0.2983 - val_acc: 0.8997\n",
      "Epoch 163/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2909 - acc: 0.8980 - val_loss: 0.2960 - val_acc: 0.9016\n",
      "Epoch 164/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2932 - acc: 0.8973 - val_loss: 0.3023 - val_acc: 0.9008\n",
      "Epoch 165/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2901 - acc: 0.8980 - val_loss: 0.2983 - val_acc: 0.9016\n",
      "Epoch 166/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2922 - acc: 0.8980 - val_loss: 0.2970 - val_acc: 0.9016\n",
      "Epoch 167/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2920 - acc: 0.8988 - val_loss: 0.2978 - val_acc: 0.9000\n",
      "Epoch 168/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2905 - acc: 0.8987 - val_loss: 0.2955 - val_acc: 0.9018\n",
      "Epoch 169/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2911 - acc: 0.8975 - val_loss: 0.3007 - val_acc: 0.9018\n",
      "Epoch 170/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.2896 - acc: 0.8971 - val_loss: 0.2941 - val_acc: 0.9008\n",
      "Epoch 171/500\n",
      "8745/8745 [==============================] - 0s 22us/step - loss: 0.2908 - acc: 0.8978 - val_loss: 0.3116 - val_acc: 0.9018\n",
      "Epoch 172/500\n",
      "8745/8745 [==============================] - 0s 23us/step - loss: 0.2907 - acc: 0.8987 - val_loss: 0.2983 - val_acc: 0.9018\n",
      "Epoch 173/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2902 - acc: 0.8991 - val_loss: 0.2990 - val_acc: 0.9016\n",
      "Epoch 174/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2917 - acc: 0.8971 - val_loss: 0.3008 - val_acc: 0.8994\n",
      "Epoch 175/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2909 - acc: 0.8983 - val_loss: 0.2931 - val_acc: 0.9032\n",
      "Epoch 176/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2911 - acc: 0.8988 - val_loss: 0.2950 - val_acc: 0.9013\n",
      "Epoch 177/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2934 - acc: 0.8977 - val_loss: 0.2996 - val_acc: 0.9005\n",
      "Epoch 178/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2920 - acc: 0.8983 - val_loss: 0.2995 - val_acc: 0.9021\n",
      "Epoch 179/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2890 - acc: 0.8974 - val_loss: 0.2966 - val_acc: 0.9013\n",
      "Epoch 180/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2879 - acc: 0.8980 - val_loss: 0.2963 - val_acc: 0.9010\n",
      "Epoch 181/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2887 - acc: 0.8991 - val_loss: 0.2979 - val_acc: 0.9034\n",
      "Epoch 182/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2913 - acc: 0.8986 - val_loss: 0.2965 - val_acc: 0.8986\n",
      "Epoch 183/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2893 - acc: 0.8973 - val_loss: 0.2977 - val_acc: 0.9008\n",
      "Epoch 184/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2916 - acc: 0.8965 - val_loss: 0.2977 - val_acc: 0.9018\n",
      "Epoch 185/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.2886 - acc: 0.8988 - val_loss: 0.2957 - val_acc: 0.9013\n",
      "Epoch 186/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.2901 - acc: 0.8982 - val_loss: 0.2927 - val_acc: 0.9002\n",
      "Epoch 187/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2910 - acc: 0.8981 - val_loss: 0.3021 - val_acc: 0.9024\n",
      "Epoch 188/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2935 - acc: 0.8965 - val_loss: 0.3079 - val_acc: 0.9005\n",
      "Epoch 189/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2912 - acc: 0.8967 - val_loss: 0.3012 - val_acc: 0.9018\n",
      "Epoch 190/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2890 - acc: 0.8978 - val_loss: 0.2965 - val_acc: 0.9032\n",
      "Epoch 191/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2900 - acc: 0.8972 - val_loss: 0.2986 - val_acc: 0.9026\n",
      "Epoch 192/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2900 - acc: 0.8974 - val_loss: 0.2994 - val_acc: 0.9010\n",
      "Epoch 193/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2882 - acc: 0.8982 - val_loss: 0.2967 - val_acc: 0.9016\n",
      "Epoch 194/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2892 - acc: 0.8988 - val_loss: 0.2982 - val_acc: 0.9016\n",
      "Epoch 195/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2932 - acc: 0.8975 - val_loss: 0.3041 - val_acc: 0.9000\n",
      "Epoch 196/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2897 - acc: 0.8982 - val_loss: 0.3016 - val_acc: 0.8994\n",
      "Epoch 197/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2895 - acc: 0.8978 - val_loss: 0.3006 - val_acc: 0.9026\n",
      "Epoch 198/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2918 - acc: 0.8990 - val_loss: 0.2991 - val_acc: 0.9008\n",
      "Epoch 199/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2882 - acc: 0.8981 - val_loss: 0.2995 - val_acc: 0.9018\n",
      "Epoch 200/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2907 - acc: 0.8963 - val_loss: 0.2981 - val_acc: 0.9021\n",
      "Epoch 201/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2929 - acc: 0.8974 - val_loss: 0.3002 - val_acc: 0.9026\n",
      "Epoch 202/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2900 - acc: 0.8981 - val_loss: 0.3014 - val_acc: 0.9018\n",
      "Epoch 203/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2883 - acc: 0.8986 - val_loss: 0.2982 - val_acc: 0.9016\n",
      "Epoch 204/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2918 - acc: 0.8979 - val_loss: 0.2989 - val_acc: 0.9010\n",
      "Epoch 205/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2874 - acc: 0.8974 - val_loss: 0.3007 - val_acc: 0.9000\n",
      "Epoch 206/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2873 - acc: 0.8970 - val_loss: 0.3001 - val_acc: 0.9032\n",
      "Epoch 207/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2871 - acc: 0.8988 - val_loss: 0.3006 - val_acc: 0.9021\n",
      "Epoch 208/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2875 - acc: 0.8980 - val_loss: 0.2972 - val_acc: 0.9010\n",
      "Epoch 209/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2872 - acc: 0.8981 - val_loss: 0.2978 - val_acc: 0.9005\n",
      "Epoch 210/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2865 - acc: 0.8978 - val_loss: 0.2981 - val_acc: 0.9010\n",
      "Epoch 211/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2882 - acc: 0.8983 - val_loss: 0.3020 - val_acc: 0.9018\n",
      "Epoch 212/500\n",
      "8745/8745 [==============================] - 0s 10us/step - loss: 0.2899 - acc: 0.8986 - val_loss: 0.2975 - val_acc: 0.9026\n",
      "Epoch 213/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2879 - acc: 0.8979 - val_loss: 0.3005 - val_acc: 0.9016\n",
      "Epoch 214/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2887 - acc: 0.8980 - val_loss: 0.3003 - val_acc: 0.9016\n",
      "Epoch 215/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2943 - acc: 0.8967 - val_loss: 0.3062 - val_acc: 0.9008\n",
      "Epoch 216/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2879 - acc: 0.8973 - val_loss: 0.3000 - val_acc: 0.9021\n",
      "Epoch 217/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2889 - acc: 0.8987 - val_loss: 0.2993 - val_acc: 0.9016\n",
      "Epoch 218/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.2868 - acc: 0.8986 - val_loss: 0.3002 - val_acc: 0.9024\n",
      "Epoch 219/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.2868 - acc: 0.8975 - val_loss: 0.3013 - val_acc: 0.9013\n",
      "Epoch 220/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2878 - acc: 0.8986 - val_loss: 0.3010 - val_acc: 0.8981\n",
      "Epoch 221/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2878 - acc: 0.8989 - val_loss: 0.3052 - val_acc: 0.9018\n",
      "Epoch 222/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2873 - acc: 0.8978 - val_loss: 0.3006 - val_acc: 0.9013\n",
      "Epoch 223/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2853 - acc: 0.8977 - val_loss: 0.3060 - val_acc: 0.9005\n",
      "Epoch 224/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2856 - acc: 0.8979 - val_loss: 0.3022 - val_acc: 0.9018\n",
      "Epoch 225/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2851 - acc: 0.8997 - val_loss: 0.3019 - val_acc: 0.9000\n",
      "Epoch 226/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2870 - acc: 0.8980 - val_loss: 0.3039 - val_acc: 0.9013\n",
      "Epoch 227/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2854 - acc: 0.8985 - val_loss: 0.2999 - val_acc: 0.9021\n",
      "Epoch 228/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2855 - acc: 0.8981 - val_loss: 0.3035 - val_acc: 0.9010\n",
      "Epoch 229/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2870 - acc: 0.8990 - val_loss: 0.3013 - val_acc: 0.9029\n",
      "Epoch 230/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2856 - acc: 0.8989 - val_loss: 0.2991 - val_acc: 0.9018\n",
      "Epoch 231/500\n",
      "8745/8745 [==============================] - 0s 22us/step - loss: 0.2845 - acc: 0.8993 - val_loss: 0.3075 - val_acc: 0.9018\n",
      "Epoch 232/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2872 - acc: 0.8986 - val_loss: 0.3056 - val_acc: 0.9002\n",
      "Epoch 233/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2847 - acc: 0.8983 - val_loss: 0.3018 - val_acc: 0.9002\n",
      "Epoch 234/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2876 - acc: 0.8982 - val_loss: 0.3023 - val_acc: 0.9005\n",
      "Epoch 235/500\n",
      "8745/8745 [==============================] - 0s 10us/step - loss: 0.2850 - acc: 0.8979 - val_loss: 0.3007 - val_acc: 0.9010\n",
      "Epoch 236/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2856 - acc: 0.8982 - val_loss: 0.3113 - val_acc: 0.8978\n",
      "Epoch 237/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2971 - acc: 0.8973 - val_loss: 0.3059 - val_acc: 0.9018\n",
      "Epoch 238/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2871 - acc: 0.8978 - val_loss: 0.3008 - val_acc: 0.9016\n",
      "Epoch 239/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2878 - acc: 0.8966 - val_loss: 0.3053 - val_acc: 0.9016\n",
      "Epoch 240/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2857 - acc: 0.8975 - val_loss: 0.3006 - val_acc: 0.9024\n",
      "Epoch 241/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2832 - acc: 0.8985 - val_loss: 0.3003 - val_acc: 0.9013\n",
      "Epoch 242/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2849 - acc: 0.8985 - val_loss: 0.3009 - val_acc: 0.9024\n",
      "Epoch 243/500\n",
      "8745/8745 [==============================] - 0s 24us/step - loss: 0.2873 - acc: 0.8978 - val_loss: 0.3063 - val_acc: 0.8994\n",
      "Epoch 244/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2827 - acc: 0.8996 - val_loss: 0.3055 - val_acc: 0.8989\n",
      "Epoch 245/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2843 - acc: 0.8988 - val_loss: 0.3021 - val_acc: 0.9021\n",
      "Epoch 246/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2854 - acc: 0.8988 - val_loss: 0.3042 - val_acc: 0.9029\n",
      "Epoch 247/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2827 - acc: 0.8993 - val_loss: 0.3017 - val_acc: 0.9008\n",
      "Epoch 248/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2825 - acc: 0.8980 - val_loss: 0.3065 - val_acc: 0.9029\n",
      "Epoch 249/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2847 - acc: 0.8982 - val_loss: 0.3120 - val_acc: 0.8946\n",
      "Epoch 250/500\n",
      "8745/8745 [==============================] - 0s 10us/step - loss: 0.2856 - acc: 0.8985 - val_loss: 0.3081 - val_acc: 0.8978\n",
      "Epoch 251/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2872 - acc: 0.8982 - val_loss: 0.3050 - val_acc: 0.9032\n",
      "Epoch 252/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2838 - acc: 0.8991 - val_loss: 0.3063 - val_acc: 0.9008\n",
      "Epoch 253/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2837 - acc: 0.8982 - val_loss: 0.3001 - val_acc: 0.9013\n",
      "Epoch 254/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2842 - acc: 0.8990 - val_loss: 0.3046 - val_acc: 0.9040\n",
      "Epoch 255/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2865 - acc: 0.8980 - val_loss: 0.3010 - val_acc: 0.8997\n",
      "Epoch 256/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2834 - acc: 0.8985 - val_loss: 0.2996 - val_acc: 0.8994\n",
      "Epoch 257/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2834 - acc: 0.8983 - val_loss: 0.3024 - val_acc: 0.8989\n",
      "Epoch 258/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2861 - acc: 0.8986 - val_loss: 0.3081 - val_acc: 0.8989\n",
      "Epoch 259/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2890 - acc: 0.8953 - val_loss: 0.3040 - val_acc: 0.8986\n",
      "Epoch 260/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2862 - acc: 0.8988 - val_loss: 0.3057 - val_acc: 0.9010\n",
      "Epoch 261/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2875 - acc: 0.8989 - val_loss: 0.3066 - val_acc: 0.9010\n",
      "Epoch 262/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2851 - acc: 0.8981 - val_loss: 0.2977 - val_acc: 0.9008\n",
      "Epoch 263/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2858 - acc: 0.8987 - val_loss: 0.3054 - val_acc: 0.9008\n",
      "Epoch 264/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2831 - acc: 0.8986 - val_loss: 0.3035 - val_acc: 0.9013\n",
      "Epoch 265/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2838 - acc: 0.8983 - val_loss: 0.3018 - val_acc: 0.9024\n",
      "Epoch 266/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2827 - acc: 0.8989 - val_loss: 0.3000 - val_acc: 0.9029\n",
      "Epoch 267/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2828 - acc: 0.9005 - val_loss: 0.3047 - val_acc: 0.9021\n",
      "Epoch 268/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2838 - acc: 0.9001 - val_loss: 0.2991 - val_acc: 0.9010\n",
      "Epoch 269/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2844 - acc: 0.8980 - val_loss: 0.3002 - val_acc: 0.9000\n",
      "Epoch 270/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2839 - acc: 0.8986 - val_loss: 0.3022 - val_acc: 0.8994\n",
      "Epoch 271/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2830 - acc: 0.8987 - val_loss: 0.2989 - val_acc: 0.9002\n",
      "Epoch 272/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2821 - acc: 0.8998 - val_loss: 0.3025 - val_acc: 0.9008\n",
      "Epoch 273/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2840 - acc: 0.9010 - val_loss: 0.3017 - val_acc: 0.9024\n",
      "Epoch 274/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2865 - acc: 0.8979 - val_loss: 0.3043 - val_acc: 0.9000\n",
      "Epoch 275/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2885 - acc: 0.8978 - val_loss: 0.3023 - val_acc: 0.9026\n",
      "Epoch 276/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2843 - acc: 0.8993 - val_loss: 0.2988 - val_acc: 0.9016\n",
      "Epoch 277/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2847 - acc: 0.8985 - val_loss: 0.3021 - val_acc: 0.9021\n",
      "Epoch 278/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2825 - acc: 0.8988 - val_loss: 0.3059 - val_acc: 0.9042\n",
      "Epoch 279/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2843 - acc: 0.9003 - val_loss: 0.2969 - val_acc: 0.9010\n",
      "Epoch 280/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2818 - acc: 0.8991 - val_loss: 0.2990 - val_acc: 0.9010\n",
      "Epoch 281/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2821 - acc: 0.8982 - val_loss: 0.3004 - val_acc: 0.9029\n",
      "Epoch 282/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2841 - acc: 0.8971 - val_loss: 0.3096 - val_acc: 0.9018\n",
      "Epoch 283/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2817 - acc: 0.9006 - val_loss: 0.3023 - val_acc: 0.9013\n",
      "Epoch 284/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2828 - acc: 0.8994 - val_loss: 0.3004 - val_acc: 0.9021\n",
      "Epoch 285/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2823 - acc: 0.8989 - val_loss: 0.2994 - val_acc: 0.9002\n",
      "Epoch 286/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2883 - acc: 0.8975 - val_loss: 0.3079 - val_acc: 0.9026\n",
      "Epoch 287/500\n",
      "8745/8745 [==============================] - 0s 10us/step - loss: 0.2894 - acc: 0.8988 - val_loss: 0.2977 - val_acc: 0.9002\n",
      "Epoch 288/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2846 - acc: 0.8978 - val_loss: 0.3081 - val_acc: 0.9024\n",
      "Epoch 289/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2852 - acc: 0.8995 - val_loss: 0.3025 - val_acc: 0.9026\n",
      "Epoch 290/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2820 - acc: 0.8988 - val_loss: 0.2999 - val_acc: 0.9005\n",
      "Epoch 291/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.2812 - acc: 0.8988 - val_loss: 0.3031 - val_acc: 0.8978\n",
      "Epoch 292/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2809 - acc: 0.8996 - val_loss: 0.3030 - val_acc: 0.9024\n",
      "Epoch 293/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2816 - acc: 0.8988 - val_loss: 0.3042 - val_acc: 0.9029\n",
      "Epoch 294/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2865 - acc: 0.8983 - val_loss: 0.3070 - val_acc: 0.9029\n",
      "Epoch 295/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2824 - acc: 0.8978 - val_loss: 0.2987 - val_acc: 0.9021\n",
      "Epoch 296/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2814 - acc: 0.8989 - val_loss: 0.3013 - val_acc: 0.9018\n",
      "Epoch 297/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2846 - acc: 0.8990 - val_loss: 0.3022 - val_acc: 0.9026\n",
      "Epoch 298/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2820 - acc: 0.8986 - val_loss: 0.3036 - val_acc: 0.9026\n",
      "Epoch 299/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2819 - acc: 0.8999 - val_loss: 0.3010 - val_acc: 0.9026\n",
      "Epoch 300/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2819 - acc: 0.8975 - val_loss: 0.3041 - val_acc: 0.9000\n",
      "Epoch 301/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2835 - acc: 0.8986 - val_loss: 0.2991 - val_acc: 0.9000\n",
      "Epoch 302/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2841 - acc: 0.8980 - val_loss: 0.3040 - val_acc: 0.9021\n",
      "Epoch 303/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2800 - acc: 0.8986 - val_loss: 0.3085 - val_acc: 0.8997\n",
      "Epoch 304/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2827 - acc: 0.8983 - val_loss: 0.3039 - val_acc: 0.8992\n",
      "Epoch 305/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2830 - acc: 0.8987 - val_loss: 0.3001 - val_acc: 0.9026\n",
      "Epoch 306/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2834 - acc: 0.8982 - val_loss: 0.2993 - val_acc: 0.9037\n",
      "Epoch 307/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2811 - acc: 0.8996 - val_loss: 0.2981 - val_acc: 0.9021\n",
      "Epoch 308/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2803 - acc: 0.8991 - val_loss: 0.3097 - val_acc: 0.9010\n",
      "Epoch 309/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2820 - acc: 0.8989 - val_loss: 0.3058 - val_acc: 0.9013\n",
      "Epoch 310/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2802 - acc: 0.8993 - val_loss: 0.3071 - val_acc: 0.9013\n",
      "Epoch 311/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2824 - acc: 0.8982 - val_loss: 0.3013 - val_acc: 0.9013\n",
      "Epoch 312/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2822 - acc: 0.8981 - val_loss: 0.3029 - val_acc: 0.8984\n",
      "Epoch 313/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2816 - acc: 0.8991 - val_loss: 0.3021 - val_acc: 0.9034\n",
      "Epoch 314/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2945 - acc: 0.8946 - val_loss: 0.3077 - val_acc: 0.9000\n",
      "Epoch 315/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2863 - acc: 0.8975 - val_loss: 0.3026 - val_acc: 0.9008\n",
      "Epoch 316/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2858 - acc: 0.8973 - val_loss: 0.3020 - val_acc: 0.9010\n",
      "Epoch 317/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2819 - acc: 0.8985 - val_loss: 0.3025 - val_acc: 0.9016\n",
      "Epoch 318/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2821 - acc: 0.8994 - val_loss: 0.3040 - val_acc: 0.9016\n",
      "Epoch 319/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2802 - acc: 0.8999 - val_loss: 0.2985 - val_acc: 0.9016\n",
      "Epoch 320/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2826 - acc: 0.8985 - val_loss: 0.3014 - val_acc: 0.9029\n",
      "Epoch 321/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2806 - acc: 0.8995 - val_loss: 0.2997 - val_acc: 0.9002\n",
      "Epoch 322/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2820 - acc: 0.8988 - val_loss: 0.3012 - val_acc: 0.9008\n",
      "Epoch 323/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2807 - acc: 0.8996 - val_loss: 0.3009 - val_acc: 0.9010\n",
      "Epoch 324/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2810 - acc: 0.8990 - val_loss: 0.3017 - val_acc: 0.9005\n",
      "Epoch 325/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2814 - acc: 0.8988 - val_loss: 0.3063 - val_acc: 0.9021\n",
      "Epoch 326/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2805 - acc: 0.9010 - val_loss: 0.3018 - val_acc: 0.9013\n",
      "Epoch 327/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2817 - acc: 0.8990 - val_loss: 0.3008 - val_acc: 0.9002\n",
      "Epoch 328/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2804 - acc: 0.8987 - val_loss: 0.2992 - val_acc: 0.9034\n",
      "Epoch 329/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2827 - acc: 0.8977 - val_loss: 0.3062 - val_acc: 0.8989\n",
      "Epoch 330/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2827 - acc: 0.8983 - val_loss: 0.3064 - val_acc: 0.9010\n",
      "Epoch 331/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2849 - acc: 0.8970 - val_loss: 0.2978 - val_acc: 0.9018\n",
      "Epoch 332/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2850 - acc: 0.8988 - val_loss: 0.3004 - val_acc: 0.9008\n",
      "Epoch 333/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2821 - acc: 0.8989 - val_loss: 0.2999 - val_acc: 0.9029\n",
      "Epoch 334/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2812 - acc: 0.8987 - val_loss: 0.3011 - val_acc: 0.9008\n",
      "Epoch 335/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2799 - acc: 0.8990 - val_loss: 0.3033 - val_acc: 0.9013\n",
      "Epoch 336/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2801 - acc: 0.8998 - val_loss: 0.3014 - val_acc: 0.9018\n",
      "Epoch 337/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2816 - acc: 0.8988 - val_loss: 0.3031 - val_acc: 0.9008\n",
      "Epoch 338/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2808 - acc: 0.9001 - val_loss: 0.3003 - val_acc: 0.9026\n",
      "Epoch 339/500\n",
      "8745/8745 [==============================] - 0s 24us/step - loss: 0.2811 - acc: 0.8986 - val_loss: 0.3007 - val_acc: 0.9000\n",
      "Epoch 340/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2807 - acc: 0.8980 - val_loss: 0.3030 - val_acc: 0.9013\n",
      "Epoch 341/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2793 - acc: 0.8981 - val_loss: 0.3038 - val_acc: 0.9013\n",
      "Epoch 342/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2785 - acc: 0.8991 - val_loss: 0.3037 - val_acc: 0.9002\n",
      "Epoch 343/500\n",
      "8745/8745 [==============================] - 0s 25us/step - loss: 0.2846 - acc: 0.8982 - val_loss: 0.3113 - val_acc: 0.9010\n",
      "Epoch 344/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2819 - acc: 0.8981 - val_loss: 0.3033 - val_acc: 0.9021\n",
      "Epoch 345/500\n",
      "8745/8745 [==============================] - ETA: 0s - loss: 0.2739 - acc: 0.900 - 0s 16us/step - loss: 0.2806 - acc: 0.8982 - val_loss: 0.3115 - val_acc: 0.9013\n",
      "Epoch 346/500\n",
      "8745/8745 [==============================] - 0s 21us/step - loss: 0.2816 - acc: 0.8987 - val_loss: 0.3045 - val_acc: 0.9008\n",
      "Epoch 347/500\n",
      "8745/8745 [==============================] - 0s 30us/step - loss: 0.2798 - acc: 0.8989 - val_loss: 0.3071 - val_acc: 0.8994\n",
      "Epoch 348/500\n",
      "8745/8745 [==============================] - 0s 28us/step - loss: 0.2792 - acc: 0.8999 - val_loss: 0.3079 - val_acc: 0.9005\n",
      "Epoch 349/500\n",
      "8745/8745 [==============================] - 0s 21us/step - loss: 0.2801 - acc: 0.8994 - val_loss: 0.3075 - val_acc: 0.9010\n",
      "Epoch 350/500\n",
      "8745/8745 [==============================] - 0s 21us/step - loss: 0.2795 - acc: 0.8971 - val_loss: 0.3047 - val_acc: 0.9021\n",
      "Epoch 351/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2786 - acc: 0.9015 - val_loss: 0.3058 - val_acc: 0.8989\n",
      "Epoch 352/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2900 - acc: 0.8965 - val_loss: 0.3364 - val_acc: 0.8994\n",
      "Epoch 353/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2939 - acc: 0.8971 - val_loss: 0.3074 - val_acc: 0.9005\n",
      "Epoch 354/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2846 - acc: 0.8978 - val_loss: 0.3038 - val_acc: 0.9018\n",
      "Epoch 355/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2842 - acc: 0.8985 - val_loss: 0.3014 - val_acc: 0.9010\n",
      "Epoch 356/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2808 - acc: 0.8980 - val_loss: 0.3024 - val_acc: 0.9005\n",
      "Epoch 357/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2803 - acc: 0.9001 - val_loss: 0.3059 - val_acc: 0.9029\n",
      "Epoch 358/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2798 - acc: 0.8990 - val_loss: 0.3027 - val_acc: 0.9016\n",
      "Epoch 359/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.2796 - acc: 0.8987 - val_loss: 0.3040 - val_acc: 0.9013\n",
      "Epoch 360/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2793 - acc: 0.8997 - val_loss: 0.3028 - val_acc: 0.9021\n",
      "Epoch 361/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2794 - acc: 0.8982 - val_loss: 0.3044 - val_acc: 0.9032\n",
      "Epoch 362/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2789 - acc: 0.9005 - val_loss: 0.3011 - val_acc: 0.9010\n",
      "Epoch 363/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2778 - acc: 0.9002 - val_loss: 0.3034 - val_acc: 0.9026\n",
      "Epoch 364/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2778 - acc: 0.8988 - val_loss: 0.3038 - val_acc: 0.9013\n",
      "Epoch 365/500\n",
      "8745/8745 [==============================] - 0s 10us/step - loss: 0.2796 - acc: 0.8993 - val_loss: 0.3031 - val_acc: 0.9008\n",
      "Epoch 366/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2779 - acc: 0.8998 - val_loss: 0.3046 - val_acc: 0.9000\n",
      "Epoch 367/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2790 - acc: 0.9002 - val_loss: 0.3040 - val_acc: 0.9002\n",
      "Epoch 368/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2791 - acc: 0.8981 - val_loss: 0.3038 - val_acc: 0.9016\n",
      "Epoch 369/500\n",
      "8745/8745 [==============================] - ETA: 0s - loss: 0.2837 - acc: 0.897 - 0s 15us/step - loss: 0.2823 - acc: 0.8980 - val_loss: 0.3056 - val_acc: 0.9010\n",
      "Epoch 370/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2798 - acc: 0.8986 - val_loss: 0.3061 - val_acc: 0.9021\n",
      "Epoch 371/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2780 - acc: 0.8993 - val_loss: 0.3043 - val_acc: 0.9026\n",
      "Epoch 372/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.2808 - acc: 0.8978 - val_loss: 0.3094 - val_acc: 0.8994\n",
      "Epoch 373/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2834 - acc: 0.8983 - val_loss: 0.3022 - val_acc: 0.9016\n",
      "Epoch 374/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2782 - acc: 0.8999 - val_loss: 0.3051 - val_acc: 0.8986\n",
      "Epoch 375/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2779 - acc: 0.8993 - val_loss: 0.3031 - val_acc: 0.9005\n",
      "Epoch 376/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2822 - acc: 0.8988 - val_loss: 0.3049 - val_acc: 0.9005\n",
      "Epoch 377/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2820 - acc: 0.8971 - val_loss: 0.3039 - val_acc: 0.9000\n",
      "Epoch 378/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2810 - acc: 0.8970 - val_loss: 0.3078 - val_acc: 0.9024\n",
      "Epoch 379/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2800 - acc: 0.8986 - val_loss: 0.3035 - val_acc: 0.9010\n",
      "Epoch 380/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2794 - acc: 0.8998 - val_loss: 0.3037 - val_acc: 0.8997\n",
      "Epoch 381/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2845 - acc: 0.8991 - val_loss: 0.3069 - val_acc: 0.9018\n",
      "Epoch 382/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2838 - acc: 0.8980 - val_loss: 0.3060 - val_acc: 0.9016\n",
      "Epoch 383/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2778 - acc: 0.8989 - val_loss: 0.3055 - val_acc: 0.9018\n",
      "Epoch 384/500\n",
      "8745/8745 [==============================] - 0s 21us/step - loss: 0.2793 - acc: 0.8993 - val_loss: 0.3044 - val_acc: 0.9024\n",
      "Epoch 385/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2796 - acc: 0.8988 - val_loss: 0.3029 - val_acc: 0.9018\n",
      "Epoch 386/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2785 - acc: 0.8995 - val_loss: 0.3042 - val_acc: 0.8994\n",
      "Epoch 387/500\n",
      "8745/8745 [==============================] - 0s 19us/step - loss: 0.2794 - acc: 0.8981 - val_loss: 0.3067 - val_acc: 0.9013\n",
      "Epoch 388/500\n",
      "8745/8745 [==============================] - 0s 10us/step - loss: 0.2785 - acc: 0.8991 - val_loss: 0.3034 - val_acc: 0.9000\n",
      "Epoch 389/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2780 - acc: 0.8999 - val_loss: 0.3057 - val_acc: 0.9016\n",
      "Epoch 390/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2787 - acc: 0.8974 - val_loss: 0.3050 - val_acc: 0.8981\n",
      "Epoch 391/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2820 - acc: 0.8965 - val_loss: 0.3068 - val_acc: 0.9000\n",
      "Epoch 392/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2778 - acc: 0.8995 - val_loss: 0.3074 - val_acc: 0.8984\n",
      "Epoch 393/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2771 - acc: 0.8993 - val_loss: 0.3049 - val_acc: 0.9013\n",
      "Epoch 394/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2760 - acc: 0.9003 - val_loss: 0.3036 - val_acc: 0.9018\n",
      "Epoch 395/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2799 - acc: 0.8996 - val_loss: 0.3036 - val_acc: 0.9005\n",
      "Epoch 396/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2778 - acc: 0.9002 - val_loss: 0.3025 - val_acc: 0.9008\n",
      "Epoch 397/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2782 - acc: 0.9011 - val_loss: 0.3049 - val_acc: 0.9013\n",
      "Epoch 398/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2789 - acc: 0.8999 - val_loss: 0.3075 - val_acc: 0.9002\n",
      "Epoch 399/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2797 - acc: 0.8989 - val_loss: 0.3045 - val_acc: 0.9010\n",
      "Epoch 400/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2766 - acc: 0.8990 - val_loss: 0.3056 - val_acc: 0.9018\n",
      "Epoch 401/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2779 - acc: 0.8988 - val_loss: 0.3044 - val_acc: 0.9016\n",
      "Epoch 402/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2819 - acc: 0.8983 - val_loss: 0.3100 - val_acc: 0.8989\n",
      "Epoch 403/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2796 - acc: 0.8991 - val_loss: 0.3041 - val_acc: 0.9000\n",
      "Epoch 404/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2784 - acc: 0.8991 - val_loss: 0.3078 - val_acc: 0.9013\n",
      "Epoch 405/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2779 - acc: 0.9002 - val_loss: 0.3049 - val_acc: 0.9008\n",
      "Epoch 406/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2787 - acc: 0.8988 - val_loss: 0.3033 - val_acc: 0.8997\n",
      "Epoch 407/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2791 - acc: 0.8994 - val_loss: 0.3088 - val_acc: 0.8986\n",
      "Epoch 408/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2785 - acc: 0.8981 - val_loss: 0.3035 - val_acc: 0.9000\n",
      "Epoch 409/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2776 - acc: 0.9001 - val_loss: 0.3077 - val_acc: 0.8997\n",
      "Epoch 410/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2764 - acc: 0.9011 - val_loss: 0.3052 - val_acc: 0.8992\n",
      "Epoch 411/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2768 - acc: 0.8993 - val_loss: 0.3040 - val_acc: 0.9008\n",
      "Epoch 412/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2781 - acc: 0.8987 - val_loss: 0.3082 - val_acc: 0.9010\n",
      "Epoch 413/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2797 - acc: 0.8989 - val_loss: 0.3072 - val_acc: 0.9005\n",
      "Epoch 414/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2778 - acc: 0.8987 - val_loss: 0.3055 - val_acc: 0.9002\n",
      "Epoch 415/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2779 - acc: 0.8996 - val_loss: 0.3037 - val_acc: 0.9016\n",
      "Epoch 416/500\n",
      "8745/8745 [==============================] - 0s 21us/step - loss: 0.2771 - acc: 0.9001 - val_loss: 0.3079 - val_acc: 0.9013\n",
      "Epoch 417/500\n",
      "8745/8745 [==============================] - 0s 23us/step - loss: 0.2767 - acc: 0.9001 - val_loss: 0.3088 - val_acc: 0.9005\n",
      "Epoch 418/500\n",
      "8745/8745 [==============================] - 0s 23us/step - loss: 0.2802 - acc: 0.9003 - val_loss: 0.3046 - val_acc: 0.9002\n",
      "Epoch 419/500\n",
      "8745/8745 [==============================] - 0s 22us/step - loss: 0.2791 - acc: 0.8995 - val_loss: 0.3031 - val_acc: 0.9008\n",
      "Epoch 420/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2765 - acc: 0.8983 - val_loss: 0.3043 - val_acc: 0.8986\n",
      "Epoch 421/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2768 - acc: 0.8991 - val_loss: 0.3100 - val_acc: 0.9016\n",
      "Epoch 422/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2830 - acc: 0.8979 - val_loss: 0.3069 - val_acc: 0.9008\n",
      "Epoch 423/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2777 - acc: 0.8996 - val_loss: 0.3060 - val_acc: 0.9008\n",
      "Epoch 424/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2764 - acc: 0.9003 - val_loss: 0.3066 - val_acc: 0.9018\n",
      "Epoch 425/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2762 - acc: 0.8987 - val_loss: 0.3071 - val_acc: 0.9010\n",
      "Epoch 426/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2765 - acc: 0.8986 - val_loss: 0.3060 - val_acc: 0.9016\n",
      "Epoch 427/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2790 - acc: 0.8981 - val_loss: 0.3062 - val_acc: 0.9018\n",
      "Epoch 428/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2747 - acc: 0.8997 - val_loss: 0.3061 - val_acc: 0.9018\n",
      "Epoch 429/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2754 - acc: 0.9011 - val_loss: 0.2996 - val_acc: 0.9002\n",
      "Epoch 430/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2787 - acc: 0.8986 - val_loss: 0.3215 - val_acc: 0.9002\n",
      "Epoch 431/500\n",
      "8745/8745 [==============================] - 0s 23us/step - loss: 0.2859 - acc: 0.8995 - val_loss: 0.2970 - val_acc: 0.9021\n",
      "Epoch 432/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2778 - acc: 0.8971 - val_loss: 0.3031 - val_acc: 0.9008\n",
      "Epoch 433/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2753 - acc: 0.9003 - val_loss: 0.3033 - val_acc: 0.9002\n",
      "Epoch 434/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2824 - acc: 0.8970 - val_loss: 0.2995 - val_acc: 0.9005\n",
      "Epoch 435/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2815 - acc: 0.8980 - val_loss: 0.3079 - val_acc: 0.9016\n",
      "Epoch 436/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2787 - acc: 0.8975 - val_loss: 0.3061 - val_acc: 0.8992\n",
      "Epoch 437/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2796 - acc: 0.8989 - val_loss: 0.3099 - val_acc: 0.9016\n",
      "Epoch 438/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2782 - acc: 0.9003 - val_loss: 0.3013 - val_acc: 0.9010\n",
      "Epoch 439/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2770 - acc: 0.8986 - val_loss: 0.2983 - val_acc: 0.9040\n",
      "Epoch 440/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2777 - acc: 0.8985 - val_loss: 0.3006 - val_acc: 0.9002\n",
      "Epoch 441/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2754 - acc: 0.8999 - val_loss: 0.3026 - val_acc: 0.9010\n",
      "Epoch 442/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2736 - acc: 0.9013 - val_loss: 0.3055 - val_acc: 0.8978\n",
      "Epoch 443/500\n",
      "8745/8745 [==============================] - 0s 22us/step - loss: 0.2754 - acc: 0.8999 - val_loss: 0.3066 - val_acc: 0.9002\n",
      "Epoch 444/500\n",
      "8745/8745 [==============================] - 0s 20us/step - loss: 0.2781 - acc: 0.8982 - val_loss: 0.3178 - val_acc: 0.8952\n",
      "Epoch 445/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2821 - acc: 0.8988 - val_loss: 0.3086 - val_acc: 0.8997\n",
      "Epoch 446/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2772 - acc: 0.8997 - val_loss: 0.3044 - val_acc: 0.8994\n",
      "Epoch 447/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2763 - acc: 0.8999 - val_loss: 0.3078 - val_acc: 0.8997\n",
      "Epoch 448/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2781 - acc: 0.8974 - val_loss: 0.3098 - val_acc: 0.8997\n",
      "Epoch 449/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2764 - acc: 0.8988 - val_loss: 0.3114 - val_acc: 0.9013\n",
      "Epoch 450/500\n",
      "8745/8745 [==============================] - 0s 10us/step - loss: 0.2781 - acc: 0.8981 - val_loss: 0.3099 - val_acc: 0.9005\n",
      "Epoch 451/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2769 - acc: 0.8981 - val_loss: 0.3109 - val_acc: 0.9010\n",
      "Epoch 452/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2764 - acc: 0.8988 - val_loss: 0.3109 - val_acc: 0.8978\n",
      "Epoch 453/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2808 - acc: 0.8989 - val_loss: 0.3070 - val_acc: 0.9002\n",
      "Epoch 454/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2829 - acc: 0.8996 - val_loss: 0.3110 - val_acc: 0.8989\n",
      "Epoch 455/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2825 - acc: 0.8997 - val_loss: 0.3061 - val_acc: 0.9005\n",
      "Epoch 456/500\n",
      "8745/8745 [==============================] - 0s 22us/step - loss: 0.2787 - acc: 0.8994 - val_loss: 0.3065 - val_acc: 0.8949\n",
      "Epoch 457/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2831 - acc: 0.8982 - val_loss: 0.3175 - val_acc: 0.9026\n",
      "Epoch 458/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2791 - acc: 0.8981 - val_loss: 0.3090 - val_acc: 0.8981\n",
      "Epoch 459/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2761 - acc: 0.8995 - val_loss: 0.3097 - val_acc: 0.8973\n",
      "Epoch 460/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2776 - acc: 0.8997 - val_loss: 0.3102 - val_acc: 0.8992\n",
      "Epoch 461/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2781 - acc: 0.9006 - val_loss: 0.3064 - val_acc: 0.9021\n",
      "Epoch 462/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2759 - acc: 0.9003 - val_loss: 0.3030 - val_acc: 0.9018\n",
      "Epoch 463/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2753 - acc: 0.8996 - val_loss: 0.3038 - val_acc: 0.9010\n",
      "Epoch 464/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2753 - acc: 0.9002 - val_loss: 0.3100 - val_acc: 0.9002\n",
      "Epoch 465/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2801 - acc: 0.8981 - val_loss: 0.3104 - val_acc: 0.8984\n",
      "Epoch 466/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2744 - acc: 0.9001 - val_loss: 0.3075 - val_acc: 0.9008\n",
      "Epoch 467/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2768 - acc: 0.8999 - val_loss: 0.3058 - val_acc: 0.9008\n",
      "Epoch 468/500\n",
      "8745/8745 [==============================] - 0s 21us/step - loss: 0.2771 - acc: 0.8994 - val_loss: 0.3108 - val_acc: 0.8973\n",
      "Epoch 469/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2746 - acc: 0.8993 - val_loss: 0.3077 - val_acc: 0.9005\n",
      "Epoch 470/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2755 - acc: 0.8995 - val_loss: 0.3101 - val_acc: 0.9000\n",
      "Epoch 471/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2768 - acc: 0.8991 - val_loss: 0.3031 - val_acc: 0.8986\n",
      "Epoch 472/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2798 - acc: 0.8986 - val_loss: 0.3057 - val_acc: 0.9000\n",
      "Epoch 473/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2759 - acc: 0.8989 - val_loss: 0.3081 - val_acc: 0.9016\n",
      "Epoch 474/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2743 - acc: 0.8999 - val_loss: 0.3070 - val_acc: 0.8994\n",
      "Epoch 475/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2785 - acc: 0.8982 - val_loss: 0.3107 - val_acc: 0.9008\n",
      "Epoch 476/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2759 - acc: 0.9001 - val_loss: 0.3085 - val_acc: 0.8997\n",
      "Epoch 477/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2751 - acc: 0.8996 - val_loss: 0.3118 - val_acc: 0.8970\n",
      "Epoch 478/500\n",
      "8745/8745 [==============================] - 0s 14us/step - loss: 0.2792 - acc: 0.8983 - val_loss: 0.3099 - val_acc: 0.8986\n",
      "Epoch 479/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2794 - acc: 0.8983 - val_loss: 0.3015 - val_acc: 0.9010\n",
      "Epoch 480/500\n",
      "8745/8745 [==============================] - 0s 17us/step - loss: 0.2779 - acc: 0.8994 - val_loss: 0.3036 - val_acc: 0.9008\n",
      "Epoch 481/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2748 - acc: 0.9005 - val_loss: 0.3050 - val_acc: 0.8992\n",
      "Epoch 482/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2742 - acc: 0.9003 - val_loss: 0.3043 - val_acc: 0.9000\n",
      "Epoch 483/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2738 - acc: 0.9004 - val_loss: 0.3034 - val_acc: 0.8986\n",
      "Epoch 484/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2751 - acc: 0.9005 - val_loss: 0.3128 - val_acc: 0.9000\n",
      "Epoch 485/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2769 - acc: 0.8978 - val_loss: 0.3059 - val_acc: 0.8981\n",
      "Epoch 486/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2774 - acc: 0.8989 - val_loss: 0.3071 - val_acc: 0.8992\n",
      "Epoch 487/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2763 - acc: 0.8993 - val_loss: 0.3133 - val_acc: 0.8986\n",
      "Epoch 488/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2792 - acc: 0.8986 - val_loss: 0.3098 - val_acc: 0.8965\n",
      "Epoch 489/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2777 - acc: 0.8989 - val_loss: 0.3053 - val_acc: 0.8984\n",
      "Epoch 490/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2760 - acc: 0.8986 - val_loss: 0.3057 - val_acc: 0.9008\n",
      "Epoch 491/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2754 - acc: 0.8993 - val_loss: 0.3085 - val_acc: 0.9005\n",
      "Epoch 492/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2755 - acc: 0.9009 - val_loss: 0.3105 - val_acc: 0.9005\n",
      "Epoch 493/500\n",
      "8745/8745 [==============================] - 0s 22us/step - loss: 0.2775 - acc: 0.8994 - val_loss: 0.3159 - val_acc: 0.8997\n",
      "Epoch 494/500\n",
      "8745/8745 [==============================] - 0s 18us/step - loss: 0.2806 - acc: 0.8982 - val_loss: 0.3105 - val_acc: 0.9002\n",
      "Epoch 495/500\n",
      "8745/8745 [==============================] - 0s 16us/step - loss: 0.2767 - acc: 0.8979 - val_loss: 0.3071 - val_acc: 0.9000\n",
      "Epoch 496/500\n",
      "8745/8745 [==============================] - 0s 15us/step - loss: 0.2752 - acc: 0.9004 - val_loss: 0.3089 - val_acc: 0.8994\n",
      "Epoch 497/500\n",
      "8745/8745 [==============================] - 0s 11us/step - loss: 0.2745 - acc: 0.8996 - val_loss: 0.3112 - val_acc: 0.8973\n",
      "Epoch 498/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2778 - acc: 0.8989 - val_loss: 0.3041 - val_acc: 0.9013\n",
      "Epoch 499/500\n",
      "8745/8745 [==============================] - 0s 13us/step - loss: 0.2757 - acc: 0.9019 - val_loss: 0.3086 - val_acc: 0.9005\n",
      "Epoch 500/500\n",
      "8745/8745 [==============================] - 0s 12us/step - loss: 0.2761 - acc: 0.8989 - val_loss: 0.3107 - val_acc: 0.8968\n",
      "3749/3749 [==============================] - 0s 2us/step\n",
      "1 5 403 403 12494 12355 5 1093 1088\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "12355 12355\n",
      "../linkPrediction/dataframes/apnea\n",
      "article (12355, 7, 11) --------------------------------------------------------------------\n",
      "(12355, 11) (12355,)\n",
      "[12355, 11, 1]\n",
      "(8648, 11) (8648,)\n",
      "Train on 8648 samples, validate on 3707 samples\n",
      "Epoch 1/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 1.0073 - acc: 0.8843 - val_loss: 0.8418 - val_acc: 0.8576\n",
      "Epoch 2/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.7232 - acc: 0.8781 - val_loss: 0.6228 - val_acc: 0.8940\n",
      "Epoch 3/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.6098 - acc: 0.8847 - val_loss: 0.5790 - val_acc: 0.8875\n",
      "Epoch 4/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.5603 - acc: 0.8881 - val_loss: 0.5156 - val_acc: 0.8864\n",
      "Epoch 5/500\n",
      "8648/8648 [==============================] - 0s 21us/step - loss: 0.5217 - acc: 0.8875 - val_loss: 0.4742 - val_acc: 0.8905\n",
      "Epoch 6/500\n",
      "8648/8648 [==============================] - 0s 20us/step - loss: 0.5048 - acc: 0.8906 - val_loss: 0.5048 - val_acc: 0.8905\n",
      "Epoch 7/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.4912 - acc: 0.8929 - val_loss: 0.4519 - val_acc: 0.8924\n",
      "Epoch 8/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.4822 - acc: 0.8929 - val_loss: 0.4786 - val_acc: 0.8959\n",
      "Epoch 9/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.4528 - acc: 0.8944 - val_loss: 0.4449 - val_acc: 0.8886\n",
      "Epoch 10/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.4403 - acc: 0.8937 - val_loss: 0.4111 - val_acc: 0.8943\n",
      "Epoch 11/500\n",
      "8648/8648 [==============================] - 0s 10us/step - loss: 0.4333 - acc: 0.8959 - val_loss: 0.3877 - val_acc: 0.8956\n",
      "Epoch 12/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.4089 - acc: 0.8965 - val_loss: 0.3851 - val_acc: 0.8953\n",
      "Epoch 13/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3851 - acc: 0.8969 - val_loss: 0.4534 - val_acc: 0.8959\n",
      "Epoch 14/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3918 - acc: 0.8960 - val_loss: 0.4054 - val_acc: 0.8913\n",
      "Epoch 15/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.4202 - acc: 0.8910 - val_loss: 0.3559 - val_acc: 0.8991\n",
      "Epoch 16/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.3954 - acc: 0.8958 - val_loss: 0.3813 - val_acc: 0.8988\n",
      "Epoch 17/500\n",
      "8648/8648 [==============================] - 0s 20us/step - loss: 0.4135 - acc: 0.8870 - val_loss: 0.4323 - val_acc: 0.8886\n",
      "Epoch 18/500\n",
      "8648/8648 [==============================] - 0s 19us/step - loss: 0.3991 - acc: 0.8952 - val_loss: 0.4171 - val_acc: 0.8967\n",
      "Epoch 19/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.4017 - acc: 0.8945 - val_loss: 0.3811 - val_acc: 0.8970\n",
      "Epoch 20/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.3643 - acc: 0.8985 - val_loss: 0.3979 - val_acc: 0.8897\n",
      "Epoch 21/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.3751 - acc: 0.8941 - val_loss: 0.5549 - val_acc: 0.8516\n",
      "Epoch 22/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3819 - acc: 0.8904 - val_loss: 0.3723 - val_acc: 0.8959\n",
      "Epoch 23/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3667 - acc: 0.8938 - val_loss: 0.4289 - val_acc: 0.8975\n",
      "Epoch 24/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.3806 - acc: 0.8934 - val_loss: 0.3849 - val_acc: 0.8934\n",
      "Epoch 25/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.3511 - acc: 0.8980 - val_loss: 0.3449 - val_acc: 0.8945\n",
      "Epoch 26/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3540 - acc: 0.8957 - val_loss: 0.3771 - val_acc: 0.8956\n",
      "Epoch 27/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.3579 - acc: 0.8981 - val_loss: 0.3486 - val_acc: 0.8970\n",
      "Epoch 28/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.3501 - acc: 0.8980 - val_loss: 0.3326 - val_acc: 0.8978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "8648/8648 [==============================] - 0s 21us/step - loss: 0.3371 - acc: 0.8985 - val_loss: 0.3702 - val_acc: 0.8961\n",
      "Epoch 30/500\n",
      "8648/8648 [==============================] - 0s 21us/step - loss: 0.3592 - acc: 0.8949 - val_loss: 0.4010 - val_acc: 0.8886\n",
      "Epoch 31/500\n",
      "8648/8648 [==============================] - 0s 19us/step - loss: 0.3621 - acc: 0.8977 - val_loss: 0.4755 - val_acc: 0.8967\n",
      "Epoch 32/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.4006 - acc: 0.8959 - val_loss: 0.3702 - val_acc: 0.8934\n",
      "Epoch 33/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.3351 - acc: 0.8985 - val_loss: 0.3618 - val_acc: 0.8996\n",
      "Epoch 34/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.3322 - acc: 0.8986 - val_loss: 0.3496 - val_acc: 0.8999\n",
      "Epoch 35/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.3647 - acc: 0.8954 - val_loss: 0.3658 - val_acc: 0.8945\n",
      "Epoch 36/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3569 - acc: 0.8974 - val_loss: 0.3477 - val_acc: 0.8929\n",
      "Epoch 37/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.3331 - acc: 0.8989 - val_loss: 0.3608 - val_acc: 0.8943\n",
      "Epoch 38/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.3796 - acc: 0.8948 - val_loss: 0.3957 - val_acc: 0.8980\n",
      "Epoch 39/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.3634 - acc: 0.8952 - val_loss: 0.3730 - val_acc: 0.8956\n",
      "Epoch 40/500\n",
      "8648/8648 [==============================] - 0s 19us/step - loss: 0.3243 - acc: 0.8982 - val_loss: 0.3890 - val_acc: 0.8924\n",
      "Epoch 41/500\n",
      "8648/8648 [==============================] - 0s 19us/step - loss: 0.3686 - acc: 0.8958 - val_loss: 0.3615 - val_acc: 0.8983\n",
      "Epoch 42/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.3390 - acc: 0.8972 - val_loss: 0.3552 - val_acc: 0.8975\n",
      "Epoch 43/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.3462 - acc: 0.8972 - val_loss: 0.3569 - val_acc: 0.8961\n",
      "Epoch 44/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.3374 - acc: 0.8987 - val_loss: 0.3267 - val_acc: 0.8991\n",
      "Epoch 45/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3307 - acc: 0.8985 - val_loss: 0.4015 - val_acc: 0.8937\n",
      "Epoch 46/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3262 - acc: 0.8978 - val_loss: 0.3529 - val_acc: 0.8961\n",
      "Epoch 47/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3429 - acc: 0.8958 - val_loss: 0.3641 - val_acc: 0.8943\n",
      "Epoch 48/500\n",
      "8648/8648 [==============================] - 0s 10us/step - loss: 0.3520 - acc: 0.8964 - val_loss: 0.3756 - val_acc: 0.8953\n",
      "Epoch 49/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3279 - acc: 0.8985 - val_loss: 0.3629 - val_acc: 0.8970\n",
      "Epoch 50/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.3273 - acc: 0.8964 - val_loss: 0.3297 - val_acc: 0.8975\n",
      "Epoch 51/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.3122 - acc: 0.8994 - val_loss: 0.3696 - val_acc: 0.8948\n",
      "Epoch 52/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.3548 - acc: 0.8952 - val_loss: 0.3553 - val_acc: 0.8964\n",
      "Epoch 53/500\n",
      "8648/8648 [==============================] - 0s 19us/step - loss: 0.3199 - acc: 0.8989 - val_loss: 0.3326 - val_acc: 0.8970\n",
      "Epoch 54/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.3179 - acc: 0.8996 - val_loss: 0.3249 - val_acc: 0.8970\n",
      "Epoch 55/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.3111 - acc: 0.8994 - val_loss: 0.3229 - val_acc: 0.8975\n",
      "Epoch 56/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.3277 - acc: 0.8978 - val_loss: 0.3573 - val_acc: 0.8951\n",
      "Epoch 57/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.3274 - acc: 0.8966 - val_loss: 0.3313 - val_acc: 0.8972\n",
      "Epoch 58/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.3304 - acc: 0.8989 - val_loss: 0.3229 - val_acc: 0.8975\n",
      "Epoch 59/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3156 - acc: 0.8980 - val_loss: 0.3338 - val_acc: 0.8961\n",
      "Epoch 60/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.3175 - acc: 0.8981 - val_loss: 0.3586 - val_acc: 0.8967\n",
      "Epoch 61/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.3427 - acc: 0.8965 - val_loss: 0.3526 - val_acc: 0.8932\n",
      "Epoch 62/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.3066 - acc: 0.8987 - val_loss: 0.3312 - val_acc: 0.8986\n",
      "Epoch 63/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.3240 - acc: 0.8984 - val_loss: 0.3392 - val_acc: 0.8945\n",
      "Epoch 64/500\n",
      "8648/8648 [==============================] - 0s 21us/step - loss: 0.3126 - acc: 0.8999 - val_loss: 0.3309 - val_acc: 0.8959\n",
      "Epoch 65/500\n",
      "8648/8648 [==============================] - 0s 20us/step - loss: 0.3463 - acc: 0.8941 - val_loss: 0.3487 - val_acc: 0.8945\n",
      "Epoch 66/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.3207 - acc: 0.8978 - val_loss: 0.3202 - val_acc: 0.8983\n",
      "Epoch 67/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.3193 - acc: 0.8972 - val_loss: 0.3216 - val_acc: 0.8986\n",
      "Epoch 68/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.3071 - acc: 0.8987 - val_loss: 0.3192 - val_acc: 0.8964\n",
      "Epoch 69/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3126 - acc: 0.8993 - val_loss: 0.3345 - val_acc: 0.8975\n",
      "Epoch 70/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3145 - acc: 0.8979 - val_loss: 0.3215 - val_acc: 0.8972\n",
      "Epoch 71/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.3271 - acc: 0.8974 - val_loss: 0.3161 - val_acc: 0.8994\n",
      "Epoch 72/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3200 - acc: 0.8991 - val_loss: 0.3168 - val_acc: 0.8967\n",
      "Epoch 73/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.3098 - acc: 0.8985 - val_loss: 0.3320 - val_acc: 0.8961\n",
      "Epoch 74/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.3294 - acc: 0.8981 - val_loss: 0.3400 - val_acc: 0.8956\n",
      "Epoch 75/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2999 - acc: 0.9003 - val_loss: 0.3254 - val_acc: 0.8978\n",
      "Epoch 76/500\n",
      "8648/8648 [==============================] - 0s 21us/step - loss: 0.3189 - acc: 0.8981 - val_loss: 0.3447 - val_acc: 0.8948\n",
      "Epoch 77/500\n",
      "8648/8648 [==============================] - 0s 22us/step - loss: 0.3041 - acc: 0.8997 - val_loss: 0.3218 - val_acc: 0.8967\n",
      "Epoch 78/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.3191 - acc: 0.8973 - val_loss: 0.3339 - val_acc: 0.8967\n",
      "Epoch 79/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.3059 - acc: 0.9000 - val_loss: 0.3662 - val_acc: 0.8897\n",
      "Epoch 80/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.3098 - acc: 0.8984 - val_loss: 0.3195 - val_acc: 0.8964\n",
      "Epoch 81/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.3032 - acc: 0.9001 - val_loss: 0.3089 - val_acc: 0.8991\n",
      "Epoch 82/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3067 - acc: 0.8997 - val_loss: 0.3141 - val_acc: 0.8961\n",
      "Epoch 83/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3114 - acc: 0.8991 - val_loss: 0.3379 - val_acc: 0.8953\n",
      "Epoch 84/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.3009 - acc: 0.8988 - val_loss: 0.3072 - val_acc: 0.8994\n",
      "Epoch 85/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3047 - acc: 0.8988 - val_loss: 0.3089 - val_acc: 0.8983\n",
      "Epoch 86/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2972 - acc: 0.9007 - val_loss: 0.3159 - val_acc: 0.8961\n",
      "Epoch 87/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2971 - acc: 0.9009 - val_loss: 0.3344 - val_acc: 0.8945\n",
      "Epoch 88/500\n",
      "8648/8648 [==============================] - 0s 20us/step - loss: 0.3007 - acc: 0.9001 - val_loss: 0.3105 - val_acc: 0.8991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500\n",
      "8648/8648 [==============================] - 0s 22us/step - loss: 0.3118 - acc: 0.8991 - val_loss: 0.3772 - val_acc: 0.8894\n",
      "Epoch 90/500\n",
      "8648/8648 [==============================] - 0s 21us/step - loss: 0.3018 - acc: 0.9015 - val_loss: 0.3061 - val_acc: 0.8986\n",
      "Epoch 91/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2995 - acc: 0.9007 - val_loss: 0.3065 - val_acc: 0.8991\n",
      "Epoch 92/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2964 - acc: 0.9004 - val_loss: 0.3188 - val_acc: 0.8983\n",
      "Epoch 93/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3006 - acc: 0.8991 - val_loss: 0.3135 - val_acc: 0.8972\n",
      "Epoch 94/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2946 - acc: 0.9002 - val_loss: 0.3035 - val_acc: 0.8980\n",
      "Epoch 95/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2981 - acc: 0.9006 - val_loss: 0.3267 - val_acc: 0.8961\n",
      "Epoch 96/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2945 - acc: 0.9004 - val_loss: 0.3079 - val_acc: 0.8994\n",
      "Epoch 97/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.3030 - acc: 0.8986 - val_loss: 0.3147 - val_acc: 0.8967\n",
      "Epoch 98/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2916 - acc: 0.9014 - val_loss: 0.3067 - val_acc: 0.8996\n",
      "Epoch 99/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2917 - acc: 0.9003 - val_loss: 0.3402 - val_acc: 0.8926\n",
      "Epoch 100/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.3209 - acc: 0.8985 - val_loss: 0.3078 - val_acc: 0.8988\n",
      "Epoch 101/500\n",
      "8648/8648 [==============================] - 0s 20us/step - loss: 0.2955 - acc: 0.9008 - val_loss: 0.3096 - val_acc: 0.8970\n",
      "Epoch 102/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2971 - acc: 0.8996 - val_loss: 0.3167 - val_acc: 0.8988\n",
      "Epoch 103/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.3099 - acc: 0.8982 - val_loss: 0.3164 - val_acc: 0.8980\n",
      "Epoch 104/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2900 - acc: 0.9001 - val_loss: 0.3131 - val_acc: 0.8991\n",
      "Epoch 105/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2930 - acc: 0.9006 - val_loss: 0.3087 - val_acc: 0.8967\n",
      "Epoch 106/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2934 - acc: 0.9008 - val_loss: 0.3045 - val_acc: 0.8983\n",
      "Epoch 107/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2914 - acc: 0.9008 - val_loss: 0.3055 - val_acc: 0.8988\n",
      "Epoch 108/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2914 - acc: 0.9006 - val_loss: 0.3063 - val_acc: 0.8972\n",
      "Epoch 109/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2928 - acc: 0.9003 - val_loss: 0.3125 - val_acc: 0.8986\n",
      "Epoch 110/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2875 - acc: 0.9010 - val_loss: 0.3073 - val_acc: 0.8978\n",
      "Epoch 111/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2904 - acc: 0.9009 - val_loss: 0.3434 - val_acc: 0.8937\n",
      "Epoch 112/500\n",
      "8648/8648 [==============================] - 0s 19us/step - loss: 0.3091 - acc: 0.8969 - val_loss: 0.3310 - val_acc: 0.8961\n",
      "Epoch 113/500\n",
      "8648/8648 [==============================] - 0s 22us/step - loss: 0.2904 - acc: 0.8997 - val_loss: 0.3149 - val_acc: 0.8972\n",
      "Epoch 114/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2920 - acc: 0.9014 - val_loss: 0.3057 - val_acc: 0.8996\n",
      "Epoch 115/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2903 - acc: 0.8996 - val_loss: 0.3070 - val_acc: 0.8988\n",
      "Epoch 116/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2884 - acc: 0.9014 - val_loss: 0.3257 - val_acc: 0.8945\n",
      "Epoch 117/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2947 - acc: 0.8996 - val_loss: 0.3150 - val_acc: 0.8983\n",
      "Epoch 118/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2905 - acc: 0.9001 - val_loss: 0.3170 - val_acc: 0.8972\n",
      "Epoch 119/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2945 - acc: 0.8999 - val_loss: 0.3488 - val_acc: 0.8926\n",
      "Epoch 120/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2946 - acc: 0.9012 - val_loss: 0.3043 - val_acc: 0.8975\n",
      "Epoch 121/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.3035 - acc: 0.8995 - val_loss: 0.3124 - val_acc: 0.8978\n",
      "Epoch 122/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2944 - acc: 0.9000 - val_loss: 0.3101 - val_acc: 0.8975\n",
      "Epoch 123/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2965 - acc: 0.8995 - val_loss: 0.3199 - val_acc: 0.8959\n",
      "Epoch 124/500\n",
      "8648/8648 [==============================] - 0s 19us/step - loss: 0.2953 - acc: 0.9007 - val_loss: 0.3055 - val_acc: 0.8988\n",
      "Epoch 125/500\n",
      "8648/8648 [==============================] - 0s 19us/step - loss: 0.2940 - acc: 0.8999 - val_loss: 0.3263 - val_acc: 0.8948\n",
      "Epoch 126/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2911 - acc: 0.9000 - val_loss: 0.3180 - val_acc: 0.8991\n",
      "Epoch 127/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2888 - acc: 0.9014 - val_loss: 0.3079 - val_acc: 0.8988\n",
      "Epoch 128/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2928 - acc: 0.9012 - val_loss: 0.3037 - val_acc: 0.9010\n",
      "Epoch 129/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2868 - acc: 0.9014 - val_loss: 0.3011 - val_acc: 0.8999\n",
      "Epoch 130/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2872 - acc: 0.9012 - val_loss: 0.3025 - val_acc: 0.8996\n",
      "Epoch 131/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2951 - acc: 0.9001 - val_loss: 0.2997 - val_acc: 0.8991\n",
      "Epoch 132/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2864 - acc: 0.8988 - val_loss: 0.3020 - val_acc: 0.8991\n",
      "Epoch 133/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2900 - acc: 0.8987 - val_loss: 0.3066 - val_acc: 0.8980\n",
      "Epoch 134/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2854 - acc: 0.9010 - val_loss: 0.3036 - val_acc: 0.8994\n",
      "Epoch 135/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2844 - acc: 0.9008 - val_loss: 0.2988 - val_acc: 0.9007\n",
      "Epoch 136/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2889 - acc: 0.9002 - val_loss: 0.3037 - val_acc: 0.8972\n",
      "Epoch 137/500\n",
      "8648/8648 [==============================] - 0s 21us/step - loss: 0.2862 - acc: 0.9004 - val_loss: 0.3061 - val_acc: 0.8999\n",
      "Epoch 138/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2883 - acc: 0.9016 - val_loss: 0.3092 - val_acc: 0.8967\n",
      "Epoch 139/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2902 - acc: 0.9000 - val_loss: 0.3079 - val_acc: 0.8975\n",
      "Epoch 140/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2971 - acc: 0.8993 - val_loss: 0.3052 - val_acc: 0.8983\n",
      "Epoch 141/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2862 - acc: 0.9002 - val_loss: 0.3061 - val_acc: 0.8970\n",
      "Epoch 142/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2858 - acc: 0.9014 - val_loss: 0.3050 - val_acc: 0.8972\n",
      "Epoch 143/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2870 - acc: 0.9007 - val_loss: 0.3056 - val_acc: 0.8986\n",
      "Epoch 144/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2900 - acc: 0.9001 - val_loss: 0.3012 - val_acc: 0.8986\n",
      "Epoch 145/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2860 - acc: 0.9006 - val_loss: 0.2993 - val_acc: 0.8988\n",
      "Epoch 146/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2839 - acc: 0.9002 - val_loss: 0.2998 - val_acc: 0.8994\n",
      "Epoch 147/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2850 - acc: 0.9015 - val_loss: 0.3042 - val_acc: 0.8994\n",
      "Epoch 148/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2896 - acc: 0.8989 - val_loss: 0.3039 - val_acc: 0.8986\n",
      "Epoch 149/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2842 - acc: 0.9022 - val_loss: 0.3025 - val_acc: 0.8988\n",
      "Epoch 150/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2868 - acc: 0.8993 - val_loss: 0.3000 - val_acc: 0.8986\n",
      "Epoch 151/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2854 - acc: 0.9010 - val_loss: 0.3041 - val_acc: 0.8970\n",
      "Epoch 152/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2906 - acc: 0.9001 - val_loss: 0.3069 - val_acc: 0.8970\n",
      "Epoch 153/500\n",
      "8648/8648 [==============================] - 0s 10us/step - loss: 0.2843 - acc: 0.9009 - val_loss: 0.3094 - val_acc: 0.8951\n",
      "Epoch 154/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2930 - acc: 0.8988 - val_loss: 0.3010 - val_acc: 0.8986\n",
      "Epoch 155/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2835 - acc: 0.8996 - val_loss: 0.3033 - val_acc: 0.8991\n",
      "Epoch 156/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2857 - acc: 0.9006 - val_loss: 0.3034 - val_acc: 0.8980\n",
      "Epoch 157/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2841 - acc: 0.9008 - val_loss: 0.3100 - val_acc: 0.8951\n",
      "Epoch 158/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2833 - acc: 0.9015 - val_loss: 0.3127 - val_acc: 0.8975\n",
      "Epoch 159/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2870 - acc: 0.8992 - val_loss: 0.3101 - val_acc: 0.8975\n",
      "Epoch 160/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2922 - acc: 0.8978 - val_loss: 0.3057 - val_acc: 0.8986\n",
      "Epoch 161/500\n",
      "8648/8648 [==============================] - 0s 21us/step - loss: 0.2836 - acc: 0.8999 - val_loss: 0.3062 - val_acc: 0.8988\n",
      "Epoch 162/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2842 - acc: 0.9000 - val_loss: 0.3134 - val_acc: 0.8970\n",
      "Epoch 163/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2869 - acc: 0.8997 - val_loss: 0.3074 - val_acc: 0.8980\n",
      "Epoch 164/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2844 - acc: 0.9003 - val_loss: 0.3043 - val_acc: 0.8986\n",
      "Epoch 165/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2853 - acc: 0.9006 - val_loss: 0.3058 - val_acc: 0.8991\n",
      "Epoch 166/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2826 - acc: 0.9003 - val_loss: 0.3039 - val_acc: 0.8991\n",
      "Epoch 167/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2854 - acc: 0.9007 - val_loss: 0.3281 - val_acc: 0.8959\n",
      "Epoch 168/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2876 - acc: 0.9002 - val_loss: 0.3039 - val_acc: 0.8975\n",
      "Epoch 169/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2861 - acc: 0.9004 - val_loss: 0.3105 - val_acc: 0.8983\n",
      "Epoch 170/500\n",
      "8648/8648 [==============================] - 0s 21us/step - loss: 0.2847 - acc: 0.9000 - val_loss: 0.3065 - val_acc: 0.8983\n",
      "Epoch 171/500\n",
      "8648/8648 [==============================] - 0s 27us/step - loss: 0.2868 - acc: 0.8987 - val_loss: 0.3217 - val_acc: 0.8943\n",
      "Epoch 172/500\n",
      "8648/8648 [==============================] - 0s 24us/step - loss: 0.2857 - acc: 0.8995 - val_loss: 0.3071 - val_acc: 0.8970\n",
      "Epoch 173/500\n",
      "8648/8648 [==============================] - 0s 22us/step - loss: 0.2881 - acc: 0.8994 - val_loss: 0.3211 - val_acc: 0.8956\n",
      "Epoch 174/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2951 - acc: 0.9001 - val_loss: 0.3154 - val_acc: 0.8970\n",
      "Epoch 175/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2892 - acc: 0.9008 - val_loss: 0.3107 - val_acc: 0.8972\n",
      "Epoch 176/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2885 - acc: 0.9003 - val_loss: 0.3122 - val_acc: 0.8970\n",
      "Epoch 177/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2909 - acc: 0.8991 - val_loss: 0.3081 - val_acc: 0.8970\n",
      "Epoch 178/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2876 - acc: 0.8991 - val_loss: 0.3037 - val_acc: 0.8986\n",
      "Epoch 179/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2867 - acc: 0.8996 - val_loss: 0.3007 - val_acc: 0.8983\n",
      "Epoch 180/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2849 - acc: 0.9001 - val_loss: 0.3011 - val_acc: 0.8988\n",
      "Epoch 181/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2830 - acc: 0.9001 - val_loss: 0.3009 - val_acc: 0.8972\n",
      "Epoch 182/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2830 - acc: 0.9006 - val_loss: 0.3011 - val_acc: 0.8970\n",
      "Epoch 183/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2828 - acc: 0.9007 - val_loss: 0.3022 - val_acc: 0.8980\n",
      "Epoch 184/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2828 - acc: 0.9008 - val_loss: 0.3016 - val_acc: 0.8983\n",
      "Epoch 185/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2821 - acc: 0.9009 - val_loss: 0.3001 - val_acc: 0.8991\n",
      "Epoch 186/500\n",
      "8648/8648 [==============================] - 0s 19us/step - loss: 0.2831 - acc: 0.9011 - val_loss: 0.3027 - val_acc: 0.8986\n",
      "Epoch 187/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2820 - acc: 0.9000 - val_loss: 0.3009 - val_acc: 0.8983\n",
      "Epoch 188/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2836 - acc: 0.9009 - val_loss: 0.3040 - val_acc: 0.8972\n",
      "Epoch 189/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2828 - acc: 0.9016 - val_loss: 0.3018 - val_acc: 0.8996\n",
      "Epoch 190/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2827 - acc: 0.9008 - val_loss: 0.2994 - val_acc: 0.8980\n",
      "Epoch 191/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2829 - acc: 0.9008 - val_loss: 0.3002 - val_acc: 0.8988\n",
      "Epoch 192/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2818 - acc: 0.9009 - val_loss: 0.3021 - val_acc: 0.8986\n",
      "Epoch 193/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2836 - acc: 0.9006 - val_loss: 0.3027 - val_acc: 0.8983\n",
      "Epoch 194/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2838 - acc: 0.9001 - val_loss: 0.3035 - val_acc: 0.8980\n",
      "Epoch 195/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2857 - acc: 0.9006 - val_loss: 0.3092 - val_acc: 0.8970\n",
      "Epoch 196/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2822 - acc: 0.9021 - val_loss: 0.3042 - val_acc: 0.8983\n",
      "Epoch 197/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2811 - acc: 0.9019 - val_loss: 0.3056 - val_acc: 0.8972\n",
      "Epoch 198/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2846 - acc: 0.9004 - val_loss: 0.3066 - val_acc: 0.8970\n",
      "Epoch 199/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2871 - acc: 0.9004 - val_loss: 0.3109 - val_acc: 0.8970\n",
      "Epoch 200/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2822 - acc: 0.9019 - val_loss: 0.3095 - val_acc: 0.8975\n",
      "Epoch 201/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2818 - acc: 0.9003 - val_loss: 0.3078 - val_acc: 0.8988\n",
      "Epoch 202/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2858 - acc: 0.9001 - val_loss: 0.3033 - val_acc: 0.8978\n",
      "Epoch 203/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2853 - acc: 0.9004 - val_loss: 0.3053 - val_acc: 0.8983\n",
      "Epoch 204/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2811 - acc: 0.9001 - val_loss: 0.3128 - val_acc: 0.8970\n",
      "Epoch 205/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2820 - acc: 0.9011 - val_loss: 0.3067 - val_acc: 0.8988\n",
      "Epoch 206/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2835 - acc: 0.9018 - val_loss: 0.3066 - val_acc: 0.8975\n",
      "Epoch 207/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8648/8648 [==============================] - 0s 20us/step - loss: 0.2817 - acc: 0.9007 - val_loss: 0.3079 - val_acc: 0.8983\n",
      "Epoch 208/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2815 - acc: 0.9007 - val_loss: 0.3180 - val_acc: 0.8978\n",
      "Epoch 209/500\n",
      "8648/8648 [==============================] - 0s 19us/step - loss: 0.2830 - acc: 0.9011 - val_loss: 0.3075 - val_acc: 0.8978\n",
      "Epoch 210/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2820 - acc: 0.9010 - val_loss: 0.3105 - val_acc: 0.8978\n",
      "Epoch 211/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2829 - acc: 0.9016 - val_loss: 0.3084 - val_acc: 0.8991\n",
      "Epoch 212/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2852 - acc: 0.9003 - val_loss: 0.3040 - val_acc: 0.8988\n",
      "Epoch 213/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2837 - acc: 0.9006 - val_loss: 0.3033 - val_acc: 0.8986\n",
      "Epoch 214/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2821 - acc: 0.9008 - val_loss: 0.3041 - val_acc: 0.8988\n",
      "Epoch 215/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2806 - acc: 0.9008 - val_loss: 0.3054 - val_acc: 0.8999\n",
      "Epoch 216/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2814 - acc: 0.9015 - val_loss: 0.3032 - val_acc: 0.8980\n",
      "Epoch 217/500\n",
      "8648/8648 [==============================] - 0s 21us/step - loss: 0.2808 - acc: 0.9008 - val_loss: 0.3044 - val_acc: 0.8986\n",
      "Epoch 218/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2816 - acc: 0.9018 - val_loss: 0.3047 - val_acc: 0.8972\n",
      "Epoch 219/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2809 - acc: 0.9001 - val_loss: 0.3048 - val_acc: 0.9002\n",
      "Epoch 220/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2795 - acc: 0.9014 - val_loss: 0.3088 - val_acc: 0.8991\n",
      "Epoch 221/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2798 - acc: 0.9023 - val_loss: 0.3033 - val_acc: 0.8978\n",
      "Epoch 222/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2816 - acc: 0.9006 - val_loss: 0.3036 - val_acc: 0.8994\n",
      "Epoch 223/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2804 - acc: 0.9000 - val_loss: 0.3027 - val_acc: 0.8986\n",
      "Epoch 224/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2810 - acc: 0.9011 - val_loss: 0.3042 - val_acc: 0.8978\n",
      "Epoch 225/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2830 - acc: 0.8989 - val_loss: 0.3063 - val_acc: 0.8951\n",
      "Epoch 226/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2820 - acc: 0.9016 - val_loss: 0.3070 - val_acc: 0.8978\n",
      "Epoch 227/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2813 - acc: 0.9011 - val_loss: 0.3055 - val_acc: 0.8972\n",
      "Epoch 228/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2794 - acc: 0.9009 - val_loss: 0.3067 - val_acc: 0.8959\n",
      "Epoch 229/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2833 - acc: 0.9007 - val_loss: 0.3026 - val_acc: 0.8978\n",
      "Epoch 230/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2792 - acc: 0.9011 - val_loss: 0.3069 - val_acc: 0.8988\n",
      "Epoch 231/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2811 - acc: 0.9011 - val_loss: 0.3031 - val_acc: 0.8970\n",
      "Epoch 232/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2806 - acc: 0.9008 - val_loss: 0.3068 - val_acc: 0.8972\n",
      "Epoch 233/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2787 - acc: 0.9014 - val_loss: 0.3057 - val_acc: 0.8978\n",
      "Epoch 234/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2801 - acc: 0.9015 - val_loss: 0.3067 - val_acc: 0.8975\n",
      "Epoch 235/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2785 - acc: 0.9023 - val_loss: 0.3053 - val_acc: 0.8988\n",
      "Epoch 236/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2789 - acc: 0.9003 - val_loss: 0.3136 - val_acc: 0.8956\n",
      "Epoch 237/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2807 - acc: 0.9000 - val_loss: 0.3022 - val_acc: 0.8986\n",
      "Epoch 238/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2813 - acc: 0.9011 - val_loss: 0.3178 - val_acc: 0.8983\n",
      "Epoch 239/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2872 - acc: 0.8999 - val_loss: 0.3049 - val_acc: 0.8988\n",
      "Epoch 240/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2807 - acc: 0.9008 - val_loss: 0.3042 - val_acc: 0.8964\n",
      "Epoch 241/500\n",
      "8648/8648 [==============================] - 0s 22us/step - loss: 0.2792 - acc: 0.9014 - val_loss: 0.3075 - val_acc: 0.8975\n",
      "Epoch 242/500\n",
      "8648/8648 [==============================] - 0s 27us/step - loss: 0.2793 - acc: 0.9023 - val_loss: 0.3101 - val_acc: 0.8964\n",
      "Epoch 243/500\n",
      "8648/8648 [==============================] - 0s 25us/step - loss: 0.2801 - acc: 0.9017 - val_loss: 0.3139 - val_acc: 0.8980\n",
      "Epoch 244/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2788 - acc: 0.9021 - val_loss: 0.3069 - val_acc: 0.8988\n",
      "Epoch 245/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2802 - acc: 0.8999 - val_loss: 0.3075 - val_acc: 0.8970\n",
      "Epoch 246/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2786 - acc: 0.9008 - val_loss: 0.3021 - val_acc: 0.8983\n",
      "Epoch 247/500\n",
      "8648/8648 [==============================] - 0s 19us/step - loss: 0.2777 - acc: 0.9014 - val_loss: 0.3033 - val_acc: 0.8967\n",
      "Epoch 248/500\n",
      "8648/8648 [==============================] - 0s 24us/step - loss: 0.2825 - acc: 0.9023 - val_loss: 0.3098 - val_acc: 0.8983\n",
      "Epoch 249/500\n",
      "8648/8648 [==============================] - 0s 22us/step - loss: 0.2805 - acc: 0.9007 - val_loss: 0.3050 - val_acc: 0.9002\n",
      "Epoch 250/500\n",
      "8648/8648 [==============================] - 0s 27us/step - loss: 0.2780 - acc: 0.9011 - val_loss: 0.3050 - val_acc: 0.8988\n",
      "Epoch 251/500\n",
      "8648/8648 [==============================] - 0s 21us/step - loss: 0.2786 - acc: 0.9011 - val_loss: 0.3057 - val_acc: 0.8967\n",
      "Epoch 252/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2779 - acc: 0.9015 - val_loss: 0.3074 - val_acc: 0.8994\n",
      "Epoch 253/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2783 - acc: 0.9014 - val_loss: 0.3036 - val_acc: 0.8980\n",
      "Epoch 254/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2773 - acc: 0.9018 - val_loss: 0.3073 - val_acc: 0.8991\n",
      "Epoch 255/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2808 - acc: 0.9018 - val_loss: 0.3031 - val_acc: 0.8978\n",
      "Epoch 256/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2770 - acc: 0.9022 - val_loss: 0.3020 - val_acc: 0.8988\n",
      "Epoch 257/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2772 - acc: 0.9016 - val_loss: 0.3026 - val_acc: 0.8991\n",
      "Epoch 258/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2772 - acc: 0.9021 - val_loss: 0.3012 - val_acc: 0.8996\n",
      "Epoch 259/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2796 - acc: 0.9000 - val_loss: 0.3025 - val_acc: 0.8975\n",
      "Epoch 260/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2780 - acc: 0.9007 - val_loss: 0.3018 - val_acc: 0.8988\n",
      "Epoch 261/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2783 - acc: 0.9010 - val_loss: 0.3050 - val_acc: 0.8970\n",
      "Epoch 262/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2793 - acc: 0.9012 - val_loss: 0.3008 - val_acc: 0.8967\n",
      "Epoch 263/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2778 - acc: 0.9011 - val_loss: 0.3051 - val_acc: 0.8978\n",
      "Epoch 264/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2799 - acc: 0.9018 - val_loss: 0.3039 - val_acc: 0.8980\n",
      "Epoch 265/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2766 - acc: 0.9019 - val_loss: 0.3055 - val_acc: 0.8988\n",
      "Epoch 266/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2779 - acc: 0.9007 - val_loss: 0.3032 - val_acc: 0.8986\n",
      "Epoch 267/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2782 - acc: 0.9001 - val_loss: 0.3056 - val_acc: 0.8980\n",
      "Epoch 268/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2765 - acc: 0.9006 - val_loss: 0.3024 - val_acc: 0.8988\n",
      "Epoch 269/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2757 - acc: 0.9029 - val_loss: 0.3078 - val_acc: 0.8975\n",
      "Epoch 270/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2770 - acc: 0.9010 - val_loss: 0.3051 - val_acc: 0.8980\n",
      "Epoch 271/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2781 - acc: 0.9025 - val_loss: 0.3108 - val_acc: 0.8972\n",
      "Epoch 272/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2782 - acc: 0.9010 - val_loss: 0.3067 - val_acc: 0.8996\n",
      "Epoch 273/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2775 - acc: 0.9009 - val_loss: 0.3078 - val_acc: 0.8953\n",
      "Epoch 274/500\n",
      "8648/8648 [==============================] - 0s 28us/step - loss: 0.2786 - acc: 0.9004 - val_loss: 0.3022 - val_acc: 0.8986\n",
      "Epoch 275/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2771 - acc: 0.9016 - val_loss: 0.3036 - val_acc: 0.8980\n",
      "Epoch 276/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2760 - acc: 0.9010 - val_loss: 0.3007 - val_acc: 0.8983\n",
      "Epoch 277/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2758 - acc: 0.9018 - val_loss: 0.3038 - val_acc: 0.8980\n",
      "Epoch 278/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2743 - acc: 0.9026 - val_loss: 0.3048 - val_acc: 0.8994\n",
      "Epoch 279/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2767 - acc: 0.9014 - val_loss: 0.3026 - val_acc: 0.8988\n",
      "Epoch 280/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2775 - acc: 0.9017 - val_loss: 0.3054 - val_acc: 0.8975\n",
      "Epoch 281/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2751 - acc: 0.9017 - val_loss: 0.3100 - val_acc: 0.8983\n",
      "Epoch 282/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2773 - acc: 0.9011 - val_loss: 0.3111 - val_acc: 0.8980\n",
      "Epoch 283/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2774 - acc: 0.9007 - val_loss: 0.3052 - val_acc: 0.8964\n",
      "Epoch 284/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2766 - acc: 0.9026 - val_loss: 0.3080 - val_acc: 0.8980\n",
      "Epoch 285/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2766 - acc: 0.9011 - val_loss: 0.3001 - val_acc: 0.8999\n",
      "Epoch 286/500\n",
      "8648/8648 [==============================] - 0s 22us/step - loss: 0.2781 - acc: 0.9021 - val_loss: 0.3057 - val_acc: 0.8978\n",
      "Epoch 287/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2768 - acc: 0.9022 - val_loss: 0.3010 - val_acc: 0.8988\n",
      "Epoch 288/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2817 - acc: 0.9001 - val_loss: 0.3058 - val_acc: 0.8983\n",
      "Epoch 289/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2799 - acc: 0.9006 - val_loss: 0.3102 - val_acc: 0.8970\n",
      "Epoch 290/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2770 - acc: 0.9012 - val_loss: 0.3064 - val_acc: 0.8986\n",
      "Epoch 291/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2751 - acc: 0.9014 - val_loss: 0.3021 - val_acc: 0.8999\n",
      "Epoch 292/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2742 - acc: 0.9025 - val_loss: 0.3018 - val_acc: 0.8994\n",
      "Epoch 293/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2740 - acc: 0.9007 - val_loss: 0.3126 - val_acc: 0.8994\n",
      "Epoch 294/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2795 - acc: 0.9001 - val_loss: 0.3136 - val_acc: 0.8983\n",
      "Epoch 295/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2746 - acc: 0.9017 - val_loss: 0.3052 - val_acc: 0.8970\n",
      "Epoch 296/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2747 - acc: 0.9040 - val_loss: 0.3056 - val_acc: 0.8991\n",
      "Epoch 297/500\n",
      "8648/8648 [==============================] - 0s 20us/step - loss: 0.2736 - acc: 0.9017 - val_loss: 0.3101 - val_acc: 0.8999\n",
      "Epoch 298/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2780 - acc: 0.9006 - val_loss: 0.3035 - val_acc: 0.8975\n",
      "Epoch 299/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2730 - acc: 0.9031 - val_loss: 0.3059 - val_acc: 0.8991\n",
      "Epoch 300/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2756 - acc: 0.9029 - val_loss: 0.3068 - val_acc: 0.8983\n",
      "Epoch 301/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2749 - acc: 0.9024 - val_loss: 0.3021 - val_acc: 0.8978\n",
      "Epoch 302/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2738 - acc: 0.9018 - val_loss: 0.3066 - val_acc: 0.8970\n",
      "Epoch 303/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2744 - acc: 0.9029 - val_loss: 0.3056 - val_acc: 0.8986\n",
      "Epoch 304/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2755 - acc: 0.9014 - val_loss: 0.3142 - val_acc: 0.8951\n",
      "Epoch 305/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2763 - acc: 0.8999 - val_loss: 0.2993 - val_acc: 0.8991\n",
      "Epoch 306/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2743 - acc: 0.9021 - val_loss: 0.3016 - val_acc: 0.8986\n",
      "Epoch 307/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2748 - acc: 0.9022 - val_loss: 0.3053 - val_acc: 0.8967\n",
      "Epoch 308/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2754 - acc: 0.9006 - val_loss: 0.3009 - val_acc: 0.8983\n",
      "Epoch 309/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2755 - acc: 0.9024 - val_loss: 0.3056 - val_acc: 0.8972\n",
      "Epoch 310/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2763 - acc: 0.9003 - val_loss: 0.2992 - val_acc: 0.8978\n",
      "Epoch 311/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2746 - acc: 0.9012 - val_loss: 0.2991 - val_acc: 0.8994\n",
      "Epoch 312/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2740 - acc: 0.9023 - val_loss: 0.3095 - val_acc: 0.8978\n",
      "Epoch 313/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2897 - acc: 0.9017 - val_loss: 0.3096 - val_acc: 0.8972\n",
      "Epoch 314/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2769 - acc: 0.9018 - val_loss: 0.2962 - val_acc: 0.9002\n",
      "Epoch 315/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2737 - acc: 0.9014 - val_loss: 0.2984 - val_acc: 0.8975\n",
      "Epoch 316/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2740 - acc: 0.9014 - val_loss: 0.3032 - val_acc: 0.8986\n",
      "Epoch 317/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2728 - acc: 0.9017 - val_loss: 0.3015 - val_acc: 0.8996\n",
      "Epoch 318/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2796 - acc: 0.8997 - val_loss: 0.2973 - val_acc: 0.8970\n",
      "Epoch 319/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2753 - acc: 0.9004 - val_loss: 0.2979 - val_acc: 0.8991\n",
      "Epoch 320/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2738 - acc: 0.9011 - val_loss: 0.2964 - val_acc: 0.8988\n",
      "Epoch 321/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2733 - acc: 0.9008 - val_loss: 0.2965 - val_acc: 0.8975\n",
      "Epoch 322/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2730 - acc: 0.9029 - val_loss: 0.2966 - val_acc: 0.8986\n",
      "Epoch 323/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2741 - acc: 0.9014 - val_loss: 0.3065 - val_acc: 0.8967\n",
      "Epoch 324/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2721 - acc: 0.9037 - val_loss: 0.2992 - val_acc: 0.8983\n",
      "Epoch 325/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2747 - acc: 0.9029 - val_loss: 0.3018 - val_acc: 0.8980\n",
      "Epoch 326/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2731 - acc: 0.9022 - val_loss: 0.3021 - val_acc: 0.8967\n",
      "Epoch 327/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2734 - acc: 0.9033 - val_loss: 0.2995 - val_acc: 0.8988\n",
      "Epoch 328/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2736 - acc: 0.9017 - val_loss: 0.3033 - val_acc: 0.8972\n",
      "Epoch 329/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2722 - acc: 0.9028 - val_loss: 0.3069 - val_acc: 0.8970\n",
      "Epoch 330/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2730 - acc: 0.9017 - val_loss: 0.3098 - val_acc: 0.8978\n",
      "Epoch 331/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2778 - acc: 0.9015 - val_loss: 0.3016 - val_acc: 0.8991\n",
      "Epoch 332/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2732 - acc: 0.9021 - val_loss: 0.3022 - val_acc: 0.8978\n",
      "Epoch 333/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2713 - acc: 0.9037 - val_loss: 0.3031 - val_acc: 0.8978\n",
      "Epoch 334/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2736 - acc: 0.9037 - val_loss: 0.3083 - val_acc: 0.8980\n",
      "Epoch 335/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2765 - acc: 0.9026 - val_loss: 0.3104 - val_acc: 0.8975\n",
      "Epoch 336/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2751 - acc: 0.9004 - val_loss: 0.2997 - val_acc: 0.8983\n",
      "Epoch 337/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2755 - acc: 0.8999 - val_loss: 0.3015 - val_acc: 0.8980\n",
      "Epoch 338/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2757 - acc: 0.9009 - val_loss: 0.2999 - val_acc: 0.8978\n",
      "Epoch 339/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2738 - acc: 0.9021 - val_loss: 0.3010 - val_acc: 0.8983\n",
      "Epoch 340/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2720 - acc: 0.9019 - val_loss: 0.3073 - val_acc: 0.8975\n",
      "Epoch 341/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2704 - acc: 0.9029 - val_loss: 0.3064 - val_acc: 0.8959\n",
      "Epoch 342/500\n",
      "8648/8648 [==============================] - 0s 19us/step - loss: 0.2739 - acc: 0.9015 - val_loss: 0.3014 - val_acc: 0.9007\n",
      "Epoch 343/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2725 - acc: 0.9026 - val_loss: 0.3056 - val_acc: 0.8978\n",
      "Epoch 344/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2726 - acc: 0.9025 - val_loss: 0.3006 - val_acc: 0.8980\n",
      "Epoch 345/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2717 - acc: 0.9030 - val_loss: 0.3117 - val_acc: 0.8991\n",
      "Epoch 346/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2735 - acc: 0.9029 - val_loss: 0.3012 - val_acc: 0.8978\n",
      "Epoch 347/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2719 - acc: 0.9033 - val_loss: 0.2984 - val_acc: 0.8972\n",
      "Epoch 348/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2737 - acc: 0.9029 - val_loss: 0.3006 - val_acc: 0.8986\n",
      "Epoch 349/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2714 - acc: 0.9026 - val_loss: 0.3056 - val_acc: 0.8983\n",
      "Epoch 350/500\n",
      "8648/8648 [==============================] - 0s 19us/step - loss: 0.2719 - acc: 0.9034 - val_loss: 0.3042 - val_acc: 0.8986\n",
      "Epoch 351/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2714 - acc: 0.9030 - val_loss: 0.3030 - val_acc: 0.8983\n",
      "Epoch 352/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2713 - acc: 0.9031 - val_loss: 0.2962 - val_acc: 0.8980\n",
      "Epoch 353/500\n",
      "8648/8648 [==============================] - 0s 23us/step - loss: 0.2752 - acc: 0.9006 - val_loss: 0.3003 - val_acc: 0.9007\n",
      "Epoch 354/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2710 - acc: 0.9019 - val_loss: 0.2981 - val_acc: 0.8967\n",
      "Epoch 355/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2706 - acc: 0.9030 - val_loss: 0.2985 - val_acc: 0.8991\n",
      "Epoch 356/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2727 - acc: 0.9028 - val_loss: 0.2992 - val_acc: 0.8972\n",
      "Epoch 357/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2705 - acc: 0.9029 - val_loss: 0.2987 - val_acc: 0.8991\n",
      "Epoch 358/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2700 - acc: 0.9033 - val_loss: 0.3090 - val_acc: 0.8980\n",
      "Epoch 359/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2721 - acc: 0.9016 - val_loss: 0.3043 - val_acc: 0.8972\n",
      "Epoch 360/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2749 - acc: 0.9026 - val_loss: 0.3304 - val_acc: 0.8978\n",
      "Epoch 361/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2747 - acc: 0.9010 - val_loss: 0.3108 - val_acc: 0.8970\n",
      "Epoch 362/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2734 - acc: 0.9017 - val_loss: 0.3095 - val_acc: 0.8978\n",
      "Epoch 363/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2741 - acc: 0.9029 - val_loss: 0.3038 - val_acc: 0.8983\n",
      "Epoch 364/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2699 - acc: 0.9037 - val_loss: 0.3107 - val_acc: 0.8964\n",
      "Epoch 365/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2707 - acc: 0.9033 - val_loss: 0.3058 - val_acc: 0.8986\n",
      "Epoch 366/500\n",
      "8648/8648 [==============================] - 0s 22us/step - loss: 0.2695 - acc: 0.9028 - val_loss: 0.3109 - val_acc: 0.8980\n",
      "Epoch 367/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2710 - acc: 0.9025 - val_loss: 0.3072 - val_acc: 0.8961\n",
      "Epoch 368/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2725 - acc: 0.9038 - val_loss: 0.2974 - val_acc: 0.8961\n",
      "Epoch 369/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2722 - acc: 0.9031 - val_loss: 0.3057 - val_acc: 0.8988\n",
      "Epoch 370/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2706 - acc: 0.9032 - val_loss: 0.3093 - val_acc: 0.8975\n",
      "Epoch 371/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2695 - acc: 0.9032 - val_loss: 0.3128 - val_acc: 0.8972\n",
      "Epoch 372/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2739 - acc: 0.9009 - val_loss: 0.3123 - val_acc: 0.8975\n",
      "Epoch 373/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2724 - acc: 0.9009 - val_loss: 0.3036 - val_acc: 0.8994\n",
      "Epoch 374/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2705 - acc: 0.9025 - val_loss: 0.3056 - val_acc: 0.8994\n",
      "Epoch 375/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2702 - acc: 0.9026 - val_loss: 0.3025 - val_acc: 0.8961\n",
      "Epoch 376/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2716 - acc: 0.9024 - val_loss: 0.3027 - val_acc: 0.8983\n",
      "Epoch 377/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2698 - acc: 0.9037 - val_loss: 0.3026 - val_acc: 0.8959\n",
      "Epoch 378/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2736 - acc: 0.9022 - val_loss: 0.3035 - val_acc: 0.8986\n",
      "Epoch 379/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2695 - acc: 0.9025 - val_loss: 0.2957 - val_acc: 0.8986\n",
      "Epoch 380/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2704 - acc: 0.9030 - val_loss: 0.3078 - val_acc: 0.8983\n",
      "Epoch 381/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2704 - acc: 0.9023 - val_loss: 0.3005 - val_acc: 0.8986\n",
      "Epoch 382/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2704 - acc: 0.9014 - val_loss: 0.3051 - val_acc: 0.8988\n",
      "Epoch 383/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2713 - acc: 0.9028 - val_loss: 0.3028 - val_acc: 0.8980\n",
      "Epoch 384/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2705 - acc: 0.9047 - val_loss: 0.3083 - val_acc: 0.8980\n",
      "Epoch 385/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2727 - acc: 0.9025 - val_loss: 0.3008 - val_acc: 0.8996\n",
      "Epoch 386/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2723 - acc: 0.9008 - val_loss: 0.2946 - val_acc: 0.8988\n",
      "Epoch 387/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2699 - acc: 0.9026 - val_loss: 0.3111 - val_acc: 0.8972\n",
      "Epoch 388/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2705 - acc: 0.9026 - val_loss: 0.2969 - val_acc: 0.8996\n",
      "Epoch 389/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2699 - acc: 0.9031 - val_loss: 0.3114 - val_acc: 0.8978\n",
      "Epoch 390/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2709 - acc: 0.9021 - val_loss: 0.3029 - val_acc: 0.9029\n",
      "Epoch 391/500\n",
      "8648/8648 [==============================] - 0s 23us/step - loss: 0.2728 - acc: 0.9026 - val_loss: 0.3057 - val_acc: 0.8994\n",
      "Epoch 392/500\n",
      "8648/8648 [==============================] - 0s 27us/step - loss: 0.2683 - acc: 0.9031 - val_loss: 0.3001 - val_acc: 0.8967\n",
      "Epoch 393/500\n",
      "8648/8648 [==============================] - 0s 27us/step - loss: 0.2690 - acc: 0.9026 - val_loss: 0.3061 - val_acc: 0.8986\n",
      "Epoch 394/500\n",
      "8648/8648 [==============================] - 0s 24us/step - loss: 0.2708 - acc: 0.9034 - val_loss: 0.3024 - val_acc: 0.8967\n",
      "Epoch 395/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2707 - acc: 0.9031 - val_loss: 0.3079 - val_acc: 0.8986\n",
      "Epoch 396/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2698 - acc: 0.9028 - val_loss: 0.3037 - val_acc: 0.8972\n",
      "Epoch 397/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2685 - acc: 0.9048 - val_loss: 0.2972 - val_acc: 0.8983\n",
      "Epoch 398/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2694 - acc: 0.9017 - val_loss: 0.3075 - val_acc: 0.8970\n",
      "Epoch 399/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2731 - acc: 0.9037 - val_loss: 0.3102 - val_acc: 0.8970\n",
      "Epoch 400/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2707 - acc: 0.9033 - val_loss: 0.3099 - val_acc: 0.8959\n",
      "Epoch 401/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2719 - acc: 0.9029 - val_loss: 0.3030 - val_acc: 0.8975\n",
      "Epoch 402/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2750 - acc: 0.9032 - val_loss: 0.3049 - val_acc: 0.8980\n",
      "Epoch 403/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2700 - acc: 0.9037 - val_loss: 0.3097 - val_acc: 0.9007\n",
      "Epoch 404/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2703 - acc: 0.9025 - val_loss: 0.3066 - val_acc: 0.9015\n",
      "Epoch 405/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2721 - acc: 0.9008 - val_loss: 0.3091 - val_acc: 0.8986\n",
      "Epoch 406/500\n",
      "8648/8648 [==============================] - 0s 19us/step - loss: 0.2688 - acc: 0.9034 - val_loss: 0.3119 - val_acc: 0.8961\n",
      "Epoch 407/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2721 - acc: 0.9024 - val_loss: 0.3053 - val_acc: 0.9013\n",
      "Epoch 408/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2685 - acc: 0.9037 - val_loss: 0.3033 - val_acc: 0.8999\n",
      "Epoch 409/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2714 - acc: 0.9025 - val_loss: 0.3104 - val_acc: 0.8991\n",
      "Epoch 410/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2680 - acc: 0.9052 - val_loss: 0.3064 - val_acc: 0.9002\n",
      "Epoch 411/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2719 - acc: 0.9039 - val_loss: 0.3091 - val_acc: 0.8996\n",
      "Epoch 412/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2689 - acc: 0.9037 - val_loss: 0.3045 - val_acc: 0.8983\n",
      "Epoch 413/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2711 - acc: 0.9019 - val_loss: 0.3143 - val_acc: 0.8980\n",
      "Epoch 414/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2705 - acc: 0.9018 - val_loss: 0.3054 - val_acc: 0.8964\n",
      "Epoch 415/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2694 - acc: 0.9029 - val_loss: 0.2965 - val_acc: 0.8996\n",
      "Epoch 416/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2698 - acc: 0.9031 - val_loss: 0.2993 - val_acc: 0.8994\n",
      "Epoch 417/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2697 - acc: 0.9034 - val_loss: 0.3037 - val_acc: 0.8980\n",
      "Epoch 418/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2708 - acc: 0.9016 - val_loss: 0.3071 - val_acc: 0.8986\n",
      "Epoch 419/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2678 - acc: 0.9045 - val_loss: 0.3121 - val_acc: 0.8970\n",
      "Epoch 420/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2686 - acc: 0.9028 - val_loss: 0.3160 - val_acc: 0.8959\n",
      "Epoch 421/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2682 - acc: 0.9030 - val_loss: 0.3179 - val_acc: 0.8972\n",
      "Epoch 422/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2682 - acc: 0.9041 - val_loss: 0.3149 - val_acc: 0.8956\n",
      "Epoch 423/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2718 - acc: 0.9017 - val_loss: 0.2981 - val_acc: 0.8967\n",
      "Epoch 424/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2681 - acc: 0.9043 - val_loss: 0.2993 - val_acc: 0.9021\n",
      "Epoch 425/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2692 - acc: 0.9030 - val_loss: 0.3085 - val_acc: 0.8988\n",
      "Epoch 426/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2705 - acc: 0.9022 - val_loss: 0.3083 - val_acc: 0.8972\n",
      "Epoch 427/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2702 - acc: 0.9036 - val_loss: 0.2987 - val_acc: 0.8972\n",
      "Epoch 428/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2707 - acc: 0.9033 - val_loss: 0.3057 - val_acc: 0.8988\n",
      "Epoch 429/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2692 - acc: 0.9032 - val_loss: 0.3049 - val_acc: 0.8980\n",
      "Epoch 430/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2673 - acc: 0.9034 - val_loss: 0.3059 - val_acc: 0.9010\n",
      "Epoch 431/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2728 - acc: 0.9003 - val_loss: 0.3027 - val_acc: 0.8986\n",
      "Epoch 432/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2682 - acc: 0.9030 - val_loss: 0.3031 - val_acc: 0.8975\n",
      "Epoch 433/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2682 - acc: 0.9038 - val_loss: 0.3062 - val_acc: 0.8975\n",
      "Epoch 434/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2684 - acc: 0.9021 - val_loss: 0.3029 - val_acc: 0.9005\n",
      "Epoch 435/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2682 - acc: 0.9041 - val_loss: 0.3141 - val_acc: 0.9005\n",
      "Epoch 436/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2680 - acc: 0.9026 - val_loss: 0.3060 - val_acc: 0.8980\n",
      "Epoch 437/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2683 - acc: 0.9032 - val_loss: 0.3067 - val_acc: 0.9023\n",
      "Epoch 438/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2665 - acc: 0.9038 - val_loss: 0.3111 - val_acc: 0.9005\n",
      "Epoch 439/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2671 - acc: 0.9031 - val_loss: 0.3166 - val_acc: 0.9007\n",
      "Epoch 440/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2687 - acc: 0.9024 - val_loss: 0.2980 - val_acc: 0.9007\n",
      "Epoch 441/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2663 - acc: 0.9048 - val_loss: 0.3118 - val_acc: 0.9015\n",
      "Epoch 442/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2691 - acc: 0.9022 - val_loss: 0.3052 - val_acc: 0.8986\n",
      "Epoch 443/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2697 - acc: 0.9032 - val_loss: 0.3031 - val_acc: 0.9013\n",
      "Epoch 444/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2670 - acc: 0.9031 - val_loss: 0.3083 - val_acc: 0.8983\n",
      "Epoch 445/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2704 - acc: 0.9033 - val_loss: 0.3211 - val_acc: 0.9005\n",
      "Epoch 446/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2699 - acc: 0.9028 - val_loss: 0.3048 - val_acc: 0.8991\n",
      "Epoch 447/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2698 - acc: 0.9021 - val_loss: 0.2978 - val_acc: 0.8980\n",
      "Epoch 448/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2732 - acc: 0.9004 - val_loss: 0.3082 - val_acc: 0.8980\n",
      "Epoch 449/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2698 - acc: 0.9025 - val_loss: 0.3081 - val_acc: 0.9005\n",
      "Epoch 450/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2676 - acc: 0.9049 - val_loss: 0.3050 - val_acc: 0.9013\n",
      "Epoch 451/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2689 - acc: 0.9040 - val_loss: 0.3096 - val_acc: 0.9018\n",
      "Epoch 452/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2670 - acc: 0.9046 - val_loss: 0.3044 - val_acc: 0.9021\n",
      "Epoch 453/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2689 - acc: 0.9028 - val_loss: 0.3065 - val_acc: 0.9002\n",
      "Epoch 454/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2681 - acc: 0.9030 - val_loss: 0.3030 - val_acc: 0.9013\n",
      "Epoch 455/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2660 - acc: 0.9048 - val_loss: 0.3096 - val_acc: 0.9010\n",
      "Epoch 456/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2668 - acc: 0.9033 - val_loss: 0.3076 - val_acc: 0.8999\n",
      "Epoch 457/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2698 - acc: 0.9009 - val_loss: 0.3061 - val_acc: 0.8988\n",
      "Epoch 458/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2687 - acc: 0.9023 - val_loss: 0.3077 - val_acc: 0.9015\n",
      "Epoch 459/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2700 - acc: 0.9024 - val_loss: 0.3065 - val_acc: 0.8991\n",
      "Epoch 460/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2658 - acc: 0.9031 - val_loss: 0.3046 - val_acc: 0.8978\n",
      "Epoch 461/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2653 - acc: 0.9045 - val_loss: 0.3158 - val_acc: 0.8978\n",
      "Epoch 462/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2686 - acc: 0.9026 - val_loss: 0.3093 - val_acc: 0.8967\n",
      "Epoch 463/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2675 - acc: 0.9038 - val_loss: 0.3024 - val_acc: 0.9002\n",
      "Epoch 464/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2665 - acc: 0.9046 - val_loss: 0.3092 - val_acc: 0.9023\n",
      "Epoch 465/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2694 - acc: 0.9038 - val_loss: 0.3050 - val_acc: 0.9015\n",
      "Epoch 466/500\n",
      "8648/8648 [==============================] - 0s 16us/step - loss: 0.2677 - acc: 0.9044 - val_loss: 0.3086 - val_acc: 0.8978\n",
      "Epoch 467/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2679 - acc: 0.9043 - val_loss: 0.3097 - val_acc: 0.8994\n",
      "Epoch 468/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2699 - acc: 0.9037 - val_loss: 0.3075 - val_acc: 0.9013\n",
      "Epoch 469/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2668 - acc: 0.9031 - val_loss: 0.3127 - val_acc: 0.8986\n",
      "Epoch 470/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2663 - acc: 0.9043 - val_loss: 0.3063 - val_acc: 0.8996\n",
      "Epoch 471/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2680 - acc: 0.9033 - val_loss: 0.3051 - val_acc: 0.9007\n",
      "Epoch 472/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2665 - acc: 0.9056 - val_loss: 0.3030 - val_acc: 0.9005\n",
      "Epoch 473/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2652 - acc: 0.9048 - val_loss: 0.3055 - val_acc: 0.9010\n",
      "Epoch 474/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2666 - acc: 0.9048 - val_loss: 0.3085 - val_acc: 0.9010\n",
      "Epoch 475/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2674 - acc: 0.9031 - val_loss: 0.3083 - val_acc: 0.9013\n",
      "Epoch 476/500\n",
      "8648/8648 [==============================] - ETA: 0s - loss: 0.2711 - acc: 0.902 - 0s 16us/step - loss: 0.2670 - acc: 0.9040 - val_loss: 0.3073 - val_acc: 0.9005\n",
      "Epoch 477/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2666 - acc: 0.9031 - val_loss: 0.3244 - val_acc: 0.8991\n",
      "Epoch 478/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2700 - acc: 0.9032 - val_loss: 0.3082 - val_acc: 0.8999\n",
      "Epoch 479/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2662 - acc: 0.9046 - val_loss: 0.3062 - val_acc: 0.8986\n",
      "Epoch 480/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2650 - acc: 0.9029 - val_loss: 0.3074 - val_acc: 0.9013\n",
      "Epoch 481/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2672 - acc: 0.9024 - val_loss: 0.3079 - val_acc: 0.9002\n",
      "Epoch 482/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2671 - acc: 0.9030 - val_loss: 0.3108 - val_acc: 0.9013\n",
      "Epoch 483/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2654 - acc: 0.9041 - val_loss: 0.3068 - val_acc: 0.8980\n",
      "Epoch 484/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2658 - acc: 0.9041 - val_loss: 0.3186 - val_acc: 0.8996\n",
      "Epoch 485/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2663 - acc: 0.9030 - val_loss: 0.3040 - val_acc: 0.8996\n",
      "Epoch 486/500\n",
      "8648/8648 [==============================] - 0s 18us/step - loss: 0.2671 - acc: 0.9036 - val_loss: 0.3061 - val_acc: 0.9007\n",
      "Epoch 487/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2653 - acc: 0.9039 - val_loss: 0.3104 - val_acc: 0.9010\n",
      "Epoch 488/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2665 - acc: 0.9029 - val_loss: 0.3105 - val_acc: 0.8991\n",
      "Epoch 489/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2668 - acc: 0.9040 - val_loss: 0.3102 - val_acc: 0.9013\n",
      "Epoch 490/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2651 - acc: 0.9049 - val_loss: 0.3121 - val_acc: 0.9007\n",
      "Epoch 491/500\n",
      "8648/8648 [==============================] - 0s 13us/step - loss: 0.2684 - acc: 0.9034 - val_loss: 0.3090 - val_acc: 0.9002\n",
      "Epoch 492/500\n",
      "8648/8648 [==============================] - 0s 11us/step - loss: 0.2683 - acc: 0.9032 - val_loss: 0.3061 - val_acc: 0.9015\n",
      "Epoch 493/500\n",
      "8648/8648 [==============================] - 0s 12us/step - loss: 0.2659 - acc: 0.9034 - val_loss: 0.3047 - val_acc: 0.8996\n",
      "Epoch 494/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2667 - acc: 0.9039 - val_loss: 0.3075 - val_acc: 0.8988\n",
      "Epoch 495/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2674 - acc: 0.9037 - val_loss: 0.3102 - val_acc: 0.8975\n",
      "Epoch 496/500\n",
      "8648/8648 [==============================] - 0s 15us/step - loss: 0.2662 - acc: 0.9033 - val_loss: 0.3106 - val_acc: 0.8980\n",
      "Epoch 497/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2661 - acc: 0.9033 - val_loss: 0.3038 - val_acc: 0.8975\n",
      "Epoch 498/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2657 - acc: 0.9053 - val_loss: 0.3113 - val_acc: 0.9002\n",
      "Epoch 499/500\n",
      "8648/8648 [==============================] - 0s 14us/step - loss: 0.2671 - acc: 0.9026 - val_loss: 0.3096 - val_acc: 0.8996\n",
      "Epoch 500/500\n",
      "8648/8648 [==============================] - 0s 17us/step - loss: 0.2650 - acc: 0.9056 - val_loss: 0.3096 - val_acc: 0.9005\n",
      "3707/3707 [==============================] - 0s 3us/step\n",
      "5 21 403 403 12494 11887 21 1093 1072\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11887 11887\n",
      "../linkPrediction/dataframes/apnea\n",
      "article (11887, 7, 11) --------------------------------------------------------------------\n",
      "(11887, 11) (11887,)\n",
      "[11887, 11, 1]\n",
      "(8320, 11) (8320,)\n",
      "Train on 8320 samples, validate on 3567 samples\n",
      "Epoch 1/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 1.4829 - acc: 0.7466 - val_loss: 0.8259 - val_acc: 0.8694\n",
      "Epoch 2/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.8420 - acc: 0.8897 - val_loss: 0.7567 - val_acc: 0.9013\n",
      "Epoch 3/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.7712 - acc: 0.8821 - val_loss: 0.7271 - val_acc: 0.8691\n",
      "Epoch 4/500\n",
      "8320/8320 [==============================] - 0s 23us/step - loss: 0.7068 - acc: 0.8790 - val_loss: 0.6271 - val_acc: 0.9041\n",
      "Epoch 5/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.6041 - acc: 0.8897 - val_loss: 0.5783 - val_acc: 0.8862\n",
      "Epoch 6/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.6220 - acc: 0.8918 - val_loss: 0.7039 - val_acc: 0.9041\n",
      "Epoch 7/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.6027 - acc: 0.8939 - val_loss: 0.5426 - val_acc: 0.8800\n",
      "Epoch 8/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.5315 - acc: 0.8879 - val_loss: 0.4847 - val_acc: 0.9005\n",
      "Epoch 9/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.5377 - acc: 0.8851 - val_loss: 0.4696 - val_acc: 0.8937\n",
      "Epoch 10/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.4907 - acc: 0.8909 - val_loss: 0.4889 - val_acc: 0.8895\n",
      "Epoch 11/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.5012 - acc: 0.8918 - val_loss: 0.4677 - val_acc: 0.8909\n",
      "Epoch 12/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.4688 - acc: 0.8929 - val_loss: 0.4405 - val_acc: 0.9016\n",
      "Epoch 13/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.4761 - acc: 0.8918 - val_loss: 0.5224 - val_acc: 0.8738\n",
      "Epoch 14/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.4690 - acc: 0.8905 - val_loss: 0.5390 - val_acc: 0.8741\n",
      "Epoch 15/500\n",
      "8320/8320 [==============================] - 0s 11us/step - loss: 0.4763 - acc: 0.8916 - val_loss: 0.4189 - val_acc: 0.8999\n",
      "Epoch 16/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.4259 - acc: 0.8921 - val_loss: 0.4374 - val_acc: 0.8921\n",
      "Epoch 17/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.4317 - acc: 0.8933 - val_loss: 0.4031 - val_acc: 0.9024\n",
      "Epoch 18/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.4702 - acc: 0.8895 - val_loss: 0.4779 - val_acc: 0.9013\n",
      "Epoch 19/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.4350 - acc: 0.8936 - val_loss: 0.4372 - val_acc: 0.9038\n",
      "Epoch 20/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.4486 - acc: 0.8927 - val_loss: 0.4905 - val_acc: 0.8895\n",
      "Epoch 21/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.4067 - acc: 0.8948 - val_loss: 0.4142 - val_acc: 0.9008\n",
      "Epoch 22/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.4014 - acc: 0.8940 - val_loss: 0.4139 - val_acc: 0.8988\n",
      "Epoch 23/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.4265 - acc: 0.8933 - val_loss: 0.3678 - val_acc: 0.9030\n",
      "Epoch 24/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.4072 - acc: 0.8935 - val_loss: 0.3933 - val_acc: 0.8999\n",
      "Epoch 25/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.4402 - acc: 0.8893 - val_loss: 0.4332 - val_acc: 0.8960\n",
      "Epoch 26/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.4015 - acc: 0.8948 - val_loss: 0.3728 - val_acc: 0.9041\n",
      "Epoch 27/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.3827 - acc: 0.8957 - val_loss: 0.4195 - val_acc: 0.8985\n",
      "Epoch 28/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.4191 - acc: 0.8951 - val_loss: 0.3868 - val_acc: 0.9013\n",
      "Epoch 29/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3991 - acc: 0.8962 - val_loss: 0.4236 - val_acc: 0.9033\n",
      "Epoch 30/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.4579 - acc: 0.8913 - val_loss: 0.4182 - val_acc: 0.8974\n",
      "Epoch 31/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.3843 - acc: 0.8960 - val_loss: 0.3728 - val_acc: 0.9052\n",
      "Epoch 32/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.4039 - acc: 0.8956 - val_loss: 0.5066 - val_acc: 0.8795\n",
      "Epoch 33/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.4008 - acc: 0.8918 - val_loss: 0.4530 - val_acc: 0.9064\n",
      "Epoch 34/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3999 - acc: 0.8957 - val_loss: 0.3795 - val_acc: 0.8988\n",
      "Epoch 35/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.3791 - acc: 0.8983 - val_loss: 0.3565 - val_acc: 0.9027\n",
      "Epoch 36/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.4209 - acc: 0.8959 - val_loss: 0.3607 - val_acc: 0.9022\n",
      "Epoch 37/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3870 - acc: 0.8933 - val_loss: 0.3716 - val_acc: 0.8977\n",
      "Epoch 38/500\n",
      "8320/8320 [==============================] - 0s 10us/step - loss: 0.3977 - acc: 0.8953 - val_loss: 0.5414 - val_acc: 0.8792\n",
      "Epoch 39/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.4058 - acc: 0.8923 - val_loss: 0.3823 - val_acc: 0.9005\n",
      "Epoch 40/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.4508 - acc: 0.8905 - val_loss: 0.3784 - val_acc: 0.9027\n",
      "Epoch 41/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.4034 - acc: 0.8957 - val_loss: 0.3842 - val_acc: 0.8960\n",
      "Epoch 42/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3805 - acc: 0.8963 - val_loss: 0.4512 - val_acc: 0.9047\n",
      "Epoch 43/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.4160 - acc: 0.8940 - val_loss: 0.3851 - val_acc: 0.9005\n",
      "Epoch 44/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3954 - acc: 0.8940 - val_loss: 0.4552 - val_acc: 0.9038\n",
      "Epoch 45/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.4063 - acc: 0.8913 - val_loss: 0.4393 - val_acc: 0.8904\n",
      "Epoch 46/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3947 - acc: 0.8971 - val_loss: 0.4006 - val_acc: 0.9030\n",
      "Epoch 47/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.3571 - acc: 0.8982 - val_loss: 0.4640 - val_acc: 0.8898\n",
      "Epoch 48/500\n",
      "8320/8320 [==============================] - 0s 11us/step - loss: 0.3561 - acc: 0.8995 - val_loss: 0.3653 - val_acc: 0.9030\n",
      "Epoch 49/500\n",
      "8320/8320 [==============================] - 0s 11us/step - loss: 0.3924 - acc: 0.8960 - val_loss: 0.3815 - val_acc: 0.9013\n",
      "Epoch 50/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.3556 - acc: 0.8982 - val_loss: 0.4304 - val_acc: 0.8999\n",
      "Epoch 51/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.4257 - acc: 0.8906 - val_loss: 0.4267 - val_acc: 0.9033\n",
      "Epoch 52/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3897 - acc: 0.8958 - val_loss: 0.3547 - val_acc: 0.9022\n",
      "Epoch 53/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3685 - acc: 0.8968 - val_loss: 0.4143 - val_acc: 0.9069\n",
      "Epoch 54/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.3872 - acc: 0.8928 - val_loss: 0.4646 - val_acc: 0.8890\n",
      "Epoch 55/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3730 - acc: 0.8976 - val_loss: 0.3839 - val_acc: 0.9038\n",
      "Epoch 56/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3606 - acc: 0.8986 - val_loss: 0.3889 - val_acc: 0.9030\n",
      "Epoch 57/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3515 - acc: 0.9000 - val_loss: 0.4173 - val_acc: 0.8898\n",
      "Epoch 58/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3644 - acc: 0.8999 - val_loss: 0.3549 - val_acc: 0.9047\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3544 - acc: 0.8982 - val_loss: 0.3980 - val_acc: 0.8963\n",
      "Epoch 60/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.3871 - acc: 0.8959 - val_loss: 0.3641 - val_acc: 0.9033\n",
      "Epoch 61/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.3739 - acc: 0.8987 - val_loss: 0.4698 - val_acc: 0.8907\n",
      "Epoch 62/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.4229 - acc: 0.8975 - val_loss: 0.4401 - val_acc: 0.9050\n",
      "Epoch 63/500\n",
      "8320/8320 [==============================] - 0s 11us/step - loss: 0.4172 - acc: 0.8969 - val_loss: 0.4182 - val_acc: 0.8929\n",
      "Epoch 64/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3547 - acc: 0.8957 - val_loss: 0.3806 - val_acc: 0.8977\n",
      "Epoch 65/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3511 - acc: 0.8999 - val_loss: 0.3759 - val_acc: 0.9002\n",
      "Epoch 66/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3613 - acc: 0.8971 - val_loss: 0.3530 - val_acc: 0.9024\n",
      "Epoch 67/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3474 - acc: 0.8993 - val_loss: 0.3680 - val_acc: 0.8980\n",
      "Epoch 68/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3468 - acc: 0.9004 - val_loss: 0.4081 - val_acc: 0.8974\n",
      "Epoch 69/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3516 - acc: 0.8987 - val_loss: 0.3665 - val_acc: 0.8985\n",
      "Epoch 70/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3817 - acc: 0.8986 - val_loss: 0.3562 - val_acc: 0.8991\n",
      "Epoch 71/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.3700 - acc: 0.8983 - val_loss: 0.3827 - val_acc: 0.9022\n",
      "Epoch 72/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3600 - acc: 0.8980 - val_loss: 0.4558 - val_acc: 0.8876\n",
      "Epoch 73/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3437 - acc: 0.8994 - val_loss: 0.3410 - val_acc: 0.9002\n",
      "Epoch 74/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3802 - acc: 0.8986 - val_loss: 0.4059 - val_acc: 0.9036\n",
      "Epoch 75/500\n",
      "8320/8320 [==============================] - 0s 11us/step - loss: 0.3456 - acc: 0.8998 - val_loss: 0.3490 - val_acc: 0.9019\n",
      "Epoch 76/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3810 - acc: 0.8987 - val_loss: 0.3746 - val_acc: 0.8988\n",
      "Epoch 77/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3514 - acc: 0.8999 - val_loss: 0.3913 - val_acc: 0.8960\n",
      "Epoch 78/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3340 - acc: 0.8998 - val_loss: 0.4028 - val_acc: 0.8999\n",
      "Epoch 79/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3831 - acc: 0.8953 - val_loss: 0.4479 - val_acc: 0.8867\n",
      "Epoch 80/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.3600 - acc: 0.8976 - val_loss: 0.3804 - val_acc: 0.9044\n",
      "Epoch 81/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3504 - acc: 0.8996 - val_loss: 0.3620 - val_acc: 0.8999\n",
      "Epoch 82/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3614 - acc: 0.9008 - val_loss: 0.3569 - val_acc: 0.9036\n",
      "Epoch 83/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3500 - acc: 0.8981 - val_loss: 0.4295 - val_acc: 0.8907\n",
      "Epoch 84/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.3328 - acc: 0.8996 - val_loss: 0.3434 - val_acc: 0.9055\n",
      "Epoch 85/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3288 - acc: 0.9018 - val_loss: 0.3565 - val_acc: 0.8982\n",
      "Epoch 86/500\n",
      "8320/8320 [==============================] - 0s 11us/step - loss: 0.3398 - acc: 0.8996 - val_loss: 0.3429 - val_acc: 0.9052\n",
      "Epoch 87/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.3542 - acc: 0.9002 - val_loss: 0.3776 - val_acc: 0.9027\n",
      "Epoch 88/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3559 - acc: 0.8994 - val_loss: 0.3473 - val_acc: 0.9013\n",
      "Epoch 89/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3390 - acc: 0.8988 - val_loss: 0.3522 - val_acc: 0.9052\n",
      "Epoch 90/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3471 - acc: 0.8989 - val_loss: 0.3471 - val_acc: 0.9013\n",
      "Epoch 91/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3415 - acc: 0.9001 - val_loss: 0.3552 - val_acc: 0.9033\n",
      "Epoch 92/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3149 - acc: 0.9032 - val_loss: 0.3253 - val_acc: 0.9058\n",
      "Epoch 93/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3485 - acc: 0.8983 - val_loss: 0.3589 - val_acc: 0.9052\n",
      "Epoch 94/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3486 - acc: 0.8981 - val_loss: 0.3925 - val_acc: 0.8940\n",
      "Epoch 95/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3390 - acc: 0.8992 - val_loss: 0.3981 - val_acc: 0.9058\n",
      "Epoch 96/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.3360 - acc: 0.9005 - val_loss: 0.3376 - val_acc: 0.9030\n",
      "Epoch 97/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.3083 - acc: 0.9013 - val_loss: 0.3383 - val_acc: 0.9013\n",
      "Epoch 98/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.3213 - acc: 0.8996 - val_loss: 0.3556 - val_acc: 0.9066\n",
      "Epoch 99/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3130 - acc: 0.9010 - val_loss: 0.3562 - val_acc: 0.9010\n",
      "Epoch 100/500\n",
      "8320/8320 [==============================] - 0s 11us/step - loss: 0.3312 - acc: 0.8995 - val_loss: 0.3615 - val_acc: 0.9002\n",
      "Epoch 101/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3330 - acc: 0.9004 - val_loss: 0.3358 - val_acc: 0.9061\n",
      "Epoch 102/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3426 - acc: 0.8988 - val_loss: 0.3450 - val_acc: 0.9027\n",
      "Epoch 103/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3321 - acc: 0.9005 - val_loss: 0.3234 - val_acc: 0.9010\n",
      "Epoch 104/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3213 - acc: 0.9014 - val_loss: 0.3308 - val_acc: 0.9044\n",
      "Epoch 105/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3532 - acc: 0.8962 - val_loss: 0.3235 - val_acc: 0.9052\n",
      "Epoch 106/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3217 - acc: 0.8990 - val_loss: 0.3236 - val_acc: 0.9005\n",
      "Epoch 107/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3088 - acc: 0.9017 - val_loss: 0.3936 - val_acc: 0.8951\n",
      "Epoch 108/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3619 - acc: 0.8974 - val_loss: 0.3599 - val_acc: 0.9008\n",
      "Epoch 109/500\n",
      "8320/8320 [==============================] - 0s 11us/step - loss: 0.3209 - acc: 0.8998 - val_loss: 0.3610 - val_acc: 0.9002\n",
      "Epoch 110/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3254 - acc: 0.9000 - val_loss: 0.3257 - val_acc: 0.9058\n",
      "Epoch 111/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3314 - acc: 0.9000 - val_loss: 0.3579 - val_acc: 0.9052\n",
      "Epoch 112/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3132 - acc: 0.9011 - val_loss: 0.3327 - val_acc: 0.9047\n",
      "Epoch 113/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.3250 - acc: 0.9010 - val_loss: 0.3259 - val_acc: 0.9036\n",
      "Epoch 114/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.3215 - acc: 0.8992 - val_loss: 0.3382 - val_acc: 0.9038\n",
      "Epoch 115/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3180 - acc: 0.8996 - val_loss: 0.3973 - val_acc: 0.9052\n",
      "Epoch 116/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3440 - acc: 0.9001 - val_loss: 0.3528 - val_acc: 0.9038\n",
      "Epoch 117/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3254 - acc: 0.8998 - val_loss: 0.3461 - val_acc: 0.9002\n",
      "Epoch 118/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3118 - acc: 0.9008 - val_loss: 0.3611 - val_acc: 0.9055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3394 - acc: 0.9008 - val_loss: 0.3534 - val_acc: 0.8994\n",
      "Epoch 120/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3566 - acc: 0.8968 - val_loss: 0.4083 - val_acc: 0.8966\n",
      "Epoch 121/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3505 - acc: 0.8987 - val_loss: 0.4500 - val_acc: 0.8901\n",
      "Epoch 122/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3454 - acc: 0.9007 - val_loss: 0.3542 - val_acc: 0.9013\n",
      "Epoch 123/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3379 - acc: 0.8995 - val_loss: 0.3415 - val_acc: 0.9055\n",
      "Epoch 124/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3251 - acc: 0.9010 - val_loss: 0.3399 - val_acc: 0.9002\n",
      "Epoch 125/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3469 - acc: 0.8981 - val_loss: 0.3575 - val_acc: 0.9022\n",
      "Epoch 126/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3338 - acc: 0.8981 - val_loss: 0.3097 - val_acc: 0.9044\n",
      "Epoch 127/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3258 - acc: 0.9005 - val_loss: 0.3384 - val_acc: 0.9064\n",
      "Epoch 128/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3044 - acc: 0.9028 - val_loss: 0.3462 - val_acc: 0.9022\n",
      "Epoch 129/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3192 - acc: 0.9011 - val_loss: 0.3397 - val_acc: 0.9036\n",
      "Epoch 130/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3352 - acc: 0.8996 - val_loss: 0.3332 - val_acc: 0.8999\n",
      "Epoch 131/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3380 - acc: 0.8981 - val_loss: 0.3111 - val_acc: 0.9069\n",
      "Epoch 132/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.3168 - acc: 0.9020 - val_loss: 0.3213 - val_acc: 0.9050\n",
      "Epoch 133/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.3286 - acc: 0.9002 - val_loss: 0.3304 - val_acc: 0.9047\n",
      "Epoch 134/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3258 - acc: 0.9011 - val_loss: 0.3701 - val_acc: 0.9050\n",
      "Epoch 135/500\n",
      "8320/8320 [==============================] - 0s 11us/step - loss: 0.3184 - acc: 0.9013 - val_loss: 0.3036 - val_acc: 0.9038\n",
      "Epoch 136/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3306 - acc: 0.9001 - val_loss: 0.3622 - val_acc: 0.9002\n",
      "Epoch 137/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3154 - acc: 0.9002 - val_loss: 0.3163 - val_acc: 0.9030\n",
      "Epoch 138/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.3160 - acc: 0.8994 - val_loss: 0.3117 - val_acc: 0.9078\n",
      "Epoch 139/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3032 - acc: 0.9019 - val_loss: 0.3306 - val_acc: 0.9008\n",
      "Epoch 140/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3324 - acc: 0.8999 - val_loss: 0.3289 - val_acc: 0.9019\n",
      "Epoch 141/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.3116 - acc: 0.9007 - val_loss: 0.3177 - val_acc: 0.9052\n",
      "Epoch 142/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3049 - acc: 0.9023 - val_loss: 0.3496 - val_acc: 0.8982\n",
      "Epoch 143/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3128 - acc: 0.8999 - val_loss: 0.3725 - val_acc: 0.8977\n",
      "Epoch 144/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3216 - acc: 0.8980 - val_loss: 0.3211 - val_acc: 0.9041\n",
      "Epoch 145/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3042 - acc: 0.9022 - val_loss: 0.3321 - val_acc: 0.8980\n",
      "Epoch 146/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3203 - acc: 0.8994 - val_loss: 0.3394 - val_acc: 0.8996\n",
      "Epoch 147/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3074 - acc: 0.9019 - val_loss: 0.3109 - val_acc: 0.9064\n",
      "Epoch 148/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3040 - acc: 0.9019 - val_loss: 0.3188 - val_acc: 0.9033\n",
      "Epoch 149/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3000 - acc: 0.9024 - val_loss: 0.3006 - val_acc: 0.9058\n",
      "Epoch 150/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.3150 - acc: 0.8994 - val_loss: 0.3087 - val_acc: 0.9022\n",
      "Epoch 151/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3025 - acc: 0.9000 - val_loss: 0.3074 - val_acc: 0.9036\n",
      "Epoch 152/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3031 - acc: 0.9018 - val_loss: 0.3217 - val_acc: 0.9024\n",
      "Epoch 153/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3117 - acc: 0.9004 - val_loss: 0.3060 - val_acc: 0.9083\n",
      "Epoch 154/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3187 - acc: 0.8999 - val_loss: 0.3087 - val_acc: 0.9052\n",
      "Epoch 155/500\n",
      "8320/8320 [==============================] - 0s 23us/step - loss: 0.3129 - acc: 0.8998 - val_loss: 0.3004 - val_acc: 0.9036\n",
      "Epoch 156/500\n",
      "8320/8320 [==============================] - 0s 24us/step - loss: 0.3055 - acc: 0.9014 - val_loss: 0.2974 - val_acc: 0.9089\n",
      "Epoch 157/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.3084 - acc: 0.9011 - val_loss: 0.3506 - val_acc: 0.9041\n",
      "Epoch 158/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3065 - acc: 0.9019 - val_loss: 0.3047 - val_acc: 0.9041\n",
      "Epoch 159/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3117 - acc: 0.9002 - val_loss: 0.3132 - val_acc: 0.9016\n",
      "Epoch 160/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2965 - acc: 0.9022 - val_loss: 0.3033 - val_acc: 0.9058\n",
      "Epoch 161/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.3098 - acc: 0.9025 - val_loss: 0.3090 - val_acc: 0.9075\n",
      "Epoch 162/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3191 - acc: 0.8987 - val_loss: 0.3494 - val_acc: 0.9033\n",
      "Epoch 163/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3087 - acc: 0.9007 - val_loss: 0.3110 - val_acc: 0.9044\n",
      "Epoch 164/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2995 - acc: 0.9004 - val_loss: 0.2974 - val_acc: 0.9027\n",
      "Epoch 165/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3002 - acc: 0.9020 - val_loss: 0.3443 - val_acc: 0.8999\n",
      "Epoch 166/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3017 - acc: 0.9012 - val_loss: 0.2996 - val_acc: 0.9072\n",
      "Epoch 167/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3014 - acc: 0.9013 - val_loss: 0.2984 - val_acc: 0.9036\n",
      "Epoch 168/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2991 - acc: 0.9004 - val_loss: 0.3044 - val_acc: 0.9041\n",
      "Epoch 169/500\n",
      "8320/8320 [==============================] - 0s 11us/step - loss: 0.3059 - acc: 0.9011 - val_loss: 0.3050 - val_acc: 0.9069\n",
      "Epoch 170/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.3006 - acc: 0.9025 - val_loss: 0.3054 - val_acc: 0.9041\n",
      "Epoch 171/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2962 - acc: 0.9016 - val_loss: 0.2970 - val_acc: 0.9019\n",
      "Epoch 172/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2950 - acc: 0.9025 - val_loss: 0.2978 - val_acc: 0.9072\n",
      "Epoch 173/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.3004 - acc: 0.9000 - val_loss: 0.2954 - val_acc: 0.9089\n",
      "Epoch 174/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.3100 - acc: 0.9005 - val_loss: 0.3007 - val_acc: 0.9027\n",
      "Epoch 175/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2997 - acc: 0.9005 - val_loss: 0.3033 - val_acc: 0.9027\n",
      "Epoch 176/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.3048 - acc: 0.8995 - val_loss: 0.2994 - val_acc: 0.9055\n",
      "Epoch 177/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3002 - acc: 0.8999 - val_loss: 0.2913 - val_acc: 0.9052\n",
      "Epoch 178/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.3009 - acc: 0.9019 - val_loss: 0.2970 - val_acc: 0.9069\n",
      "Epoch 179/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.3005 - acc: 0.9028 - val_loss: 0.3027 - val_acc: 0.9064\n",
      "Epoch 180/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2991 - acc: 0.9017 - val_loss: 0.3011 - val_acc: 0.9047\n",
      "Epoch 181/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2978 - acc: 0.9008 - val_loss: 0.2899 - val_acc: 0.9066\n",
      "Epoch 182/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2966 - acc: 0.9018 - val_loss: 0.2932 - val_acc: 0.9069\n",
      "Epoch 183/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2923 - acc: 0.9018 - val_loss: 0.3045 - val_acc: 0.9036\n",
      "Epoch 184/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2919 - acc: 0.9029 - val_loss: 0.2897 - val_acc: 0.9036\n",
      "Epoch 185/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2971 - acc: 0.9008 - val_loss: 0.3044 - val_acc: 0.9013\n",
      "Epoch 186/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2942 - acc: 0.9030 - val_loss: 0.2997 - val_acc: 0.9055\n",
      "Epoch 187/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2963 - acc: 0.9006 - val_loss: 0.3006 - val_acc: 0.9010\n",
      "Epoch 188/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2896 - acc: 0.9023 - val_loss: 0.2849 - val_acc: 0.9050\n",
      "Epoch 189/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2927 - acc: 0.9011 - val_loss: 0.3048 - val_acc: 0.9019\n",
      "Epoch 190/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2916 - acc: 0.9010 - val_loss: 0.2894 - val_acc: 0.9041\n",
      "Epoch 191/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2917 - acc: 0.9013 - val_loss: 0.2851 - val_acc: 0.9047\n",
      "Epoch 192/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2899 - acc: 0.9019 - val_loss: 0.3002 - val_acc: 0.9019\n",
      "Epoch 193/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.2958 - acc: 0.9019 - val_loss: 0.2969 - val_acc: 0.9064\n",
      "Epoch 194/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.2969 - acc: 0.9013 - val_loss: 0.2922 - val_acc: 0.9047\n",
      "Epoch 195/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2920 - acc: 0.9008 - val_loss: 0.2885 - val_acc: 0.9052\n",
      "Epoch 196/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2924 - acc: 0.9004 - val_loss: 0.2894 - val_acc: 0.9075\n",
      "Epoch 197/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2902 - acc: 0.9005 - val_loss: 0.2832 - val_acc: 0.9041\n",
      "Epoch 198/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2906 - acc: 0.9002 - val_loss: 0.2886 - val_acc: 0.9050\n",
      "Epoch 199/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2891 - acc: 0.9022 - val_loss: 0.2943 - val_acc: 0.9052\n",
      "Epoch 200/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2886 - acc: 0.9013 - val_loss: 0.2882 - val_acc: 0.9050\n",
      "Epoch 201/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2844 - acc: 0.9036 - val_loss: 0.2943 - val_acc: 0.9024\n",
      "Epoch 202/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2926 - acc: 0.9000 - val_loss: 0.3164 - val_acc: 0.9005\n",
      "Epoch 203/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2885 - acc: 0.9007 - val_loss: 0.3102 - val_acc: 0.9016\n",
      "Epoch 204/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2882 - acc: 0.9019 - val_loss: 0.3133 - val_acc: 0.8999\n",
      "Epoch 205/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2901 - acc: 0.9007 - val_loss: 0.2858 - val_acc: 0.9036\n",
      "Epoch 206/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.2858 - acc: 0.9017 - val_loss: 0.2861 - val_acc: 0.9041\n",
      "Epoch 207/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2862 - acc: 0.9004 - val_loss: 0.2890 - val_acc: 0.9036\n",
      "Epoch 208/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2853 - acc: 0.9020 - val_loss: 0.2952 - val_acc: 0.9027\n",
      "Epoch 209/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2925 - acc: 0.9020 - val_loss: 0.2915 - val_acc: 0.9030\n",
      "Epoch 210/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2848 - acc: 0.9013 - val_loss: 0.2886 - val_acc: 0.9038\n",
      "Epoch 211/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2854 - acc: 0.9013 - val_loss: 0.2887 - val_acc: 0.9066\n",
      "Epoch 212/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2830 - acc: 0.9022 - val_loss: 0.2884 - val_acc: 0.9061\n",
      "Epoch 213/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2862 - acc: 0.9008 - val_loss: 0.2864 - val_acc: 0.9052\n",
      "Epoch 214/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2865 - acc: 0.9018 - val_loss: 0.3030 - val_acc: 0.9022\n",
      "Epoch 215/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2862 - acc: 0.9007 - val_loss: 0.2903 - val_acc: 0.9050\n",
      "Epoch 216/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2864 - acc: 0.9010 - val_loss: 0.2915 - val_acc: 0.9047\n",
      "Epoch 217/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.2854 - acc: 0.9013 - val_loss: 0.2882 - val_acc: 0.9052\n",
      "Epoch 218/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2835 - acc: 0.9022 - val_loss: 0.2981 - val_acc: 0.9050\n",
      "Epoch 219/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2893 - acc: 0.9024 - val_loss: 0.2991 - val_acc: 0.9019\n",
      "Epoch 220/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2852 - acc: 0.9019 - val_loss: 0.3027 - val_acc: 0.9038\n",
      "Epoch 221/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2880 - acc: 0.9012 - val_loss: 0.2984 - val_acc: 0.9047\n",
      "Epoch 222/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2877 - acc: 0.9007 - val_loss: 0.2874 - val_acc: 0.9055\n",
      "Epoch 223/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2866 - acc: 0.9019 - val_loss: 0.2876 - val_acc: 0.9030\n",
      "Epoch 224/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.2827 - acc: 0.9023 - val_loss: 0.2898 - val_acc: 0.9052\n",
      "Epoch 225/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2849 - acc: 0.9011 - val_loss: 0.2818 - val_acc: 0.9044\n",
      "Epoch 226/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2829 - acc: 0.9020 - val_loss: 0.3046 - val_acc: 0.9010\n",
      "Epoch 227/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2843 - acc: 0.9010 - val_loss: 0.2872 - val_acc: 0.9050\n",
      "Epoch 228/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2860 - acc: 0.9007 - val_loss: 0.2900 - val_acc: 0.9050\n",
      "Epoch 229/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.2839 - acc: 0.9018 - val_loss: 0.2923 - val_acc: 0.9058\n",
      "Epoch 230/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2845 - acc: 0.8993 - val_loss: 0.2865 - val_acc: 0.9052\n",
      "Epoch 231/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.2838 - acc: 0.9011 - val_loss: 0.2873 - val_acc: 0.9055\n",
      "Epoch 232/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2846 - acc: 0.9014 - val_loss: 0.2950 - val_acc: 0.9047\n",
      "Epoch 233/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2875 - acc: 0.9006 - val_loss: 0.2896 - val_acc: 0.9041\n",
      "Epoch 234/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2820 - acc: 0.9031 - val_loss: 0.2879 - val_acc: 0.9044\n",
      "Epoch 235/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.2834 - acc: 0.9016 - val_loss: 0.2930 - val_acc: 0.9044\n",
      "Epoch 236/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.2837 - acc: 0.9016 - val_loss: 0.2937 - val_acc: 0.9027\n",
      "Epoch 237/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2846 - acc: 0.9011 - val_loss: 0.2886 - val_acc: 0.9041\n",
      "Epoch 238/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2818 - acc: 0.9024 - val_loss: 0.2897 - val_acc: 0.9061\n",
      "Epoch 239/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2841 - acc: 0.9018 - val_loss: 0.2955 - val_acc: 0.9036\n",
      "Epoch 240/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2829 - acc: 0.9023 - val_loss: 0.2873 - val_acc: 0.9044\n",
      "Epoch 241/500\n",
      "8320/8320 [==============================] - 0s 11us/step - loss: 0.2828 - acc: 0.9016 - val_loss: 0.2974 - val_acc: 0.9064\n",
      "Epoch 242/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2839 - acc: 0.9014 - val_loss: 0.3027 - val_acc: 0.9033\n",
      "Epoch 243/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2866 - acc: 0.9006 - val_loss: 0.2918 - val_acc: 0.9041\n",
      "Epoch 244/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2846 - acc: 0.9007 - val_loss: 0.2895 - val_acc: 0.9044\n",
      "Epoch 245/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2813 - acc: 0.9026 - val_loss: 0.3025 - val_acc: 0.9005\n",
      "Epoch 246/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2868 - acc: 0.9020 - val_loss: 0.2909 - val_acc: 0.9041\n",
      "Epoch 247/500\n",
      "8320/8320 [==============================] - 0s 11us/step - loss: 0.2848 - acc: 0.9016 - val_loss: 0.3136 - val_acc: 0.9022\n",
      "Epoch 248/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2826 - acc: 0.9008 - val_loss: 0.2930 - val_acc: 0.9047\n",
      "Epoch 249/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2831 - acc: 0.9022 - val_loss: 0.2926 - val_acc: 0.9041\n",
      "Epoch 250/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2834 - acc: 0.9022 - val_loss: 0.2888 - val_acc: 0.9033\n",
      "Epoch 251/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2853 - acc: 0.9017 - val_loss: 0.2968 - val_acc: 0.9047\n",
      "Epoch 252/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2825 - acc: 0.9017 - val_loss: 0.2939 - val_acc: 0.9022\n",
      "Epoch 253/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2845 - acc: 0.9006 - val_loss: 0.2891 - val_acc: 0.9044\n",
      "Epoch 254/500\n",
      "8320/8320 [==============================] - 0s 11us/step - loss: 0.2858 - acc: 0.9000 - val_loss: 0.2903 - val_acc: 0.9030\n",
      "Epoch 255/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2808 - acc: 0.9016 - val_loss: 0.2903 - val_acc: 0.9044\n",
      "Epoch 256/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2825 - acc: 0.9011 - val_loss: 0.2912 - val_acc: 0.9041\n",
      "Epoch 257/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2839 - acc: 0.9011 - val_loss: 0.2905 - val_acc: 0.9041\n",
      "Epoch 258/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2809 - acc: 0.9028 - val_loss: 0.2900 - val_acc: 0.9050\n",
      "Epoch 259/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2812 - acc: 0.9017 - val_loss: 0.2912 - val_acc: 0.9030\n",
      "Epoch 260/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.2820 - acc: 0.9018 - val_loss: 0.2894 - val_acc: 0.9038\n",
      "Epoch 261/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2814 - acc: 0.9019 - val_loss: 0.2888 - val_acc: 0.9050\n",
      "Epoch 262/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2808 - acc: 0.9022 - val_loss: 0.2902 - val_acc: 0.9044\n",
      "Epoch 263/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2814 - acc: 0.9018 - val_loss: 0.2878 - val_acc: 0.9050\n",
      "Epoch 264/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2811 - acc: 0.9019 - val_loss: 0.2920 - val_acc: 0.9058\n",
      "Epoch 265/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2868 - acc: 0.9016 - val_loss: 0.2902 - val_acc: 0.9044\n",
      "Epoch 266/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2819 - acc: 0.9025 - val_loss: 0.2962 - val_acc: 0.9044\n",
      "Epoch 267/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2815 - acc: 0.9019 - val_loss: 0.2892 - val_acc: 0.9041\n",
      "Epoch 268/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2820 - acc: 0.9012 - val_loss: 0.2864 - val_acc: 0.9058\n",
      "Epoch 269/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2839 - acc: 0.9013 - val_loss: 0.2870 - val_acc: 0.9058\n",
      "Epoch 270/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2836 - acc: 0.8998 - val_loss: 0.2956 - val_acc: 0.9038\n",
      "Epoch 271/500\n",
      "8320/8320 [==============================] - 0s 12us/step - loss: 0.2824 - acc: 0.9014 - val_loss: 0.2912 - val_acc: 0.9033\n",
      "Epoch 272/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2811 - acc: 0.9020 - val_loss: 0.2892 - val_acc: 0.9050\n",
      "Epoch 273/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2840 - acc: 0.9017 - val_loss: 0.3019 - val_acc: 0.9044\n",
      "Epoch 274/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2870 - acc: 0.9008 - val_loss: 0.2916 - val_acc: 0.9044\n",
      "Epoch 275/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2833 - acc: 0.9011 - val_loss: 0.2911 - val_acc: 0.9027\n",
      "Epoch 276/500\n",
      "8320/8320 [==============================] - 0s 13us/step - loss: 0.2815 - acc: 0.9020 - val_loss: 0.2962 - val_acc: 0.9044\n",
      "Epoch 277/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2824 - acc: 0.9008 - val_loss: 0.2866 - val_acc: 0.9041\n",
      "Epoch 278/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2814 - acc: 0.9012 - val_loss: 0.2911 - val_acc: 0.9047\n",
      "Epoch 279/500\n",
      "8320/8320 [==============================] - 0s 24us/step - loss: 0.2807 - acc: 0.9023 - val_loss: 0.2890 - val_acc: 0.9047\n",
      "Epoch 280/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2814 - acc: 0.9012 - val_loss: 0.2888 - val_acc: 0.9047\n",
      "Epoch 281/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.2797 - acc: 0.9007 - val_loss: 0.2906 - val_acc: 0.9038\n",
      "Epoch 282/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2812 - acc: 0.9001 - val_loss: 0.2865 - val_acc: 0.9052\n",
      "Epoch 283/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.2798 - acc: 0.9016 - val_loss: 0.2930 - val_acc: 0.9044\n",
      "Epoch 284/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2795 - acc: 0.9028 - val_loss: 0.2840 - val_acc: 0.9050\n",
      "Epoch 285/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2806 - acc: 0.9010 - val_loss: 0.2875 - val_acc: 0.9041\n",
      "Epoch 286/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2815 - acc: 0.9007 - val_loss: 0.2965 - val_acc: 0.9033\n",
      "Epoch 287/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2793 - acc: 0.9012 - val_loss: 0.2896 - val_acc: 0.9044\n",
      "Epoch 288/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2829 - acc: 0.9002 - val_loss: 0.2901 - val_acc: 0.9041\n",
      "Epoch 289/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2799 - acc: 0.9012 - val_loss: 0.2889 - val_acc: 0.9055\n",
      "Epoch 290/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2792 - acc: 0.9019 - val_loss: 0.2944 - val_acc: 0.9055\n",
      "Epoch 291/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2792 - acc: 0.9017 - val_loss: 0.2892 - val_acc: 0.9047\n",
      "Epoch 292/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2798 - acc: 0.9007 - val_loss: 0.2893 - val_acc: 0.9047\n",
      "Epoch 293/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2803 - acc: 0.9018 - val_loss: 0.2890 - val_acc: 0.9061\n",
      "Epoch 294/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.2808 - acc: 0.9024 - val_loss: 0.2865 - val_acc: 0.9033\n",
      "Epoch 295/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2798 - acc: 0.9011 - val_loss: 0.2898 - val_acc: 0.9044\n",
      "Epoch 296/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2788 - acc: 0.9010 - val_loss: 0.2890 - val_acc: 0.9041\n",
      "Epoch 297/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2789 - acc: 0.9013 - val_loss: 0.2914 - val_acc: 0.9041\n",
      "Epoch 298/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2787 - acc: 0.9013 - val_loss: 0.2900 - val_acc: 0.9041\n",
      "Epoch 299/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2782 - acc: 0.9034 - val_loss: 0.2936 - val_acc: 0.9041\n",
      "Epoch 300/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2785 - acc: 0.9020 - val_loss: 0.2894 - val_acc: 0.9055\n",
      "Epoch 301/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2803 - acc: 0.9018 - val_loss: 0.2877 - val_acc: 0.9044\n",
      "Epoch 302/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2786 - acc: 0.9010 - val_loss: 0.2844 - val_acc: 0.9061\n",
      "Epoch 303/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2769 - acc: 0.9024 - val_loss: 0.2869 - val_acc: 0.9041\n",
      "Epoch 304/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2775 - acc: 0.9030 - val_loss: 0.2862 - val_acc: 0.9055\n",
      "Epoch 305/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2802 - acc: 0.9014 - val_loss: 0.2914 - val_acc: 0.9024\n",
      "Epoch 306/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2800 - acc: 0.8999 - val_loss: 0.2870 - val_acc: 0.9036\n",
      "Epoch 307/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2805 - acc: 0.9022 - val_loss: 0.2828 - val_acc: 0.9038\n",
      "Epoch 308/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2786 - acc: 0.9010 - val_loss: 0.2838 - val_acc: 0.9033\n",
      "Epoch 309/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2779 - acc: 0.9024 - val_loss: 0.2874 - val_acc: 0.9036\n",
      "Epoch 310/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2779 - acc: 0.9018 - val_loss: 0.2818 - val_acc: 0.9038\n",
      "Epoch 311/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2763 - acc: 0.9023 - val_loss: 0.2824 - val_acc: 0.9050\n",
      "Epoch 312/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2775 - acc: 0.9017 - val_loss: 0.2832 - val_acc: 0.9044\n",
      "Epoch 313/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2772 - acc: 0.9018 - val_loss: 0.3003 - val_acc: 0.9038\n",
      "Epoch 314/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2816 - acc: 0.9004 - val_loss: 0.2811 - val_acc: 0.9047\n",
      "Epoch 315/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2775 - acc: 0.9016 - val_loss: 0.2844 - val_acc: 0.9055\n",
      "Epoch 316/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2772 - acc: 0.9014 - val_loss: 0.2882 - val_acc: 0.9041\n",
      "Epoch 317/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2777 - acc: 0.9017 - val_loss: 0.2901 - val_acc: 0.9033\n",
      "Epoch 318/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.2769 - acc: 0.9005 - val_loss: 0.2904 - val_acc: 0.9055\n",
      "Epoch 319/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2840 - acc: 0.9022 - val_loss: 0.2912 - val_acc: 0.9050\n",
      "Epoch 320/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2789 - acc: 0.9010 - val_loss: 0.2878 - val_acc: 0.9030\n",
      "Epoch 321/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2781 - acc: 0.9011 - val_loss: 0.2955 - val_acc: 0.9027\n",
      "Epoch 322/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2769 - acc: 0.9010 - val_loss: 0.2952 - val_acc: 0.9050\n",
      "Epoch 323/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.2791 - acc: 0.9018 - val_loss: 0.2843 - val_acc: 0.9055\n",
      "Epoch 324/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2769 - acc: 0.9007 - val_loss: 0.2859 - val_acc: 0.9044\n",
      "Epoch 325/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2752 - acc: 0.9023 - val_loss: 0.2862 - val_acc: 0.9058\n",
      "Epoch 326/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2785 - acc: 0.9014 - val_loss: 0.2899 - val_acc: 0.9044\n",
      "Epoch 327/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2770 - acc: 0.9020 - val_loss: 0.2875 - val_acc: 0.9064\n",
      "Epoch 328/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2765 - acc: 0.9024 - val_loss: 0.2865 - val_acc: 0.9052\n",
      "Epoch 329/500\n",
      "8320/8320 [==============================] - 0s 24us/step - loss: 0.2749 - acc: 0.9028 - val_loss: 0.2872 - val_acc: 0.9047\n",
      "Epoch 330/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2804 - acc: 0.9014 - val_loss: 0.2921 - val_acc: 0.9022\n",
      "Epoch 331/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2780 - acc: 0.9014 - val_loss: 0.2842 - val_acc: 0.9038\n",
      "Epoch 332/500\n",
      "8320/8320 [==============================] - 0s 23us/step - loss: 0.2750 - acc: 0.9016 - val_loss: 0.2944 - val_acc: 0.9030\n",
      "Epoch 333/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2754 - acc: 0.9018 - val_loss: 0.2898 - val_acc: 0.9044\n",
      "Epoch 334/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2766 - acc: 0.9018 - val_loss: 0.2923 - val_acc: 0.9050\n",
      "Epoch 335/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2767 - acc: 0.9012 - val_loss: 0.2866 - val_acc: 0.9038\n",
      "Epoch 336/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2753 - acc: 0.9018 - val_loss: 0.2878 - val_acc: 0.9050\n",
      "Epoch 337/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2730 - acc: 0.9026 - val_loss: 0.2919 - val_acc: 0.9044\n",
      "Epoch 338/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2746 - acc: 0.9023 - val_loss: 0.2918 - val_acc: 0.9033\n",
      "Epoch 339/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2757 - acc: 0.9017 - val_loss: 0.2940 - val_acc: 0.9047\n",
      "Epoch 340/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2762 - acc: 0.9012 - val_loss: 0.2889 - val_acc: 0.9058\n",
      "Epoch 341/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.2748 - acc: 0.9028 - val_loss: 0.2851 - val_acc: 0.9064\n",
      "Epoch 342/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2744 - acc: 0.9023 - val_loss: 0.2946 - val_acc: 0.9052\n",
      "Epoch 343/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2740 - acc: 0.9020 - val_loss: 0.2931 - val_acc: 0.9030\n",
      "Epoch 344/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2752 - acc: 0.9019 - val_loss: 0.2896 - val_acc: 0.9041\n",
      "Epoch 345/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2741 - acc: 0.9018 - val_loss: 0.2913 - val_acc: 0.9069\n",
      "Epoch 346/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2752 - acc: 0.9031 - val_loss: 0.2881 - val_acc: 0.9044\n",
      "Epoch 347/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2745 - acc: 0.9028 - val_loss: 0.2903 - val_acc: 0.9050\n",
      "Epoch 348/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2749 - acc: 0.9006 - val_loss: 0.2879 - val_acc: 0.9038\n",
      "Epoch 349/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2740 - acc: 0.9031 - val_loss: 0.2916 - val_acc: 0.9050\n",
      "Epoch 350/500\n",
      "8320/8320 [==============================] - ETA: 0s - loss: 0.2732 - acc: 0.902 - 0s 22us/step - loss: 0.2738 - acc: 0.9028 - val_loss: 0.2935 - val_acc: 0.9058\n",
      "Epoch 351/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2743 - acc: 0.9029 - val_loss: 0.2882 - val_acc: 0.9036\n",
      "Epoch 352/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2743 - acc: 0.9024 - val_loss: 0.2834 - val_acc: 0.9058\n",
      "Epoch 353/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2740 - acc: 0.9026 - val_loss: 0.2851 - val_acc: 0.9038\n",
      "Epoch 354/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2743 - acc: 0.9014 - val_loss: 0.2898 - val_acc: 0.9050\n",
      "Epoch 355/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2736 - acc: 0.9019 - val_loss: 0.2914 - val_acc: 0.9036\n",
      "Epoch 356/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2747 - acc: 0.9019 - val_loss: 0.2870 - val_acc: 0.9061\n",
      "Epoch 357/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.2750 - acc: 0.9022 - val_loss: 0.2851 - val_acc: 0.9052\n",
      "Epoch 358/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2739 - acc: 0.9024 - val_loss: 0.2861 - val_acc: 0.9044\n",
      "Epoch 359/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2758 - acc: 0.9024 - val_loss: 0.2898 - val_acc: 0.9083\n",
      "Epoch 360/500\n",
      "8320/8320 [==============================] - 0s 23us/step - loss: 0.2732 - acc: 0.9037 - val_loss: 0.2881 - val_acc: 0.9066\n",
      "Epoch 361/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2729 - acc: 0.9019 - val_loss: 0.2892 - val_acc: 0.9069\n",
      "Epoch 362/500\n",
      "8320/8320 [==============================] - 0s 24us/step - loss: 0.2726 - acc: 0.9040 - val_loss: 0.2921 - val_acc: 0.9047\n",
      "Epoch 363/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2748 - acc: 0.9011 - val_loss: 0.2839 - val_acc: 0.9061\n",
      "Epoch 364/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2727 - acc: 0.9028 - val_loss: 0.2881 - val_acc: 0.9041\n",
      "Epoch 365/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2726 - acc: 0.9037 - val_loss: 0.2863 - val_acc: 0.9041\n",
      "Epoch 366/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2724 - acc: 0.9020 - val_loss: 0.2859 - val_acc: 0.9050\n",
      "Epoch 367/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.2724 - acc: 0.9036 - val_loss: 0.2906 - val_acc: 0.9052\n",
      "Epoch 368/500\n",
      "8320/8320 [==============================] - 0s 25us/step - loss: 0.2740 - acc: 0.9030 - val_loss: 0.2889 - val_acc: 0.9052\n",
      "Epoch 369/500\n",
      "8320/8320 [==============================] - 0s 27us/step - loss: 0.2733 - acc: 0.9037 - val_loss: 0.2835 - val_acc: 0.9050\n",
      "Epoch 370/500\n",
      "8320/8320 [==============================] - 0s 26us/step - loss: 0.2751 - acc: 0.9019 - val_loss: 0.2946 - val_acc: 0.9027\n",
      "Epoch 371/500\n",
      "8320/8320 [==============================] - 0s 24us/step - loss: 0.2761 - acc: 0.9029 - val_loss: 0.2854 - val_acc: 0.9052\n",
      "Epoch 372/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2738 - acc: 0.9026 - val_loss: 0.2910 - val_acc: 0.9055\n",
      "Epoch 373/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2721 - acc: 0.9029 - val_loss: 0.2951 - val_acc: 0.9050\n",
      "Epoch 374/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2726 - acc: 0.9050 - val_loss: 0.2889 - val_acc: 0.9069\n",
      "Epoch 375/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2723 - acc: 0.9030 - val_loss: 0.2917 - val_acc: 0.9052\n",
      "Epoch 376/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2731 - acc: 0.9023 - val_loss: 0.2947 - val_acc: 0.9038\n",
      "Epoch 377/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2721 - acc: 0.9017 - val_loss: 0.2908 - val_acc: 0.9047\n",
      "Epoch 378/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2709 - acc: 0.9047 - val_loss: 0.2920 - val_acc: 0.9024\n",
      "Epoch 379/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2730 - acc: 0.9038 - val_loss: 0.2878 - val_acc: 0.9052\n",
      "Epoch 380/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2714 - acc: 0.9028 - val_loss: 0.2881 - val_acc: 0.9064\n",
      "Epoch 381/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2723 - acc: 0.9026 - val_loss: 0.2944 - val_acc: 0.9033\n",
      "Epoch 382/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2716 - acc: 0.9041 - val_loss: 0.2887 - val_acc: 0.9055\n",
      "Epoch 383/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2738 - acc: 0.9006 - val_loss: 0.2900 - val_acc: 0.9038\n",
      "Epoch 384/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2735 - acc: 0.9032 - val_loss: 0.2900 - val_acc: 0.9058\n",
      "Epoch 385/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2717 - acc: 0.9028 - val_loss: 0.2907 - val_acc: 0.9061\n",
      "Epoch 386/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2724 - acc: 0.9023 - val_loss: 0.2964 - val_acc: 0.9050\n",
      "Epoch 387/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2727 - acc: 0.9035 - val_loss: 0.2937 - val_acc: 0.9002\n",
      "Epoch 388/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.2707 - acc: 0.9031 - val_loss: 0.2873 - val_acc: 0.9044\n",
      "Epoch 389/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2763 - acc: 0.9012 - val_loss: 0.2906 - val_acc: 0.9038\n",
      "Epoch 390/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2744 - acc: 0.9022 - val_loss: 0.2921 - val_acc: 0.9058\n",
      "Epoch 391/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2711 - acc: 0.9040 - val_loss: 0.2942 - val_acc: 0.9038\n",
      "Epoch 392/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2730 - acc: 0.9032 - val_loss: 0.2875 - val_acc: 0.9069\n",
      "Epoch 393/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2714 - acc: 0.9038 - val_loss: 0.2821 - val_acc: 0.9061\n",
      "Epoch 394/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2714 - acc: 0.9032 - val_loss: 0.2898 - val_acc: 0.9058\n",
      "Epoch 395/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2705 - acc: 0.9035 - val_loss: 0.2848 - val_acc: 0.9052\n",
      "Epoch 396/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2703 - acc: 0.9038 - val_loss: 0.2962 - val_acc: 0.9024\n",
      "Epoch 397/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2719 - acc: 0.9038 - val_loss: 0.2901 - val_acc: 0.9058\n",
      "Epoch 398/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2715 - acc: 0.9014 - val_loss: 0.2859 - val_acc: 0.9044\n",
      "Epoch 399/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2717 - acc: 0.9025 - val_loss: 0.2936 - val_acc: 0.9050\n",
      "Epoch 400/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.2736 - acc: 0.9030 - val_loss: 0.2845 - val_acc: 0.9044\n",
      "Epoch 401/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2743 - acc: 0.9029 - val_loss: 0.2843 - val_acc: 0.9058\n",
      "Epoch 402/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2722 - acc: 0.9037 - val_loss: 0.2882 - val_acc: 0.9052\n",
      "Epoch 403/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2733 - acc: 0.9026 - val_loss: 0.2914 - val_acc: 0.9047\n",
      "Epoch 404/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2717 - acc: 0.9038 - val_loss: 0.2873 - val_acc: 0.9055\n",
      "Epoch 405/500\n",
      "8320/8320 [==============================] - 0s 25us/step - loss: 0.2701 - acc: 0.9040 - val_loss: 0.2944 - val_acc: 0.9052\n",
      "Epoch 406/500\n",
      "8320/8320 [==============================] - 0s 25us/step - loss: 0.2708 - acc: 0.9035 - val_loss: 0.2890 - val_acc: 0.9069\n",
      "Epoch 407/500\n",
      "8320/8320 [==============================] - 0s 23us/step - loss: 0.2709 - acc: 0.9040 - val_loss: 0.2835 - val_acc: 0.9033\n",
      "Epoch 408/500\n",
      "8320/8320 [==============================] - 0s 24us/step - loss: 0.2693 - acc: 0.9047 - val_loss: 0.2906 - val_acc: 0.9016\n",
      "Epoch 409/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2708 - acc: 0.9029 - val_loss: 0.2876 - val_acc: 0.9072\n",
      "Epoch 410/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2714 - acc: 0.9023 - val_loss: 0.2857 - val_acc: 0.9050\n",
      "Epoch 411/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2705 - acc: 0.9034 - val_loss: 0.2909 - val_acc: 0.9041\n",
      "Epoch 412/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2708 - acc: 0.9022 - val_loss: 0.2874 - val_acc: 0.9066\n",
      "Epoch 413/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2698 - acc: 0.9030 - val_loss: 0.2905 - val_acc: 0.9047\n",
      "Epoch 414/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2697 - acc: 0.9038 - val_loss: 0.2905 - val_acc: 0.9044\n",
      "Epoch 415/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2733 - acc: 0.9036 - val_loss: 0.2990 - val_acc: 0.9027\n",
      "Epoch 416/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.2717 - acc: 0.9037 - val_loss: 0.2896 - val_acc: 0.9038\n",
      "Epoch 417/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2713 - acc: 0.9031 - val_loss: 0.2900 - val_acc: 0.9033\n",
      "Epoch 418/500\n",
      "8320/8320 [==============================] - 0s 25us/step - loss: 0.2703 - acc: 0.9028 - val_loss: 0.2910 - val_acc: 0.9013\n",
      "Epoch 419/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2692 - acc: 0.9038 - val_loss: 0.2908 - val_acc: 0.9058\n",
      "Epoch 420/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.2721 - acc: 0.9020 - val_loss: 0.2905 - val_acc: 0.9052\n",
      "Epoch 421/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2714 - acc: 0.9038 - val_loss: 0.2891 - val_acc: 0.9080\n",
      "Epoch 422/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2705 - acc: 0.9037 - val_loss: 0.2883 - val_acc: 0.9055\n",
      "Epoch 423/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2716 - acc: 0.9014 - val_loss: 0.2900 - val_acc: 0.9033\n",
      "Epoch 424/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2691 - acc: 0.9034 - val_loss: 0.2881 - val_acc: 0.9052\n",
      "Epoch 425/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2716 - acc: 0.9020 - val_loss: 0.2943 - val_acc: 0.9022\n",
      "Epoch 426/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.2689 - acc: 0.9048 - val_loss: 0.2893 - val_acc: 0.9052\n",
      "Epoch 427/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2700 - acc: 0.9034 - val_loss: 0.2903 - val_acc: 0.9041\n",
      "Epoch 428/500\n",
      "8320/8320 [==============================] - 0s 24us/step - loss: 0.2702 - acc: 0.9046 - val_loss: 0.2886 - val_acc: 0.9055\n",
      "Epoch 429/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2699 - acc: 0.9023 - val_loss: 0.2867 - val_acc: 0.9058\n",
      "Epoch 430/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2699 - acc: 0.9052 - val_loss: 0.2907 - val_acc: 0.9005\n",
      "Epoch 431/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2708 - acc: 0.9024 - val_loss: 0.2882 - val_acc: 0.9061\n",
      "Epoch 432/500\n",
      "8320/8320 [==============================] - 0s 23us/step - loss: 0.2689 - acc: 0.9047 - val_loss: 0.2894 - val_acc: 0.9038\n",
      "Epoch 433/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2691 - acc: 0.9038 - val_loss: 0.2846 - val_acc: 0.9061\n",
      "Epoch 434/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2709 - acc: 0.9025 - val_loss: 0.2872 - val_acc: 0.9027\n",
      "Epoch 435/500\n",
      "8320/8320 [==============================] - 0s 27us/step - loss: 0.2704 - acc: 0.9028 - val_loss: 0.2885 - val_acc: 0.9047\n",
      "Epoch 436/500\n",
      "8320/8320 [==============================] - 0s 28us/step - loss: 0.2704 - acc: 0.9043 - val_loss: 0.2882 - val_acc: 0.9047\n",
      "Epoch 437/500\n",
      "8320/8320 [==============================] - 0s 28us/step - loss: 0.2692 - acc: 0.9042 - val_loss: 0.2892 - val_acc: 0.9036\n",
      "Epoch 438/500\n",
      "8320/8320 [==============================] - 0s 29us/step - loss: 0.2696 - acc: 0.9025 - val_loss: 0.2898 - val_acc: 0.9047\n",
      "Epoch 439/500\n",
      "8320/8320 [==============================] - 0s 31us/step - loss: 0.2727 - acc: 0.9030 - val_loss: 0.2903 - val_acc: 0.9061\n",
      "Epoch 440/500\n",
      "8320/8320 [==============================] - 0s 29us/step - loss: 0.2693 - acc: 0.9028 - val_loss: 0.2910 - val_acc: 0.9030\n",
      "Epoch 441/500\n",
      "8320/8320 [==============================] - 0s 23us/step - loss: 0.2679 - acc: 0.9037 - val_loss: 0.2843 - val_acc: 0.9058\n",
      "Epoch 442/500\n",
      "8320/8320 [==============================] - 0s 23us/step - loss: 0.2679 - acc: 0.9054 - val_loss: 0.2934 - val_acc: 0.9036\n",
      "Epoch 443/500\n",
      "8320/8320 [==============================] - 0s 20us/step - loss: 0.2696 - acc: 0.9040 - val_loss: 0.2933 - val_acc: 0.9075\n",
      "Epoch 444/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2684 - acc: 0.9041 - val_loss: 0.2907 - val_acc: 0.9038\n",
      "Epoch 445/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2691 - acc: 0.9042 - val_loss: 0.2948 - val_acc: 0.9041\n",
      "Epoch 446/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2705 - acc: 0.9044 - val_loss: 0.2880 - val_acc: 0.9052\n",
      "Epoch 447/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2731 - acc: 0.9017 - val_loss: 0.2877 - val_acc: 0.9022\n",
      "Epoch 448/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2706 - acc: 0.9028 - val_loss: 0.2918 - val_acc: 0.9005\n",
      "Epoch 449/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2701 - acc: 0.9044 - val_loss: 0.2875 - val_acc: 0.9038\n",
      "Epoch 450/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2691 - acc: 0.9047 - val_loss: 0.2920 - val_acc: 0.9036\n",
      "Epoch 451/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2683 - acc: 0.9043 - val_loss: 0.2889 - val_acc: 0.9030\n",
      "Epoch 452/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2713 - acc: 0.9046 - val_loss: 0.2948 - val_acc: 0.9047\n",
      "Epoch 453/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2695 - acc: 0.9042 - val_loss: 0.2931 - val_acc: 0.9041\n",
      "Epoch 454/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2701 - acc: 0.9035 - val_loss: 0.2837 - val_acc: 0.9061\n",
      "Epoch 455/500\n",
      "8320/8320 [==============================] - 0s 30us/step - loss: 0.2687 - acc: 0.9048 - val_loss: 0.2907 - val_acc: 0.9030\n",
      "Epoch 456/500\n",
      "8320/8320 [==============================] - 0s 28us/step - loss: 0.2687 - acc: 0.9032 - val_loss: 0.2875 - val_acc: 0.9044\n",
      "Epoch 457/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2681 - acc: 0.9053 - val_loss: 0.2890 - val_acc: 0.9052\n",
      "Epoch 458/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2718 - acc: 0.9020 - val_loss: 0.2915 - val_acc: 0.9008\n",
      "Epoch 459/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2680 - acc: 0.9041 - val_loss: 0.2916 - val_acc: 0.9005\n",
      "Epoch 460/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2692 - acc: 0.9040 - val_loss: 0.2953 - val_acc: 0.9002\n",
      "Epoch 461/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2689 - acc: 0.9034 - val_loss: 0.2922 - val_acc: 0.9058\n",
      "Epoch 462/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2690 - acc: 0.9032 - val_loss: 0.2926 - val_acc: 0.9022\n",
      "Epoch 463/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2696 - acc: 0.9042 - val_loss: 0.2924 - val_acc: 0.9019\n",
      "Epoch 464/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2680 - acc: 0.9034 - val_loss: 0.2901 - val_acc: 0.9036\n",
      "Epoch 465/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2683 - acc: 0.9047 - val_loss: 0.2948 - val_acc: 0.9013\n",
      "Epoch 466/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2681 - acc: 0.9037 - val_loss: 0.2857 - val_acc: 0.9052\n",
      "Epoch 467/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2669 - acc: 0.9053 - val_loss: 0.2943 - val_acc: 0.9052\n",
      "Epoch 468/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2699 - acc: 0.9029 - val_loss: 0.2875 - val_acc: 0.9022\n",
      "Epoch 469/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2692 - acc: 0.9043 - val_loss: 0.2903 - val_acc: 0.9069\n",
      "Epoch 470/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2717 - acc: 0.9046 - val_loss: 0.2935 - val_acc: 0.9027\n",
      "Epoch 471/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2692 - acc: 0.9029 - val_loss: 0.2910 - val_acc: 0.9041\n",
      "Epoch 472/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2671 - acc: 0.9029 - val_loss: 0.2889 - val_acc: 0.9055\n",
      "Epoch 473/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2681 - acc: 0.9037 - val_loss: 0.2887 - val_acc: 0.9072\n",
      "Epoch 474/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2690 - acc: 0.9040 - val_loss: 0.2827 - val_acc: 0.9058\n",
      "Epoch 475/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2676 - acc: 0.9042 - val_loss: 0.2856 - val_acc: 0.9047\n",
      "Epoch 476/500\n",
      "8320/8320 [==============================] - 0s 23us/step - loss: 0.2685 - acc: 0.9047 - val_loss: 0.2851 - val_acc: 0.9033\n",
      "Epoch 477/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2698 - acc: 0.9052 - val_loss: 0.2915 - val_acc: 0.9005\n",
      "Epoch 478/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2675 - acc: 0.9037 - val_loss: 0.2888 - val_acc: 0.9033\n",
      "Epoch 479/500\n",
      "8320/8320 [==============================] - 0s 14us/step - loss: 0.2666 - acc: 0.9036 - val_loss: 0.2882 - val_acc: 0.9061\n",
      "Epoch 480/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2676 - acc: 0.9032 - val_loss: 0.2881 - val_acc: 0.9050\n",
      "Epoch 481/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2670 - acc: 0.9046 - val_loss: 0.2866 - val_acc: 0.9058\n",
      "Epoch 482/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2677 - acc: 0.9024 - val_loss: 0.2899 - val_acc: 0.9038\n",
      "Epoch 483/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2669 - acc: 0.9044 - val_loss: 0.2835 - val_acc: 0.9047\n",
      "Epoch 484/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2673 - acc: 0.9037 - val_loss: 0.2932 - val_acc: 0.9010\n",
      "Epoch 485/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2714 - acc: 0.9016 - val_loss: 0.2892 - val_acc: 0.9058\n",
      "Epoch 486/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2684 - acc: 0.9030 - val_loss: 0.2893 - val_acc: 0.9047\n",
      "Epoch 487/500\n",
      "8320/8320 [==============================] - 0s 23us/step - loss: 0.2682 - acc: 0.9048 - val_loss: 0.2860 - val_acc: 0.9047\n",
      "Epoch 488/500\n",
      "8320/8320 [==============================] - 0s 19us/step - loss: 0.2685 - acc: 0.9026 - val_loss: 0.2914 - val_acc: 0.9038\n",
      "Epoch 489/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2683 - acc: 0.9046 - val_loss: 0.2885 - val_acc: 0.9016\n",
      "Epoch 490/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2691 - acc: 0.9028 - val_loss: 0.2895 - val_acc: 0.9019\n",
      "Epoch 491/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2685 - acc: 0.9034 - val_loss: 0.2962 - val_acc: 0.9019\n",
      "Epoch 492/500\n",
      "8320/8320 [==============================] - 0s 17us/step - loss: 0.2678 - acc: 0.9052 - val_loss: 0.2915 - val_acc: 0.9030\n",
      "Epoch 493/500\n",
      "8320/8320 [==============================] - 0s 18us/step - loss: 0.2658 - acc: 0.9056 - val_loss: 0.2965 - val_acc: 0.9024\n",
      "Epoch 494/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2670 - acc: 0.9040 - val_loss: 0.2971 - val_acc: 0.9027\n",
      "Epoch 495/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2661 - acc: 0.9052 - val_loss: 0.2896 - val_acc: 0.9016\n",
      "Epoch 496/500\n",
      "8320/8320 [==============================] - 0s 22us/step - loss: 0.2667 - acc: 0.9046 - val_loss: 0.2853 - val_acc: 0.9058\n",
      "Epoch 497/500\n",
      "8320/8320 [==============================] - 0s 21us/step - loss: 0.2693 - acc: 0.9032 - val_loss: 0.2883 - val_acc: 0.9052\n",
      "Epoch 498/500\n",
      "8320/8320 [==============================] - 0s 24us/step - loss: 0.2661 - acc: 0.9035 - val_loss: 0.2860 - val_acc: 0.9055\n",
      "Epoch 499/500\n",
      "8320/8320 [==============================] - 0s 15us/step - loss: 0.2652 - acc: 0.9054 - val_loss: 0.2849 - val_acc: 0.9038\n",
      "Epoch 500/500\n",
      "8320/8320 [==============================] - 0s 16us/step - loss: 0.2675 - acc: 0.9030 - val_loss: 0.2856 - val_acc: 0.9072\n",
      "3567/3567 [==============================] - 0s 3us/step\n",
      "10 41 403 403 12494 11309 41 1093 1052\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "11309 11309\n",
      "../linkPrediction/dataframes/apnea\n",
      "article (11309, 7, 11) --------------------------------------------------------------------\n",
      "(11309, 11) (11309,)\n",
      "[11309, 11, 1]\n",
      "(7916, 11) (7916,)\n",
      "Train on 7916 samples, validate on 3393 samples\n",
      "Epoch 1/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 1.2002 - acc: 0.8533 - val_loss: 0.9007 - val_acc: 0.8895\n",
      "Epoch 2/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.8625 - acc: 0.8902 - val_loss: 0.7532 - val_acc: 0.8998\n",
      "Epoch 3/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.7166 - acc: 0.8902 - val_loss: 0.5873 - val_acc: 0.8868\n",
      "Epoch 4/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.6419 - acc: 0.8886 - val_loss: 0.6158 - val_acc: 0.8800\n",
      "Epoch 5/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.5925 - acc: 0.8943 - val_loss: 0.5747 - val_acc: 0.9063\n",
      "Epoch 6/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.5627 - acc: 0.8963 - val_loss: 0.5504 - val_acc: 0.8848\n",
      "Epoch 7/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.5671 - acc: 0.8978 - val_loss: 0.6022 - val_acc: 0.9048\n",
      "Epoch 8/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.5399 - acc: 0.8935 - val_loss: 0.4984 - val_acc: 0.8977\n",
      "Epoch 9/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.5072 - acc: 0.8998 - val_loss: 0.4991 - val_acc: 0.8942\n",
      "Epoch 10/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.5483 - acc: 0.8920 - val_loss: 0.7456 - val_acc: 0.8435\n",
      "Epoch 11/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.5092 - acc: 0.8921 - val_loss: 0.4876 - val_acc: 0.8927\n",
      "Epoch 12/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.5182 - acc: 0.8972 - val_loss: 0.4852 - val_acc: 0.8918\n",
      "Epoch 13/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.4712 - acc: 0.9006 - val_loss: 0.4761 - val_acc: 0.8977\n",
      "Epoch 14/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.4865 - acc: 0.8998 - val_loss: 0.5282 - val_acc: 0.8880\n",
      "Epoch 15/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.4928 - acc: 0.8987 - val_loss: 0.4332 - val_acc: 0.9060\n",
      "Epoch 16/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.4540 - acc: 0.8999 - val_loss: 0.4519 - val_acc: 0.9001\n",
      "Epoch 17/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.4289 - acc: 0.9008 - val_loss: 0.5044 - val_acc: 0.8839\n",
      "Epoch 18/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.4346 - acc: 0.8992 - val_loss: 0.4004 - val_acc: 0.9063\n",
      "Epoch 19/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.4237 - acc: 0.9025 - val_loss: 0.3952 - val_acc: 0.9048\n",
      "Epoch 20/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.4297 - acc: 0.8968 - val_loss: 0.4234 - val_acc: 0.9036\n",
      "Epoch 21/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.4036 - acc: 0.8998 - val_loss: 0.3944 - val_acc: 0.9045\n",
      "Epoch 22/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.4377 - acc: 0.8987 - val_loss: 0.4263 - val_acc: 0.9063\n",
      "Epoch 23/500\n",
      "7916/7916 [==============================] - 0s 26us/step - loss: 0.4462 - acc: 0.8945 - val_loss: 0.4531 - val_acc: 0.8915\n",
      "Epoch 24/500\n",
      "7916/7916 [==============================] - 0s 23us/step - loss: 0.4104 - acc: 0.9010 - val_loss: 0.5229 - val_acc: 0.8830\n",
      "Epoch 25/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.4518 - acc: 0.8925 - val_loss: 0.4347 - val_acc: 0.9051\n",
      "Epoch 26/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.4140 - acc: 0.8992 - val_loss: 0.4215 - val_acc: 0.9054\n",
      "Epoch 27/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.4137 - acc: 0.8987 - val_loss: 0.3813 - val_acc: 0.9078\n",
      "Epoch 28/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.4026 - acc: 0.9008 - val_loss: 0.4053 - val_acc: 0.9066\n",
      "Epoch 29/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.3793 - acc: 0.9030 - val_loss: 0.3979 - val_acc: 0.8998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.4885 - acc: 0.8850 - val_loss: 0.4654 - val_acc: 0.9048\n",
      "Epoch 31/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.4078 - acc: 0.9016 - val_loss: 0.5222 - val_acc: 0.8821\n",
      "Epoch 32/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3918 - acc: 0.8998 - val_loss: 0.4224 - val_acc: 0.8974\n",
      "Epoch 33/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3800 - acc: 0.8996 - val_loss: 0.3924 - val_acc: 0.9019\n",
      "Epoch 34/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.4301 - acc: 0.8982 - val_loss: 0.5441 - val_acc: 0.8765\n",
      "Epoch 35/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3863 - acc: 0.9023 - val_loss: 0.4389 - val_acc: 0.9007\n",
      "Epoch 36/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.4363 - acc: 0.8979 - val_loss: 0.3936 - val_acc: 0.9054\n",
      "Epoch 37/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.4110 - acc: 0.8964 - val_loss: 0.5344 - val_acc: 0.8815\n",
      "Epoch 38/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.4293 - acc: 0.9006 - val_loss: 0.4604 - val_acc: 0.8995\n",
      "Epoch 39/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.3800 - acc: 0.9036 - val_loss: 0.3994 - val_acc: 0.8986\n",
      "Epoch 40/500\n",
      "7916/7916 [==============================] - 0s 25us/step - loss: 0.3766 - acc: 0.9034 - val_loss: 0.3762 - val_acc: 0.9024\n",
      "Epoch 41/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3620 - acc: 0.9055 - val_loss: 0.4257 - val_acc: 0.8915\n",
      "Epoch 42/500\n",
      "7916/7916 [==============================] - 0s 26us/step - loss: 0.3799 - acc: 0.9021 - val_loss: 0.3929 - val_acc: 0.9054\n",
      "Epoch 43/500\n",
      "7916/7916 [==============================] - 0s 24us/step - loss: 0.3744 - acc: 0.9005 - val_loss: 0.4666 - val_acc: 0.8907\n",
      "Epoch 44/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.4076 - acc: 0.9031 - val_loss: 0.4652 - val_acc: 0.8998\n",
      "Epoch 45/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.4228 - acc: 0.9012 - val_loss: 0.4092 - val_acc: 0.8977\n",
      "Epoch 46/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.3858 - acc: 0.9054 - val_loss: 0.3733 - val_acc: 0.9057\n",
      "Epoch 47/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.3714 - acc: 0.9029 - val_loss: 0.5957 - val_acc: 0.8644\n",
      "Epoch 48/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3652 - acc: 0.9003 - val_loss: 0.4085 - val_acc: 0.9010\n",
      "Epoch 49/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3600 - acc: 0.9025 - val_loss: 0.3986 - val_acc: 0.8995\n",
      "Epoch 50/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.3865 - acc: 0.9032 - val_loss: 0.4047 - val_acc: 0.9057\n",
      "Epoch 51/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.3554 - acc: 0.9026 - val_loss: 0.3545 - val_acc: 0.9042\n",
      "Epoch 52/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3457 - acc: 0.9053 - val_loss: 0.3855 - val_acc: 0.9063\n",
      "Epoch 53/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3566 - acc: 0.9060 - val_loss: 0.3461 - val_acc: 0.9051\n",
      "Epoch 54/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3748 - acc: 0.9029 - val_loss: 0.3387 - val_acc: 0.9045\n",
      "Epoch 55/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3461 - acc: 0.9070 - val_loss: 0.5367 - val_acc: 0.8809\n",
      "Epoch 56/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.3568 - acc: 0.9041 - val_loss: 0.3604 - val_acc: 0.9063\n",
      "Epoch 57/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.4110 - acc: 0.8994 - val_loss: 0.3527 - val_acc: 0.9054\n",
      "Epoch 58/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3507 - acc: 0.9046 - val_loss: 0.4607 - val_acc: 0.8912\n",
      "Epoch 59/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.4026 - acc: 0.9023 - val_loss: 0.4506 - val_acc: 0.8901\n",
      "Epoch 60/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.3691 - acc: 0.9054 - val_loss: 0.3513 - val_acc: 0.9045\n",
      "Epoch 61/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.3769 - acc: 0.9036 - val_loss: 0.3611 - val_acc: 0.9083\n",
      "Epoch 62/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.3599 - acc: 0.9023 - val_loss: 0.3718 - val_acc: 0.8995\n",
      "Epoch 63/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3550 - acc: 0.9041 - val_loss: 0.4055 - val_acc: 0.9057\n",
      "Epoch 64/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3431 - acc: 0.9044 - val_loss: 0.3920 - val_acc: 0.9066\n",
      "Epoch 65/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.3465 - acc: 0.9051 - val_loss: 0.3522 - val_acc: 0.9042\n",
      "Epoch 66/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.3403 - acc: 0.9060 - val_loss: 0.3541 - val_acc: 0.9013\n",
      "Epoch 67/500\n",
      "7916/7916 [==============================] - 0s 13us/step - loss: 0.3844 - acc: 0.8991 - val_loss: 0.4040 - val_acc: 0.8968\n",
      "Epoch 68/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.3959 - acc: 0.9027 - val_loss: 0.4065 - val_acc: 0.8936\n",
      "Epoch 69/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3384 - acc: 0.9066 - val_loss: 0.3464 - val_acc: 0.9072\n",
      "Epoch 70/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3520 - acc: 0.9039 - val_loss: 0.3726 - val_acc: 0.9069\n",
      "Epoch 71/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3920 - acc: 0.8981 - val_loss: 0.3535 - val_acc: 0.9095\n",
      "Epoch 72/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.3430 - acc: 0.9077 - val_loss: 0.3503 - val_acc: 0.9039\n",
      "Epoch 73/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.3337 - acc: 0.9049 - val_loss: 0.3960 - val_acc: 0.9078\n",
      "Epoch 74/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3722 - acc: 0.9017 - val_loss: 0.3851 - val_acc: 0.9004\n",
      "Epoch 75/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.3402 - acc: 0.9069 - val_loss: 0.3898 - val_acc: 0.9027\n",
      "Epoch 76/500\n",
      "7916/7916 [==============================] - 0s 23us/step - loss: 0.3566 - acc: 0.9056 - val_loss: 0.4970 - val_acc: 0.8859\n",
      "Epoch 77/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.3741 - acc: 0.9012 - val_loss: 0.4160 - val_acc: 0.9069\n",
      "Epoch 78/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.3390 - acc: 0.9058 - val_loss: 0.3950 - val_acc: 0.8998\n",
      "Epoch 79/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3309 - acc: 0.9060 - val_loss: 0.3746 - val_acc: 0.9013\n",
      "Epoch 80/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3264 - acc: 0.9046 - val_loss: 0.3882 - val_acc: 0.8977\n",
      "Epoch 81/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3193 - acc: 0.9064 - val_loss: 0.3502 - val_acc: 0.9072\n",
      "Epoch 82/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.3221 - acc: 0.9085 - val_loss: 0.3991 - val_acc: 0.8992\n",
      "Epoch 83/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.3286 - acc: 0.9060 - val_loss: 0.4948 - val_acc: 0.8856\n",
      "Epoch 84/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3393 - acc: 0.9068 - val_loss: 0.3328 - val_acc: 0.9069\n",
      "Epoch 85/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3219 - acc: 0.9085 - val_loss: 0.3774 - val_acc: 0.9066\n",
      "Epoch 86/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3295 - acc: 0.9056 - val_loss: 0.3631 - val_acc: 0.9048\n",
      "Epoch 87/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3249 - acc: 0.9064 - val_loss: 0.3878 - val_acc: 0.8995\n",
      "Epoch 88/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.3466 - acc: 0.9049 - val_loss: 0.3493 - val_acc: 0.9089\n",
      "Epoch 89/500\n",
      "7916/7916 [==============================] - 0s 13us/step - loss: 0.3394 - acc: 0.9065 - val_loss: 0.3353 - val_acc: 0.9048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3231 - acc: 0.9077 - val_loss: 0.3518 - val_acc: 0.9027\n",
      "Epoch 91/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3593 - acc: 0.9042 - val_loss: 0.3301 - val_acc: 0.9092\n",
      "Epoch 92/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3404 - acc: 0.9066 - val_loss: 0.3970 - val_acc: 0.8998\n",
      "Epoch 93/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.3635 - acc: 0.9013 - val_loss: 0.3850 - val_acc: 0.9024\n",
      "Epoch 94/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.3394 - acc: 0.9010 - val_loss: 0.4351 - val_acc: 0.8930\n",
      "Epoch 95/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.3886 - acc: 0.9020 - val_loss: 0.3724 - val_acc: 0.9019\n",
      "Epoch 96/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3162 - acc: 0.9088 - val_loss: 0.4025 - val_acc: 0.9066\n",
      "Epoch 97/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3161 - acc: 0.9080 - val_loss: 0.3269 - val_acc: 0.9033\n",
      "Epoch 98/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.3418 - acc: 0.9075 - val_loss: 0.3335 - val_acc: 0.9092\n",
      "Epoch 99/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.3232 - acc: 0.9060 - val_loss: 0.3762 - val_acc: 0.9001\n",
      "Epoch 100/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3491 - acc: 0.9030 - val_loss: 0.3348 - val_acc: 0.9057\n",
      "Epoch 101/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3094 - acc: 0.9058 - val_loss: 0.3550 - val_acc: 0.9051\n",
      "Epoch 102/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3219 - acc: 0.9073 - val_loss: 0.3540 - val_acc: 0.9078\n",
      "Epoch 103/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3408 - acc: 0.9035 - val_loss: 0.3216 - val_acc: 0.9075\n",
      "Epoch 104/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3025 - acc: 0.9107 - val_loss: 0.3457 - val_acc: 0.9060\n",
      "Epoch 105/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.3227 - acc: 0.9066 - val_loss: 0.3820 - val_acc: 0.8986\n",
      "Epoch 106/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3007 - acc: 0.9102 - val_loss: 0.3426 - val_acc: 0.9033\n",
      "Epoch 107/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3629 - acc: 0.9029 - val_loss: 0.3585 - val_acc: 0.9030\n",
      "Epoch 108/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3146 - acc: 0.9078 - val_loss: 0.3239 - val_acc: 0.9072\n",
      "Epoch 109/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3068 - acc: 0.9090 - val_loss: 0.4653 - val_acc: 0.8874\n",
      "Epoch 110/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.3576 - acc: 0.9025 - val_loss: 0.3353 - val_acc: 0.9072\n",
      "Epoch 111/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3004 - acc: 0.9080 - val_loss: 0.3486 - val_acc: 0.9036\n",
      "Epoch 112/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3223 - acc: 0.9026 - val_loss: 0.3847 - val_acc: 0.8989\n",
      "Epoch 113/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3249 - acc: 0.9070 - val_loss: 0.3423 - val_acc: 0.9045\n",
      "Epoch 114/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3242 - acc: 0.9070 - val_loss: 0.3727 - val_acc: 0.9054\n",
      "Epoch 115/500\n",
      "7916/7916 [==============================] - 0s 13us/step - loss: 0.3224 - acc: 0.9070 - val_loss: 0.3290 - val_acc: 0.9057\n",
      "Epoch 116/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2959 - acc: 0.9085 - val_loss: 0.3422 - val_acc: 0.9010\n",
      "Epoch 117/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.3265 - acc: 0.9063 - val_loss: 0.3526 - val_acc: 0.9063\n",
      "Epoch 118/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2937 - acc: 0.9088 - val_loss: 0.3307 - val_acc: 0.9045\n",
      "Epoch 119/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3170 - acc: 0.9047 - val_loss: 0.3927 - val_acc: 0.8936\n",
      "Epoch 120/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.3460 - acc: 0.9053 - val_loss: 0.3369 - val_acc: 0.9083\n",
      "Epoch 121/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.3249 - acc: 0.9056 - val_loss: 0.3201 - val_acc: 0.9069\n",
      "Epoch 122/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.2955 - acc: 0.9087 - val_loss: 0.3317 - val_acc: 0.9057\n",
      "Epoch 123/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2915 - acc: 0.9089 - val_loss: 0.3222 - val_acc: 0.9086\n",
      "Epoch 124/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3314 - acc: 0.9068 - val_loss: 0.3363 - val_acc: 0.9075\n",
      "Epoch 125/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2997 - acc: 0.9089 - val_loss: 0.3228 - val_acc: 0.9080\n",
      "Epoch 126/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.3141 - acc: 0.9068 - val_loss: 0.3069 - val_acc: 0.9104\n",
      "Epoch 127/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3111 - acc: 0.9089 - val_loss: 0.3062 - val_acc: 0.9051\n",
      "Epoch 128/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2943 - acc: 0.9088 - val_loss: 0.3274 - val_acc: 0.9022\n",
      "Epoch 129/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3044 - acc: 0.9070 - val_loss: 0.3185 - val_acc: 0.9054\n",
      "Epoch 130/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2995 - acc: 0.9085 - val_loss: 0.3934 - val_acc: 0.8957\n",
      "Epoch 131/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.3186 - acc: 0.9063 - val_loss: 0.3439 - val_acc: 0.9007\n",
      "Epoch 132/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3306 - acc: 0.9049 - val_loss: 0.3203 - val_acc: 0.9078\n",
      "Epoch 133/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2900 - acc: 0.9085 - val_loss: 0.3445 - val_acc: 0.9066\n",
      "Epoch 134/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3107 - acc: 0.9073 - val_loss: 0.3570 - val_acc: 0.9033\n",
      "Epoch 135/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3120 - acc: 0.9072 - val_loss: 0.4261 - val_acc: 0.8904\n",
      "Epoch 136/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.3144 - acc: 0.9072 - val_loss: 0.3142 - val_acc: 0.9092\n",
      "Epoch 137/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3416 - acc: 0.9021 - val_loss: 0.3597 - val_acc: 0.9027\n",
      "Epoch 138/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.3004 - acc: 0.9075 - val_loss: 0.3156 - val_acc: 0.9101\n",
      "Epoch 139/500\n",
      "7916/7916 [==============================] - 0s 25us/step - loss: 0.3182 - acc: 0.9074 - val_loss: 0.3317 - val_acc: 0.9063\n",
      "Epoch 140/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3099 - acc: 0.9068 - val_loss: 0.3154 - val_acc: 0.9060\n",
      "Epoch 141/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2881 - acc: 0.9084 - val_loss: 0.3381 - val_acc: 0.9019\n",
      "Epoch 142/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3069 - acc: 0.9073 - val_loss: 0.3072 - val_acc: 0.9086\n",
      "Epoch 143/500\n",
      "7916/7916 [==============================] - 0s 24us/step - loss: 0.2992 - acc: 0.9080 - val_loss: 0.3576 - val_acc: 0.8992\n",
      "Epoch 144/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.3185 - acc: 0.9089 - val_loss: 0.3151 - val_acc: 0.9069\n",
      "Epoch 145/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.3129 - acc: 0.9050 - val_loss: 0.3166 - val_acc: 0.9083\n",
      "Epoch 146/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2964 - acc: 0.9069 - val_loss: 0.3117 - val_acc: 0.9086\n",
      "Epoch 147/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3066 - acc: 0.9074 - val_loss: 0.3940 - val_acc: 0.9072\n",
      "Epoch 148/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3108 - acc: 0.9064 - val_loss: 0.3100 - val_acc: 0.9066\n",
      "Epoch 149/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3079 - acc: 0.9079 - val_loss: 0.3241 - val_acc: 0.9042\n",
      "Epoch 150/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2969 - acc: 0.9092 - val_loss: 0.3351 - val_acc: 0.9066\n",
      "Epoch 151/500\n",
      "7916/7916 [==============================] - 0s 13us/step - loss: 0.3035 - acc: 0.9063 - val_loss: 0.3082 - val_acc: 0.9075\n",
      "Epoch 152/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.3051 - acc: 0.9066 - val_loss: 0.3167 - val_acc: 0.9033\n",
      "Epoch 153/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2781 - acc: 0.9083 - val_loss: 0.3114 - val_acc: 0.9060\n",
      "Epoch 154/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2869 - acc: 0.9088 - val_loss: 0.3062 - val_acc: 0.9095\n",
      "Epoch 155/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.3008 - acc: 0.9072 - val_loss: 0.3098 - val_acc: 0.9083\n",
      "Epoch 156/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3091 - acc: 0.9070 - val_loss: 0.3259 - val_acc: 0.9054\n",
      "Epoch 157/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2812 - acc: 0.9102 - val_loss: 0.2998 - val_acc: 0.9086\n",
      "Epoch 158/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2996 - acc: 0.9074 - val_loss: 0.3235 - val_acc: 0.9045\n",
      "Epoch 159/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2879 - acc: 0.9080 - val_loss: 0.2977 - val_acc: 0.9080\n",
      "Epoch 160/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.3034 - acc: 0.9068 - val_loss: 0.3077 - val_acc: 0.9089\n",
      "Epoch 161/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2891 - acc: 0.9093 - val_loss: 0.3723 - val_acc: 0.8968\n",
      "Epoch 162/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.3162 - acc: 0.9042 - val_loss: 0.3108 - val_acc: 0.9075\n",
      "Epoch 163/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3143 - acc: 0.9066 - val_loss: 0.3098 - val_acc: 0.9098\n",
      "Epoch 164/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2748 - acc: 0.9089 - val_loss: 0.3011 - val_acc: 0.9075\n",
      "Epoch 165/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2816 - acc: 0.9098 - val_loss: 0.3130 - val_acc: 0.9072\n",
      "Epoch 166/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.2976 - acc: 0.9064 - val_loss: 0.3579 - val_acc: 0.9039\n",
      "Epoch 167/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.2863 - acc: 0.9079 - val_loss: 0.3232 - val_acc: 0.9080\n",
      "Epoch 168/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2967 - acc: 0.9078 - val_loss: 0.3898 - val_acc: 0.9069\n",
      "Epoch 169/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2936 - acc: 0.9087 - val_loss: 0.3173 - val_acc: 0.9069\n",
      "Epoch 170/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2894 - acc: 0.9093 - val_loss: 0.3412 - val_acc: 0.9069\n",
      "Epoch 171/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.3279 - acc: 0.9068 - val_loss: 0.3196 - val_acc: 0.9060\n",
      "Epoch 172/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.3128 - acc: 0.9064 - val_loss: 0.3262 - val_acc: 0.9072\n",
      "Epoch 173/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2836 - acc: 0.9102 - val_loss: 0.3197 - val_acc: 0.9057\n",
      "Epoch 174/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2741 - acc: 0.9113 - val_loss: 0.3298 - val_acc: 0.9024\n",
      "Epoch 175/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2871 - acc: 0.9085 - val_loss: 0.3036 - val_acc: 0.9098\n",
      "Epoch 176/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.2777 - acc: 0.9078 - val_loss: 0.3033 - val_acc: 0.9098\n",
      "Epoch 177/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2962 - acc: 0.9085 - val_loss: 0.3455 - val_acc: 0.9030\n",
      "Epoch 178/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2852 - acc: 0.9079 - val_loss: 0.3101 - val_acc: 0.9075\n",
      "Epoch 179/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2951 - acc: 0.9078 - val_loss: 0.3117 - val_acc: 0.9083\n",
      "Epoch 180/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2960 - acc: 0.9080 - val_loss: 0.3718 - val_acc: 0.8957\n",
      "Epoch 181/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2883 - acc: 0.9078 - val_loss: 0.2993 - val_acc: 0.9080\n",
      "Epoch 182/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2788 - acc: 0.9117 - val_loss: 0.3061 - val_acc: 0.9078\n",
      "Epoch 183/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2805 - acc: 0.9089 - val_loss: 0.3542 - val_acc: 0.8998\n",
      "Epoch 184/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2859 - acc: 0.9079 - val_loss: 0.3184 - val_acc: 0.9013\n",
      "Epoch 185/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2726 - acc: 0.9092 - val_loss: 0.3017 - val_acc: 0.9101\n",
      "Epoch 186/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2776 - acc: 0.9087 - val_loss: 0.2997 - val_acc: 0.9086\n",
      "Epoch 187/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2798 - acc: 0.9096 - val_loss: 0.3341 - val_acc: 0.9078\n",
      "Epoch 188/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2796 - acc: 0.9097 - val_loss: 0.3291 - val_acc: 0.9057\n",
      "Epoch 189/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2943 - acc: 0.9068 - val_loss: 0.3088 - val_acc: 0.9054\n",
      "Epoch 190/500\n",
      "7916/7916 [==============================] - 0s 23us/step - loss: 0.2724 - acc: 0.9097 - val_loss: 0.3192 - val_acc: 0.9036\n",
      "Epoch 191/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2968 - acc: 0.9092 - val_loss: 0.3009 - val_acc: 0.9101\n",
      "Epoch 192/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2894 - acc: 0.9094 - val_loss: 0.3739 - val_acc: 0.8986\n",
      "Epoch 193/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2824 - acc: 0.9085 - val_loss: 0.3056 - val_acc: 0.9104\n",
      "Epoch 194/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2841 - acc: 0.9090 - val_loss: 0.3339 - val_acc: 0.9063\n",
      "Epoch 195/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.3050 - acc: 0.9050 - val_loss: 0.3734 - val_acc: 0.8998\n",
      "Epoch 196/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2931 - acc: 0.9078 - val_loss: 0.3050 - val_acc: 0.9092\n",
      "Epoch 197/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2701 - acc: 0.9103 - val_loss: 0.3208 - val_acc: 0.9080\n",
      "Epoch 198/500\n",
      "7916/7916 [==============================] - 0s 13us/step - loss: 0.2763 - acc: 0.9106 - val_loss: 0.2961 - val_acc: 0.9119\n",
      "Epoch 199/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2785 - acc: 0.9085 - val_loss: 0.3388 - val_acc: 0.9075\n",
      "Epoch 200/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2789 - acc: 0.9077 - val_loss: 0.3120 - val_acc: 0.9078\n",
      "Epoch 201/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2790 - acc: 0.9096 - val_loss: 0.3129 - val_acc: 0.9033\n",
      "Epoch 202/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2755 - acc: 0.9108 - val_loss: 0.2969 - val_acc: 0.9086\n",
      "Epoch 203/500\n",
      "7916/7916 [==============================] - 0s 13us/step - loss: 0.2821 - acc: 0.9087 - val_loss: 0.3544 - val_acc: 0.9063\n",
      "Epoch 204/500\n",
      "7916/7916 [==============================] - 0s 13us/step - loss: 0.2696 - acc: 0.9103 - val_loss: 0.3342 - val_acc: 0.9004\n",
      "Epoch 205/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2783 - acc: 0.9096 - val_loss: 0.3351 - val_acc: 0.9042\n",
      "Epoch 206/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.2773 - acc: 0.9089 - val_loss: 0.3184 - val_acc: 0.9051\n",
      "Epoch 207/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2677 - acc: 0.9108 - val_loss: 0.3132 - val_acc: 0.9075\n",
      "Epoch 208/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2714 - acc: 0.9092 - val_loss: 0.3037 - val_acc: 0.9089\n",
      "Epoch 209/500\n",
      "7916/7916 [==============================] - 0s 13us/step - loss: 0.2743 - acc: 0.9099 - val_loss: 0.3000 - val_acc: 0.9078\n",
      "Epoch 210/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2705 - acc: 0.9098 - val_loss: 0.2963 - val_acc: 0.9101\n",
      "Epoch 211/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2717 - acc: 0.9107 - val_loss: 0.3223 - val_acc: 0.9078\n",
      "Epoch 212/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2917 - acc: 0.9070 - val_loss: 0.3670 - val_acc: 0.8995\n",
      "Epoch 213/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2987 - acc: 0.9065 - val_loss: 0.3167 - val_acc: 0.9095\n",
      "Epoch 214/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.2914 - acc: 0.9066 - val_loss: 0.3293 - val_acc: 0.9042\n",
      "Epoch 215/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2876 - acc: 0.9083 - val_loss: 0.3487 - val_acc: 0.9001\n",
      "Epoch 216/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2788 - acc: 0.9073 - val_loss: 0.3188 - val_acc: 0.9048\n",
      "Epoch 217/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2834 - acc: 0.9094 - val_loss: 0.3732 - val_acc: 0.9010\n",
      "Epoch 218/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2881 - acc: 0.9068 - val_loss: 0.3040 - val_acc: 0.9072\n",
      "Epoch 219/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2780 - acc: 0.9096 - val_loss: 0.3093 - val_acc: 0.9024\n",
      "Epoch 220/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.2720 - acc: 0.9087 - val_loss: 0.3039 - val_acc: 0.9042\n",
      "Epoch 221/500\n",
      "7916/7916 [==============================] - 0s 13us/step - loss: 0.2765 - acc: 0.9083 - val_loss: 0.2965 - val_acc: 0.9098\n",
      "Epoch 222/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2852 - acc: 0.9080 - val_loss: 0.3274 - val_acc: 0.9069\n",
      "Epoch 223/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2896 - acc: 0.9070 - val_loss: 0.3108 - val_acc: 0.9066\n",
      "Epoch 224/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2725 - acc: 0.9092 - val_loss: 0.3003 - val_acc: 0.9116\n",
      "Epoch 225/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2866 - acc: 0.9066 - val_loss: 0.2982 - val_acc: 0.9060\n",
      "Epoch 226/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.2636 - acc: 0.9104 - val_loss: 0.3018 - val_acc: 0.9086\n",
      "Epoch 227/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2674 - acc: 0.9099 - val_loss: 0.2974 - val_acc: 0.9083\n",
      "Epoch 228/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2786 - acc: 0.9107 - val_loss: 0.2886 - val_acc: 0.9098\n",
      "Epoch 229/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2666 - acc: 0.9111 - val_loss: 0.2962 - val_acc: 0.9086\n",
      "Epoch 230/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2836 - acc: 0.9085 - val_loss: 0.3149 - val_acc: 0.9072\n",
      "Epoch 231/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2756 - acc: 0.9089 - val_loss: 0.2940 - val_acc: 0.9083\n",
      "Epoch 232/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2640 - acc: 0.9106 - val_loss: 0.2913 - val_acc: 0.9092\n",
      "Epoch 233/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2787 - acc: 0.9075 - val_loss: 0.3421 - val_acc: 0.9027\n",
      "Epoch 234/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2734 - acc: 0.9097 - val_loss: 0.2866 - val_acc: 0.9104\n",
      "Epoch 235/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2749 - acc: 0.9093 - val_loss: 0.3187 - val_acc: 0.9022\n",
      "Epoch 236/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2689 - acc: 0.9098 - val_loss: 0.2987 - val_acc: 0.9089\n",
      "Epoch 237/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2683 - acc: 0.9090 - val_loss: 0.2951 - val_acc: 0.9083\n",
      "Epoch 238/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2646 - acc: 0.9106 - val_loss: 0.3058 - val_acc: 0.9060\n",
      "Epoch 239/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2743 - acc: 0.9106 - val_loss: 0.3061 - val_acc: 0.9075\n",
      "Epoch 240/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2630 - acc: 0.9099 - val_loss: 0.2980 - val_acc: 0.9107\n",
      "Epoch 241/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2620 - acc: 0.9104 - val_loss: 0.2929 - val_acc: 0.9089\n",
      "Epoch 242/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2783 - acc: 0.9104 - val_loss: 0.3246 - val_acc: 0.9060\n",
      "Epoch 243/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2808 - acc: 0.9077 - val_loss: 0.3325 - val_acc: 0.9045\n",
      "Epoch 244/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2820 - acc: 0.9090 - val_loss: 0.2879 - val_acc: 0.9083\n",
      "Epoch 245/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2859 - acc: 0.9085 - val_loss: 0.3011 - val_acc: 0.9104\n",
      "Epoch 246/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.2726 - acc: 0.9092 - val_loss: 0.2936 - val_acc: 0.9104\n",
      "Epoch 247/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2687 - acc: 0.9096 - val_loss: 0.2957 - val_acc: 0.9086\n",
      "Epoch 248/500\n",
      "7916/7916 [==============================] - 0s 26us/step - loss: 0.2633 - acc: 0.9116 - val_loss: 0.3191 - val_acc: 0.9045\n",
      "Epoch 249/500\n",
      "7916/7916 [==============================] - 0s 26us/step - loss: 0.2698 - acc: 0.9102 - val_loss: 0.3005 - val_acc: 0.9086\n",
      "Epoch 250/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2679 - acc: 0.9098 - val_loss: 0.2996 - val_acc: 0.9089\n",
      "Epoch 251/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2648 - acc: 0.9093 - val_loss: 0.2856 - val_acc: 0.9086\n",
      "Epoch 252/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2605 - acc: 0.9120 - val_loss: 0.3001 - val_acc: 0.9060\n",
      "Epoch 253/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2752 - acc: 0.9090 - val_loss: 0.3001 - val_acc: 0.9080\n",
      "Epoch 254/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2692 - acc: 0.9088 - val_loss: 0.2984 - val_acc: 0.9072\n",
      "Epoch 255/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2672 - acc: 0.9108 - val_loss: 0.3411 - val_acc: 0.9022\n",
      "Epoch 256/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.2843 - acc: 0.9079 - val_loss: 0.2938 - val_acc: 0.9098\n",
      "Epoch 257/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2648 - acc: 0.9120 - val_loss: 0.2982 - val_acc: 0.9048\n",
      "Epoch 258/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2762 - acc: 0.9093 - val_loss: 0.2893 - val_acc: 0.9080\n",
      "Epoch 259/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2705 - acc: 0.9114 - val_loss: 0.2926 - val_acc: 0.9063\n",
      "Epoch 260/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2744 - acc: 0.9101 - val_loss: 0.2903 - val_acc: 0.9063\n",
      "Epoch 261/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2727 - acc: 0.9106 - val_loss: 0.3011 - val_acc: 0.9069\n",
      "Epoch 262/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2730 - acc: 0.9098 - val_loss: 0.3149 - val_acc: 0.9054\n",
      "Epoch 263/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2841 - acc: 0.9070 - val_loss: 0.3205 - val_acc: 0.9054\n",
      "Epoch 264/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2713 - acc: 0.9098 - val_loss: 0.2946 - val_acc: 0.9107\n",
      "Epoch 265/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2676 - acc: 0.9101 - val_loss: 0.2982 - val_acc: 0.9063\n",
      "Epoch 266/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2621 - acc: 0.9109 - val_loss: 0.2862 - val_acc: 0.9101\n",
      "Epoch 267/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2667 - acc: 0.9103 - val_loss: 0.3163 - val_acc: 0.9069\n",
      "Epoch 268/500\n",
      "7916/7916 [==============================] - 0s 25us/step - loss: 0.2794 - acc: 0.9084 - val_loss: 0.2943 - val_acc: 0.9075\n",
      "Epoch 269/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2788 - acc: 0.9089 - val_loss: 0.3024 - val_acc: 0.9057\n",
      "Epoch 270/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2817 - acc: 0.9101 - val_loss: 0.3042 - val_acc: 0.9080\n",
      "Epoch 271/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2870 - acc: 0.9078 - val_loss: 0.2915 - val_acc: 0.9069\n",
      "Epoch 272/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2831 - acc: 0.9082 - val_loss: 0.2984 - val_acc: 0.9063\n",
      "Epoch 273/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2694 - acc: 0.9085 - val_loss: 0.2938 - val_acc: 0.9078\n",
      "Epoch 274/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2647 - acc: 0.9117 - val_loss: 0.2955 - val_acc: 0.9083\n",
      "Epoch 275/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2652 - acc: 0.9102 - val_loss: 0.2934 - val_acc: 0.9063\n",
      "Epoch 276/500\n",
      "7916/7916 [==============================] - 0s 13us/step - loss: 0.2642 - acc: 0.9101 - val_loss: 0.2964 - val_acc: 0.9063\n",
      "Epoch 277/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2686 - acc: 0.9109 - val_loss: 0.2864 - val_acc: 0.9072\n",
      "Epoch 278/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.2666 - acc: 0.9084 - val_loss: 0.3042 - val_acc: 0.9036\n",
      "Epoch 279/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2686 - acc: 0.9103 - val_loss: 0.2985 - val_acc: 0.9057\n",
      "Epoch 280/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2735 - acc: 0.9107 - val_loss: 0.2941 - val_acc: 0.9092\n",
      "Epoch 281/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2684 - acc: 0.9101 - val_loss: 0.2889 - val_acc: 0.9078\n",
      "Epoch 282/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2594 - acc: 0.9094 - val_loss: 0.2866 - val_acc: 0.9066\n",
      "Epoch 283/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2598 - acc: 0.9111 - val_loss: 0.3071 - val_acc: 0.9063\n",
      "Epoch 284/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2606 - acc: 0.9113 - val_loss: 0.3004 - val_acc: 0.9063\n",
      "Epoch 285/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2656 - acc: 0.9106 - val_loss: 0.3089 - val_acc: 0.9027\n",
      "Epoch 286/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2703 - acc: 0.9093 - val_loss: 0.2949 - val_acc: 0.9063\n",
      "Epoch 287/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2741 - acc: 0.9087 - val_loss: 0.3132 - val_acc: 0.9033\n",
      "Epoch 288/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.2630 - acc: 0.9088 - val_loss: 0.2912 - val_acc: 0.9063\n",
      "Epoch 289/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2670 - acc: 0.9102 - val_loss: 0.2948 - val_acc: 0.9078\n",
      "Epoch 290/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2695 - acc: 0.9099 - val_loss: 0.2937 - val_acc: 0.9057\n",
      "Epoch 291/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2618 - acc: 0.9126 - val_loss: 0.2952 - val_acc: 0.9086\n",
      "Epoch 292/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2592 - acc: 0.9116 - val_loss: 0.2868 - val_acc: 0.9119\n",
      "Epoch 293/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2602 - acc: 0.9118 - val_loss: 0.2910 - val_acc: 0.9060\n",
      "Epoch 294/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2656 - acc: 0.9113 - val_loss: 0.2880 - val_acc: 0.9086\n",
      "Epoch 295/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2818 - acc: 0.9089 - val_loss: 0.3042 - val_acc: 0.9060\n",
      "Epoch 296/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2638 - acc: 0.9111 - val_loss: 0.3085 - val_acc: 0.9072\n",
      "Epoch 297/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2606 - acc: 0.9112 - val_loss: 0.3037 - val_acc: 0.9107\n",
      "Epoch 298/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2644 - acc: 0.9103 - val_loss: 0.3003 - val_acc: 0.9072\n",
      "Epoch 299/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2637 - acc: 0.9102 - val_loss: 0.3041 - val_acc: 0.9039\n",
      "Epoch 300/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2620 - acc: 0.9126 - val_loss: 0.3020 - val_acc: 0.9063\n",
      "Epoch 301/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2697 - acc: 0.9098 - val_loss: 0.2953 - val_acc: 0.9063\n",
      "Epoch 302/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2618 - acc: 0.9099 - val_loss: 0.2884 - val_acc: 0.9072\n",
      "Epoch 303/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2578 - acc: 0.9106 - val_loss: 0.2887 - val_acc: 0.9086\n",
      "Epoch 304/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2675 - acc: 0.9098 - val_loss: 0.2987 - val_acc: 0.9048\n",
      "Epoch 305/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2677 - acc: 0.9102 - val_loss: 0.2981 - val_acc: 0.9080\n",
      "Epoch 306/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2706 - acc: 0.9082 - val_loss: 0.2909 - val_acc: 0.9086\n",
      "Epoch 307/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2632 - acc: 0.9092 - val_loss: 0.2872 - val_acc: 0.9072\n",
      "Epoch 308/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2673 - acc: 0.9096 - val_loss: 0.3055 - val_acc: 0.9066\n",
      "Epoch 309/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.2672 - acc: 0.9103 - val_loss: 0.2873 - val_acc: 0.9089\n",
      "Epoch 310/500\n",
      "7916/7916 [==============================] - 0s 13us/step - loss: 0.2583 - acc: 0.9111 - val_loss: 0.3138 - val_acc: 0.9054\n",
      "Epoch 311/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2687 - acc: 0.9097 - val_loss: 0.3026 - val_acc: 0.9083\n",
      "Epoch 312/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2768 - acc: 0.9074 - val_loss: 0.2888 - val_acc: 0.9083\n",
      "Epoch 313/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2598 - acc: 0.9094 - val_loss: 0.2925 - val_acc: 0.9101\n",
      "Epoch 314/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2597 - acc: 0.9117 - val_loss: 0.2911 - val_acc: 0.9072\n",
      "Epoch 315/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2657 - acc: 0.9089 - val_loss: 0.3050 - val_acc: 0.9060\n",
      "Epoch 316/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2588 - acc: 0.9117 - val_loss: 0.2917 - val_acc: 0.9089\n",
      "Epoch 317/500\n",
      "7916/7916 [==============================] - 0s 23us/step - loss: 0.2616 - acc: 0.9101 - val_loss: 0.2983 - val_acc: 0.9075\n",
      "Epoch 318/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.2691 - acc: 0.9098 - val_loss: 0.3180 - val_acc: 0.9033\n",
      "Epoch 319/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2690 - acc: 0.9089 - val_loss: 0.2973 - val_acc: 0.9042\n",
      "Epoch 320/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.2646 - acc: 0.9099 - val_loss: 0.3008 - val_acc: 0.9063\n",
      "Epoch 321/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.2620 - acc: 0.9092 - val_loss: 0.2947 - val_acc: 0.9092\n",
      "Epoch 322/500\n",
      "7916/7916 [==============================] - 0s 23us/step - loss: 0.2634 - acc: 0.9107 - val_loss: 0.2969 - val_acc: 0.9069\n",
      "Epoch 323/500\n",
      "7916/7916 [==============================] - 0s 23us/step - loss: 0.2571 - acc: 0.9107 - val_loss: 0.2932 - val_acc: 0.9092\n",
      "Epoch 324/500\n",
      "7916/7916 [==============================] - 0s 23us/step - loss: 0.2550 - acc: 0.9106 - val_loss: 0.3068 - val_acc: 0.9036\n",
      "Epoch 325/500\n",
      "7916/7916 [==============================] - 0s 24us/step - loss: 0.2562 - acc: 0.9130 - val_loss: 0.2928 - val_acc: 0.9078\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7916/7916 [==============================] - 0s 25us/step - loss: 0.2618 - acc: 0.9107 - val_loss: 0.3023 - val_acc: 0.9063\n",
      "Epoch 327/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2615 - acc: 0.9102 - val_loss: 0.2914 - val_acc: 0.9078\n",
      "Epoch 328/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2649 - acc: 0.9072 - val_loss: 0.3039 - val_acc: 0.9075\n",
      "Epoch 329/500\n",
      "7916/7916 [==============================] - 0s 23us/step - loss: 0.2614 - acc: 0.9120 - val_loss: 0.3001 - val_acc: 0.9057\n",
      "Epoch 330/500\n",
      "7916/7916 [==============================] - 0s 23us/step - loss: 0.2583 - acc: 0.9109 - val_loss: 0.3082 - val_acc: 0.9019\n",
      "Epoch 331/500\n",
      "7916/7916 [==============================] - 0s 25us/step - loss: 0.2620 - acc: 0.9103 - val_loss: 0.2908 - val_acc: 0.9086\n",
      "Epoch 332/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2613 - acc: 0.9106 - val_loss: 0.2920 - val_acc: 0.9063\n",
      "Epoch 333/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2605 - acc: 0.9106 - val_loss: 0.3035 - val_acc: 0.9045\n",
      "Epoch 334/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2605 - acc: 0.9097 - val_loss: 0.3008 - val_acc: 0.9054\n",
      "Epoch 335/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2612 - acc: 0.9099 - val_loss: 0.3020 - val_acc: 0.9045\n",
      "Epoch 336/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2628 - acc: 0.9117 - val_loss: 0.2860 - val_acc: 0.9086\n",
      "Epoch 337/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.2715 - acc: 0.9090 - val_loss: 0.2877 - val_acc: 0.9086\n",
      "Epoch 338/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2582 - acc: 0.9136 - val_loss: 0.3156 - val_acc: 0.9072\n",
      "Epoch 339/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2659 - acc: 0.9104 - val_loss: 0.2827 - val_acc: 0.9116\n",
      "Epoch 340/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2569 - acc: 0.9113 - val_loss: 0.2856 - val_acc: 0.9089\n",
      "Epoch 341/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2565 - acc: 0.9123 - val_loss: 0.2924 - val_acc: 0.9104\n",
      "Epoch 342/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2599 - acc: 0.9103 - val_loss: 0.2966 - val_acc: 0.9069\n",
      "Epoch 343/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2631 - acc: 0.9084 - val_loss: 0.2962 - val_acc: 0.9054\n",
      "Epoch 344/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2572 - acc: 0.9117 - val_loss: 0.2895 - val_acc: 0.9107\n",
      "Epoch 345/500\n",
      "7916/7916 [==============================] - 0s 23us/step - loss: 0.2846 - acc: 0.9085 - val_loss: 0.2936 - val_acc: 0.9078\n",
      "Epoch 346/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2579 - acc: 0.9099 - val_loss: 0.2897 - val_acc: 0.9098\n",
      "Epoch 347/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2612 - acc: 0.9096 - val_loss: 0.2865 - val_acc: 0.9089\n",
      "Epoch 348/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2552 - acc: 0.9109 - val_loss: 0.2890 - val_acc: 0.9066\n",
      "Epoch 349/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2604 - acc: 0.9112 - val_loss: 0.2932 - val_acc: 0.9092\n",
      "Epoch 350/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2577 - acc: 0.9126 - val_loss: 0.3028 - val_acc: 0.9048\n",
      "Epoch 351/500\n",
      "7916/7916 [==============================] - 0s 26us/step - loss: 0.2614 - acc: 0.9104 - val_loss: 0.2980 - val_acc: 0.9066\n",
      "Epoch 352/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2626 - acc: 0.9096 - val_loss: 0.3032 - val_acc: 0.9063\n",
      "Epoch 353/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2677 - acc: 0.9094 - val_loss: 0.2930 - val_acc: 0.9083\n",
      "Epoch 354/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2591 - acc: 0.9098 - val_loss: 0.2911 - val_acc: 0.9069\n",
      "Epoch 355/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2607 - acc: 0.9089 - val_loss: 0.2918 - val_acc: 0.9066\n",
      "Epoch 356/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2646 - acc: 0.9096 - val_loss: 0.2946 - val_acc: 0.9072\n",
      "Epoch 357/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2601 - acc: 0.9107 - val_loss: 0.2930 - val_acc: 0.9069\n",
      "Epoch 358/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2634 - acc: 0.9096 - val_loss: 0.3016 - val_acc: 0.9075\n",
      "Epoch 359/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2623 - acc: 0.9085 - val_loss: 0.3077 - val_acc: 0.9072\n",
      "Epoch 360/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2638 - acc: 0.9108 - val_loss: 0.2913 - val_acc: 0.9089\n",
      "Epoch 361/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2578 - acc: 0.9099 - val_loss: 0.2950 - val_acc: 0.9089\n",
      "Epoch 362/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2556 - acc: 0.9123 - val_loss: 0.2982 - val_acc: 0.9063\n",
      "Epoch 363/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2658 - acc: 0.9093 - val_loss: 0.3090 - val_acc: 0.9066\n",
      "Epoch 364/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2630 - acc: 0.9090 - val_loss: 0.2891 - val_acc: 0.9069\n",
      "Epoch 365/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2606 - acc: 0.9094 - val_loss: 0.2917 - val_acc: 0.9075\n",
      "Epoch 366/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2579 - acc: 0.9107 - val_loss: 0.3060 - val_acc: 0.9066\n",
      "Epoch 367/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2581 - acc: 0.9117 - val_loss: 0.3039 - val_acc: 0.9063\n",
      "Epoch 368/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2568 - acc: 0.9120 - val_loss: 0.3007 - val_acc: 0.9089\n",
      "Epoch 369/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2534 - acc: 0.9127 - val_loss: 0.2931 - val_acc: 0.9110\n",
      "Epoch 370/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2558 - acc: 0.9112 - val_loss: 0.2906 - val_acc: 0.9110\n",
      "Epoch 371/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2563 - acc: 0.9112 - val_loss: 0.2909 - val_acc: 0.9092\n",
      "Epoch 372/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2558 - acc: 0.9113 - val_loss: 0.3037 - val_acc: 0.9063\n",
      "Epoch 373/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2561 - acc: 0.9088 - val_loss: 0.2989 - val_acc: 0.9069\n",
      "Epoch 374/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2532 - acc: 0.9130 - val_loss: 0.2947 - val_acc: 0.9075\n",
      "Epoch 375/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2563 - acc: 0.9122 - val_loss: 0.3037 - val_acc: 0.9066\n",
      "Epoch 376/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2616 - acc: 0.9088 - val_loss: 0.3178 - val_acc: 0.9039\n",
      "Epoch 377/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2694 - acc: 0.9096 - val_loss: 0.2965 - val_acc: 0.9078\n",
      "Epoch 378/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2643 - acc: 0.9087 - val_loss: 0.2938 - val_acc: 0.9051\n",
      "Epoch 379/500\n",
      "7916/7916 [==============================] - 0s 31us/step - loss: 0.2582 - acc: 0.9112 - val_loss: 0.2894 - val_acc: 0.9078\n",
      "Epoch 380/500\n",
      "7916/7916 [==============================] - 0s 28us/step - loss: 0.2544 - acc: 0.9118 - val_loss: 0.2944 - val_acc: 0.9086\n",
      "Epoch 381/500\n",
      "7916/7916 [==============================] - 0s 29us/step - loss: 0.2590 - acc: 0.9103 - val_loss: 0.2891 - val_acc: 0.9092\n",
      "Epoch 382/500\n",
      "7916/7916 [==============================] - 0s 25us/step - loss: 0.2549 - acc: 0.9125 - val_loss: 0.2990 - val_acc: 0.9045\n",
      "Epoch 383/500\n",
      "7916/7916 [==============================] - 0s 30us/step - loss: 0.2579 - acc: 0.9114 - val_loss: 0.2932 - val_acc: 0.9083\n",
      "Epoch 384/500\n",
      "7916/7916 [==============================] - 0s 31us/step - loss: 0.2560 - acc: 0.9103 - val_loss: 0.3083 - val_acc: 0.9051\n",
      "Epoch 385/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7916/7916 [==============================] - 0s 30us/step - loss: 0.2583 - acc: 0.9104 - val_loss: 0.2951 - val_acc: 0.9078\n",
      "Epoch 386/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2561 - acc: 0.9094 - val_loss: 0.3021 - val_acc: 0.9086\n",
      "Epoch 387/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2562 - acc: 0.9108 - val_loss: 0.2950 - val_acc: 0.9080\n",
      "Epoch 388/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2566 - acc: 0.9099 - val_loss: 0.2952 - val_acc: 0.9089\n",
      "Epoch 389/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2634 - acc: 0.9108 - val_loss: 0.3023 - val_acc: 0.9075\n",
      "Epoch 390/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2580 - acc: 0.9107 - val_loss: 0.2974 - val_acc: 0.9101\n",
      "Epoch 391/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2567 - acc: 0.9089 - val_loss: 0.2965 - val_acc: 0.9083\n",
      "Epoch 392/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2614 - acc: 0.9098 - val_loss: 0.2899 - val_acc: 0.9098\n",
      "Epoch 393/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2602 - acc: 0.9089 - val_loss: 0.2986 - val_acc: 0.9095\n",
      "Epoch 394/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2551 - acc: 0.9122 - val_loss: 0.2946 - val_acc: 0.9083\n",
      "Epoch 395/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2565 - acc: 0.9094 - val_loss: 0.3004 - val_acc: 0.9075\n",
      "Epoch 396/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2562 - acc: 0.9096 - val_loss: 0.2947 - val_acc: 0.9095\n",
      "Epoch 397/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2563 - acc: 0.9118 - val_loss: 0.3152 - val_acc: 0.9030\n",
      "Epoch 398/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2575 - acc: 0.9094 - val_loss: 0.3026 - val_acc: 0.9078\n",
      "Epoch 399/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2558 - acc: 0.9099 - val_loss: 0.2900 - val_acc: 0.9104\n",
      "Epoch 400/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2539 - acc: 0.9117 - val_loss: 0.3023 - val_acc: 0.9072\n",
      "Epoch 401/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2538 - acc: 0.9126 - val_loss: 0.3090 - val_acc: 0.9078\n",
      "Epoch 402/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2604 - acc: 0.9085 - val_loss: 0.2932 - val_acc: 0.9095\n",
      "Epoch 403/500\n",
      "7916/7916 [==============================] - 0s 27us/step - loss: 0.2611 - acc: 0.9090 - val_loss: 0.2975 - val_acc: 0.9083\n",
      "Epoch 404/500\n",
      "7916/7916 [==============================] - 0s 27us/step - loss: 0.2605 - acc: 0.9093 - val_loss: 0.2930 - val_acc: 0.9089\n",
      "Epoch 405/500\n",
      "7916/7916 [==============================] - 0s 25us/step - loss: 0.2574 - acc: 0.9102 - val_loss: 0.2967 - val_acc: 0.9089\n",
      "Epoch 406/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2571 - acc: 0.9120 - val_loss: 0.3152 - val_acc: 0.9066\n",
      "Epoch 407/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2633 - acc: 0.9082 - val_loss: 0.2954 - val_acc: 0.9072\n",
      "Epoch 408/500\n",
      "7916/7916 [==============================] - 0s 25us/step - loss: 0.2546 - acc: 0.9104 - val_loss: 0.2918 - val_acc: 0.9063\n",
      "Epoch 409/500\n",
      "7916/7916 [==============================] - 0s 24us/step - loss: 0.2525 - acc: 0.9108 - val_loss: 0.2949 - val_acc: 0.9075\n",
      "Epoch 410/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.2536 - acc: 0.9098 - val_loss: 0.2978 - val_acc: 0.9092\n",
      "Epoch 411/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2534 - acc: 0.9107 - val_loss: 0.2987 - val_acc: 0.9080\n",
      "Epoch 412/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2533 - acc: 0.9116 - val_loss: 0.2955 - val_acc: 0.9095\n",
      "Epoch 413/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2553 - acc: 0.9089 - val_loss: 0.2974 - val_acc: 0.9104\n",
      "Epoch 414/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.2547 - acc: 0.9113 - val_loss: 0.2933 - val_acc: 0.9104\n",
      "Epoch 415/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2555 - acc: 0.9123 - val_loss: 0.2940 - val_acc: 0.9078\n",
      "Epoch 416/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2537 - acc: 0.9120 - val_loss: 0.2964 - val_acc: 0.9089\n",
      "Epoch 417/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2552 - acc: 0.9107 - val_loss: 0.2992 - val_acc: 0.9101\n",
      "Epoch 418/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2527 - acc: 0.9118 - val_loss: 0.3022 - val_acc: 0.9078\n",
      "Epoch 419/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2543 - acc: 0.9126 - val_loss: 0.3092 - val_acc: 0.9054\n",
      "Epoch 420/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.2538 - acc: 0.9112 - val_loss: 0.3078 - val_acc: 0.9060\n",
      "Epoch 421/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2575 - acc: 0.9112 - val_loss: 0.3083 - val_acc: 0.9069\n",
      "Epoch 422/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2590 - acc: 0.9108 - val_loss: 0.3013 - val_acc: 0.9066\n",
      "Epoch 423/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2544 - acc: 0.9109 - val_loss: 0.2965 - val_acc: 0.9092\n",
      "Epoch 424/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2519 - acc: 0.9123 - val_loss: 0.2961 - val_acc: 0.9060\n",
      "Epoch 425/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2573 - acc: 0.9092 - val_loss: 0.3004 - val_acc: 0.9083\n",
      "Epoch 426/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.2536 - acc: 0.9101 - val_loss: 0.2925 - val_acc: 0.9080\n",
      "Epoch 427/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2529 - acc: 0.9107 - val_loss: 0.3049 - val_acc: 0.9033\n",
      "Epoch 428/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2563 - acc: 0.9130 - val_loss: 0.3039 - val_acc: 0.9036\n",
      "Epoch 429/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2588 - acc: 0.9093 - val_loss: 0.2938 - val_acc: 0.9086\n",
      "Epoch 430/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2566 - acc: 0.9099 - val_loss: 0.3060 - val_acc: 0.9033\n",
      "Epoch 431/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2581 - acc: 0.9098 - val_loss: 0.2938 - val_acc: 0.9086\n",
      "Epoch 432/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2526 - acc: 0.9113 - val_loss: 0.2936 - val_acc: 0.9057\n",
      "Epoch 433/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2561 - acc: 0.9108 - val_loss: 0.2972 - val_acc: 0.9086\n",
      "Epoch 434/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2568 - acc: 0.9106 - val_loss: 0.3009 - val_acc: 0.9060\n",
      "Epoch 435/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2533 - acc: 0.9114 - val_loss: 0.3032 - val_acc: 0.9051\n",
      "Epoch 436/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2551 - acc: 0.9112 - val_loss: 0.2974 - val_acc: 0.9083\n",
      "Epoch 437/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2558 - acc: 0.9106 - val_loss: 0.3071 - val_acc: 0.9098\n",
      "Epoch 438/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2540 - acc: 0.9102 - val_loss: 0.3019 - val_acc: 0.9078\n",
      "Epoch 439/500\n",
      "7916/7916 [==============================] - 0s 23us/step - loss: 0.2512 - acc: 0.9126 - val_loss: 0.2982 - val_acc: 0.9101\n",
      "Epoch 440/500\n",
      "7916/7916 [==============================] - 0s 28us/step - loss: 0.2537 - acc: 0.9094 - val_loss: 0.3004 - val_acc: 0.9051\n",
      "Epoch 441/500\n",
      "7916/7916 [==============================] - 0s 25us/step - loss: 0.2544 - acc: 0.9113 - val_loss: 0.3030 - val_acc: 0.9072\n",
      "Epoch 442/500\n",
      "7916/7916 [==============================] - 0s 27us/step - loss: 0.2548 - acc: 0.9120 - val_loss: 0.3246 - val_acc: 0.9045\n",
      "Epoch 443/500\n",
      "7916/7916 [==============================] - 0s 24us/step - loss: 0.2579 - acc: 0.9102 - val_loss: 0.2976 - val_acc: 0.9083\n",
      "Epoch 444/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7916/7916 [==============================] - 0s 23us/step - loss: 0.2511 - acc: 0.9121 - val_loss: 0.3061 - val_acc: 0.9060\n",
      "Epoch 445/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2552 - acc: 0.9113 - val_loss: 0.3040 - val_acc: 0.9078\n",
      "Epoch 446/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.2571 - acc: 0.9117 - val_loss: 0.3178 - val_acc: 0.9042\n",
      "Epoch 447/500\n",
      "7916/7916 [==============================] - 0s 13us/step - loss: 0.2572 - acc: 0.9098 - val_loss: 0.2982 - val_acc: 0.9092\n",
      "Epoch 448/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2551 - acc: 0.9097 - val_loss: 0.3099 - val_acc: 0.9063\n",
      "Epoch 449/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2607 - acc: 0.9078 - val_loss: 0.3049 - val_acc: 0.9066\n",
      "Epoch 450/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2570 - acc: 0.9075 - val_loss: 0.3027 - val_acc: 0.9069\n",
      "Epoch 451/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2578 - acc: 0.9101 - val_loss: 0.3006 - val_acc: 0.9042\n",
      "Epoch 452/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2531 - acc: 0.9102 - val_loss: 0.2961 - val_acc: 0.9078\n",
      "Epoch 453/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2528 - acc: 0.9094 - val_loss: 0.2960 - val_acc: 0.9095\n",
      "Epoch 454/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2538 - acc: 0.9118 - val_loss: 0.3002 - val_acc: 0.9075\n",
      "Epoch 455/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2547 - acc: 0.9116 - val_loss: 0.3124 - val_acc: 0.9069\n",
      "Epoch 456/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2510 - acc: 0.9126 - val_loss: 0.3062 - val_acc: 0.9075\n",
      "Epoch 457/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2530 - acc: 0.9104 - val_loss: 0.2964 - val_acc: 0.9089\n",
      "Epoch 458/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2536 - acc: 0.9104 - val_loss: 0.3043 - val_acc: 0.9101\n",
      "Epoch 459/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2522 - acc: 0.9103 - val_loss: 0.2981 - val_acc: 0.9104\n",
      "Epoch 460/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2500 - acc: 0.9114 - val_loss: 0.3022 - val_acc: 0.9075\n",
      "Epoch 461/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2565 - acc: 0.9112 - val_loss: 0.3012 - val_acc: 0.9078\n",
      "Epoch 462/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2528 - acc: 0.9101 - val_loss: 0.3024 - val_acc: 0.9075\n",
      "Epoch 463/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2524 - acc: 0.9122 - val_loss: 0.3062 - val_acc: 0.9057\n",
      "Epoch 464/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2529 - acc: 0.9108 - val_loss: 0.2991 - val_acc: 0.9086\n",
      "Epoch 465/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2542 - acc: 0.9109 - val_loss: 0.3017 - val_acc: 0.9066\n",
      "Epoch 466/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2524 - acc: 0.9101 - val_loss: 0.3066 - val_acc: 0.9072\n",
      "Epoch 467/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2529 - acc: 0.9109 - val_loss: 0.3068 - val_acc: 0.9098\n",
      "Epoch 468/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2527 - acc: 0.9122 - val_loss: 0.3045 - val_acc: 0.9060\n",
      "Epoch 469/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2517 - acc: 0.9096 - val_loss: 0.3049 - val_acc: 0.9066\n",
      "Epoch 470/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2550 - acc: 0.9093 - val_loss: 0.3016 - val_acc: 0.9098\n",
      "Epoch 471/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2527 - acc: 0.9112 - val_loss: 0.3011 - val_acc: 0.9075\n",
      "Epoch 472/500\n",
      "7916/7916 [==============================] - 0s 23us/step - loss: 0.2526 - acc: 0.9108 - val_loss: 0.3087 - val_acc: 0.9042\n",
      "Epoch 473/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2540 - acc: 0.9103 - val_loss: 0.3139 - val_acc: 0.9083\n",
      "Epoch 474/500\n",
      "7916/7916 [==============================] - 0s 23us/step - loss: 0.2607 - acc: 0.9090 - val_loss: 0.3054 - val_acc: 0.9101\n",
      "Epoch 475/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2534 - acc: 0.9098 - val_loss: 0.3017 - val_acc: 0.9075\n",
      "Epoch 476/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2542 - acc: 0.9104 - val_loss: 0.3086 - val_acc: 0.9080\n",
      "Epoch 477/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2509 - acc: 0.9103 - val_loss: 0.3018 - val_acc: 0.9080\n",
      "Epoch 478/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2517 - acc: 0.9117 - val_loss: 0.2983 - val_acc: 0.9072\n",
      "Epoch 479/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2552 - acc: 0.9114 - val_loss: 0.3073 - val_acc: 0.9072\n",
      "Epoch 480/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2554 - acc: 0.9099 - val_loss: 0.3021 - val_acc: 0.9083\n",
      "Epoch 481/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2579 - acc: 0.9082 - val_loss: 0.2995 - val_acc: 0.9092\n",
      "Epoch 482/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2492 - acc: 0.9132 - val_loss: 0.2988 - val_acc: 0.9086\n",
      "Epoch 483/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2563 - acc: 0.9104 - val_loss: 0.3041 - val_acc: 0.9045\n",
      "Epoch 484/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2515 - acc: 0.9092 - val_loss: 0.3081 - val_acc: 0.9072\n",
      "Epoch 485/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2528 - acc: 0.9109 - val_loss: 0.3061 - val_acc: 0.9042\n",
      "Epoch 486/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2521 - acc: 0.9106 - val_loss: 0.3268 - val_acc: 0.9016\n",
      "Epoch 487/500\n",
      "7916/7916 [==============================] - 0s 20us/step - loss: 0.2583 - acc: 0.9114 - val_loss: 0.3158 - val_acc: 0.9045\n",
      "Epoch 488/500\n",
      "7916/7916 [==============================] - 0s 15us/step - loss: 0.2537 - acc: 0.9101 - val_loss: 0.3009 - val_acc: 0.9069\n",
      "Epoch 489/500\n",
      "7916/7916 [==============================] - 0s 14us/step - loss: 0.2530 - acc: 0.9121 - val_loss: 0.3074 - val_acc: 0.9060\n",
      "Epoch 490/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2562 - acc: 0.9069 - val_loss: 0.3042 - val_acc: 0.9057\n",
      "Epoch 491/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2525 - acc: 0.9120 - val_loss: 0.3094 - val_acc: 0.9027\n",
      "Epoch 492/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2542 - acc: 0.9084 - val_loss: 0.3010 - val_acc: 0.9080\n",
      "Epoch 493/500\n",
      "7916/7916 [==============================] - 0s 22us/step - loss: 0.2519 - acc: 0.9096 - val_loss: 0.3108 - val_acc: 0.9078\n",
      "Epoch 494/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2522 - acc: 0.9132 - val_loss: 0.3181 - val_acc: 0.9039\n",
      "Epoch 495/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2537 - acc: 0.9103 - val_loss: 0.3120 - val_acc: 0.9042\n",
      "Epoch 496/500\n",
      "7916/7916 [==============================] - 0s 21us/step - loss: 0.2510 - acc: 0.9103 - val_loss: 0.3005 - val_acc: 0.9075\n",
      "Epoch 497/500\n",
      "7916/7916 [==============================] - 0s 19us/step - loss: 0.2512 - acc: 0.9114 - val_loss: 0.2969 - val_acc: 0.9083\n",
      "Epoch 498/500\n",
      "7916/7916 [==============================] - 0s 18us/step - loss: 0.2514 - acc: 0.9108 - val_loss: 0.3122 - val_acc: 0.9066\n",
      "Epoch 499/500\n",
      "7916/7916 [==============================] - 0s 16us/step - loss: 0.2493 - acc: 0.9125 - val_loss: 0.3107 - val_acc: 0.9045\n",
      "Epoch 500/500\n",
      "7916/7916 [==============================] - 0s 17us/step - loss: 0.2521 - acc: 0.9109 - val_loss: 0.3034 - val_acc: 0.9060\n",
      "3393/3393 [==============================] - 0s 4us/step\n",
      "15 61 403 403 12494 10805 61 1093 1032\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "10805 10805\n",
      "../linkPrediction/dataframes/apnea\n",
      "article (10805, 7, 11) --------------------------------------------------------------------\n",
      "(10805, 11) (10805,)\n",
      "[10805, 11, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7563, 11) (7563,)\n",
      "Train on 7563 samples, validate on 3242 samples\n",
      "Epoch 1/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 1.2538 - acc: 0.7482 - val_loss: 0.8392 - val_acc: 0.8769\n",
      "Epoch 2/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.6239 - acc: 0.8921 - val_loss: 0.5877 - val_acc: 0.9004\n",
      "Epoch 3/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.5084 - acc: 0.8994 - val_loss: 0.5642 - val_acc: 0.8877\n",
      "Epoch 4/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.4923 - acc: 0.8994 - val_loss: 0.4924 - val_acc: 0.9084\n",
      "Epoch 5/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.4403 - acc: 0.9014 - val_loss: 0.4620 - val_acc: 0.9084\n",
      "Epoch 6/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.4330 - acc: 0.9012 - val_loss: 0.4818 - val_acc: 0.9090\n",
      "Epoch 7/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.4409 - acc: 0.8932 - val_loss: 0.4542 - val_acc: 0.9016\n",
      "Epoch 8/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.4284 - acc: 0.9006 - val_loss: 0.4257 - val_acc: 0.9081\n",
      "Epoch 9/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.3971 - acc: 0.9015 - val_loss: 0.4646 - val_acc: 0.8939\n",
      "Epoch 10/500\n",
      "7563/7563 [==============================] - 0s 24us/step - loss: 0.3935 - acc: 0.9007 - val_loss: 0.4610 - val_acc: 0.9093\n",
      "Epoch 11/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.3803 - acc: 0.9000 - val_loss: 0.3862 - val_acc: 0.9093\n",
      "Epoch 12/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.3872 - acc: 0.8991 - val_loss: 0.3741 - val_acc: 0.9081\n",
      "Epoch 13/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.3658 - acc: 0.9039 - val_loss: 0.4223 - val_acc: 0.9065\n",
      "Epoch 14/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.3800 - acc: 0.8992 - val_loss: 0.3987 - val_acc: 0.9081\n",
      "Epoch 15/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.3619 - acc: 0.9033 - val_loss: 0.3661 - val_acc: 0.9084\n",
      "Epoch 16/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.3694 - acc: 0.9041 - val_loss: 0.3749 - val_acc: 0.9081\n",
      "Epoch 17/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.3515 - acc: 0.9036 - val_loss: 0.3400 - val_acc: 0.9105\n",
      "Epoch 18/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.3439 - acc: 0.9049 - val_loss: 0.3829 - val_acc: 0.9068\n",
      "Epoch 19/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.3591 - acc: 0.8996 - val_loss: 0.3750 - val_acc: 0.9078\n",
      "Epoch 20/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.3554 - acc: 0.8990 - val_loss: 0.4189 - val_acc: 0.9031\n",
      "Epoch 21/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.3580 - acc: 0.9018 - val_loss: 0.4378 - val_acc: 0.9081\n",
      "Epoch 22/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.3342 - acc: 0.9047 - val_loss: 0.3322 - val_acc: 0.9087\n",
      "Epoch 23/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.3261 - acc: 0.9039 - val_loss: 0.3510 - val_acc: 0.9090\n",
      "Epoch 24/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.3157 - acc: 0.9069 - val_loss: 0.3471 - val_acc: 0.9084\n",
      "Epoch 25/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.3335 - acc: 0.9028 - val_loss: 0.3423 - val_acc: 0.9065\n",
      "Epoch 26/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.3090 - acc: 0.9057 - val_loss: 0.3209 - val_acc: 0.9093\n",
      "Epoch 27/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.3290 - acc: 0.9049 - val_loss: 0.3796 - val_acc: 0.9075\n",
      "Epoch 28/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.3276 - acc: 0.9041 - val_loss: 0.3228 - val_acc: 0.9075\n",
      "Epoch 29/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.3329 - acc: 0.9043 - val_loss: 0.3323 - val_acc: 0.9072\n",
      "Epoch 30/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.3404 - acc: 0.9024 - val_loss: 0.3829 - val_acc: 0.9035\n",
      "Epoch 31/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.3151 - acc: 0.9065 - val_loss: 0.3246 - val_acc: 0.9087\n",
      "Epoch 32/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.3075 - acc: 0.9044 - val_loss: 0.3709 - val_acc: 0.8985\n",
      "Epoch 33/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.3857 - acc: 0.8937 - val_loss: 0.3456 - val_acc: 0.9056\n",
      "Epoch 34/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.3440 - acc: 0.9016 - val_loss: 0.3523 - val_acc: 0.9093\n",
      "Epoch 35/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.3138 - acc: 0.9057 - val_loss: 0.3127 - val_acc: 0.9102\n",
      "Epoch 36/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.3178 - acc: 0.9045 - val_loss: 0.3503 - val_acc: 0.9093\n",
      "Epoch 37/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.3028 - acc: 0.9077 - val_loss: 0.3070 - val_acc: 0.9081\n",
      "Epoch 38/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.3310 - acc: 0.9037 - val_loss: 0.3102 - val_acc: 0.9109\n",
      "Epoch 39/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.3037 - acc: 0.9068 - val_loss: 0.3210 - val_acc: 0.9078\n",
      "Epoch 40/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.3111 - acc: 0.9055 - val_loss: 0.3123 - val_acc: 0.9112\n",
      "Epoch 41/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.3036 - acc: 0.9076 - val_loss: 0.3281 - val_acc: 0.9096\n",
      "Epoch 42/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.3169 - acc: 0.9045 - val_loss: 0.3181 - val_acc: 0.9084\n",
      "Epoch 43/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.3011 - acc: 0.9064 - val_loss: 0.3063 - val_acc: 0.9090\n",
      "Epoch 44/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.3014 - acc: 0.9065 - val_loss: 0.3136 - val_acc: 0.9078\n",
      "Epoch 45/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.3061 - acc: 0.9069 - val_loss: 0.3123 - val_acc: 0.9062\n",
      "Epoch 46/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.3198 - acc: 0.9040 - val_loss: 0.3107 - val_acc: 0.9102\n",
      "Epoch 47/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.3212 - acc: 0.9044 - val_loss: 0.3296 - val_acc: 0.9075\n",
      "Epoch 48/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.3518 - acc: 0.9024 - val_loss: 0.3958 - val_acc: 0.9084\n",
      "Epoch 49/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.3138 - acc: 0.9064 - val_loss: 0.3230 - val_acc: 0.9081\n",
      "Epoch 50/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.3068 - acc: 0.9059 - val_loss: 0.3387 - val_acc: 0.9062\n",
      "Epoch 51/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.3075 - acc: 0.9064 - val_loss: 0.3479 - val_acc: 0.9075\n",
      "Epoch 52/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.3082 - acc: 0.9059 - val_loss: 0.3223 - val_acc: 0.9090\n",
      "Epoch 53/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.3008 - acc: 0.9072 - val_loss: 0.3025 - val_acc: 0.9065\n",
      "Epoch 54/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2962 - acc: 0.9065 - val_loss: 0.3014 - val_acc: 0.9078\n",
      "Epoch 55/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2931 - acc: 0.9070 - val_loss: 0.3001 - val_acc: 0.9084\n",
      "Epoch 56/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.3035 - acc: 0.9069 - val_loss: 0.3067 - val_acc: 0.9090\n",
      "Epoch 57/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.3045 - acc: 0.9065 - val_loss: 0.2969 - val_acc: 0.9081\n",
      "Epoch 58/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2987 - acc: 0.9063 - val_loss: 0.3370 - val_acc: 0.9075\n",
      "Epoch 59/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2958 - acc: 0.9073 - val_loss: 0.3043 - val_acc: 0.9090\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2968 - acc: 0.9070 - val_loss: 0.2917 - val_acc: 0.9084\n",
      "Epoch 61/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.3217 - acc: 0.9048 - val_loss: 0.3032 - val_acc: 0.9090\n",
      "Epoch 62/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.3144 - acc: 0.9055 - val_loss: 0.3149 - val_acc: 0.9093\n",
      "Epoch 63/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.3103 - acc: 0.9069 - val_loss: 0.2944 - val_acc: 0.9093\n",
      "Epoch 64/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2968 - acc: 0.9077 - val_loss: 0.3110 - val_acc: 0.9081\n",
      "Epoch 65/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2994 - acc: 0.9078 - val_loss: 0.3668 - val_acc: 0.9062\n",
      "Epoch 66/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.3069 - acc: 0.9064 - val_loss: 0.2917 - val_acc: 0.9081\n",
      "Epoch 67/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2964 - acc: 0.9073 - val_loss: 0.2851 - val_acc: 0.9072\n",
      "Epoch 68/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2957 - acc: 0.9057 - val_loss: 0.2928 - val_acc: 0.9084\n",
      "Epoch 69/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.3029 - acc: 0.9056 - val_loss: 0.3121 - val_acc: 0.9072\n",
      "Epoch 70/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2990 - acc: 0.9072 - val_loss: 0.3058 - val_acc: 0.9075\n",
      "Epoch 71/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2855 - acc: 0.9080 - val_loss: 0.2902 - val_acc: 0.9078\n",
      "Epoch 72/500\n",
      "7563/7563 [==============================] - 0s 24us/step - loss: 0.2982 - acc: 0.9069 - val_loss: 0.2870 - val_acc: 0.9093\n",
      "Epoch 73/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2860 - acc: 0.9074 - val_loss: 0.2881 - val_acc: 0.9078\n",
      "Epoch 74/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2839 - acc: 0.9078 - val_loss: 0.2965 - val_acc: 0.9075\n",
      "Epoch 75/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.3011 - acc: 0.9068 - val_loss: 0.3092 - val_acc: 0.9084\n",
      "Epoch 76/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2905 - acc: 0.9061 - val_loss: 0.3275 - val_acc: 0.9078\n",
      "Epoch 77/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2918 - acc: 0.9077 - val_loss: 0.2939 - val_acc: 0.9075\n",
      "Epoch 78/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2906 - acc: 0.9076 - val_loss: 0.2913 - val_acc: 0.9075\n",
      "Epoch 79/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2881 - acc: 0.9076 - val_loss: 0.3059 - val_acc: 0.9078\n",
      "Epoch 80/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2855 - acc: 0.9081 - val_loss: 0.2799 - val_acc: 0.9087\n",
      "Epoch 81/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2861 - acc: 0.9069 - val_loss: 0.2789 - val_acc: 0.9087\n",
      "Epoch 82/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2894 - acc: 0.9076 - val_loss: 0.2895 - val_acc: 0.9081\n",
      "Epoch 83/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2947 - acc: 0.9076 - val_loss: 0.2919 - val_acc: 0.9105\n",
      "Epoch 84/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2891 - acc: 0.9076 - val_loss: 0.2842 - val_acc: 0.9090\n",
      "Epoch 85/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2931 - acc: 0.9064 - val_loss: 0.2842 - val_acc: 0.9068\n",
      "Epoch 86/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2865 - acc: 0.9068 - val_loss: 0.3139 - val_acc: 0.9084\n",
      "Epoch 87/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2876 - acc: 0.9074 - val_loss: 0.2854 - val_acc: 0.9072\n",
      "Epoch 88/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2909 - acc: 0.9067 - val_loss: 0.2911 - val_acc: 0.9072\n",
      "Epoch 89/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2966 - acc: 0.9052 - val_loss: 0.2868 - val_acc: 0.9078\n",
      "Epoch 90/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2865 - acc: 0.9088 - val_loss: 0.2811 - val_acc: 0.9078\n",
      "Epoch 91/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2912 - acc: 0.9063 - val_loss: 0.2879 - val_acc: 0.9099\n",
      "Epoch 92/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2882 - acc: 0.9082 - val_loss: 0.2805 - val_acc: 0.9102\n",
      "Epoch 93/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2864 - acc: 0.9072 - val_loss: 0.2768 - val_acc: 0.9105\n",
      "Epoch 94/500\n",
      "7563/7563 [==============================] - 0s 24us/step - loss: 0.2866 - acc: 0.9076 - val_loss: 0.2839 - val_acc: 0.9090\n",
      "Epoch 95/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.2829 - acc: 0.9078 - val_loss: 0.2773 - val_acc: 0.9096\n",
      "Epoch 96/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2883 - acc: 0.9065 - val_loss: 0.2774 - val_acc: 0.9096\n",
      "Epoch 97/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.2823 - acc: 0.9073 - val_loss: 0.2721 - val_acc: 0.9096\n",
      "Epoch 98/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2975 - acc: 0.9065 - val_loss: 0.3024 - val_acc: 0.9093\n",
      "Epoch 99/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2901 - acc: 0.9076 - val_loss: 0.2757 - val_acc: 0.9078\n",
      "Epoch 100/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2831 - acc: 0.9090 - val_loss: 0.2826 - val_acc: 0.9075\n",
      "Epoch 101/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2970 - acc: 0.9064 - val_loss: 0.2891 - val_acc: 0.9084\n",
      "Epoch 102/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2876 - acc: 0.9063 - val_loss: 0.2797 - val_acc: 0.9084\n",
      "Epoch 103/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2884 - acc: 0.9067 - val_loss: 0.2804 - val_acc: 0.9096\n",
      "Epoch 104/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2890 - acc: 0.9070 - val_loss: 0.2984 - val_acc: 0.9093\n",
      "Epoch 105/500\n",
      "7563/7563 [==============================] - 0s 24us/step - loss: 0.2879 - acc: 0.9077 - val_loss: 0.2752 - val_acc: 0.9093\n",
      "Epoch 106/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.2844 - acc: 0.9073 - val_loss: 0.2764 - val_acc: 0.9102\n",
      "Epoch 107/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2827 - acc: 0.9072 - val_loss: 0.2799 - val_acc: 0.9105\n",
      "Epoch 108/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2837 - acc: 0.9069 - val_loss: 0.2777 - val_acc: 0.9109\n",
      "Epoch 109/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2823 - acc: 0.9081 - val_loss: 0.2776 - val_acc: 0.9093\n",
      "Epoch 110/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2830 - acc: 0.9076 - val_loss: 0.2840 - val_acc: 0.9109\n",
      "Epoch 111/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2814 - acc: 0.9081 - val_loss: 0.2778 - val_acc: 0.9081\n",
      "Epoch 112/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2824 - acc: 0.9077 - val_loss: 0.2972 - val_acc: 0.9096\n",
      "Epoch 113/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2900 - acc: 0.9047 - val_loss: 0.3087 - val_acc: 0.9075\n",
      "Epoch 114/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2891 - acc: 0.9053 - val_loss: 0.2749 - val_acc: 0.9096\n",
      "Epoch 115/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2850 - acc: 0.9080 - val_loss: 0.2813 - val_acc: 0.9087\n",
      "Epoch 116/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.2806 - acc: 0.9076 - val_loss: 0.2823 - val_acc: 0.9081\n",
      "Epoch 117/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2849 - acc: 0.9077 - val_loss: 0.2780 - val_acc: 0.9102\n",
      "Epoch 118/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2823 - acc: 0.9082 - val_loss: 0.2737 - val_acc: 0.9096\n",
      "Epoch 119/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2835 - acc: 0.9073 - val_loss: 0.2740 - val_acc: 0.9090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2859 - acc: 0.9070 - val_loss: 0.2939 - val_acc: 0.9099\n",
      "Epoch 121/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2949 - acc: 0.9073 - val_loss: 0.2866 - val_acc: 0.9099\n",
      "Epoch 122/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2951 - acc: 0.9064 - val_loss: 0.2873 - val_acc: 0.9099\n",
      "Epoch 123/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2886 - acc: 0.9074 - val_loss: 0.2830 - val_acc: 0.9096\n",
      "Epoch 124/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2857 - acc: 0.9073 - val_loss: 0.2791 - val_acc: 0.9093\n",
      "Epoch 125/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2848 - acc: 0.9073 - val_loss: 0.2791 - val_acc: 0.9096\n",
      "Epoch 126/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2878 - acc: 0.9076 - val_loss: 0.2770 - val_acc: 0.9087\n",
      "Epoch 127/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2865 - acc: 0.9073 - val_loss: 0.2813 - val_acc: 0.9096\n",
      "Epoch 128/500\n",
      "7563/7563 [==============================] - 0s 31us/step - loss: 0.2827 - acc: 0.9085 - val_loss: 0.2756 - val_acc: 0.9099\n",
      "Epoch 129/500\n",
      "7563/7563 [==============================] - 0s 27us/step - loss: 0.2825 - acc: 0.9076 - val_loss: 0.2833 - val_acc: 0.9078\n",
      "Epoch 130/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2826 - acc: 0.9077 - val_loss: 0.2757 - val_acc: 0.9096\n",
      "Epoch 131/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2801 - acc: 0.9086 - val_loss: 0.2797 - val_acc: 0.9081\n",
      "Epoch 132/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2839 - acc: 0.9082 - val_loss: 0.2877 - val_acc: 0.9087\n",
      "Epoch 133/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2863 - acc: 0.9070 - val_loss: 0.2778 - val_acc: 0.9090\n",
      "Epoch 134/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2823 - acc: 0.9089 - val_loss: 0.2786 - val_acc: 0.9109\n",
      "Epoch 135/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2849 - acc: 0.9074 - val_loss: 0.2900 - val_acc: 0.9075\n",
      "Epoch 136/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2817 - acc: 0.9085 - val_loss: 0.2804 - val_acc: 0.9105\n",
      "Epoch 137/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2845 - acc: 0.9072 - val_loss: 0.2796 - val_acc: 0.9105\n",
      "Epoch 138/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2868 - acc: 0.9060 - val_loss: 0.2760 - val_acc: 0.9093\n",
      "Epoch 139/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2833 - acc: 0.9070 - val_loss: 0.2871 - val_acc: 0.9096\n",
      "Epoch 140/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2824 - acc: 0.9089 - val_loss: 0.2814 - val_acc: 0.9090\n",
      "Epoch 141/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2805 - acc: 0.9082 - val_loss: 0.2755 - val_acc: 0.9078\n",
      "Epoch 142/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2800 - acc: 0.9081 - val_loss: 0.2804 - val_acc: 0.9078\n",
      "Epoch 143/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2822 - acc: 0.9074 - val_loss: 0.2776 - val_acc: 0.9096\n",
      "Epoch 144/500\n",
      "7563/7563 [==============================] - 0s 26us/step - loss: 0.2840 - acc: 0.9080 - val_loss: 0.2929 - val_acc: 0.9093\n",
      "Epoch 145/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2891 - acc: 0.9074 - val_loss: 0.2856 - val_acc: 0.9099\n",
      "Epoch 146/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2894 - acc: 0.9077 - val_loss: 0.2834 - val_acc: 0.9087\n",
      "Epoch 147/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2843 - acc: 0.9080 - val_loss: 0.2783 - val_acc: 0.9112\n",
      "Epoch 148/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2866 - acc: 0.9070 - val_loss: 0.2815 - val_acc: 0.9081\n",
      "Epoch 149/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2864 - acc: 0.9081 - val_loss: 0.2795 - val_acc: 0.9081\n",
      "Epoch 150/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2873 - acc: 0.9070 - val_loss: 0.2798 - val_acc: 0.9081\n",
      "Epoch 151/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2814 - acc: 0.9078 - val_loss: 0.2753 - val_acc: 0.9087\n",
      "Epoch 152/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2810 - acc: 0.9074 - val_loss: 0.2727 - val_acc: 0.9090\n",
      "Epoch 153/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2803 - acc: 0.9085 - val_loss: 0.2719 - val_acc: 0.9096\n",
      "Epoch 154/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2797 - acc: 0.9084 - val_loss: 0.2725 - val_acc: 0.9087\n",
      "Epoch 155/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2801 - acc: 0.9074 - val_loss: 0.2731 - val_acc: 0.9090\n",
      "Epoch 156/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2795 - acc: 0.9084 - val_loss: 0.2803 - val_acc: 0.9096\n",
      "Epoch 157/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2802 - acc: 0.9082 - val_loss: 0.2734 - val_acc: 0.9099\n",
      "Epoch 158/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2799 - acc: 0.9089 - val_loss: 0.2743 - val_acc: 0.9078\n",
      "Epoch 159/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2802 - acc: 0.9080 - val_loss: 0.2779 - val_acc: 0.9087\n",
      "Epoch 160/500\n",
      "7563/7563 [==============================] - 0s 26us/step - loss: 0.2806 - acc: 0.9074 - val_loss: 0.2722 - val_acc: 0.9102\n",
      "Epoch 161/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2837 - acc: 0.9081 - val_loss: 0.2914 - val_acc: 0.9084\n",
      "Epoch 162/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2902 - acc: 0.9076 - val_loss: 0.2817 - val_acc: 0.9099\n",
      "Epoch 163/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2879 - acc: 0.9077 - val_loss: 0.2810 - val_acc: 0.9081\n",
      "Epoch 164/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2845 - acc: 0.9077 - val_loss: 0.2780 - val_acc: 0.9096\n",
      "Epoch 165/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2837 - acc: 0.9084 - val_loss: 0.2783 - val_acc: 0.9105\n",
      "Epoch 166/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2822 - acc: 0.9082 - val_loss: 0.2748 - val_acc: 0.9081\n",
      "Epoch 167/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.2831 - acc: 0.9068 - val_loss: 0.2735 - val_acc: 0.9087\n",
      "Epoch 168/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2819 - acc: 0.9080 - val_loss: 0.2743 - val_acc: 0.9087\n",
      "Epoch 169/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2828 - acc: 0.9078 - val_loss: 0.2756 - val_acc: 0.9075\n",
      "Epoch 170/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2794 - acc: 0.9085 - val_loss: 0.2739 - val_acc: 0.9090\n",
      "Epoch 171/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2794 - acc: 0.9074 - val_loss: 0.2736 - val_acc: 0.9087\n",
      "Epoch 172/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2788 - acc: 0.9089 - val_loss: 0.2752 - val_acc: 0.9078\n",
      "Epoch 173/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2809 - acc: 0.9073 - val_loss: 0.2728 - val_acc: 0.9099\n",
      "Epoch 174/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2789 - acc: 0.9081 - val_loss: 0.2745 - val_acc: 0.9081\n",
      "Epoch 175/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2812 - acc: 0.9080 - val_loss: 0.2707 - val_acc: 0.9081\n",
      "Epoch 176/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2793 - acc: 0.9078 - val_loss: 0.2829 - val_acc: 0.9084\n",
      "Epoch 177/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2866 - acc: 0.9057 - val_loss: 0.2705 - val_acc: 0.9099\n",
      "Epoch 178/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2807 - acc: 0.9069 - val_loss: 0.2741 - val_acc: 0.9096\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2786 - acc: 0.9078 - val_loss: 0.2685 - val_acc: 0.9087\n",
      "Epoch 180/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2794 - acc: 0.9082 - val_loss: 0.2847 - val_acc: 0.9087\n",
      "Epoch 181/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2795 - acc: 0.9074 - val_loss: 0.2729 - val_acc: 0.9087\n",
      "Epoch 182/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2790 - acc: 0.9073 - val_loss: 0.2711 - val_acc: 0.9115\n",
      "Epoch 183/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2777 - acc: 0.9069 - val_loss: 0.2705 - val_acc: 0.9093\n",
      "Epoch 184/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2817 - acc: 0.9070 - val_loss: 0.2742 - val_acc: 0.9084\n",
      "Epoch 185/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2801 - acc: 0.9072 - val_loss: 0.2679 - val_acc: 0.9096\n",
      "Epoch 186/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2795 - acc: 0.9074 - val_loss: 0.2696 - val_acc: 0.9096\n",
      "Epoch 187/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2793 - acc: 0.9069 - val_loss: 0.2688 - val_acc: 0.9102\n",
      "Epoch 188/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2779 - acc: 0.9074 - val_loss: 0.2957 - val_acc: 0.9084\n",
      "Epoch 189/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2799 - acc: 0.9078 - val_loss: 0.2708 - val_acc: 0.9112\n",
      "Epoch 190/500\n",
      "7563/7563 [==============================] - 0s 24us/step - loss: 0.2877 - acc: 0.9065 - val_loss: 0.2862 - val_acc: 0.9112\n",
      "Epoch 191/500\n",
      "7563/7563 [==============================] - 0s 24us/step - loss: 0.2869 - acc: 0.9077 - val_loss: 0.2777 - val_acc: 0.9102\n",
      "Epoch 192/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2843 - acc: 0.9080 - val_loss: 0.2777 - val_acc: 0.9090\n",
      "Epoch 193/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2836 - acc: 0.9076 - val_loss: 0.2751 - val_acc: 0.9093\n",
      "Epoch 194/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2823 - acc: 0.9080 - val_loss: 0.2723 - val_acc: 0.9102\n",
      "Epoch 195/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2803 - acc: 0.9074 - val_loss: 0.2705 - val_acc: 0.9102\n",
      "Epoch 196/500\n",
      "7563/7563 [==============================] - 0s 32us/step - loss: 0.2790 - acc: 0.9085 - val_loss: 0.2719 - val_acc: 0.9105\n",
      "Epoch 197/500\n",
      "7563/7563 [==============================] - 0s 28us/step - loss: 0.2793 - acc: 0.9073 - val_loss: 0.2697 - val_acc: 0.9087\n",
      "Epoch 198/500\n",
      "7563/7563 [==============================] - 0s 27us/step - loss: 0.2799 - acc: 0.9072 - val_loss: 0.2691 - val_acc: 0.9096\n",
      "Epoch 199/500\n",
      "7563/7563 [==============================] - 0s 25us/step - loss: 0.2790 - acc: 0.9081 - val_loss: 0.2712 - val_acc: 0.9090\n",
      "Epoch 200/500\n",
      "7563/7563 [==============================] - 0s 30us/step - loss: 0.2773 - acc: 0.9080 - val_loss: 0.2705 - val_acc: 0.9084\n",
      "Epoch 201/500\n",
      "7563/7563 [==============================] - 0s 29us/step - loss: 0.2795 - acc: 0.9064 - val_loss: 0.2692 - val_acc: 0.9105\n",
      "Epoch 202/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.2774 - acc: 0.9074 - val_loss: 0.2702 - val_acc: 0.9087\n",
      "Epoch 203/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2779 - acc: 0.9077 - val_loss: 0.2695 - val_acc: 0.9115\n",
      "Epoch 204/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2770 - acc: 0.9078 - val_loss: 0.2682 - val_acc: 0.9096\n",
      "Epoch 205/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2758 - acc: 0.9081 - val_loss: 0.2696 - val_acc: 0.9096\n",
      "Epoch 206/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2782 - acc: 0.9078 - val_loss: 0.2706 - val_acc: 0.9099\n",
      "Epoch 207/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2780 - acc: 0.9076 - val_loss: 0.2708 - val_acc: 0.9109\n",
      "Epoch 208/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2782 - acc: 0.9080 - val_loss: 0.2681 - val_acc: 0.9112\n",
      "Epoch 209/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2772 - acc: 0.9069 - val_loss: 0.2690 - val_acc: 0.9096\n",
      "Epoch 210/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2870 - acc: 0.9077 - val_loss: 0.2801 - val_acc: 0.9112\n",
      "Epoch 211/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2850 - acc: 0.9072 - val_loss: 0.2771 - val_acc: 0.9096\n",
      "Epoch 212/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2839 - acc: 0.9081 - val_loss: 0.2735 - val_acc: 0.9105\n",
      "Epoch 213/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2821 - acc: 0.9073 - val_loss: 0.2723 - val_acc: 0.9096\n",
      "Epoch 214/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2795 - acc: 0.9085 - val_loss: 0.2704 - val_acc: 0.9096\n",
      "Epoch 215/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2809 - acc: 0.9070 - val_loss: 0.2715 - val_acc: 0.9099\n",
      "Epoch 216/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2774 - acc: 0.9073 - val_loss: 0.2679 - val_acc: 0.9109\n",
      "Epoch 217/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2796 - acc: 0.9069 - val_loss: 0.2714 - val_acc: 0.9099\n",
      "Epoch 218/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2768 - acc: 0.9076 - val_loss: 0.2682 - val_acc: 0.9087\n",
      "Epoch 219/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2760 - acc: 0.9076 - val_loss: 0.2696 - val_acc: 0.9112\n",
      "Epoch 220/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2789 - acc: 0.9073 - val_loss: 0.2832 - val_acc: 0.9096\n",
      "Epoch 221/500\n",
      "7563/7563 [==============================] - 0s 28us/step - loss: 0.2808 - acc: 0.9074 - val_loss: 0.2736 - val_acc: 0.9109\n",
      "Epoch 222/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2872 - acc: 0.9074 - val_loss: 0.2772 - val_acc: 0.9112\n",
      "Epoch 223/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2838 - acc: 0.9076 - val_loss: 0.2772 - val_acc: 0.9099\n",
      "Epoch 224/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2819 - acc: 0.9073 - val_loss: 0.2754 - val_acc: 0.9090\n",
      "Epoch 225/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2798 - acc: 0.9089 - val_loss: 0.2717 - val_acc: 0.9096\n",
      "Epoch 226/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2788 - acc: 0.9074 - val_loss: 0.2704 - val_acc: 0.9118\n",
      "Epoch 227/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2778 - acc: 0.9086 - val_loss: 0.2718 - val_acc: 0.9090\n",
      "Epoch 228/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2770 - acc: 0.9081 - val_loss: 0.2696 - val_acc: 0.9099\n",
      "Epoch 229/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2787 - acc: 0.9080 - val_loss: 0.2668 - val_acc: 0.9109\n",
      "Epoch 230/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2759 - acc: 0.9076 - val_loss: 0.2672 - val_acc: 0.9102\n",
      "Epoch 231/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2755 - acc: 0.9084 - val_loss: 0.2670 - val_acc: 0.9102\n",
      "Epoch 232/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2750 - acc: 0.9084 - val_loss: 0.2675 - val_acc: 0.9109\n",
      "Epoch 233/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2771 - acc: 0.9082 - val_loss: 0.2679 - val_acc: 0.9112\n",
      "Epoch 234/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2757 - acc: 0.9085 - val_loss: 0.2695 - val_acc: 0.9109\n",
      "Epoch 235/500\n",
      "7563/7563 [==============================] - 0s 24us/step - loss: 0.2750 - acc: 0.9077 - val_loss: 0.2674 - val_acc: 0.9105\n",
      "Epoch 236/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2743 - acc: 0.9090 - val_loss: 0.2832 - val_acc: 0.9102\n",
      "Epoch 237/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2770 - acc: 0.9081 - val_loss: 0.2684 - val_acc: 0.9102\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2753 - acc: 0.9077 - val_loss: 0.2745 - val_acc: 0.9087\n",
      "Epoch 239/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2747 - acc: 0.9077 - val_loss: 0.2651 - val_acc: 0.9102\n",
      "Epoch 240/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2760 - acc: 0.9086 - val_loss: 0.2698 - val_acc: 0.9109\n",
      "Epoch 241/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2758 - acc: 0.9078 - val_loss: 0.2708 - val_acc: 0.9105\n",
      "Epoch 242/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2743 - acc: 0.9086 - val_loss: 0.2747 - val_acc: 0.9087\n",
      "Epoch 243/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2761 - acc: 0.9076 - val_loss: 0.2707 - val_acc: 0.9093\n",
      "Epoch 244/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2754 - acc: 0.9082 - val_loss: 0.2747 - val_acc: 0.9090\n",
      "Epoch 245/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2780 - acc: 0.9073 - val_loss: 0.2697 - val_acc: 0.9118\n",
      "Epoch 246/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2752 - acc: 0.9067 - val_loss: 0.2696 - val_acc: 0.9105\n",
      "Epoch 247/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2737 - acc: 0.9080 - val_loss: 0.2693 - val_acc: 0.9109\n",
      "Epoch 248/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2804 - acc: 0.9072 - val_loss: 0.2721 - val_acc: 0.9084\n",
      "Epoch 249/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2760 - acc: 0.9080 - val_loss: 0.2697 - val_acc: 0.9096\n",
      "Epoch 250/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2749 - acc: 0.9073 - val_loss: 0.2690 - val_acc: 0.9112\n",
      "Epoch 251/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2770 - acc: 0.9078 - val_loss: 0.2671 - val_acc: 0.9093\n",
      "Epoch 252/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2750 - acc: 0.9082 - val_loss: 0.2680 - val_acc: 0.9105\n",
      "Epoch 253/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2743 - acc: 0.9089 - val_loss: 0.2664 - val_acc: 0.9105\n",
      "Epoch 254/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2770 - acc: 0.9076 - val_loss: 0.2733 - val_acc: 0.9087\n",
      "Epoch 255/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2758 - acc: 0.9073 - val_loss: 0.2636 - val_acc: 0.9102\n",
      "Epoch 256/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2745 - acc: 0.9084 - val_loss: 0.2675 - val_acc: 0.9099\n",
      "Epoch 257/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2740 - acc: 0.9085 - val_loss: 0.2673 - val_acc: 0.9099\n",
      "Epoch 258/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2746 - acc: 0.9078 - val_loss: 0.2660 - val_acc: 0.9102\n",
      "Epoch 259/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2740 - acc: 0.9068 - val_loss: 0.2679 - val_acc: 0.9099\n",
      "Epoch 260/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2740 - acc: 0.9078 - val_loss: 0.2776 - val_acc: 0.9090\n",
      "Epoch 261/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2748 - acc: 0.9086 - val_loss: 0.2671 - val_acc: 0.9109\n",
      "Epoch 262/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2728 - acc: 0.9076 - val_loss: 0.2866 - val_acc: 0.9109\n",
      "Epoch 263/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2739 - acc: 0.9078 - val_loss: 0.2677 - val_acc: 0.9105\n",
      "Epoch 264/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2776 - acc: 0.9077 - val_loss: 0.2777 - val_acc: 0.9093\n",
      "Epoch 265/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2742 - acc: 0.9084 - val_loss: 0.2678 - val_acc: 0.9099\n",
      "Epoch 266/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2730 - acc: 0.9082 - val_loss: 0.2700 - val_acc: 0.9099\n",
      "Epoch 267/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2749 - acc: 0.9088 - val_loss: 0.2710 - val_acc: 0.9099\n",
      "Epoch 268/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2736 - acc: 0.9078 - val_loss: 0.2725 - val_acc: 0.9087\n",
      "Epoch 269/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2738 - acc: 0.9085 - val_loss: 0.2663 - val_acc: 0.9090\n",
      "Epoch 270/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2762 - acc: 0.9073 - val_loss: 0.2636 - val_acc: 0.9112\n",
      "Epoch 271/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2731 - acc: 0.9077 - val_loss: 0.2664 - val_acc: 0.9093\n",
      "Epoch 272/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2757 - acc: 0.9076 - val_loss: 0.2669 - val_acc: 0.9105\n",
      "Epoch 273/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2735 - acc: 0.9082 - val_loss: 0.2763 - val_acc: 0.9099\n",
      "Epoch 274/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2728 - acc: 0.9093 - val_loss: 0.2653 - val_acc: 0.9081\n",
      "Epoch 275/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2723 - acc: 0.9090 - val_loss: 0.2788 - val_acc: 0.9096\n",
      "Epoch 276/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2730 - acc: 0.9085 - val_loss: 0.2748 - val_acc: 0.9078\n",
      "Epoch 277/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2751 - acc: 0.9088 - val_loss: 0.2800 - val_acc: 0.9090\n",
      "Epoch 278/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2773 - acc: 0.9081 - val_loss: 0.2835 - val_acc: 0.9096\n",
      "Epoch 279/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2765 - acc: 0.9074 - val_loss: 0.2663 - val_acc: 0.9109\n",
      "Epoch 280/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2746 - acc: 0.9089 - val_loss: 0.2653 - val_acc: 0.9096\n",
      "Epoch 281/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2743 - acc: 0.9084 - val_loss: 0.2671 - val_acc: 0.9087\n",
      "Epoch 282/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2755 - acc: 0.9072 - val_loss: 0.2803 - val_acc: 0.9084\n",
      "Epoch 283/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2732 - acc: 0.9078 - val_loss: 0.2646 - val_acc: 0.9087\n",
      "Epoch 284/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.2746 - acc: 0.9082 - val_loss: 0.2657 - val_acc: 0.9090\n",
      "Epoch 285/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2725 - acc: 0.9080 - val_loss: 0.2644 - val_acc: 0.9099\n",
      "Epoch 286/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2731 - acc: 0.9082 - val_loss: 0.2694 - val_acc: 0.9099\n",
      "Epoch 287/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2727 - acc: 0.9073 - val_loss: 0.2680 - val_acc: 0.9093\n",
      "Epoch 288/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2734 - acc: 0.9077 - val_loss: 0.2634 - val_acc: 0.9096\n",
      "Epoch 289/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2721 - acc: 0.9081 - val_loss: 0.2638 - val_acc: 0.9099\n",
      "Epoch 290/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2749 - acc: 0.9074 - val_loss: 0.2668 - val_acc: 0.9096\n",
      "Epoch 291/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2747 - acc: 0.9074 - val_loss: 0.2673 - val_acc: 0.9084\n",
      "Epoch 292/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2751 - acc: 0.9081 - val_loss: 0.2646 - val_acc: 0.9105\n",
      "Epoch 293/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2728 - acc: 0.9082 - val_loss: 0.2675 - val_acc: 0.9093\n",
      "Epoch 294/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2760 - acc: 0.9084 - val_loss: 0.2657 - val_acc: 0.9096\n",
      "Epoch 295/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2722 - acc: 0.9070 - val_loss: 0.2670 - val_acc: 0.9099\n",
      "Epoch 296/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2723 - acc: 0.9085 - val_loss: 0.2656 - val_acc: 0.9090\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2719 - acc: 0.9072 - val_loss: 0.2662 - val_acc: 0.9090\n",
      "Epoch 298/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2729 - acc: 0.9076 - val_loss: 0.2658 - val_acc: 0.9096\n",
      "Epoch 299/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2718 - acc: 0.9090 - val_loss: 0.2654 - val_acc: 0.9105\n",
      "Epoch 300/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2707 - acc: 0.9093 - val_loss: 0.2660 - val_acc: 0.9090\n",
      "Epoch 301/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2850 - acc: 0.9078 - val_loss: 0.2776 - val_acc: 0.9084\n",
      "Epoch 302/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2806 - acc: 0.9074 - val_loss: 0.2704 - val_acc: 0.9118\n",
      "Epoch 303/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2788 - acc: 0.9085 - val_loss: 0.2754 - val_acc: 0.9090\n",
      "Epoch 304/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.2754 - acc: 0.9072 - val_loss: 0.2656 - val_acc: 0.9093\n",
      "Epoch 305/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2720 - acc: 0.9088 - val_loss: 0.2702 - val_acc: 0.9105\n",
      "Epoch 306/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2754 - acc: 0.9080 - val_loss: 0.2695 - val_acc: 0.9084\n",
      "Epoch 307/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2758 - acc: 0.9077 - val_loss: 0.2662 - val_acc: 0.9096\n",
      "Epoch 308/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2719 - acc: 0.9078 - val_loss: 0.2653 - val_acc: 0.9105\n",
      "Epoch 309/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2708 - acc: 0.9076 - val_loss: 0.2709 - val_acc: 0.9084\n",
      "Epoch 310/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2722 - acc: 0.9074 - val_loss: 0.2657 - val_acc: 0.9096\n",
      "Epoch 311/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2704 - acc: 0.9086 - val_loss: 0.2642 - val_acc: 0.9127\n",
      "Epoch 312/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2710 - acc: 0.9077 - val_loss: 0.2672 - val_acc: 0.9099\n",
      "Epoch 313/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2702 - acc: 0.9092 - val_loss: 0.2701 - val_acc: 0.9087\n",
      "Epoch 314/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2704 - acc: 0.9084 - val_loss: 0.2738 - val_acc: 0.9096\n",
      "Epoch 315/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2713 - acc: 0.9081 - val_loss: 0.2665 - val_acc: 0.9118\n",
      "Epoch 316/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2703 - acc: 0.9074 - val_loss: 0.2716 - val_acc: 0.9099\n",
      "Epoch 317/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2706 - acc: 0.9093 - val_loss: 0.2648 - val_acc: 0.9105\n",
      "Epoch 318/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2719 - acc: 0.9078 - val_loss: 0.2667 - val_acc: 0.9115\n",
      "Epoch 319/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2708 - acc: 0.9086 - val_loss: 0.2650 - val_acc: 0.9102\n",
      "Epoch 320/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2698 - acc: 0.9088 - val_loss: 0.2645 - val_acc: 0.9109\n",
      "Epoch 321/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2720 - acc: 0.9080 - val_loss: 0.2633 - val_acc: 0.9121\n",
      "Epoch 322/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2717 - acc: 0.9074 - val_loss: 0.2619 - val_acc: 0.9099\n",
      "Epoch 323/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2708 - acc: 0.9088 - val_loss: 0.2704 - val_acc: 0.9090\n",
      "Epoch 324/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2735 - acc: 0.9092 - val_loss: 0.2657 - val_acc: 0.9093\n",
      "Epoch 325/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2700 - acc: 0.9092 - val_loss: 0.2677 - val_acc: 0.9115\n",
      "Epoch 326/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2699 - acc: 0.9085 - val_loss: 0.2784 - val_acc: 0.9112\n",
      "Epoch 327/500\n",
      "7563/7563 [==============================] - 0s 25us/step - loss: 0.2691 - acc: 0.9093 - val_loss: 0.2684 - val_acc: 0.9121\n",
      "Epoch 328/500\n",
      "7563/7563 [==============================] - 0s 26us/step - loss: 0.2699 - acc: 0.9082 - val_loss: 0.2698 - val_acc: 0.9121\n",
      "Epoch 329/500\n",
      "7563/7563 [==============================] - 0s 27us/step - loss: 0.2707 - acc: 0.9081 - val_loss: 0.2721 - val_acc: 0.9133\n",
      "Epoch 330/500\n",
      "7563/7563 [==============================] - 0s 26us/step - loss: 0.2696 - acc: 0.9078 - val_loss: 0.2648 - val_acc: 0.9112\n",
      "Epoch 331/500\n",
      "7563/7563 [==============================] - 0s 27us/step - loss: 0.2700 - acc: 0.9089 - val_loss: 0.2819 - val_acc: 0.9109\n",
      "Epoch 332/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2704 - acc: 0.9089 - val_loss: 0.2694 - val_acc: 0.9099\n",
      "Epoch 333/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2701 - acc: 0.9081 - val_loss: 0.2685 - val_acc: 0.9093\n",
      "Epoch 334/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2703 - acc: 0.9084 - val_loss: 0.2693 - val_acc: 0.9102\n",
      "Epoch 335/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2696 - acc: 0.9089 - val_loss: 0.2694 - val_acc: 0.9096\n",
      "Epoch 336/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2713 - acc: 0.9073 - val_loss: 0.2807 - val_acc: 0.9112\n",
      "Epoch 337/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2800 - acc: 0.9076 - val_loss: 0.2758 - val_acc: 0.9112\n",
      "Epoch 338/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2804 - acc: 0.9089 - val_loss: 0.2787 - val_acc: 0.9112\n",
      "Epoch 339/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2766 - acc: 0.9081 - val_loss: 0.2685 - val_acc: 0.9102\n",
      "Epoch 340/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2737 - acc: 0.9078 - val_loss: 0.2654 - val_acc: 0.9115\n",
      "Epoch 341/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2725 - acc: 0.9074 - val_loss: 0.2647 - val_acc: 0.9099\n",
      "Epoch 342/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2712 - acc: 0.9084 - val_loss: 0.2659 - val_acc: 0.9115\n",
      "Epoch 343/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2689 - acc: 0.9093 - val_loss: 0.2674 - val_acc: 0.9084\n",
      "Epoch 344/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2689 - acc: 0.9094 - val_loss: 0.2649 - val_acc: 0.9099\n",
      "Epoch 345/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2729 - acc: 0.9085 - val_loss: 0.2664 - val_acc: 0.9109\n",
      "Epoch 346/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2683 - acc: 0.9094 - val_loss: 0.2646 - val_acc: 0.9090\n",
      "Epoch 347/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2709 - acc: 0.9090 - val_loss: 0.2642 - val_acc: 0.9096\n",
      "Epoch 348/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2687 - acc: 0.9098 - val_loss: 0.2664 - val_acc: 0.9112\n",
      "Epoch 349/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2699 - acc: 0.9081 - val_loss: 0.2660 - val_acc: 0.9102\n",
      "Epoch 350/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2691 - acc: 0.9088 - val_loss: 0.2630 - val_acc: 0.9109\n",
      "Epoch 351/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2748 - acc: 0.9089 - val_loss: 0.2760 - val_acc: 0.9133\n",
      "Epoch 352/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2798 - acc: 0.9092 - val_loss: 0.2684 - val_acc: 0.9099\n",
      "Epoch 353/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2755 - acc: 0.9084 - val_loss: 0.2662 - val_acc: 0.9102\n",
      "Epoch 354/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2731 - acc: 0.9088 - val_loss: 0.2645 - val_acc: 0.9105\n",
      "Epoch 355/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2727 - acc: 0.9074 - val_loss: 0.2643 - val_acc: 0.9087\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2709 - acc: 0.9093 - val_loss: 0.2639 - val_acc: 0.9109\n",
      "Epoch 357/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2704 - acc: 0.9090 - val_loss: 0.2610 - val_acc: 0.9121\n",
      "Epoch 358/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2694 - acc: 0.9093 - val_loss: 0.2658 - val_acc: 0.9109\n",
      "Epoch 359/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2707 - acc: 0.9082 - val_loss: 0.2651 - val_acc: 0.9105\n",
      "Epoch 360/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2697 - acc: 0.9088 - val_loss: 0.2645 - val_acc: 0.9118\n",
      "Epoch 361/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2698 - acc: 0.9090 - val_loss: 0.2665 - val_acc: 0.9099\n",
      "Epoch 362/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2715 - acc: 0.9082 - val_loss: 0.2686 - val_acc: 0.9093\n",
      "Epoch 363/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2705 - acc: 0.9092 - val_loss: 0.2687 - val_acc: 0.9133\n",
      "Epoch 364/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2695 - acc: 0.9086 - val_loss: 0.2651 - val_acc: 0.9112\n",
      "Epoch 365/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2753 - acc: 0.9093 - val_loss: 0.2799 - val_acc: 0.9115\n",
      "Epoch 366/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.2778 - acc: 0.9086 - val_loss: 0.2702 - val_acc: 0.9096\n",
      "Epoch 367/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2735 - acc: 0.9089 - val_loss: 0.2674 - val_acc: 0.9124\n",
      "Epoch 368/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2726 - acc: 0.9088 - val_loss: 0.2656 - val_acc: 0.9115\n",
      "Epoch 369/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2698 - acc: 0.9086 - val_loss: 0.2640 - val_acc: 0.9115\n",
      "Epoch 370/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2715 - acc: 0.9082 - val_loss: 0.2726 - val_acc: 0.9087\n",
      "Epoch 371/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2698 - acc: 0.9085 - val_loss: 0.2684 - val_acc: 0.9099\n",
      "Epoch 372/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2697 - acc: 0.9094 - val_loss: 0.2664 - val_acc: 0.9102\n",
      "Epoch 373/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2695 - acc: 0.9085 - val_loss: 0.2637 - val_acc: 0.9118\n",
      "Epoch 374/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2679 - acc: 0.9100 - val_loss: 0.2707 - val_acc: 0.9090\n",
      "Epoch 375/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2687 - acc: 0.9097 - val_loss: 0.2653 - val_acc: 0.9155\n",
      "Epoch 376/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2693 - acc: 0.9082 - val_loss: 0.2685 - val_acc: 0.9093\n",
      "Epoch 377/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2679 - acc: 0.9100 - val_loss: 0.2715 - val_acc: 0.9109\n",
      "Epoch 378/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2684 - acc: 0.9098 - val_loss: 0.2654 - val_acc: 0.9136\n",
      "Epoch 379/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2690 - acc: 0.9089 - val_loss: 0.2735 - val_acc: 0.9115\n",
      "Epoch 380/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2722 - acc: 0.9085 - val_loss: 0.2733 - val_acc: 0.9096\n",
      "Epoch 381/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2693 - acc: 0.9090 - val_loss: 0.2644 - val_acc: 0.9099\n",
      "Epoch 382/500\n",
      "7563/7563 [==============================] - ETA: 0s - loss: 0.2653 - acc: 0.908 - 0s 18us/step - loss: 0.2682 - acc: 0.9090 - val_loss: 0.2685 - val_acc: 0.9115\n",
      "Epoch 383/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2715 - acc: 0.9084 - val_loss: 0.2684 - val_acc: 0.9099\n",
      "Epoch 384/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2693 - acc: 0.9098 - val_loss: 0.2725 - val_acc: 0.9118\n",
      "Epoch 385/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2696 - acc: 0.9086 - val_loss: 0.2633 - val_acc: 0.9105\n",
      "Epoch 386/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2694 - acc: 0.9078 - val_loss: 0.2679 - val_acc: 0.9093\n",
      "Epoch 387/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2686 - acc: 0.9093 - val_loss: 0.2655 - val_acc: 0.9102\n",
      "Epoch 388/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2680 - acc: 0.9084 - val_loss: 0.2641 - val_acc: 0.9115\n",
      "Epoch 389/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2688 - acc: 0.9080 - val_loss: 0.2639 - val_acc: 0.9112\n",
      "Epoch 390/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2678 - acc: 0.9096 - val_loss: 0.2668 - val_acc: 0.9124\n",
      "Epoch 391/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2706 - acc: 0.9081 - val_loss: 0.2636 - val_acc: 0.9105\n",
      "Epoch 392/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2681 - acc: 0.9082 - val_loss: 0.2642 - val_acc: 0.9109\n",
      "Epoch 393/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2703 - acc: 0.9089 - val_loss: 0.2807 - val_acc: 0.9096\n",
      "Epoch 394/500\n",
      "7563/7563 [==============================] - 0s 24us/step - loss: 0.2804 - acc: 0.9078 - val_loss: 0.2736 - val_acc: 0.9099\n",
      "Epoch 395/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2748 - acc: 0.9081 - val_loss: 0.2702 - val_acc: 0.9109\n",
      "Epoch 396/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2728 - acc: 0.9085 - val_loss: 0.2669 - val_acc: 0.9112\n",
      "Epoch 397/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2710 - acc: 0.9088 - val_loss: 0.2660 - val_acc: 0.9121\n",
      "Epoch 398/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2696 - acc: 0.9077 - val_loss: 0.2673 - val_acc: 0.9109\n",
      "Epoch 399/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2686 - acc: 0.9093 - val_loss: 0.2686 - val_acc: 0.9115\n",
      "Epoch 400/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2685 - acc: 0.9094 - val_loss: 0.2633 - val_acc: 0.9118\n",
      "Epoch 401/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2676 - acc: 0.9090 - val_loss: 0.2664 - val_acc: 0.9124\n",
      "Epoch 402/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2664 - acc: 0.9100 - val_loss: 0.2657 - val_acc: 0.9109\n",
      "Epoch 403/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2661 - acc: 0.9097 - val_loss: 0.2693 - val_acc: 0.9115\n",
      "Epoch 404/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2693 - acc: 0.9105 - val_loss: 0.2748 - val_acc: 0.9090\n",
      "Epoch 405/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2706 - acc: 0.9101 - val_loss: 0.2785 - val_acc: 0.9105\n",
      "Epoch 406/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2725 - acc: 0.9093 - val_loss: 0.2649 - val_acc: 0.9093\n",
      "Epoch 407/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2689 - acc: 0.9092 - val_loss: 0.2671 - val_acc: 0.9093\n",
      "Epoch 408/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2680 - acc: 0.9082 - val_loss: 0.2647 - val_acc: 0.9112\n",
      "Epoch 409/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.2671 - acc: 0.9093 - val_loss: 0.2693 - val_acc: 0.9127\n",
      "Epoch 410/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2680 - acc: 0.9077 - val_loss: 0.2670 - val_acc: 0.9121\n",
      "Epoch 411/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2667 - acc: 0.9086 - val_loss: 0.2659 - val_acc: 0.9099\n",
      "Epoch 412/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2720 - acc: 0.9104 - val_loss: 0.2753 - val_acc: 0.9127\n",
      "Epoch 413/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2747 - acc: 0.9086 - val_loss: 0.2681 - val_acc: 0.9115\n",
      "Epoch 414/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2711 - acc: 0.9094 - val_loss: 0.2706 - val_acc: 0.9139\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2713 - acc: 0.9096 - val_loss: 0.2636 - val_acc: 0.9124\n",
      "Epoch 416/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2683 - acc: 0.9089 - val_loss: 0.2639 - val_acc: 0.9133\n",
      "Epoch 417/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2672 - acc: 0.9092 - val_loss: 0.2670 - val_acc: 0.9112\n",
      "Epoch 418/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2687 - acc: 0.9094 - val_loss: 0.2727 - val_acc: 0.9124\n",
      "Epoch 419/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2671 - acc: 0.9105 - val_loss: 0.2816 - val_acc: 0.9115\n",
      "Epoch 420/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2698 - acc: 0.9081 - val_loss: 0.2664 - val_acc: 0.9124\n",
      "Epoch 421/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2665 - acc: 0.9093 - val_loss: 0.2635 - val_acc: 0.9130\n",
      "Epoch 422/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2672 - acc: 0.9100 - val_loss: 0.2669 - val_acc: 0.9112\n",
      "Epoch 423/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2696 - acc: 0.9086 - val_loss: 0.2725 - val_acc: 0.9105\n",
      "Epoch 424/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2677 - acc: 0.9092 - val_loss: 0.2716 - val_acc: 0.9115\n",
      "Epoch 425/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2676 - acc: 0.9093 - val_loss: 0.2650 - val_acc: 0.9127\n",
      "Epoch 426/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2669 - acc: 0.9090 - val_loss: 0.2749 - val_acc: 0.9090\n",
      "Epoch 427/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2673 - acc: 0.9100 - val_loss: 0.2675 - val_acc: 0.9118\n",
      "Epoch 428/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2682 - acc: 0.9093 - val_loss: 0.2644 - val_acc: 0.9118\n",
      "Epoch 429/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2670 - acc: 0.9094 - val_loss: 0.2637 - val_acc: 0.9127\n",
      "Epoch 430/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2665 - acc: 0.9098 - val_loss: 0.2661 - val_acc: 0.9105\n",
      "Epoch 431/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2682 - acc: 0.9094 - val_loss: 0.2721 - val_acc: 0.9124\n",
      "Epoch 432/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2671 - acc: 0.9096 - val_loss: 0.2714 - val_acc: 0.9087\n",
      "Epoch 433/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2672 - acc: 0.9096 - val_loss: 0.2646 - val_acc: 0.9105\n",
      "Epoch 434/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2675 - acc: 0.9096 - val_loss: 0.2627 - val_acc: 0.9127\n",
      "Epoch 435/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2676 - acc: 0.9088 - val_loss: 0.2647 - val_acc: 0.9105\n",
      "Epoch 436/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2675 - acc: 0.9088 - val_loss: 0.2745 - val_acc: 0.9090\n",
      "Epoch 437/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2736 - acc: 0.9084 - val_loss: 0.2783 - val_acc: 0.9099\n",
      "Epoch 438/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2692 - acc: 0.9090 - val_loss: 0.2665 - val_acc: 0.9130\n",
      "Epoch 439/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2672 - acc: 0.9092 - val_loss: 0.2678 - val_acc: 0.9133\n",
      "Epoch 440/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.2665 - acc: 0.9090 - val_loss: 0.2680 - val_acc: 0.9087\n",
      "Epoch 441/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2669 - acc: 0.9100 - val_loss: 0.2653 - val_acc: 0.9109\n",
      "Epoch 442/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2652 - acc: 0.9097 - val_loss: 0.2739 - val_acc: 0.9121\n",
      "Epoch 443/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2675 - acc: 0.9085 - val_loss: 0.2704 - val_acc: 0.9115\n",
      "Epoch 444/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2667 - acc: 0.9097 - val_loss: 0.2750 - val_acc: 0.9087\n",
      "Epoch 445/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2651 - acc: 0.9107 - val_loss: 0.2719 - val_acc: 0.9112\n",
      "Epoch 446/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2667 - acc: 0.9105 - val_loss: 0.2691 - val_acc: 0.9109\n",
      "Epoch 447/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2669 - acc: 0.9104 - val_loss: 0.2681 - val_acc: 0.9118\n",
      "Epoch 448/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2696 - acc: 0.9081 - val_loss: 0.2657 - val_acc: 0.9146\n",
      "Epoch 449/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2660 - acc: 0.9101 - val_loss: 0.2753 - val_acc: 0.9096\n",
      "Epoch 450/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2658 - acc: 0.9106 - val_loss: 0.2697 - val_acc: 0.9109\n",
      "Epoch 451/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2661 - acc: 0.9096 - val_loss: 0.2689 - val_acc: 0.9099\n",
      "Epoch 452/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2708 - acc: 0.9094 - val_loss: 0.2710 - val_acc: 0.9112\n",
      "Epoch 453/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2664 - acc: 0.9097 - val_loss: 0.2693 - val_acc: 0.9143\n",
      "Epoch 454/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2663 - acc: 0.9101 - val_loss: 0.2647 - val_acc: 0.9115\n",
      "Epoch 455/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2659 - acc: 0.9113 - val_loss: 0.2710 - val_acc: 0.9136\n",
      "Epoch 456/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2653 - acc: 0.9107 - val_loss: 0.2690 - val_acc: 0.9093\n",
      "Epoch 457/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2663 - acc: 0.9113 - val_loss: 0.2680 - val_acc: 0.9087\n",
      "Epoch 458/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2666 - acc: 0.9100 - val_loss: 0.2698 - val_acc: 0.9115\n",
      "Epoch 459/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2673 - acc: 0.9100 - val_loss: 0.2645 - val_acc: 0.9096\n",
      "Epoch 460/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2692 - acc: 0.9088 - val_loss: 0.2694 - val_acc: 0.9115\n",
      "Epoch 461/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2666 - acc: 0.9096 - val_loss: 0.2719 - val_acc: 0.9139\n",
      "Epoch 462/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2676 - acc: 0.9092 - val_loss: 0.2712 - val_acc: 0.9130\n",
      "Epoch 463/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2679 - acc: 0.9096 - val_loss: 0.2673 - val_acc: 0.9093\n",
      "Epoch 464/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2670 - acc: 0.9109 - val_loss: 0.2710 - val_acc: 0.9121\n",
      "Epoch 465/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2718 - acc: 0.9088 - val_loss: 0.2656 - val_acc: 0.9112\n",
      "Epoch 466/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2673 - acc: 0.9093 - val_loss: 0.2638 - val_acc: 0.9118\n",
      "Epoch 467/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.2682 - acc: 0.9092 - val_loss: 0.2661 - val_acc: 0.9102\n",
      "Epoch 468/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2659 - acc: 0.9100 - val_loss: 0.2662 - val_acc: 0.9124\n",
      "Epoch 469/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2662 - acc: 0.9098 - val_loss: 0.2659 - val_acc: 0.9118\n",
      "Epoch 470/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2688 - acc: 0.9093 - val_loss: 0.2642 - val_acc: 0.9121\n",
      "Epoch 471/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2653 - acc: 0.9102 - val_loss: 0.2657 - val_acc: 0.9109\n",
      "Epoch 472/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2677 - acc: 0.9082 - val_loss: 0.2671 - val_acc: 0.9136\n",
      "Epoch 473/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2680 - acc: 0.9098 - val_loss: 0.2689 - val_acc: 0.9109\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2654 - acc: 0.9102 - val_loss: 0.2644 - val_acc: 0.9136\n",
      "Epoch 475/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2659 - acc: 0.9105 - val_loss: 0.2641 - val_acc: 0.9112\n",
      "Epoch 476/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2686 - acc: 0.9088 - val_loss: 0.2720 - val_acc: 0.9105\n",
      "Epoch 477/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2648 - acc: 0.9107 - val_loss: 0.2680 - val_acc: 0.9112\n",
      "Epoch 478/500\n",
      "7563/7563 [==============================] - 0s 20us/step - loss: 0.2658 - acc: 0.9089 - val_loss: 0.2669 - val_acc: 0.9112\n",
      "Epoch 479/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2675 - acc: 0.9105 - val_loss: 0.2855 - val_acc: 0.9096\n",
      "Epoch 480/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2673 - acc: 0.9101 - val_loss: 0.2694 - val_acc: 0.9102\n",
      "Epoch 481/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2677 - acc: 0.9085 - val_loss: 0.2631 - val_acc: 0.9105\n",
      "Epoch 482/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2673 - acc: 0.9084 - val_loss: 0.2639 - val_acc: 0.9099\n",
      "Epoch 483/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2667 - acc: 0.9096 - val_loss: 0.2659 - val_acc: 0.9124\n",
      "Epoch 484/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2676 - acc: 0.9104 - val_loss: 0.2646 - val_acc: 0.9109\n",
      "Epoch 485/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2670 - acc: 0.9100 - val_loss: 0.2681 - val_acc: 0.9096\n",
      "Epoch 486/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2688 - acc: 0.9074 - val_loss: 0.2650 - val_acc: 0.9112\n",
      "Epoch 487/500\n",
      "7563/7563 [==============================] - 0s 15us/step - loss: 0.2675 - acc: 0.9084 - val_loss: 0.2690 - val_acc: 0.9087\n",
      "Epoch 488/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2726 - acc: 0.9096 - val_loss: 0.2762 - val_acc: 0.9139\n",
      "Epoch 489/500\n",
      "7563/7563 [==============================] - 0s 18us/step - loss: 0.2740 - acc: 0.9089 - val_loss: 0.2684 - val_acc: 0.9087\n",
      "Epoch 490/500\n",
      "7563/7563 [==============================] - 0s 23us/step - loss: 0.2702 - acc: 0.9093 - val_loss: 0.2668 - val_acc: 0.9093\n",
      "Epoch 491/500\n",
      "7563/7563 [==============================] - 0s 17us/step - loss: 0.2672 - acc: 0.9101 - val_loss: 0.2714 - val_acc: 0.9127\n",
      "Epoch 492/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2690 - acc: 0.9094 - val_loss: 0.2688 - val_acc: 0.9115\n",
      "Epoch 493/500\n",
      "7563/7563 [==============================] - 0s 22us/step - loss: 0.2663 - acc: 0.9101 - val_loss: 0.2651 - val_acc: 0.9105\n",
      "Epoch 494/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2651 - acc: 0.9100 - val_loss: 0.2664 - val_acc: 0.9133\n",
      "Epoch 495/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2645 - acc: 0.9109 - val_loss: 0.2652 - val_acc: 0.9146\n",
      "Epoch 496/500\n",
      "7563/7563 [==============================] - 0s 14us/step - loss: 0.2649 - acc: 0.9110 - val_loss: 0.2671 - val_acc: 0.9093\n",
      "Epoch 497/500\n",
      "7563/7563 [==============================] - 0s 16us/step - loss: 0.2645 - acc: 0.9113 - val_loss: 0.2654 - val_acc: 0.9124\n",
      "Epoch 498/500\n",
      "7563/7563 [==============================] - 0s 21us/step - loss: 0.2690 - acc: 0.9086 - val_loss: 0.2736 - val_acc: 0.9105\n",
      "Epoch 499/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2654 - acc: 0.9094 - val_loss: 0.2654 - val_acc: 0.9099\n",
      "Epoch 500/500\n",
      "7563/7563 [==============================] - 0s 19us/step - loss: 0.2682 - acc: 0.9090 - val_loss: 0.2673 - val_acc: 0.9112\n",
      "3242/3242 [==============================] - 0s 6us/step\n",
      "20 81 403 403 12494 10311 81 1093 1012\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "10311 10311\n",
      "../linkPrediction/dataframes/apnea\n",
      "article (10311, 7, 11) --------------------------------------------------------------------\n",
      "(10311, 11) (10311,)\n",
      "[10311, 11, 1]\n",
      "(7217, 11) (7217,)\n",
      "Train on 7217 samples, validate on 3094 samples\n",
      "Epoch 1/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.8515 - acc: 0.9087 - val_loss: 0.7788 - val_acc: 0.8988\n",
      "Epoch 2/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.6438 - acc: 0.8976 - val_loss: 0.6690 - val_acc: 0.8959\n",
      "Epoch 3/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.6012 - acc: 0.8997 - val_loss: 0.6019 - val_acc: 0.9037\n",
      "Epoch 4/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.5076 - acc: 0.9011 - val_loss: 0.5208 - val_acc: 0.9001\n",
      "Epoch 5/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.4810 - acc: 0.9022 - val_loss: 0.5299 - val_acc: 0.8937\n",
      "Epoch 6/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.4985 - acc: 0.9074 - val_loss: 0.6021 - val_acc: 0.8975\n",
      "Epoch 7/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.4719 - acc: 0.9031 - val_loss: 0.5275 - val_acc: 0.8908\n",
      "Epoch 8/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.4321 - acc: 0.9016 - val_loss: 0.5334 - val_acc: 0.9021\n",
      "Epoch 9/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.4379 - acc: 0.9037 - val_loss: 0.5057 - val_acc: 0.9034\n",
      "Epoch 10/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.4270 - acc: 0.9062 - val_loss: 0.4590 - val_acc: 0.8933\n",
      "Epoch 11/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.3975 - acc: 0.9040 - val_loss: 0.4341 - val_acc: 0.8956\n",
      "Epoch 12/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.3746 - acc: 0.9104 - val_loss: 0.5541 - val_acc: 0.8911\n",
      "Epoch 13/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.4387 - acc: 0.9000 - val_loss: 0.4631 - val_acc: 0.8927\n",
      "Epoch 14/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.4030 - acc: 0.9055 - val_loss: 0.5264 - val_acc: 0.9011\n",
      "Epoch 15/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.4293 - acc: 0.9092 - val_loss: 0.5098 - val_acc: 0.8969\n",
      "Epoch 16/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.4416 - acc: 0.9061 - val_loss: 0.4681 - val_acc: 0.9014\n",
      "Epoch 17/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.4352 - acc: 0.9038 - val_loss: 0.4684 - val_acc: 0.8969\n",
      "Epoch 18/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.3861 - acc: 0.9080 - val_loss: 0.3764 - val_acc: 0.8998\n",
      "Epoch 19/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.3550 - acc: 0.9069 - val_loss: 0.4313 - val_acc: 0.9047\n",
      "Epoch 20/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.4056 - acc: 0.9065 - val_loss: 0.4146 - val_acc: 0.9024\n",
      "Epoch 21/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.3534 - acc: 0.9095 - val_loss: 0.3989 - val_acc: 0.9030\n",
      "Epoch 22/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.3587 - acc: 0.9084 - val_loss: 0.3898 - val_acc: 0.9034\n",
      "Epoch 23/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.3399 - acc: 0.9104 - val_loss: 0.3784 - val_acc: 0.9030\n",
      "Epoch 24/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.3477 - acc: 0.9076 - val_loss: 0.4616 - val_acc: 0.9050\n",
      "Epoch 25/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.3863 - acc: 0.9085 - val_loss: 0.3885 - val_acc: 0.8985\n",
      "Epoch 26/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.3414 - acc: 0.9101 - val_loss: 0.4021 - val_acc: 0.9034\n",
      "Epoch 27/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.3997 - acc: 0.9063 - val_loss: 0.4500 - val_acc: 0.9014\n",
      "Epoch 28/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.4006 - acc: 0.9063 - val_loss: 0.4127 - val_acc: 0.9024\n",
      "Epoch 29/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.3719 - acc: 0.9092 - val_loss: 0.3734 - val_acc: 0.9008\n",
      "Epoch 30/500\n",
      "7217/7217 [==============================] - 0s 27us/step - loss: 0.3560 - acc: 0.9095 - val_loss: 0.4444 - val_acc: 0.9037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/500\n",
      "7217/7217 [==============================] - 0s 29us/step - loss: 0.3425 - acc: 0.9099 - val_loss: 0.4193 - val_acc: 0.8959\n",
      "Epoch 32/500\n",
      "7217/7217 [==============================] - 0s 27us/step - loss: 0.3583 - acc: 0.9067 - val_loss: 0.4116 - val_acc: 0.8898\n",
      "Epoch 33/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.3651 - acc: 0.9087 - val_loss: 0.4074 - val_acc: 0.8975\n",
      "Epoch 34/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.3911 - acc: 0.9040 - val_loss: 0.4837 - val_acc: 0.8959\n",
      "Epoch 35/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.3534 - acc: 0.9070 - val_loss: 0.3703 - val_acc: 0.9001\n",
      "Epoch 36/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.3245 - acc: 0.9124 - val_loss: 0.3837 - val_acc: 0.8975\n",
      "Epoch 37/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.3309 - acc: 0.9105 - val_loss: 0.3777 - val_acc: 0.8985\n",
      "Epoch 38/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.3364 - acc: 0.9090 - val_loss: 0.4024 - val_acc: 0.9040\n",
      "Epoch 39/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.3333 - acc: 0.9108 - val_loss: 0.3496 - val_acc: 0.9005\n",
      "Epoch 40/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.3709 - acc: 0.9023 - val_loss: 0.3722 - val_acc: 0.8969\n",
      "Epoch 41/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.3454 - acc: 0.9079 - val_loss: 0.3761 - val_acc: 0.9014\n",
      "Epoch 42/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.3283 - acc: 0.9090 - val_loss: 0.3726 - val_acc: 0.9030\n",
      "Epoch 43/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.3628 - acc: 0.9083 - val_loss: 0.4389 - val_acc: 0.9017\n",
      "Epoch 44/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.3642 - acc: 0.9088 - val_loss: 0.4291 - val_acc: 0.9001\n",
      "Epoch 45/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.3673 - acc: 0.9063 - val_loss: 0.3709 - val_acc: 0.8963\n",
      "Epoch 46/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.3875 - acc: 0.9117 - val_loss: 0.4428 - val_acc: 0.9034\n",
      "Epoch 47/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.3839 - acc: 0.9097 - val_loss: 0.4040 - val_acc: 0.9011\n",
      "Epoch 48/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.3427 - acc: 0.9077 - val_loss: 0.3729 - val_acc: 0.9008\n",
      "Epoch 49/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.3654 - acc: 0.9067 - val_loss: 0.3695 - val_acc: 0.9047\n",
      "Epoch 50/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.3108 - acc: 0.9097 - val_loss: 0.3399 - val_acc: 0.9030\n",
      "Epoch 51/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.3388 - acc: 0.9085 - val_loss: 0.3714 - val_acc: 0.9008\n",
      "Epoch 52/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.3448 - acc: 0.9048 - val_loss: 0.3593 - val_acc: 0.9011\n",
      "Epoch 53/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.3346 - acc: 0.9062 - val_loss: 0.3357 - val_acc: 0.8995\n",
      "Epoch 54/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.3156 - acc: 0.9080 - val_loss: 0.3353 - val_acc: 0.9030\n",
      "Epoch 55/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.3132 - acc: 0.9106 - val_loss: 0.3432 - val_acc: 0.9001\n",
      "Epoch 56/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.3185 - acc: 0.9109 - val_loss: 0.3677 - val_acc: 0.9011\n",
      "Epoch 57/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.3234 - acc: 0.9091 - val_loss: 0.3252 - val_acc: 0.9014\n",
      "Epoch 58/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.3146 - acc: 0.9084 - val_loss: 0.3831 - val_acc: 0.8998\n",
      "Epoch 59/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.3456 - acc: 0.9090 - val_loss: 0.3728 - val_acc: 0.9014\n",
      "Epoch 60/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.3252 - acc: 0.9117 - val_loss: 0.3401 - val_acc: 0.9021\n",
      "Epoch 61/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.3056 - acc: 0.9138 - val_loss: 0.3462 - val_acc: 0.9017\n",
      "Epoch 62/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.3380 - acc: 0.9080 - val_loss: 0.4161 - val_acc: 0.9001\n",
      "Epoch 63/500\n",
      "7217/7217 [==============================] - 0s 26us/step - loss: 0.3261 - acc: 0.9095 - val_loss: 0.3412 - val_acc: 0.9021\n",
      "Epoch 64/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.3037 - acc: 0.9112 - val_loss: 0.3495 - val_acc: 0.8937\n",
      "Epoch 65/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.3521 - acc: 0.9069 - val_loss: 0.4156 - val_acc: 0.8943\n",
      "Epoch 66/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.3333 - acc: 0.9066 - val_loss: 0.3340 - val_acc: 0.9030\n",
      "Epoch 67/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.3016 - acc: 0.9113 - val_loss: 0.3254 - val_acc: 0.9027\n",
      "Epoch 68/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.3129 - acc: 0.9101 - val_loss: 0.3331 - val_acc: 0.9017\n",
      "Epoch 69/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2944 - acc: 0.9127 - val_loss: 0.3311 - val_acc: 0.9014\n",
      "Epoch 70/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2918 - acc: 0.9137 - val_loss: 0.3243 - val_acc: 0.9001\n",
      "Epoch 71/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2960 - acc: 0.9110 - val_loss: 0.3297 - val_acc: 0.9001\n",
      "Epoch 72/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2971 - acc: 0.9115 - val_loss: 0.3241 - val_acc: 0.9047\n",
      "Epoch 73/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.3127 - acc: 0.9102 - val_loss: 0.3457 - val_acc: 0.8988\n",
      "Epoch 74/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2994 - acc: 0.9116 - val_loss: 0.3305 - val_acc: 0.9021\n",
      "Epoch 75/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.3078 - acc: 0.9090 - val_loss: 0.3877 - val_acc: 0.8956\n",
      "Epoch 76/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.3027 - acc: 0.9116 - val_loss: 0.3693 - val_acc: 0.9027\n",
      "Epoch 77/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2981 - acc: 0.9123 - val_loss: 0.3294 - val_acc: 0.9017\n",
      "Epoch 78/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.3039 - acc: 0.9131 - val_loss: 0.3423 - val_acc: 0.9027\n",
      "Epoch 79/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2949 - acc: 0.9133 - val_loss: 0.3346 - val_acc: 0.9027\n",
      "Epoch 80/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.3045 - acc: 0.9102 - val_loss: 0.3267 - val_acc: 0.9001\n",
      "Epoch 81/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.3056 - acc: 0.9105 - val_loss: 0.3230 - val_acc: 0.9037\n",
      "Epoch 82/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.3003 - acc: 0.9104 - val_loss: 0.3613 - val_acc: 0.9008\n",
      "Epoch 83/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.3045 - acc: 0.9105 - val_loss: 0.3350 - val_acc: 0.9024\n",
      "Epoch 84/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.3109 - acc: 0.9105 - val_loss: 0.3351 - val_acc: 0.8988\n",
      "Epoch 85/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.3043 - acc: 0.9110 - val_loss: 0.3783 - val_acc: 0.8966\n",
      "Epoch 86/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.2998 - acc: 0.9112 - val_loss: 0.3162 - val_acc: 0.9040\n",
      "Epoch 87/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2939 - acc: 0.9109 - val_loss: 0.3378 - val_acc: 0.9008\n",
      "Epoch 88/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.3030 - acc: 0.9127 - val_loss: 0.4998 - val_acc: 0.8859\n",
      "Epoch 89/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.3721 - acc: 0.9045 - val_loss: 0.4160 - val_acc: 0.8930\n",
      "Epoch 90/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.3403 - acc: 0.9070 - val_loss: 0.3367 - val_acc: 0.8992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.3104 - acc: 0.9112 - val_loss: 0.3232 - val_acc: 0.9043\n",
      "Epoch 92/500\n",
      "7217/7217 [==============================] - 0s 13us/step - loss: 0.2928 - acc: 0.9119 - val_loss: 0.3346 - val_acc: 0.8982\n",
      "Epoch 93/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2865 - acc: 0.9117 - val_loss: 0.3642 - val_acc: 0.9021\n",
      "Epoch 94/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.3052 - acc: 0.9104 - val_loss: 0.3217 - val_acc: 0.8998\n",
      "Epoch 95/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2868 - acc: 0.9108 - val_loss: 0.3202 - val_acc: 0.9024\n",
      "Epoch 96/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2925 - acc: 0.9120 - val_loss: 0.3300 - val_acc: 0.9008\n",
      "Epoch 97/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2930 - acc: 0.9119 - val_loss: 0.3266 - val_acc: 0.8998\n",
      "Epoch 98/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2900 - acc: 0.9116 - val_loss: 0.3332 - val_acc: 0.9005\n",
      "Epoch 99/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.3264 - acc: 0.9090 - val_loss: 0.3260 - val_acc: 0.9014\n",
      "Epoch 100/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.3070 - acc: 0.9109 - val_loss: 0.3412 - val_acc: 0.9030\n",
      "Epoch 101/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.3070 - acc: 0.9119 - val_loss: 0.3398 - val_acc: 0.9059\n",
      "Epoch 102/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2933 - acc: 0.9133 - val_loss: 0.3244 - val_acc: 0.9011\n",
      "Epoch 103/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.3006 - acc: 0.9108 - val_loss: 0.3137 - val_acc: 0.9040\n",
      "Epoch 104/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2824 - acc: 0.9135 - val_loss: 0.3232 - val_acc: 0.9017\n",
      "Epoch 105/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.3122 - acc: 0.9102 - val_loss: 0.3456 - val_acc: 0.8995\n",
      "Epoch 106/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.3384 - acc: 0.9091 - val_loss: 0.3653 - val_acc: 0.9047\n",
      "Epoch 107/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.3045 - acc: 0.9104 - val_loss: 0.3401 - val_acc: 0.9008\n",
      "Epoch 108/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2930 - acc: 0.9138 - val_loss: 0.3397 - val_acc: 0.9027\n",
      "Epoch 109/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.3048 - acc: 0.9115 - val_loss: 0.3324 - val_acc: 0.9008\n",
      "Epoch 110/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2910 - acc: 0.9120 - val_loss: 0.3165 - val_acc: 0.9005\n",
      "Epoch 111/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2901 - acc: 0.9108 - val_loss: 0.3146 - val_acc: 0.9027\n",
      "Epoch 112/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2908 - acc: 0.9134 - val_loss: 0.3050 - val_acc: 0.9024\n",
      "Epoch 113/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2847 - acc: 0.9119 - val_loss: 0.3177 - val_acc: 0.9017\n",
      "Epoch 114/500\n",
      "7217/7217 [==============================] - 0s 13us/step - loss: 0.2765 - acc: 0.9115 - val_loss: 0.3132 - val_acc: 0.9001\n",
      "Epoch 115/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2832 - acc: 0.9134 - val_loss: 0.3278 - val_acc: 0.9027\n",
      "Epoch 116/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.3277 - acc: 0.9122 - val_loss: 0.3451 - val_acc: 0.9021\n",
      "Epoch 117/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.3017 - acc: 0.9116 - val_loss: 0.3406 - val_acc: 0.9001\n",
      "Epoch 118/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2819 - acc: 0.9119 - val_loss: 0.3407 - val_acc: 0.8985\n",
      "Epoch 119/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2855 - acc: 0.9123 - val_loss: 0.3395 - val_acc: 0.8979\n",
      "Epoch 120/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2880 - acc: 0.9124 - val_loss: 0.3201 - val_acc: 0.9024\n",
      "Epoch 121/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2819 - acc: 0.9130 - val_loss: 0.3074 - val_acc: 0.9027\n",
      "Epoch 122/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2871 - acc: 0.9127 - val_loss: 0.3157 - val_acc: 0.9024\n",
      "Epoch 123/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2855 - acc: 0.9115 - val_loss: 0.3154 - val_acc: 0.9043\n",
      "Epoch 124/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2799 - acc: 0.9131 - val_loss: 0.3173 - val_acc: 0.8998\n",
      "Epoch 125/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2819 - acc: 0.9138 - val_loss: 0.3149 - val_acc: 0.9011\n",
      "Epoch 126/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2774 - acc: 0.9138 - val_loss: 0.3099 - val_acc: 0.9008\n",
      "Epoch 127/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.3039 - acc: 0.9102 - val_loss: 0.3707 - val_acc: 0.8975\n",
      "Epoch 128/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2938 - acc: 0.9128 - val_loss: 0.3062 - val_acc: 0.8992\n",
      "Epoch 129/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2794 - acc: 0.9119 - val_loss: 0.3172 - val_acc: 0.9005\n",
      "Epoch 130/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2771 - acc: 0.9137 - val_loss: 0.3089 - val_acc: 0.8979\n",
      "Epoch 131/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2858 - acc: 0.9123 - val_loss: 0.3088 - val_acc: 0.9017\n",
      "Epoch 132/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2841 - acc: 0.9140 - val_loss: 0.3584 - val_acc: 0.8956\n",
      "Epoch 133/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2999 - acc: 0.9090 - val_loss: 0.3300 - val_acc: 0.8995\n",
      "Epoch 134/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2843 - acc: 0.9106 - val_loss: 0.3010 - val_acc: 0.8985\n",
      "Epoch 135/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2779 - acc: 0.9123 - val_loss: 0.3043 - val_acc: 0.9021\n",
      "Epoch 136/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2836 - acc: 0.9133 - val_loss: 0.2978 - val_acc: 0.9021\n",
      "Epoch 137/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2850 - acc: 0.9108 - val_loss: 0.3135 - val_acc: 0.9014\n",
      "Epoch 138/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2820 - acc: 0.9133 - val_loss: 0.3242 - val_acc: 0.8995\n",
      "Epoch 139/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2790 - acc: 0.9127 - val_loss: 0.3075 - val_acc: 0.9017\n",
      "Epoch 140/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2814 - acc: 0.9113 - val_loss: 0.3001 - val_acc: 0.9014\n",
      "Epoch 141/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2929 - acc: 0.9120 - val_loss: 0.3295 - val_acc: 0.8995\n",
      "Epoch 142/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2982 - acc: 0.9094 - val_loss: 0.3162 - val_acc: 0.8998\n",
      "Epoch 143/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2890 - acc: 0.9130 - val_loss: 0.3175 - val_acc: 0.9017\n",
      "Epoch 144/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2816 - acc: 0.9108 - val_loss: 0.3054 - val_acc: 0.8998\n",
      "Epoch 145/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.2837 - acc: 0.9127 - val_loss: 0.3109 - val_acc: 0.9030\n",
      "Epoch 146/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2924 - acc: 0.9112 - val_loss: 0.3185 - val_acc: 0.8988\n",
      "Epoch 147/500\n",
      "7217/7217 [==============================] - 0s 26us/step - loss: 0.2849 - acc: 0.9131 - val_loss: 0.2977 - val_acc: 0.9021\n",
      "Epoch 148/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2746 - acc: 0.9126 - val_loss: 0.3240 - val_acc: 0.8988\n",
      "Epoch 149/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2742 - acc: 0.9135 - val_loss: 0.3028 - val_acc: 0.9011\n",
      "Epoch 150/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2795 - acc: 0.9130 - val_loss: 0.2971 - val_acc: 0.9024\n",
      "Epoch 151/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2720 - acc: 0.9141 - val_loss: 0.3072 - val_acc: 0.8992\n",
      "Epoch 152/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2957 - acc: 0.9106 - val_loss: 0.3337 - val_acc: 0.8998\n",
      "Epoch 153/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2849 - acc: 0.9126 - val_loss: 0.2977 - val_acc: 0.9024\n",
      "Epoch 154/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2804 - acc: 0.9108 - val_loss: 0.2976 - val_acc: 0.9017\n",
      "Epoch 155/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2751 - acc: 0.9130 - val_loss: 0.3021 - val_acc: 0.9011\n",
      "Epoch 156/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2786 - acc: 0.9134 - val_loss: 0.3099 - val_acc: 0.9024\n",
      "Epoch 157/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2772 - acc: 0.9124 - val_loss: 0.2976 - val_acc: 0.9008\n",
      "Epoch 158/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2769 - acc: 0.9133 - val_loss: 0.2947 - val_acc: 0.8995\n",
      "Epoch 159/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2754 - acc: 0.9141 - val_loss: 0.3151 - val_acc: 0.9008\n",
      "Epoch 160/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2778 - acc: 0.9128 - val_loss: 0.2906 - val_acc: 0.9017\n",
      "Epoch 161/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2778 - acc: 0.9119 - val_loss: 0.2970 - val_acc: 0.9030\n",
      "Epoch 162/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2759 - acc: 0.9137 - val_loss: 0.2880 - val_acc: 0.9005\n",
      "Epoch 163/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2797 - acc: 0.9148 - val_loss: 0.3047 - val_acc: 0.9021\n",
      "Epoch 164/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2793 - acc: 0.9137 - val_loss: 0.3214 - val_acc: 0.9030\n",
      "Epoch 165/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2850 - acc: 0.9131 - val_loss: 0.2966 - val_acc: 0.9001\n",
      "Epoch 166/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2804 - acc: 0.9130 - val_loss: 0.3034 - val_acc: 0.9011\n",
      "Epoch 167/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.2725 - acc: 0.9138 - val_loss: 0.3054 - val_acc: 0.9014\n",
      "Epoch 168/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2730 - acc: 0.9134 - val_loss: 0.2924 - val_acc: 0.9014\n",
      "Epoch 169/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2724 - acc: 0.9140 - val_loss: 0.2963 - val_acc: 0.9024\n",
      "Epoch 170/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2752 - acc: 0.9119 - val_loss: 0.2967 - val_acc: 0.9034\n",
      "Epoch 171/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2814 - acc: 0.9134 - val_loss: 0.3211 - val_acc: 0.9034\n",
      "Epoch 172/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2793 - acc: 0.9137 - val_loss: 0.3008 - val_acc: 0.9011\n",
      "Epoch 173/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2704 - acc: 0.9145 - val_loss: 0.2941 - val_acc: 0.9001\n",
      "Epoch 174/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2640 - acc: 0.9149 - val_loss: 0.3195 - val_acc: 0.8992\n",
      "Epoch 175/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2749 - acc: 0.9140 - val_loss: 0.2970 - val_acc: 0.9034\n",
      "Epoch 176/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2756 - acc: 0.9130 - val_loss: 0.2897 - val_acc: 0.9021\n",
      "Epoch 177/500\n",
      "7217/7217 [==============================] - ETA: 0s - loss: 0.2701 - acc: 0.914 - 0s 26us/step - loss: 0.2711 - acc: 0.9146 - val_loss: 0.2983 - val_acc: 0.9008\n",
      "Epoch 178/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.2703 - acc: 0.9140 - val_loss: 0.3019 - val_acc: 0.9024\n",
      "Epoch 179/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2679 - acc: 0.9130 - val_loss: 0.2936 - val_acc: 0.9011\n",
      "Epoch 180/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2743 - acc: 0.9124 - val_loss: 0.3209 - val_acc: 0.9017\n",
      "Epoch 181/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2813 - acc: 0.9134 - val_loss: 0.3005 - val_acc: 0.9011\n",
      "Epoch 182/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2737 - acc: 0.9141 - val_loss: 0.3109 - val_acc: 0.8998\n",
      "Epoch 183/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2717 - acc: 0.9144 - val_loss: 0.3030 - val_acc: 0.8988\n",
      "Epoch 184/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2681 - acc: 0.9138 - val_loss: 0.2924 - val_acc: 0.9005\n",
      "Epoch 185/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2756 - acc: 0.9124 - val_loss: 0.3051 - val_acc: 0.9014\n",
      "Epoch 186/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2735 - acc: 0.9134 - val_loss: 0.2937 - val_acc: 0.9014\n",
      "Epoch 187/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2723 - acc: 0.9141 - val_loss: 0.2943 - val_acc: 0.9001\n",
      "Epoch 188/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2684 - acc: 0.9138 - val_loss: 0.2944 - val_acc: 0.9014\n",
      "Epoch 189/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2665 - acc: 0.9140 - val_loss: 0.2912 - val_acc: 0.9008\n",
      "Epoch 190/500\n",
      "7217/7217 [==============================] - 0s 26us/step - loss: 0.2766 - acc: 0.9128 - val_loss: 0.3482 - val_acc: 0.9021\n",
      "Epoch 191/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2909 - acc: 0.9127 - val_loss: 0.2987 - val_acc: 0.9034\n",
      "Epoch 192/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2693 - acc: 0.9134 - val_loss: 0.2905 - val_acc: 0.9043\n",
      "Epoch 193/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2662 - acc: 0.9145 - val_loss: 0.3018 - val_acc: 0.9027\n",
      "Epoch 194/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2737 - acc: 0.9128 - val_loss: 0.2986 - val_acc: 0.9014\n",
      "Epoch 195/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2657 - acc: 0.9133 - val_loss: 0.2934 - val_acc: 0.9008\n",
      "Epoch 196/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2700 - acc: 0.9133 - val_loss: 0.3132 - val_acc: 0.9011\n",
      "Epoch 197/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2765 - acc: 0.9149 - val_loss: 0.3012 - val_acc: 0.9043\n",
      "Epoch 198/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2687 - acc: 0.9141 - val_loss: 0.2925 - val_acc: 0.9037\n",
      "Epoch 199/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2671 - acc: 0.9142 - val_loss: 0.2954 - val_acc: 0.9017\n",
      "Epoch 200/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2687 - acc: 0.9134 - val_loss: 0.2951 - val_acc: 0.9005\n",
      "Epoch 201/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2662 - acc: 0.9156 - val_loss: 0.2972 - val_acc: 0.9034\n",
      "Epoch 202/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2672 - acc: 0.9124 - val_loss: 0.2988 - val_acc: 0.9027\n",
      "Epoch 203/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2833 - acc: 0.9128 - val_loss: 0.2995 - val_acc: 0.9030\n",
      "Epoch 204/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2720 - acc: 0.9140 - val_loss: 0.3134 - val_acc: 0.9030\n",
      "Epoch 205/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2790 - acc: 0.9112 - val_loss: 0.3032 - val_acc: 0.8998\n",
      "Epoch 206/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2688 - acc: 0.9128 - val_loss: 0.2936 - val_acc: 0.9030\n",
      "Epoch 207/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2677 - acc: 0.9138 - val_loss: 0.2871 - val_acc: 0.9043\n",
      "Epoch 208/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2673 - acc: 0.9140 - val_loss: 0.3027 - val_acc: 0.9005\n",
      "Epoch 209/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2704 - acc: 0.9138 - val_loss: 0.2937 - val_acc: 0.9027\n",
      "Epoch 210/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2680 - acc: 0.9135 - val_loss: 0.2990 - val_acc: 0.9021\n",
      "Epoch 211/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2658 - acc: 0.9141 - val_loss: 0.2979 - val_acc: 0.9024\n",
      "Epoch 212/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2658 - acc: 0.9152 - val_loss: 0.2926 - val_acc: 0.9024\n",
      "Epoch 213/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.2712 - acc: 0.9122 - val_loss: 0.3053 - val_acc: 0.9037\n",
      "Epoch 214/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2719 - acc: 0.9134 - val_loss: 0.2935 - val_acc: 0.9008\n",
      "Epoch 215/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2674 - acc: 0.9120 - val_loss: 0.2956 - val_acc: 0.9037\n",
      "Epoch 216/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2664 - acc: 0.9142 - val_loss: 0.2911 - val_acc: 0.9011\n",
      "Epoch 217/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2687 - acc: 0.9144 - val_loss: 0.2898 - val_acc: 0.9030\n",
      "Epoch 218/500\n",
      "7217/7217 [==============================] - 0s 13us/step - loss: 0.2680 - acc: 0.9137 - val_loss: 0.2943 - val_acc: 0.9021\n",
      "Epoch 219/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2676 - acc: 0.9131 - val_loss: 0.2906 - val_acc: 0.9037\n",
      "Epoch 220/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2637 - acc: 0.9133 - val_loss: 0.2879 - val_acc: 0.9021\n",
      "Epoch 221/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2674 - acc: 0.9144 - val_loss: 0.2939 - val_acc: 0.9008\n",
      "Epoch 222/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2676 - acc: 0.9135 - val_loss: 0.2917 - val_acc: 0.9040\n",
      "Epoch 223/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2664 - acc: 0.9128 - val_loss: 0.3056 - val_acc: 0.9005\n",
      "Epoch 224/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2642 - acc: 0.9135 - val_loss: 0.2931 - val_acc: 0.9008\n",
      "Epoch 225/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2645 - acc: 0.9141 - val_loss: 0.2968 - val_acc: 0.9005\n",
      "Epoch 226/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2752 - acc: 0.9128 - val_loss: 0.2976 - val_acc: 0.9027\n",
      "Epoch 227/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2649 - acc: 0.9137 - val_loss: 0.2950 - val_acc: 0.9001\n",
      "Epoch 228/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2630 - acc: 0.9135 - val_loss: 0.3042 - val_acc: 0.9014\n",
      "Epoch 229/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2692 - acc: 0.9138 - val_loss: 0.3033 - val_acc: 0.9021\n",
      "Epoch 230/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2623 - acc: 0.9145 - val_loss: 0.2831 - val_acc: 0.9024\n",
      "Epoch 231/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2615 - acc: 0.9144 - val_loss: 0.2896 - val_acc: 0.9014\n",
      "Epoch 232/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2680 - acc: 0.9123 - val_loss: 0.2874 - val_acc: 0.9017\n",
      "Epoch 233/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2621 - acc: 0.9140 - val_loss: 0.2851 - val_acc: 0.9008\n",
      "Epoch 234/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2643 - acc: 0.9145 - val_loss: 0.3004 - val_acc: 0.9014\n",
      "Epoch 235/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2623 - acc: 0.9141 - val_loss: 0.2930 - val_acc: 0.9024\n",
      "Epoch 236/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2676 - acc: 0.9138 - val_loss: 0.3077 - val_acc: 0.9017\n",
      "Epoch 237/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2658 - acc: 0.9135 - val_loss: 0.2981 - val_acc: 0.9021\n",
      "Epoch 238/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2796 - acc: 0.9127 - val_loss: 0.3003 - val_acc: 0.9037\n",
      "Epoch 239/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2687 - acc: 0.9134 - val_loss: 0.2946 - val_acc: 0.9037\n",
      "Epoch 240/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2608 - acc: 0.9134 - val_loss: 0.2906 - val_acc: 0.9027\n",
      "Epoch 241/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2657 - acc: 0.9140 - val_loss: 0.3030 - val_acc: 0.9024\n",
      "Epoch 242/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2641 - acc: 0.9133 - val_loss: 0.2877 - val_acc: 0.9014\n",
      "Epoch 243/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2628 - acc: 0.9145 - val_loss: 0.2872 - val_acc: 0.9011\n",
      "Epoch 244/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2584 - acc: 0.9162 - val_loss: 0.2892 - val_acc: 0.9014\n",
      "Epoch 245/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2598 - acc: 0.9156 - val_loss: 0.2901 - val_acc: 0.9037\n",
      "Epoch 246/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2605 - acc: 0.9138 - val_loss: 0.3104 - val_acc: 0.9017\n",
      "Epoch 247/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2643 - acc: 0.9140 - val_loss: 0.2878 - val_acc: 0.9027\n",
      "Epoch 248/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.2672 - acc: 0.9134 - val_loss: 0.3064 - val_acc: 0.9001\n",
      "Epoch 249/500\n",
      "7217/7217 [==============================] - 0s 28us/step - loss: 0.2617 - acc: 0.9141 - val_loss: 0.2873 - val_acc: 0.9014\n",
      "Epoch 250/500\n",
      "7217/7217 [==============================] - 0s 28us/step - loss: 0.2622 - acc: 0.9146 - val_loss: 0.3222 - val_acc: 0.9014\n",
      "Epoch 251/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2677 - acc: 0.9122 - val_loss: 0.2888 - val_acc: 0.9021\n",
      "Epoch 252/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2632 - acc: 0.9133 - val_loss: 0.2956 - val_acc: 0.9027\n",
      "Epoch 253/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2642 - acc: 0.9145 - val_loss: 0.2918 - val_acc: 0.9050\n",
      "Epoch 254/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2646 - acc: 0.9131 - val_loss: 0.2892 - val_acc: 0.9037\n",
      "Epoch 255/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2631 - acc: 0.9145 - val_loss: 0.2867 - val_acc: 0.9030\n",
      "Epoch 256/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2637 - acc: 0.9127 - val_loss: 0.2985 - val_acc: 0.9017\n",
      "Epoch 257/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2626 - acc: 0.9144 - val_loss: 0.3024 - val_acc: 0.9008\n",
      "Epoch 258/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2720 - acc: 0.9126 - val_loss: 0.2931 - val_acc: 0.8992\n",
      "Epoch 259/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2593 - acc: 0.9151 - val_loss: 0.2928 - val_acc: 0.9021\n",
      "Epoch 260/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2627 - acc: 0.9138 - val_loss: 0.2867 - val_acc: 0.9024\n",
      "Epoch 261/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2609 - acc: 0.9144 - val_loss: 0.2913 - val_acc: 0.9021\n",
      "Epoch 262/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2607 - acc: 0.9134 - val_loss: 0.2913 - val_acc: 0.9008\n",
      "Epoch 263/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2605 - acc: 0.9145 - val_loss: 0.3077 - val_acc: 0.9027\n",
      "Epoch 264/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2670 - acc: 0.9122 - val_loss: 0.2919 - val_acc: 0.9008\n",
      "Epoch 265/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2639 - acc: 0.9137 - val_loss: 0.2935 - val_acc: 0.9034\n",
      "Epoch 266/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2640 - acc: 0.9117 - val_loss: 0.2969 - val_acc: 0.9008\n",
      "Epoch 267/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2615 - acc: 0.9149 - val_loss: 0.2895 - val_acc: 0.9024\n",
      "Epoch 268/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2618 - acc: 0.9138 - val_loss: 0.2889 - val_acc: 0.8998\n",
      "Epoch 269/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2615 - acc: 0.9142 - val_loss: 0.2896 - val_acc: 0.9017\n",
      "Epoch 270/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2583 - acc: 0.9152 - val_loss: 0.2870 - val_acc: 0.9030\n",
      "Epoch 271/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2603 - acc: 0.9141 - val_loss: 0.2904 - val_acc: 0.8998\n",
      "Epoch 272/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2581 - acc: 0.9135 - val_loss: 0.2881 - val_acc: 0.9011\n",
      "Epoch 273/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2601 - acc: 0.9137 - val_loss: 0.2918 - val_acc: 0.9024\n",
      "Epoch 274/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2635 - acc: 0.9141 - val_loss: 0.2992 - val_acc: 0.9005\n",
      "Epoch 275/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2610 - acc: 0.9120 - val_loss: 0.2938 - val_acc: 0.9017\n",
      "Epoch 276/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2646 - acc: 0.9130 - val_loss: 0.2888 - val_acc: 0.9005\n",
      "Epoch 277/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2634 - acc: 0.9133 - val_loss: 0.2880 - val_acc: 0.9011\n",
      "Epoch 278/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2585 - acc: 0.9138 - val_loss: 0.2899 - val_acc: 0.9024\n",
      "Epoch 279/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2611 - acc: 0.9131 - val_loss: 0.2892 - val_acc: 0.9017\n",
      "Epoch 280/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2625 - acc: 0.9140 - val_loss: 0.2902 - val_acc: 0.9017\n",
      "Epoch 281/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2596 - acc: 0.9144 - val_loss: 0.2927 - val_acc: 0.9008\n",
      "Epoch 282/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2614 - acc: 0.9140 - val_loss: 0.2925 - val_acc: 0.9001\n",
      "Epoch 283/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2581 - acc: 0.9141 - val_loss: 0.2927 - val_acc: 0.9001\n",
      "Epoch 284/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2603 - acc: 0.9137 - val_loss: 0.2923 - val_acc: 0.9017\n",
      "Epoch 285/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2647 - acc: 0.9113 - val_loss: 0.2908 - val_acc: 0.9017\n",
      "Epoch 286/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2589 - acc: 0.9137 - val_loss: 0.2889 - val_acc: 0.9017\n",
      "Epoch 287/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2706 - acc: 0.9137 - val_loss: 0.2948 - val_acc: 0.9014\n",
      "Epoch 288/500\n",
      "7217/7217 [==============================] - 0s 32us/step - loss: 0.2648 - acc: 0.9123 - val_loss: 0.2851 - val_acc: 0.9024\n",
      "Epoch 289/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2607 - acc: 0.9138 - val_loss: 0.2889 - val_acc: 0.9017\n",
      "Epoch 290/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.2562 - acc: 0.9138 - val_loss: 0.2935 - val_acc: 0.9008\n",
      "Epoch 291/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2604 - acc: 0.9130 - val_loss: 0.2943 - val_acc: 0.9005\n",
      "Epoch 292/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2621 - acc: 0.9144 - val_loss: 0.2828 - val_acc: 0.9005\n",
      "Epoch 293/500\n",
      "7217/7217 [==============================] - 0s 29us/step - loss: 0.2566 - acc: 0.9141 - val_loss: 0.2863 - val_acc: 0.9021\n",
      "Epoch 294/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2569 - acc: 0.9155 - val_loss: 0.2929 - val_acc: 0.9027\n",
      "Epoch 295/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2572 - acc: 0.9134 - val_loss: 0.2870 - val_acc: 0.9027\n",
      "Epoch 296/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2600 - acc: 0.9117 - val_loss: 0.2887 - val_acc: 0.9005\n",
      "Epoch 297/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2614 - acc: 0.9128 - val_loss: 0.2913 - val_acc: 0.9005\n",
      "Epoch 298/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2597 - acc: 0.9127 - val_loss: 0.2870 - val_acc: 0.9011\n",
      "Epoch 299/500\n",
      "7217/7217 [==============================] - 0s 27us/step - loss: 0.2570 - acc: 0.9141 - val_loss: 0.2938 - val_acc: 0.9008\n",
      "Epoch 300/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.2561 - acc: 0.9133 - val_loss: 0.2881 - val_acc: 0.9008\n",
      "Epoch 301/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2565 - acc: 0.9142 - val_loss: 0.2869 - val_acc: 0.9017\n",
      "Epoch 302/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2565 - acc: 0.9130 - val_loss: 0.2845 - val_acc: 0.9024\n",
      "Epoch 303/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2551 - acc: 0.9151 - val_loss: 0.2945 - val_acc: 0.9034\n",
      "Epoch 304/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.2604 - acc: 0.9127 - val_loss: 0.2847 - val_acc: 0.9017\n",
      "Epoch 305/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2561 - acc: 0.9131 - val_loss: 0.2888 - val_acc: 0.8998\n",
      "Epoch 306/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2573 - acc: 0.9134 - val_loss: 0.2902 - val_acc: 0.8998\n",
      "Epoch 307/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2563 - acc: 0.9135 - val_loss: 0.2890 - val_acc: 0.9005\n",
      "Epoch 308/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2625 - acc: 0.9137 - val_loss: 0.2931 - val_acc: 0.9011\n",
      "Epoch 309/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2613 - acc: 0.9135 - val_loss: 0.2887 - val_acc: 0.8995\n",
      "Epoch 310/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2560 - acc: 0.9134 - val_loss: 0.2924 - val_acc: 0.8992\n",
      "Epoch 311/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2636 - acc: 0.9127 - val_loss: 0.3014 - val_acc: 0.8998\n",
      "Epoch 312/500\n",
      "7217/7217 [==============================] - 0s 26us/step - loss: 0.2622 - acc: 0.9133 - val_loss: 0.2897 - val_acc: 0.9034\n",
      "Epoch 313/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2597 - acc: 0.9127 - val_loss: 0.2899 - val_acc: 0.8985\n",
      "Epoch 314/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2584 - acc: 0.9124 - val_loss: 0.2868 - val_acc: 0.9017\n",
      "Epoch 315/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2550 - acc: 0.9142 - val_loss: 0.2891 - val_acc: 0.9014\n",
      "Epoch 316/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2563 - acc: 0.9146 - val_loss: 0.2902 - val_acc: 0.8992\n",
      "Epoch 317/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2554 - acc: 0.9153 - val_loss: 0.2944 - val_acc: 0.8995\n",
      "Epoch 318/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2565 - acc: 0.9141 - val_loss: 0.3022 - val_acc: 0.9027\n",
      "Epoch 319/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2607 - acc: 0.9137 - val_loss: 0.2919 - val_acc: 0.9037\n",
      "Epoch 320/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2580 - acc: 0.9131 - val_loss: 0.2873 - val_acc: 0.9011\n",
      "Epoch 321/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2550 - acc: 0.9140 - val_loss: 0.2939 - val_acc: 0.8998\n",
      "Epoch 322/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2584 - acc: 0.9145 - val_loss: 0.2851 - val_acc: 0.9014\n",
      "Epoch 323/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2540 - acc: 0.9146 - val_loss: 0.2900 - val_acc: 0.9011\n",
      "Epoch 324/500\n",
      "7217/7217 [==============================] - 0s 26us/step - loss: 0.2577 - acc: 0.9133 - val_loss: 0.2884 - val_acc: 0.9001\n",
      "Epoch 325/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2575 - acc: 0.9135 - val_loss: 0.2887 - val_acc: 0.9014\n",
      "Epoch 326/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2567 - acc: 0.9141 - val_loss: 0.2906 - val_acc: 0.8995\n",
      "Epoch 327/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2557 - acc: 0.9134 - val_loss: 0.2896 - val_acc: 0.9005\n",
      "Epoch 328/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2556 - acc: 0.9141 - val_loss: 0.2900 - val_acc: 0.9014\n",
      "Epoch 329/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2568 - acc: 0.9144 - val_loss: 0.2890 - val_acc: 0.9008\n",
      "Epoch 330/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2563 - acc: 0.9137 - val_loss: 0.2965 - val_acc: 0.9011\n",
      "Epoch 331/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2577 - acc: 0.9138 - val_loss: 0.2875 - val_acc: 0.9024\n",
      "Epoch 332/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2563 - acc: 0.9140 - val_loss: 0.2892 - val_acc: 0.9017\n",
      "Epoch 333/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2573 - acc: 0.9144 - val_loss: 0.2904 - val_acc: 0.9008\n",
      "Epoch 334/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2564 - acc: 0.9148 - val_loss: 0.2964 - val_acc: 0.8988\n",
      "Epoch 335/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2560 - acc: 0.9131 - val_loss: 0.2859 - val_acc: 0.9017\n",
      "Epoch 336/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2560 - acc: 0.9144 - val_loss: 0.2988 - val_acc: 0.9017\n",
      "Epoch 337/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2570 - acc: 0.9140 - val_loss: 0.2873 - val_acc: 0.9014\n",
      "Epoch 338/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2569 - acc: 0.9126 - val_loss: 0.2836 - val_acc: 0.8998\n",
      "Epoch 339/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2535 - acc: 0.9149 - val_loss: 0.2894 - val_acc: 0.9001\n",
      "Epoch 340/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2537 - acc: 0.9142 - val_loss: 0.2918 - val_acc: 0.9001\n",
      "Epoch 341/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2568 - acc: 0.9127 - val_loss: 0.2831 - val_acc: 0.9021\n",
      "Epoch 342/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2559 - acc: 0.9137 - val_loss: 0.2902 - val_acc: 0.9008\n",
      "Epoch 343/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2574 - acc: 0.9131 - val_loss: 0.2881 - val_acc: 0.9014\n",
      "Epoch 344/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2539 - acc: 0.9144 - val_loss: 0.2848 - val_acc: 0.9024\n",
      "Epoch 345/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2539 - acc: 0.9155 - val_loss: 0.2892 - val_acc: 0.9024\n",
      "Epoch 346/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2581 - acc: 0.9135 - val_loss: 0.2904 - val_acc: 0.9027\n",
      "Epoch 347/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2556 - acc: 0.9130 - val_loss: 0.2872 - val_acc: 0.9017\n",
      "Epoch 348/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2578 - acc: 0.9133 - val_loss: 0.2836 - val_acc: 0.9030\n",
      "Epoch 349/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2609 - acc: 0.9135 - val_loss: 0.2900 - val_acc: 0.9021\n",
      "Epoch 350/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2576 - acc: 0.9137 - val_loss: 0.3027 - val_acc: 0.9005\n",
      "Epoch 351/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2570 - acc: 0.9130 - val_loss: 0.2860 - val_acc: 0.9021\n",
      "Epoch 352/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2566 - acc: 0.9138 - val_loss: 0.2907 - val_acc: 0.9014\n",
      "Epoch 353/500\n",
      "7217/7217 [==============================] - 0s 13us/step - loss: 0.2617 - acc: 0.9122 - val_loss: 0.2855 - val_acc: 0.9030\n",
      "Epoch 354/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2536 - acc: 0.9153 - val_loss: 0.2896 - val_acc: 0.9027\n",
      "Epoch 355/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2536 - acc: 0.9144 - val_loss: 0.2852 - val_acc: 0.9027\n",
      "Epoch 356/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2562 - acc: 0.9134 - val_loss: 0.2917 - val_acc: 0.8998\n",
      "Epoch 357/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.2536 - acc: 0.9137 - val_loss: 0.2935 - val_acc: 0.9021\n",
      "Epoch 358/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2532 - acc: 0.9141 - val_loss: 0.2996 - val_acc: 0.9001\n",
      "Epoch 359/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2561 - acc: 0.9124 - val_loss: 0.2908 - val_acc: 0.8998\n",
      "Epoch 360/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2563 - acc: 0.9127 - val_loss: 0.2907 - val_acc: 0.9001\n",
      "Epoch 361/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2536 - acc: 0.9140 - val_loss: 0.2904 - val_acc: 0.9024\n",
      "Epoch 362/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2545 - acc: 0.9146 - val_loss: 0.2939 - val_acc: 0.9017\n",
      "Epoch 363/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2544 - acc: 0.9137 - val_loss: 0.2952 - val_acc: 0.9008\n",
      "Epoch 364/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2570 - acc: 0.9134 - val_loss: 0.2858 - val_acc: 0.9024\n",
      "Epoch 365/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2526 - acc: 0.9163 - val_loss: 0.2912 - val_acc: 0.9017\n",
      "Epoch 366/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2540 - acc: 0.9138 - val_loss: 0.2909 - val_acc: 0.9005\n",
      "Epoch 367/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2589 - acc: 0.9135 - val_loss: 0.3013 - val_acc: 0.9024\n",
      "Epoch 368/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2553 - acc: 0.9133 - val_loss: 0.2890 - val_acc: 0.9017\n",
      "Epoch 369/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.2526 - acc: 0.9146 - val_loss: 0.2997 - val_acc: 0.9011\n",
      "Epoch 370/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2547 - acc: 0.9131 - val_loss: 0.2904 - val_acc: 0.9005\n",
      "Epoch 371/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2524 - acc: 0.9146 - val_loss: 0.2883 - val_acc: 0.8998\n",
      "Epoch 372/500\n",
      "7217/7217 [==============================] - ETA: 0s - loss: 0.2520 - acc: 0.913 - 0s 18us/step - loss: 0.2530 - acc: 0.9134 - val_loss: 0.2904 - val_acc: 0.9014\n",
      "Epoch 373/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2533 - acc: 0.9145 - val_loss: 0.2907 - val_acc: 0.9008\n",
      "Epoch 374/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2520 - acc: 0.9138 - val_loss: 0.2904 - val_acc: 0.9005\n",
      "Epoch 375/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2524 - acc: 0.9141 - val_loss: 0.2964 - val_acc: 0.9001\n",
      "Epoch 376/500\n",
      "7217/7217 [==============================] - 0s 13us/step - loss: 0.2529 - acc: 0.9148 - val_loss: 0.2905 - val_acc: 0.9014\n",
      "Epoch 377/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2551 - acc: 0.9142 - val_loss: 0.3081 - val_acc: 0.9027\n",
      "Epoch 378/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2558 - acc: 0.9142 - val_loss: 0.2903 - val_acc: 0.9005\n",
      "Epoch 379/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2548 - acc: 0.9138 - val_loss: 0.2987 - val_acc: 0.9005\n",
      "Epoch 380/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2541 - acc: 0.9138 - val_loss: 0.2904 - val_acc: 0.9008\n",
      "Epoch 381/500\n",
      "7217/7217 [==============================] - 0s 26us/step - loss: 0.2540 - acc: 0.9155 - val_loss: 0.2880 - val_acc: 0.9008\n",
      "Epoch 382/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2554 - acc: 0.9133 - val_loss: 0.2889 - val_acc: 0.9011\n",
      "Epoch 383/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2579 - acc: 0.9134 - val_loss: 0.2886 - val_acc: 0.9030\n",
      "Epoch 384/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2553 - acc: 0.9119 - val_loss: 0.2884 - val_acc: 0.9011\n",
      "Epoch 385/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2529 - acc: 0.9148 - val_loss: 0.2918 - val_acc: 0.9027\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2534 - acc: 0.9142 - val_loss: 0.2871 - val_acc: 0.9005\n",
      "Epoch 387/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2533 - acc: 0.9145 - val_loss: 0.3005 - val_acc: 0.9011\n",
      "Epoch 388/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2517 - acc: 0.9144 - val_loss: 0.2889 - val_acc: 0.9001\n",
      "Epoch 389/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2521 - acc: 0.9142 - val_loss: 0.2973 - val_acc: 0.9014\n",
      "Epoch 390/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2526 - acc: 0.9137 - val_loss: 0.2927 - val_acc: 0.9040\n",
      "Epoch 391/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2507 - acc: 0.9148 - val_loss: 0.2912 - val_acc: 0.8995\n",
      "Epoch 392/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2529 - acc: 0.9133 - val_loss: 0.2934 - val_acc: 0.9021\n",
      "Epoch 393/500\n",
      "7217/7217 [==============================] - 0s 26us/step - loss: 0.2542 - acc: 0.9137 - val_loss: 0.3065 - val_acc: 0.9011\n",
      "Epoch 394/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2551 - acc: 0.9140 - val_loss: 0.2910 - val_acc: 0.9034\n",
      "Epoch 395/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2542 - acc: 0.9140 - val_loss: 0.2922 - val_acc: 0.9017\n",
      "Epoch 396/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2541 - acc: 0.9142 - val_loss: 0.2894 - val_acc: 0.9008\n",
      "Epoch 397/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2516 - acc: 0.9138 - val_loss: 0.3009 - val_acc: 0.9005\n",
      "Epoch 398/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2577 - acc: 0.9152 - val_loss: 0.2966 - val_acc: 0.8988\n",
      "Epoch 399/500\n",
      "7217/7217 [==============================] - 0s 13us/step - loss: 0.2545 - acc: 0.9134 - val_loss: 0.2988 - val_acc: 0.9011\n",
      "Epoch 400/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2533 - acc: 0.9142 - val_loss: 0.2973 - val_acc: 0.8998\n",
      "Epoch 401/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2550 - acc: 0.9127 - val_loss: 0.2870 - val_acc: 0.9030\n",
      "Epoch 402/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2538 - acc: 0.9140 - val_loss: 0.2899 - val_acc: 0.9011\n",
      "Epoch 403/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2524 - acc: 0.9148 - val_loss: 0.2882 - val_acc: 0.9017\n",
      "Epoch 404/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2518 - acc: 0.9155 - val_loss: 0.2951 - val_acc: 0.9011\n",
      "Epoch 405/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2520 - acc: 0.9153 - val_loss: 0.2894 - val_acc: 0.9011\n",
      "Epoch 406/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2511 - acc: 0.9137 - val_loss: 0.2932 - val_acc: 0.9021\n",
      "Epoch 407/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2524 - acc: 0.9148 - val_loss: 0.2984 - val_acc: 0.9021\n",
      "Epoch 408/500\n",
      "7217/7217 [==============================] - ETA: 0s - loss: 0.2542 - acc: 0.914 - 0s 14us/step - loss: 0.2528 - acc: 0.9144 - val_loss: 0.2935 - val_acc: 0.9014\n",
      "Epoch 409/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2518 - acc: 0.9153 - val_loss: 0.2946 - val_acc: 0.8998\n",
      "Epoch 410/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2515 - acc: 0.9156 - val_loss: 0.2932 - val_acc: 0.9005\n",
      "Epoch 411/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2567 - acc: 0.9141 - val_loss: 0.2939 - val_acc: 0.9027\n",
      "Epoch 412/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2534 - acc: 0.9145 - val_loss: 0.2863 - val_acc: 0.9037\n",
      "Epoch 413/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2527 - acc: 0.9146 - val_loss: 0.2919 - val_acc: 0.9024\n",
      "Epoch 414/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2542 - acc: 0.9155 - val_loss: 0.2990 - val_acc: 0.9037\n",
      "Epoch 415/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2536 - acc: 0.9145 - val_loss: 0.2941 - val_acc: 0.8982\n",
      "Epoch 416/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2531 - acc: 0.9144 - val_loss: 0.3055 - val_acc: 0.8995\n",
      "Epoch 417/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2516 - acc: 0.9151 - val_loss: 0.2921 - val_acc: 0.8988\n",
      "Epoch 418/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2555 - acc: 0.9137 - val_loss: 0.2929 - val_acc: 0.9001\n",
      "Epoch 419/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2497 - acc: 0.9160 - val_loss: 0.2982 - val_acc: 0.9014\n",
      "Epoch 420/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2584 - acc: 0.9137 - val_loss: 0.2960 - val_acc: 0.9014\n",
      "Epoch 421/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2522 - acc: 0.9145 - val_loss: 0.3056 - val_acc: 0.9014\n",
      "Epoch 422/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2553 - acc: 0.9133 - val_loss: 0.2922 - val_acc: 0.9005\n",
      "Epoch 423/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2533 - acc: 0.9148 - val_loss: 0.2871 - val_acc: 0.9034\n",
      "Epoch 424/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2502 - acc: 0.9145 - val_loss: 0.2925 - val_acc: 0.8995\n",
      "Epoch 425/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2516 - acc: 0.9140 - val_loss: 0.2948 - val_acc: 0.9021\n",
      "Epoch 426/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2562 - acc: 0.9140 - val_loss: 0.2900 - val_acc: 0.9014\n",
      "Epoch 427/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2558 - acc: 0.9141 - val_loss: 0.2910 - val_acc: 0.9034\n",
      "Epoch 428/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2527 - acc: 0.9131 - val_loss: 0.2935 - val_acc: 0.9011\n",
      "Epoch 429/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2525 - acc: 0.9141 - val_loss: 0.2897 - val_acc: 0.9005\n",
      "Epoch 430/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2518 - acc: 0.9145 - val_loss: 0.2928 - val_acc: 0.9027\n",
      "Epoch 431/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2528 - acc: 0.9134 - val_loss: 0.2983 - val_acc: 0.9014\n",
      "Epoch 432/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2536 - acc: 0.9145 - val_loss: 0.2875 - val_acc: 0.9037\n",
      "Epoch 433/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2506 - acc: 0.9145 - val_loss: 0.2904 - val_acc: 0.9017\n",
      "Epoch 434/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2526 - acc: 0.9158 - val_loss: 0.2952 - val_acc: 0.9005\n",
      "Epoch 435/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2524 - acc: 0.9141 - val_loss: 0.2915 - val_acc: 0.9005\n",
      "Epoch 436/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2510 - acc: 0.9153 - val_loss: 0.2932 - val_acc: 0.9011\n",
      "Epoch 437/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2526 - acc: 0.9146 - val_loss: 0.2923 - val_acc: 0.8995\n",
      "Epoch 438/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2525 - acc: 0.9131 - val_loss: 0.3126 - val_acc: 0.9014\n",
      "Epoch 439/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2536 - acc: 0.9146 - val_loss: 0.2896 - val_acc: 0.9034\n",
      "Epoch 440/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2505 - acc: 0.9146 - val_loss: 0.2951 - val_acc: 0.8998\n",
      "Epoch 441/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2511 - acc: 0.9164 - val_loss: 0.3019 - val_acc: 0.9017\n",
      "Epoch 442/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2519 - acc: 0.9151 - val_loss: 0.2958 - val_acc: 0.9008\n",
      "Epoch 443/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2510 - acc: 0.9152 - val_loss: 0.2924 - val_acc: 0.8985\n",
      "Epoch 444/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2514 - acc: 0.9152 - val_loss: 0.2937 - val_acc: 0.8992\n",
      "Epoch 445/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2513 - acc: 0.9148 - val_loss: 0.2907 - val_acc: 0.9011\n",
      "Epoch 446/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2496 - acc: 0.9145 - val_loss: 0.2980 - val_acc: 0.9017\n",
      "Epoch 447/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2506 - acc: 0.9153 - val_loss: 0.2956 - val_acc: 0.9014\n",
      "Epoch 448/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2515 - acc: 0.9138 - val_loss: 0.2980 - val_acc: 0.9008\n",
      "Epoch 449/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2546 - acc: 0.9158 - val_loss: 0.2952 - val_acc: 0.9005\n",
      "Epoch 450/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2514 - acc: 0.9156 - val_loss: 0.2912 - val_acc: 0.9024\n",
      "Epoch 451/500\n",
      "7217/7217 [==============================] - 0s 26us/step - loss: 0.2509 - acc: 0.9158 - val_loss: 0.3341 - val_acc: 0.8982\n",
      "Epoch 452/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.2545 - acc: 0.9151 - val_loss: 0.2960 - val_acc: 0.9008\n",
      "Epoch 453/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2508 - acc: 0.9148 - val_loss: 0.2904 - val_acc: 0.9017\n",
      "Epoch 454/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2502 - acc: 0.9153 - val_loss: 0.2929 - val_acc: 0.9017\n",
      "Epoch 455/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2505 - acc: 0.9164 - val_loss: 0.2940 - val_acc: 0.9011\n",
      "Epoch 456/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2505 - acc: 0.9153 - val_loss: 0.2970 - val_acc: 0.9024\n",
      "Epoch 457/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2531 - acc: 0.9145 - val_loss: 0.2918 - val_acc: 0.9005\n",
      "Epoch 458/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2535 - acc: 0.9155 - val_loss: 0.2930 - val_acc: 0.9021\n",
      "Epoch 459/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2492 - acc: 0.9158 - val_loss: 0.3012 - val_acc: 0.9005\n",
      "Epoch 460/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.2526 - acc: 0.9145 - val_loss: 0.2940 - val_acc: 0.9021\n",
      "Epoch 461/500\n",
      "7217/7217 [==============================] - 0s 30us/step - loss: 0.2544 - acc: 0.9145 - val_loss: 0.2904 - val_acc: 0.9043\n",
      "Epoch 462/500\n",
      "7217/7217 [==============================] - 0s 28us/step - loss: 0.2505 - acc: 0.9149 - val_loss: 0.2862 - val_acc: 0.9014\n",
      "Epoch 463/500\n",
      "7217/7217 [==============================] - 0s 26us/step - loss: 0.2512 - acc: 0.9155 - val_loss: 0.2971 - val_acc: 0.9024\n",
      "Epoch 464/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2551 - acc: 0.9134 - val_loss: 0.2959 - val_acc: 0.9011\n",
      "Epoch 465/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2525 - acc: 0.9138 - val_loss: 0.2934 - val_acc: 0.9021\n",
      "Epoch 466/500\n",
      "7217/7217 [==============================] - 0s 14us/step - loss: 0.2555 - acc: 0.9140 - val_loss: 0.2959 - val_acc: 0.9030\n",
      "Epoch 467/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2524 - acc: 0.9151 - val_loss: 0.2919 - val_acc: 0.9001\n",
      "Epoch 468/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2500 - acc: 0.9142 - val_loss: 0.2971 - val_acc: 0.9005\n",
      "Epoch 469/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2491 - acc: 0.9159 - val_loss: 0.2954 - val_acc: 0.9005\n",
      "Epoch 470/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2494 - acc: 0.9145 - val_loss: 0.2933 - val_acc: 0.9005\n",
      "Epoch 471/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2495 - acc: 0.9155 - val_loss: 0.2965 - val_acc: 0.9017\n",
      "Epoch 472/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2507 - acc: 0.9155 - val_loss: 0.2970 - val_acc: 0.9021\n",
      "Epoch 473/500\n",
      "7217/7217 [==============================] - 0s 26us/step - loss: 0.2494 - acc: 0.9164 - val_loss: 0.2907 - val_acc: 0.9037\n",
      "Epoch 474/500\n",
      "7217/7217 [==============================] - 0s 25us/step - loss: 0.2503 - acc: 0.9144 - val_loss: 0.3004 - val_acc: 0.9034\n",
      "Epoch 475/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2549 - acc: 0.9151 - val_loss: 0.3015 - val_acc: 0.9005\n",
      "Epoch 476/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2517 - acc: 0.9155 - val_loss: 0.2908 - val_acc: 0.9011\n",
      "Epoch 477/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2496 - acc: 0.9160 - val_loss: 0.2911 - val_acc: 0.9027\n",
      "Epoch 478/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2511 - acc: 0.9162 - val_loss: 0.2971 - val_acc: 0.8992\n",
      "Epoch 479/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2515 - acc: 0.9158 - val_loss: 0.2933 - val_acc: 0.9043\n",
      "Epoch 480/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2511 - acc: 0.9153 - val_loss: 0.2900 - val_acc: 0.9024\n",
      "Epoch 481/500\n",
      "7217/7217 [==============================] - 0s 13us/step - loss: 0.2496 - acc: 0.9151 - val_loss: 0.2938 - val_acc: 0.8998\n",
      "Epoch 482/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2477 - acc: 0.9158 - val_loss: 0.2930 - val_acc: 0.9034\n",
      "Epoch 483/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2490 - acc: 0.9145 - val_loss: 0.3036 - val_acc: 0.9037\n",
      "Epoch 484/500\n",
      "7217/7217 [==============================] - 0s 21us/step - loss: 0.2514 - acc: 0.9153 - val_loss: 0.2870 - val_acc: 0.9017\n",
      "Epoch 485/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2499 - acc: 0.9151 - val_loss: 0.2874 - val_acc: 0.9021\n",
      "Epoch 486/500\n",
      "7217/7217 [==============================] - 0s 26us/step - loss: 0.2487 - acc: 0.9156 - val_loss: 0.2908 - val_acc: 0.9021\n",
      "Epoch 487/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2537 - acc: 0.9144 - val_loss: 0.2880 - val_acc: 0.9011\n",
      "Epoch 488/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2494 - acc: 0.9162 - val_loss: 0.2906 - val_acc: 0.9037\n",
      "Epoch 489/500\n",
      "7217/7217 [==============================] - 0s 18us/step - loss: 0.2514 - acc: 0.9151 - val_loss: 0.2909 - val_acc: 0.9014\n",
      "Epoch 490/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2485 - acc: 0.9166 - val_loss: 0.2890 - val_acc: 0.9024\n",
      "Epoch 491/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2482 - acc: 0.9164 - val_loss: 0.2903 - val_acc: 0.9030\n",
      "Epoch 492/500\n",
      "7217/7217 [==============================] - 0s 15us/step - loss: 0.2473 - acc: 0.9174 - val_loss: 0.2952 - val_acc: 0.9040\n",
      "Epoch 493/500\n",
      "7217/7217 [==============================] - 0s 16us/step - loss: 0.2480 - acc: 0.9163 - val_loss: 0.3003 - val_acc: 0.9021\n",
      "Epoch 494/500\n",
      "7217/7217 [==============================] - 0s 17us/step - loss: 0.2517 - acc: 0.9155 - val_loss: 0.2955 - val_acc: 0.9021\n",
      "Epoch 495/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2487 - acc: 0.9169 - val_loss: 0.2929 - val_acc: 0.9024\n",
      "Epoch 496/500\n",
      "7217/7217 [==============================] - 0s 22us/step - loss: 0.2533 - acc: 0.9148 - val_loss: 0.2946 - val_acc: 0.9037\n",
      "Epoch 497/500\n",
      "7217/7217 [==============================] - 0s 24us/step - loss: 0.2506 - acc: 0.9149 - val_loss: 0.2898 - val_acc: 0.9027\n",
      "Epoch 498/500\n",
      "7217/7217 [==============================] - 0s 23us/step - loss: 0.2495 - acc: 0.9162 - val_loss: 0.2994 - val_acc: 0.9014\n",
      "Epoch 499/500\n",
      "7217/7217 [==============================] - 0s 20us/step - loss: 0.2484 - acc: 0.9153 - val_loss: 0.2908 - val_acc: 0.9017\n",
      "Epoch 500/500\n",
      "7217/7217 [==============================] - 0s 19us/step - loss: 0.2540 - acc: 0.9152 - val_loss: 0.2912 - val_acc: 0.9024\n",
      "3094/3094 [==============================] - 0s 4us/step\n",
      "25 101 403 403 12494 9824 101 1093 992\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "9824 9824\n",
      "../linkPrediction/dataframes/apnea\n",
      "article (9824, 7, 11) --------------------------------------------------------------------\n",
      "(9824, 11) (9824,)\n",
      "[9824, 11, 1]\n",
      "(6876, 11) (6876,)\n",
      "Train on 6876 samples, validate on 2948 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.8350 - acc: 0.8547 - val_loss: 0.7155 - val_acc: 0.8935\n",
      "Epoch 2/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.6527 - acc: 0.8960 - val_loss: 0.6591 - val_acc: 0.8918\n",
      "Epoch 3/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.6116 - acc: 0.9049 - val_loss: 0.6350 - val_acc: 0.8989\n",
      "Epoch 4/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.6148 - acc: 0.8994 - val_loss: 0.5396 - val_acc: 0.8901\n",
      "Epoch 5/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.5541 - acc: 0.9066 - val_loss: 0.5610 - val_acc: 0.9026\n",
      "Epoch 6/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.4969 - acc: 0.9094 - val_loss: 0.5071 - val_acc: 0.8938\n",
      "Epoch 7/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.5472 - acc: 0.8982 - val_loss: 0.4970 - val_acc: 0.9047\n",
      "Epoch 8/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.4916 - acc: 0.9084 - val_loss: 0.5225 - val_acc: 0.9098\n",
      "Epoch 9/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.5189 - acc: 0.9049 - val_loss: 0.5233 - val_acc: 0.9006\n",
      "Epoch 10/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.5050 - acc: 0.9050 - val_loss: 0.5232 - val_acc: 0.9118\n",
      "Epoch 11/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.4510 - acc: 0.9104 - val_loss: 0.4678 - val_acc: 0.9030\n",
      "Epoch 12/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.4739 - acc: 0.9045 - val_loss: 0.4466 - val_acc: 0.9081\n",
      "Epoch 13/500\n",
      "6876/6876 [==============================] - 0s 13us/step - loss: 0.5269 - acc: 0.9004 - val_loss: 0.4991 - val_acc: 0.9023\n",
      "Epoch 14/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.4985 - acc: 0.9092 - val_loss: 0.4855 - val_acc: 0.9081\n",
      "Epoch 15/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.4646 - acc: 0.9095 - val_loss: 0.4885 - val_acc: 0.9108\n",
      "Epoch 16/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.4204 - acc: 0.9090 - val_loss: 0.5049 - val_acc: 0.9064\n",
      "Epoch 17/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.4605 - acc: 0.9113 - val_loss: 0.5266 - val_acc: 0.9064\n",
      "Epoch 18/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.4640 - acc: 0.9095 - val_loss: 0.4456 - val_acc: 0.9040\n",
      "Epoch 19/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.4383 - acc: 0.9043 - val_loss: 0.4913 - val_acc: 0.9020\n",
      "Epoch 20/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.4704 - acc: 0.9094 - val_loss: 0.4574 - val_acc: 0.9088\n",
      "Epoch 21/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.4758 - acc: 0.9063 - val_loss: 0.4508 - val_acc: 0.9088\n",
      "Epoch 22/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.4441 - acc: 0.9082 - val_loss: 0.4895 - val_acc: 0.9088\n",
      "Epoch 23/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.4374 - acc: 0.9078 - val_loss: 0.5003 - val_acc: 0.9054\n",
      "Epoch 24/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.4128 - acc: 0.9101 - val_loss: 0.4205 - val_acc: 0.9067\n",
      "Epoch 25/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.4345 - acc: 0.9072 - val_loss: 0.4929 - val_acc: 0.9121\n",
      "Epoch 26/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.4195 - acc: 0.9058 - val_loss: 0.4448 - val_acc: 0.9006\n",
      "Epoch 27/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.4006 - acc: 0.9066 - val_loss: 0.4066 - val_acc: 0.9101\n",
      "Epoch 28/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.3849 - acc: 0.9119 - val_loss: 0.4871 - val_acc: 0.8986\n",
      "Epoch 29/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.4260 - acc: 0.9078 - val_loss: 0.4567 - val_acc: 0.9020\n",
      "Epoch 30/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.4330 - acc: 0.9111 - val_loss: 0.4335 - val_acc: 0.9091\n",
      "Epoch 31/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.4690 - acc: 0.9079 - val_loss: 0.4798 - val_acc: 0.8976\n",
      "Epoch 32/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.4045 - acc: 0.9063 - val_loss: 0.4450 - val_acc: 0.9020\n",
      "Epoch 33/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.4053 - acc: 0.9092 - val_loss: 0.4146 - val_acc: 0.9043\n",
      "Epoch 34/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.3943 - acc: 0.9065 - val_loss: 0.4104 - val_acc: 0.9054\n",
      "Epoch 35/500\n",
      "6876/6876 [==============================] - 0s 25us/step - loss: 0.4304 - acc: 0.8997 - val_loss: 0.4352 - val_acc: 0.9054\n",
      "Epoch 36/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.3929 - acc: 0.9095 - val_loss: 0.4197 - val_acc: 0.9077\n",
      "Epoch 37/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.4166 - acc: 0.9116 - val_loss: 0.4060 - val_acc: 0.9081\n",
      "Epoch 38/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.4014 - acc: 0.9088 - val_loss: 0.4900 - val_acc: 0.8945\n",
      "Epoch 39/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.3904 - acc: 0.9084 - val_loss: 0.4866 - val_acc: 0.9026\n",
      "Epoch 40/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.3808 - acc: 0.9098 - val_loss: 0.4209 - val_acc: 0.9020\n",
      "Epoch 41/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.4363 - acc: 0.8978 - val_loss: 0.4169 - val_acc: 0.9064\n",
      "Epoch 42/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.3867 - acc: 0.9106 - val_loss: 0.4072 - val_acc: 0.9081\n",
      "Epoch 43/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.4013 - acc: 0.9075 - val_loss: 0.4059 - val_acc: 0.9091\n",
      "Epoch 44/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.3891 - acc: 0.9075 - val_loss: 0.4361 - val_acc: 0.9115\n",
      "Epoch 45/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.3840 - acc: 0.9082 - val_loss: 0.4133 - val_acc: 0.9060\n",
      "Epoch 46/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.3704 - acc: 0.9092 - val_loss: 0.4042 - val_acc: 0.9091\n",
      "Epoch 47/500\n",
      "6876/6876 [==============================] - 0s 32us/step - loss: 0.4115 - acc: 0.9059 - val_loss: 0.4295 - val_acc: 0.9037\n",
      "Epoch 48/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.4031 - acc: 0.9124 - val_loss: 0.4491 - val_acc: 0.9088\n",
      "Epoch 49/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.3835 - acc: 0.9081 - val_loss: 0.4471 - val_acc: 0.9020\n",
      "Epoch 50/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.3855 - acc: 0.9090 - val_loss: 0.3803 - val_acc: 0.9094\n",
      "Epoch 51/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.4525 - acc: 0.8930 - val_loss: 0.3896 - val_acc: 0.9074\n",
      "Epoch 52/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.3265 - acc: 0.9142 - val_loss: 0.3825 - val_acc: 0.9057\n",
      "Epoch 53/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.3381 - acc: 0.9113 - val_loss: 0.3705 - val_acc: 0.9098\n",
      "Epoch 54/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.3536 - acc: 0.9110 - val_loss: 0.4524 - val_acc: 0.9088\n",
      "Epoch 55/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.3834 - acc: 0.9061 - val_loss: 0.3835 - val_acc: 0.9128\n",
      "Epoch 56/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.3442 - acc: 0.9123 - val_loss: 0.5029 - val_acc: 0.8925\n",
      "Epoch 57/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.3772 - acc: 0.9088 - val_loss: 0.3889 - val_acc: 0.9111\n",
      "Epoch 58/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.3304 - acc: 0.9126 - val_loss: 0.3654 - val_acc: 0.9108\n",
      "Epoch 59/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.3370 - acc: 0.9117 - val_loss: 0.3844 - val_acc: 0.8996\n",
      "Epoch 60/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.3386 - acc: 0.9123 - val_loss: 0.3661 - val_acc: 0.9077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.3356 - acc: 0.9127 - val_loss: 0.4148 - val_acc: 0.9040\n",
      "Epoch 62/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.3615 - acc: 0.9132 - val_loss: 0.4185 - val_acc: 0.9009\n",
      "Epoch 63/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.3753 - acc: 0.9095 - val_loss: 0.4264 - val_acc: 0.9081\n",
      "Epoch 64/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.3775 - acc: 0.9114 - val_loss: 0.3898 - val_acc: 0.9067\n",
      "Epoch 65/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.3226 - acc: 0.9139 - val_loss: 0.3503 - val_acc: 0.9101\n",
      "Epoch 66/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.3310 - acc: 0.9140 - val_loss: 0.3730 - val_acc: 0.9043\n",
      "Epoch 67/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.3342 - acc: 0.9104 - val_loss: 0.4495 - val_acc: 0.9057\n",
      "Epoch 68/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.4505 - acc: 0.8951 - val_loss: 0.4056 - val_acc: 0.9067\n",
      "Epoch 69/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.3356 - acc: 0.9138 - val_loss: 0.3583 - val_acc: 0.9108\n",
      "Epoch 70/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.3308 - acc: 0.9126 - val_loss: 0.3928 - val_acc: 0.9104\n",
      "Epoch 71/500\n",
      "6876/6876 [==============================] - 0s 25us/step - loss: 0.3328 - acc: 0.9145 - val_loss: 0.3350 - val_acc: 0.9128\n",
      "Epoch 72/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.3129 - acc: 0.9142 - val_loss: 0.3776 - val_acc: 0.9101\n",
      "Epoch 73/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.3195 - acc: 0.9136 - val_loss: 0.3389 - val_acc: 0.9088\n",
      "Epoch 74/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.3393 - acc: 0.9085 - val_loss: 0.3983 - val_acc: 0.9016\n",
      "Epoch 75/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.3701 - acc: 0.9088 - val_loss: 0.3526 - val_acc: 0.9081\n",
      "Epoch 76/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.3637 - acc: 0.9098 - val_loss: 0.4268 - val_acc: 0.9077\n",
      "Epoch 77/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.3463 - acc: 0.9119 - val_loss: 0.3508 - val_acc: 0.9064\n",
      "Epoch 78/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.3252 - acc: 0.9127 - val_loss: 0.3606 - val_acc: 0.9071\n",
      "Epoch 79/500\n",
      "6876/6876 [==============================] - 0s 13us/step - loss: 0.3342 - acc: 0.9110 - val_loss: 0.3500 - val_acc: 0.9088\n",
      "Epoch 80/500\n",
      "6876/6876 [==============================] - 0s 13us/step - loss: 0.3273 - acc: 0.9142 - val_loss: 0.3975 - val_acc: 0.9125\n",
      "Epoch 81/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.3313 - acc: 0.9122 - val_loss: 0.4016 - val_acc: 0.9013\n",
      "Epoch 82/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.3465 - acc: 0.9108 - val_loss: 0.3615 - val_acc: 0.9098\n",
      "Epoch 83/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.3283 - acc: 0.9130 - val_loss: 0.3506 - val_acc: 0.9091\n",
      "Epoch 84/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.2961 - acc: 0.9152 - val_loss: 0.3386 - val_acc: 0.9104\n",
      "Epoch 85/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.3165 - acc: 0.9123 - val_loss: 0.3360 - val_acc: 0.9071\n",
      "Epoch 86/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.3644 - acc: 0.9065 - val_loss: 0.3424 - val_acc: 0.9101\n",
      "Epoch 87/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.3053 - acc: 0.9129 - val_loss: 0.3268 - val_acc: 0.9077\n",
      "Epoch 88/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.3380 - acc: 0.9107 - val_loss: 0.3670 - val_acc: 0.9098\n",
      "Epoch 89/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.3254 - acc: 0.9119 - val_loss: 0.3315 - val_acc: 0.9121\n",
      "Epoch 90/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.4149 - acc: 0.8979 - val_loss: 0.4113 - val_acc: 0.8955\n",
      "Epoch 91/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.3508 - acc: 0.9130 - val_loss: 0.3645 - val_acc: 0.9094\n",
      "Epoch 92/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.3191 - acc: 0.9133 - val_loss: 0.3547 - val_acc: 0.9088\n",
      "Epoch 93/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.3024 - acc: 0.9151 - val_loss: 0.3298 - val_acc: 0.9081\n",
      "Epoch 94/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2979 - acc: 0.9145 - val_loss: 0.3674 - val_acc: 0.9067\n",
      "Epoch 95/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.3103 - acc: 0.9132 - val_loss: 0.3686 - val_acc: 0.9098\n",
      "Epoch 96/500\n",
      "6876/6876 [==============================] - 0s 25us/step - loss: 0.3339 - acc: 0.9132 - val_loss: 0.3544 - val_acc: 0.9128\n",
      "Epoch 97/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.3237 - acc: 0.9132 - val_loss: 0.3228 - val_acc: 0.9098\n",
      "Epoch 98/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2974 - acc: 0.9142 - val_loss: 0.3287 - val_acc: 0.9077\n",
      "Epoch 99/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.3090 - acc: 0.9130 - val_loss: 0.3390 - val_acc: 0.9108\n",
      "Epoch 100/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.3653 - acc: 0.9135 - val_loss: 0.3863 - val_acc: 0.9094\n",
      "Epoch 101/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.3501 - acc: 0.9084 - val_loss: 0.3548 - val_acc: 0.9057\n",
      "Epoch 102/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.3342 - acc: 0.9120 - val_loss: 0.3574 - val_acc: 0.9118\n",
      "Epoch 103/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.3250 - acc: 0.9119 - val_loss: 0.3429 - val_acc: 0.9104\n",
      "Epoch 104/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.3127 - acc: 0.9145 - val_loss: 0.3401 - val_acc: 0.9118\n",
      "Epoch 105/500\n",
      "6876/6876 [==============================] - 0s 13us/step - loss: 0.3063 - acc: 0.9142 - val_loss: 0.3367 - val_acc: 0.9071\n",
      "Epoch 106/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2913 - acc: 0.9142 - val_loss: 0.3422 - val_acc: 0.9104\n",
      "Epoch 107/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2906 - acc: 0.9156 - val_loss: 0.3413 - val_acc: 0.9121\n",
      "Epoch 108/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.3133 - acc: 0.9136 - val_loss: 0.3646 - val_acc: 0.9060\n",
      "Epoch 109/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2933 - acc: 0.9138 - val_loss: 0.3488 - val_acc: 0.9037\n",
      "Epoch 110/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2977 - acc: 0.9132 - val_loss: 0.3729 - val_acc: 0.9077\n",
      "Epoch 111/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.3215 - acc: 0.9123 - val_loss: 0.3584 - val_acc: 0.9118\n",
      "Epoch 112/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.3397 - acc: 0.9124 - val_loss: 0.3468 - val_acc: 0.9071\n",
      "Epoch 113/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2989 - acc: 0.9156 - val_loss: 0.3278 - val_acc: 0.9077\n",
      "Epoch 114/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.3101 - acc: 0.9110 - val_loss: 0.3337 - val_acc: 0.9125\n",
      "Epoch 115/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2855 - acc: 0.9151 - val_loss: 0.3191 - val_acc: 0.9084\n",
      "Epoch 116/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2861 - acc: 0.9132 - val_loss: 0.3347 - val_acc: 0.9071\n",
      "Epoch 117/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.3472 - acc: 0.9135 - val_loss: 0.3649 - val_acc: 0.9111\n",
      "Epoch 118/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.3038 - acc: 0.9135 - val_loss: 0.3350 - val_acc: 0.9074\n",
      "Epoch 119/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2734 - acc: 0.9158 - val_loss: 0.3419 - val_acc: 0.9050\n",
      "Epoch 120/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.3257 - acc: 0.9085 - val_loss: 0.3321 - val_acc: 0.9115\n",
      "Epoch 121/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.2913 - acc: 0.9140 - val_loss: 0.3208 - val_acc: 0.9094\n",
      "Epoch 122/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2777 - acc: 0.9152 - val_loss: 0.3304 - val_acc: 0.9054\n",
      "Epoch 123/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2875 - acc: 0.9138 - val_loss: 0.3268 - val_acc: 0.9101\n",
      "Epoch 124/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2772 - acc: 0.9148 - val_loss: 0.3388 - val_acc: 0.9101\n",
      "Epoch 125/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.3036 - acc: 0.9129 - val_loss: 0.3189 - val_acc: 0.9111\n",
      "Epoch 126/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.2955 - acc: 0.9139 - val_loss: 0.3319 - val_acc: 0.9094\n",
      "Epoch 127/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2761 - acc: 0.9165 - val_loss: 0.3353 - val_acc: 0.9064\n",
      "Epoch 128/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2983 - acc: 0.9130 - val_loss: 0.3411 - val_acc: 0.9101\n",
      "Epoch 129/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2854 - acc: 0.9149 - val_loss: 0.3307 - val_acc: 0.9121\n",
      "Epoch 130/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.3127 - acc: 0.9138 - val_loss: 0.3470 - val_acc: 0.9077\n",
      "Epoch 131/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2863 - acc: 0.9172 - val_loss: 0.3203 - val_acc: 0.9074\n",
      "Epoch 132/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.2844 - acc: 0.9158 - val_loss: 0.3541 - val_acc: 0.9101\n",
      "Epoch 133/500\n",
      "6876/6876 [==============================] - 0s 27us/step - loss: 0.3043 - acc: 0.9140 - val_loss: 0.3141 - val_acc: 0.9104\n",
      "Epoch 134/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.2847 - acc: 0.9135 - val_loss: 0.3730 - val_acc: 0.9016\n",
      "Epoch 135/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.3126 - acc: 0.9138 - val_loss: 0.3290 - val_acc: 0.9108\n",
      "Epoch 136/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2822 - acc: 0.9158 - val_loss: 0.3179 - val_acc: 0.9091\n",
      "Epoch 137/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2785 - acc: 0.9164 - val_loss: 0.3292 - val_acc: 0.9081\n",
      "Epoch 138/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2861 - acc: 0.9140 - val_loss: 0.3409 - val_acc: 0.9104\n",
      "Epoch 139/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2901 - acc: 0.9149 - val_loss: 0.3206 - val_acc: 0.9104\n",
      "Epoch 140/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2891 - acc: 0.9148 - val_loss: 0.3187 - val_acc: 0.9077\n",
      "Epoch 141/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2873 - acc: 0.9168 - val_loss: 0.3363 - val_acc: 0.9108\n",
      "Epoch 142/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2793 - acc: 0.9156 - val_loss: 0.3093 - val_acc: 0.9104\n",
      "Epoch 143/500\n",
      "6876/6876 [==============================] - 0s 28us/step - loss: 0.3214 - acc: 0.9111 - val_loss: 0.3245 - val_acc: 0.9128\n",
      "Epoch 144/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.2798 - acc: 0.9148 - val_loss: 0.3148 - val_acc: 0.9101\n",
      "Epoch 145/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2687 - acc: 0.9161 - val_loss: 0.3179 - val_acc: 0.9101\n",
      "Epoch 146/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2740 - acc: 0.9162 - val_loss: 0.3680 - val_acc: 0.9108\n",
      "Epoch 147/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2956 - acc: 0.9139 - val_loss: 0.3904 - val_acc: 0.9115\n",
      "Epoch 148/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.3188 - acc: 0.9138 - val_loss: 0.3335 - val_acc: 0.9091\n",
      "Epoch 149/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2904 - acc: 0.9140 - val_loss: 0.3450 - val_acc: 0.9108\n",
      "Epoch 150/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.3099 - acc: 0.9113 - val_loss: 0.3150 - val_acc: 0.9081\n",
      "Epoch 151/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2809 - acc: 0.9152 - val_loss: 0.3118 - val_acc: 0.9094\n",
      "Epoch 152/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2797 - acc: 0.9171 - val_loss: 0.3278 - val_acc: 0.9074\n",
      "Epoch 153/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2802 - acc: 0.9152 - val_loss: 0.3243 - val_acc: 0.9115\n",
      "Epoch 154/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2757 - acc: 0.9146 - val_loss: 0.3197 - val_acc: 0.9067\n",
      "Epoch 155/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2665 - acc: 0.9175 - val_loss: 0.3235 - val_acc: 0.9088\n",
      "Epoch 156/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.2640 - acc: 0.9178 - val_loss: 0.3175 - val_acc: 0.9111\n",
      "Epoch 157/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2824 - acc: 0.9167 - val_loss: 0.3188 - val_acc: 0.9101\n",
      "Epoch 158/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2800 - acc: 0.9159 - val_loss: 0.3269 - val_acc: 0.9108\n",
      "Epoch 159/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2812 - acc: 0.9159 - val_loss: 0.3208 - val_acc: 0.9084\n",
      "Epoch 160/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2813 - acc: 0.9165 - val_loss: 0.3221 - val_acc: 0.9121\n",
      "Epoch 161/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2904 - acc: 0.9149 - val_loss: 0.3131 - val_acc: 0.9128\n",
      "Epoch 162/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.2716 - acc: 0.9161 - val_loss: 0.3216 - val_acc: 0.9091\n",
      "Epoch 163/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.2669 - acc: 0.9154 - val_loss: 0.3075 - val_acc: 0.9108\n",
      "Epoch 164/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.2817 - acc: 0.9148 - val_loss: 0.3242 - val_acc: 0.9091\n",
      "Epoch 165/500\n",
      "6876/6876 [==============================] - 0s 28us/step - loss: 0.2786 - acc: 0.9143 - val_loss: 0.3155 - val_acc: 0.9098\n",
      "Epoch 166/500\n",
      "6876/6876 [==============================] - 0s 29us/step - loss: 0.2924 - acc: 0.9139 - val_loss: 0.3212 - val_acc: 0.9132\n",
      "Epoch 167/500\n",
      "6876/6876 [==============================] - 0s 30us/step - loss: 0.2860 - acc: 0.9149 - val_loss: 0.3125 - val_acc: 0.9067\n",
      "Epoch 168/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2828 - acc: 0.9138 - val_loss: 0.3140 - val_acc: 0.9101\n",
      "Epoch 169/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2887 - acc: 0.9143 - val_loss: 0.3293 - val_acc: 0.9084\n",
      "Epoch 170/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2887 - acc: 0.9140 - val_loss: 0.3138 - val_acc: 0.9121\n",
      "Epoch 171/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2729 - acc: 0.9151 - val_loss: 0.3103 - val_acc: 0.9088\n",
      "Epoch 172/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2807 - acc: 0.9146 - val_loss: 0.3176 - val_acc: 0.9088\n",
      "Epoch 173/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2787 - acc: 0.9158 - val_loss: 0.3215 - val_acc: 0.9108\n",
      "Epoch 174/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2755 - acc: 0.9162 - val_loss: 0.3141 - val_acc: 0.9094\n",
      "Epoch 175/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2654 - acc: 0.9178 - val_loss: 0.3186 - val_acc: 0.9108\n",
      "Epoch 176/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2698 - acc: 0.9162 - val_loss: 0.3164 - val_acc: 0.9101\n",
      "Epoch 177/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2947 - acc: 0.9133 - val_loss: 0.3418 - val_acc: 0.9098\n",
      "Epoch 178/500\n",
      "6876/6876 [==============================] - 0s 27us/step - loss: 0.2685 - acc: 0.9170 - val_loss: 0.3147 - val_acc: 0.9094\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2789 - acc: 0.9145 - val_loss: 0.3828 - val_acc: 0.8942\n",
      "Epoch 180/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.3017 - acc: 0.9116 - val_loss: 0.3173 - val_acc: 0.9115\n",
      "Epoch 181/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2818 - acc: 0.9146 - val_loss: 0.2992 - val_acc: 0.9111\n",
      "Epoch 182/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2646 - acc: 0.9156 - val_loss: 0.3082 - val_acc: 0.9084\n",
      "Epoch 183/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2734 - acc: 0.9155 - val_loss: 0.3147 - val_acc: 0.9111\n",
      "Epoch 184/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2691 - acc: 0.9167 - val_loss: 0.3106 - val_acc: 0.9094\n",
      "Epoch 185/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2735 - acc: 0.9159 - val_loss: 0.2998 - val_acc: 0.9077\n",
      "Epoch 186/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2827 - acc: 0.9138 - val_loss: 0.3332 - val_acc: 0.9111\n",
      "Epoch 187/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2988 - acc: 0.9110 - val_loss: 0.4069 - val_acc: 0.8999\n",
      "Epoch 188/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.3048 - acc: 0.9117 - val_loss: 0.3030 - val_acc: 0.9101\n",
      "Epoch 189/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2907 - acc: 0.9138 - val_loss: 0.3204 - val_acc: 0.9064\n",
      "Epoch 190/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2764 - acc: 0.9145 - val_loss: 0.3097 - val_acc: 0.9094\n",
      "Epoch 191/500\n",
      "6876/6876 [==============================] - 0s 27us/step - loss: 0.2717 - acc: 0.9155 - val_loss: 0.3079 - val_acc: 0.9091\n",
      "Epoch 192/500\n",
      "6876/6876 [==============================] - 0s 25us/step - loss: 0.2714 - acc: 0.9152 - val_loss: 0.2922 - val_acc: 0.9121\n",
      "Epoch 193/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2877 - acc: 0.9138 - val_loss: 0.3093 - val_acc: 0.9115\n",
      "Epoch 194/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2832 - acc: 0.9135 - val_loss: 0.2955 - val_acc: 0.9081\n",
      "Epoch 195/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2852 - acc: 0.9143 - val_loss: 0.3147 - val_acc: 0.9091\n",
      "Epoch 196/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2716 - acc: 0.9142 - val_loss: 0.3115 - val_acc: 0.9108\n",
      "Epoch 197/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2657 - acc: 0.9154 - val_loss: 0.3019 - val_acc: 0.9098\n",
      "Epoch 198/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2836 - acc: 0.9149 - val_loss: 0.2990 - val_acc: 0.9118\n",
      "Epoch 199/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2658 - acc: 0.9148 - val_loss: 0.2947 - val_acc: 0.9121\n",
      "Epoch 200/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2681 - acc: 0.9142 - val_loss: 0.2953 - val_acc: 0.9071\n",
      "Epoch 201/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2623 - acc: 0.9162 - val_loss: 0.3035 - val_acc: 0.9104\n",
      "Epoch 202/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2731 - acc: 0.9142 - val_loss: 0.3014 - val_acc: 0.9091\n",
      "Epoch 203/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2639 - acc: 0.9148 - val_loss: 0.2966 - val_acc: 0.9077\n",
      "Epoch 204/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.2606 - acc: 0.9167 - val_loss: 0.2990 - val_acc: 0.9094\n",
      "Epoch 205/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2665 - acc: 0.9148 - val_loss: 0.2862 - val_acc: 0.9098\n",
      "Epoch 206/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2616 - acc: 0.9151 - val_loss: 0.2987 - val_acc: 0.9115\n",
      "Epoch 207/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2707 - acc: 0.9132 - val_loss: 0.2927 - val_acc: 0.9108\n",
      "Epoch 208/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2620 - acc: 0.9162 - val_loss: 0.2927 - val_acc: 0.9132\n",
      "Epoch 209/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2760 - acc: 0.9138 - val_loss: 0.3113 - val_acc: 0.9138\n",
      "Epoch 210/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2675 - acc: 0.9159 - val_loss: 0.2896 - val_acc: 0.9121\n",
      "Epoch 211/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2663 - acc: 0.9152 - val_loss: 0.3024 - val_acc: 0.9081\n",
      "Epoch 212/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2703 - acc: 0.9138 - val_loss: 0.2886 - val_acc: 0.9101\n",
      "Epoch 213/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2585 - acc: 0.9155 - val_loss: 0.2844 - val_acc: 0.9108\n",
      "Epoch 214/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2562 - acc: 0.9168 - val_loss: 0.2825 - val_acc: 0.9121\n",
      "Epoch 215/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.2567 - acc: 0.9152 - val_loss: 0.2784 - val_acc: 0.9098\n",
      "Epoch 216/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.2620 - acc: 0.9161 - val_loss: 0.2825 - val_acc: 0.9121\n",
      "Epoch 217/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2626 - acc: 0.9170 - val_loss: 0.2826 - val_acc: 0.9121\n",
      "Epoch 218/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2594 - acc: 0.9158 - val_loss: 0.2836 - val_acc: 0.9115\n",
      "Epoch 219/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2576 - acc: 0.9161 - val_loss: 0.2857 - val_acc: 0.9111\n",
      "Epoch 220/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2578 - acc: 0.9167 - val_loss: 0.2886 - val_acc: 0.9111\n",
      "Epoch 221/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2667 - acc: 0.9154 - val_loss: 0.2859 - val_acc: 0.9111\n",
      "Epoch 222/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2602 - acc: 0.9170 - val_loss: 0.2950 - val_acc: 0.9074\n",
      "Epoch 223/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2653 - acc: 0.9146 - val_loss: 0.3122 - val_acc: 0.9098\n",
      "Epoch 224/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2592 - acc: 0.9168 - val_loss: 0.2887 - val_acc: 0.9101\n",
      "Epoch 225/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2642 - acc: 0.9143 - val_loss: 0.2859 - val_acc: 0.9121\n",
      "Epoch 226/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2622 - acc: 0.9145 - val_loss: 0.2824 - val_acc: 0.9077\n",
      "Epoch 227/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2672 - acc: 0.9159 - val_loss: 0.2935 - val_acc: 0.9108\n",
      "Epoch 228/500\n",
      "6876/6876 [==============================] - 0s 25us/step - loss: 0.2594 - acc: 0.9167 - val_loss: 0.2862 - val_acc: 0.9118\n",
      "Epoch 229/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2593 - acc: 0.9146 - val_loss: 0.2765 - val_acc: 0.9101\n",
      "Epoch 230/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2545 - acc: 0.9164 - val_loss: 0.2815 - val_acc: 0.9108\n",
      "Epoch 231/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2541 - acc: 0.9177 - val_loss: 0.2842 - val_acc: 0.9098\n",
      "Epoch 232/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2555 - acc: 0.9152 - val_loss: 0.2806 - val_acc: 0.9108\n",
      "Epoch 233/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2572 - acc: 0.9162 - val_loss: 0.2907 - val_acc: 0.9125\n",
      "Epoch 234/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2580 - acc: 0.9168 - val_loss: 0.2860 - val_acc: 0.9104\n",
      "Epoch 235/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2620 - acc: 0.9154 - val_loss: 0.2799 - val_acc: 0.9128\n",
      "Epoch 236/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2610 - acc: 0.9151 - val_loss: 0.2791 - val_acc: 0.9132\n",
      "Epoch 237/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2560 - acc: 0.9162 - val_loss: 0.2782 - val_acc: 0.9108\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2577 - acc: 0.9162 - val_loss: 0.2778 - val_acc: 0.9094\n",
      "Epoch 239/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2556 - acc: 0.9168 - val_loss: 0.2783 - val_acc: 0.9104\n",
      "Epoch 240/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2570 - acc: 0.9152 - val_loss: 0.2891 - val_acc: 0.9091\n",
      "Epoch 241/500\n",
      "6876/6876 [==============================] - 0s 25us/step - loss: 0.2656 - acc: 0.9149 - val_loss: 0.2879 - val_acc: 0.9125\n",
      "Epoch 242/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2562 - acc: 0.9152 - val_loss: 0.2871 - val_acc: 0.9081\n",
      "Epoch 243/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2566 - acc: 0.9167 - val_loss: 0.2850 - val_acc: 0.9098\n",
      "Epoch 244/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2572 - acc: 0.9161 - val_loss: 0.2838 - val_acc: 0.9115\n",
      "Epoch 245/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2549 - acc: 0.9165 - val_loss: 0.2807 - val_acc: 0.9101\n",
      "Epoch 246/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2543 - acc: 0.9167 - val_loss: 0.2874 - val_acc: 0.9094\n",
      "Epoch 247/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2529 - acc: 0.9178 - val_loss: 0.2854 - val_acc: 0.9098\n",
      "Epoch 248/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2544 - acc: 0.9172 - val_loss: 0.2795 - val_acc: 0.9111\n",
      "Epoch 249/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2582 - acc: 0.9151 - val_loss: 0.2797 - val_acc: 0.9125\n",
      "Epoch 250/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2580 - acc: 0.9162 - val_loss: 0.2764 - val_acc: 0.9121\n",
      "Epoch 251/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2657 - acc: 0.9149 - val_loss: 0.2824 - val_acc: 0.9115\n",
      "Epoch 252/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.2552 - acc: 0.9167 - val_loss: 0.2873 - val_acc: 0.9118\n",
      "Epoch 253/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2672 - acc: 0.9148 - val_loss: 0.2826 - val_acc: 0.9104\n",
      "Epoch 254/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2564 - acc: 0.9158 - val_loss: 0.2799 - val_acc: 0.9108\n",
      "Epoch 255/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2676 - acc: 0.9149 - val_loss: 0.2821 - val_acc: 0.9128\n",
      "Epoch 256/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2655 - acc: 0.9142 - val_loss: 0.2832 - val_acc: 0.9142\n",
      "Epoch 257/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2615 - acc: 0.9149 - val_loss: 0.2813 - val_acc: 0.9128\n",
      "Epoch 258/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2574 - acc: 0.9162 - val_loss: 0.2770 - val_acc: 0.9118\n",
      "Epoch 259/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2540 - acc: 0.9167 - val_loss: 0.2784 - val_acc: 0.9108\n",
      "Epoch 260/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2541 - acc: 0.9167 - val_loss: 0.2790 - val_acc: 0.9115\n",
      "Epoch 261/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2544 - acc: 0.9158 - val_loss: 0.2780 - val_acc: 0.9115\n",
      "Epoch 262/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2549 - acc: 0.9170 - val_loss: 0.2767 - val_acc: 0.9104\n",
      "Epoch 263/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2601 - acc: 0.9151 - val_loss: 0.2752 - val_acc: 0.9115\n",
      "Epoch 264/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.2571 - acc: 0.9156 - val_loss: 0.2791 - val_acc: 0.9104\n",
      "Epoch 265/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.2546 - acc: 0.9170 - val_loss: 0.2762 - val_acc: 0.9111\n",
      "Epoch 266/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2576 - acc: 0.9154 - val_loss: 0.2774 - val_acc: 0.9125\n",
      "Epoch 267/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2577 - acc: 0.9159 - val_loss: 0.2763 - val_acc: 0.9115\n",
      "Epoch 268/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2528 - acc: 0.9172 - val_loss: 0.2761 - val_acc: 0.9115\n",
      "Epoch 269/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2574 - acc: 0.9161 - val_loss: 0.2838 - val_acc: 0.9111\n",
      "Epoch 270/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2572 - acc: 0.9149 - val_loss: 0.2820 - val_acc: 0.9098\n",
      "Epoch 271/500\n",
      "6876/6876 [==============================] - 0s 13us/step - loss: 0.2588 - acc: 0.9154 - val_loss: 0.2875 - val_acc: 0.9121\n",
      "Epoch 272/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2601 - acc: 0.9139 - val_loss: 0.2839 - val_acc: 0.9128\n",
      "Epoch 273/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2567 - acc: 0.9171 - val_loss: 0.2787 - val_acc: 0.9125\n",
      "Epoch 274/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2560 - acc: 0.9168 - val_loss: 0.2765 - val_acc: 0.9101\n",
      "Epoch 275/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2548 - acc: 0.9161 - val_loss: 0.2769 - val_acc: 0.9108\n",
      "Epoch 276/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2525 - acc: 0.9174 - val_loss: 0.2803 - val_acc: 0.9111\n",
      "Epoch 277/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2543 - acc: 0.9175 - val_loss: 0.2923 - val_acc: 0.9091\n",
      "Epoch 278/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2589 - acc: 0.9149 - val_loss: 0.2840 - val_acc: 0.9121\n",
      "Epoch 279/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2602 - acc: 0.9159 - val_loss: 0.2812 - val_acc: 0.9121\n",
      "Epoch 280/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2559 - acc: 0.9168 - val_loss: 0.2885 - val_acc: 0.9081\n",
      "Epoch 281/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2629 - acc: 0.9155 - val_loss: 0.2922 - val_acc: 0.9142\n",
      "Epoch 282/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2619 - acc: 0.9154 - val_loss: 0.2765 - val_acc: 0.9138\n",
      "Epoch 283/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2563 - acc: 0.9164 - val_loss: 0.2770 - val_acc: 0.9108\n",
      "Epoch 284/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2548 - acc: 0.9161 - val_loss: 0.2779 - val_acc: 0.9104\n",
      "Epoch 285/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2606 - acc: 0.9154 - val_loss: 0.2767 - val_acc: 0.9128\n",
      "Epoch 286/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2553 - acc: 0.9165 - val_loss: 0.2760 - val_acc: 0.9111\n",
      "Epoch 287/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2525 - acc: 0.9170 - val_loss: 0.2777 - val_acc: 0.9128\n",
      "Epoch 288/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2580 - acc: 0.9162 - val_loss: 0.2785 - val_acc: 0.9104\n",
      "Epoch 289/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.2553 - acc: 0.9181 - val_loss: 0.2809 - val_acc: 0.9098\n",
      "Epoch 290/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2509 - acc: 0.9186 - val_loss: 0.2932 - val_acc: 0.9091\n",
      "Epoch 291/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2592 - acc: 0.9165 - val_loss: 0.2793 - val_acc: 0.9101\n",
      "Epoch 292/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2550 - acc: 0.9168 - val_loss: 0.2766 - val_acc: 0.9104\n",
      "Epoch 293/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2573 - acc: 0.9167 - val_loss: 0.2830 - val_acc: 0.9111\n",
      "Epoch 294/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2541 - acc: 0.9175 - val_loss: 0.2862 - val_acc: 0.9091\n",
      "Epoch 295/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2526 - acc: 0.9174 - val_loss: 0.2789 - val_acc: 0.9104\n",
      "Epoch 296/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2508 - acc: 0.9186 - val_loss: 0.2843 - val_acc: 0.9094\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2532 - acc: 0.9156 - val_loss: 0.2799 - val_acc: 0.9121\n",
      "Epoch 298/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2524 - acc: 0.9180 - val_loss: 0.2750 - val_acc: 0.9118\n",
      "Epoch 299/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2563 - acc: 0.9171 - val_loss: 0.2771 - val_acc: 0.9135\n",
      "Epoch 300/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2510 - acc: 0.9186 - val_loss: 0.2816 - val_acc: 0.9125\n",
      "Epoch 301/500\n",
      "6876/6876 [==============================] - 0s 28us/step - loss: 0.2739 - acc: 0.9126 - val_loss: 0.2789 - val_acc: 0.9128\n",
      "Epoch 302/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.2546 - acc: 0.9168 - val_loss: 0.2814 - val_acc: 0.9115\n",
      "Epoch 303/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2560 - acc: 0.9148 - val_loss: 0.2756 - val_acc: 0.9108\n",
      "Epoch 304/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2571 - acc: 0.9152 - val_loss: 0.2738 - val_acc: 0.9128\n",
      "Epoch 305/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2527 - acc: 0.9154 - val_loss: 0.2759 - val_acc: 0.9111\n",
      "Epoch 306/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2519 - acc: 0.9174 - val_loss: 0.2731 - val_acc: 0.9128\n",
      "Epoch 307/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2528 - acc: 0.9172 - val_loss: 0.2763 - val_acc: 0.9115\n",
      "Epoch 308/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2503 - acc: 0.9172 - val_loss: 0.2728 - val_acc: 0.9125\n",
      "Epoch 309/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2502 - acc: 0.9183 - val_loss: 0.2746 - val_acc: 0.9128\n",
      "Epoch 310/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2497 - acc: 0.9184 - val_loss: 0.2739 - val_acc: 0.9118\n",
      "Epoch 311/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2567 - acc: 0.9154 - val_loss: 0.2778 - val_acc: 0.9118\n",
      "Epoch 312/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2506 - acc: 0.9188 - val_loss: 0.2819 - val_acc: 0.9088\n",
      "Epoch 313/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2494 - acc: 0.9193 - val_loss: 0.2772 - val_acc: 0.9098\n",
      "Epoch 314/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.2527 - acc: 0.9175 - val_loss: 0.2743 - val_acc: 0.9111\n",
      "Epoch 315/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2511 - acc: 0.9178 - val_loss: 0.2749 - val_acc: 0.9115\n",
      "Epoch 316/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2503 - acc: 0.9167 - val_loss: 0.2825 - val_acc: 0.9098\n",
      "Epoch 317/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2508 - acc: 0.9175 - val_loss: 0.2774 - val_acc: 0.9101\n",
      "Epoch 318/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2519 - acc: 0.9175 - val_loss: 0.2820 - val_acc: 0.9125\n",
      "Epoch 319/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2517 - acc: 0.9167 - val_loss: 0.2819 - val_acc: 0.9135\n",
      "Epoch 320/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2549 - acc: 0.9175 - val_loss: 0.2774 - val_acc: 0.9118\n",
      "Epoch 321/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2494 - acc: 0.9183 - val_loss: 0.2816 - val_acc: 0.9104\n",
      "Epoch 322/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2565 - acc: 0.9156 - val_loss: 0.2815 - val_acc: 0.9118\n",
      "Epoch 323/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2522 - acc: 0.9175 - val_loss: 0.2862 - val_acc: 0.9121\n",
      "Epoch 324/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2530 - acc: 0.9165 - val_loss: 0.2770 - val_acc: 0.9108\n",
      "Epoch 325/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2499 - acc: 0.9168 - val_loss: 0.2748 - val_acc: 0.9101\n",
      "Epoch 326/500\n",
      "6876/6876 [==============================] - 0s 25us/step - loss: 0.2496 - acc: 0.9171 - val_loss: 0.2817 - val_acc: 0.9125\n",
      "Epoch 327/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2541 - acc: 0.9161 - val_loss: 0.2766 - val_acc: 0.9118\n",
      "Epoch 328/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.2478 - acc: 0.9184 - val_loss: 0.2776 - val_acc: 0.9121\n",
      "Epoch 329/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2475 - acc: 0.9183 - val_loss: 0.2857 - val_acc: 0.9101\n",
      "Epoch 330/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2496 - acc: 0.9172 - val_loss: 0.2773 - val_acc: 0.9101\n",
      "Epoch 331/500\n",
      "6876/6876 [==============================] - 0s 13us/step - loss: 0.2476 - acc: 0.9178 - val_loss: 0.2780 - val_acc: 0.9128\n",
      "Epoch 332/500\n",
      "6876/6876 [==============================] - 0s 13us/step - loss: 0.2501 - acc: 0.9177 - val_loss: 0.2826 - val_acc: 0.9088\n",
      "Epoch 333/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2476 - acc: 0.9177 - val_loss: 0.2791 - val_acc: 0.9118\n",
      "Epoch 334/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2526 - acc: 0.9164 - val_loss: 0.2778 - val_acc: 0.9128\n",
      "Epoch 335/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2495 - acc: 0.9178 - val_loss: 0.2764 - val_acc: 0.9101\n",
      "Epoch 336/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2509 - acc: 0.9167 - val_loss: 0.2745 - val_acc: 0.9108\n",
      "Epoch 337/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2534 - acc: 0.9175 - val_loss: 0.2733 - val_acc: 0.9118\n",
      "Epoch 338/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2474 - acc: 0.9181 - val_loss: 0.2735 - val_acc: 0.9135\n",
      "Epoch 339/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2469 - acc: 0.9193 - val_loss: 0.2789 - val_acc: 0.9088\n",
      "Epoch 340/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2500 - acc: 0.9159 - val_loss: 0.2740 - val_acc: 0.9125\n",
      "Epoch 341/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2485 - acc: 0.9174 - val_loss: 0.2726 - val_acc: 0.9111\n",
      "Epoch 342/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2562 - acc: 0.9161 - val_loss: 0.2841 - val_acc: 0.9121\n",
      "Epoch 343/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2509 - acc: 0.9171 - val_loss: 0.2770 - val_acc: 0.9118\n",
      "Epoch 344/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2512 - acc: 0.9165 - val_loss: 0.2739 - val_acc: 0.9111\n",
      "Epoch 345/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2466 - acc: 0.9178 - val_loss: 0.2817 - val_acc: 0.9118\n",
      "Epoch 346/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2481 - acc: 0.9190 - val_loss: 0.2770 - val_acc: 0.9125\n",
      "Epoch 347/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2470 - acc: 0.9187 - val_loss: 0.2768 - val_acc: 0.9104\n",
      "Epoch 348/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2468 - acc: 0.9188 - val_loss: 0.2794 - val_acc: 0.9088\n",
      "Epoch 349/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2490 - acc: 0.9181 - val_loss: 0.2906 - val_acc: 0.9104\n",
      "Epoch 350/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2482 - acc: 0.9177 - val_loss: 0.2771 - val_acc: 0.9091\n",
      "Epoch 351/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.2468 - acc: 0.9175 - val_loss: 0.2774 - val_acc: 0.9111\n",
      "Epoch 352/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2495 - acc: 0.9184 - val_loss: 0.2761 - val_acc: 0.9094\n",
      "Epoch 353/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2521 - acc: 0.9167 - val_loss: 0.2786 - val_acc: 0.9098\n",
      "Epoch 354/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2513 - acc: 0.9156 - val_loss: 0.2790 - val_acc: 0.9094\n",
      "Epoch 355/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2492 - acc: 0.9162 - val_loss: 0.2749 - val_acc: 0.9104\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2466 - acc: 0.9175 - val_loss: 0.2754 - val_acc: 0.9094\n",
      "Epoch 357/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2470 - acc: 0.9183 - val_loss: 0.2748 - val_acc: 0.9118\n",
      "Epoch 358/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2517 - acc: 0.9175 - val_loss: 0.2782 - val_acc: 0.9111\n",
      "Epoch 359/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2490 - acc: 0.9181 - val_loss: 0.2843 - val_acc: 0.9091\n",
      "Epoch 360/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2459 - acc: 0.9187 - val_loss: 0.2744 - val_acc: 0.9108\n",
      "Epoch 361/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2504 - acc: 0.9181 - val_loss: 0.2746 - val_acc: 0.9111\n",
      "Epoch 362/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2469 - acc: 0.9184 - val_loss: 0.2749 - val_acc: 0.9111\n",
      "Epoch 363/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2458 - acc: 0.9187 - val_loss: 0.2760 - val_acc: 0.9084\n",
      "Epoch 364/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2456 - acc: 0.9187 - val_loss: 0.2755 - val_acc: 0.9115\n",
      "Epoch 365/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2458 - acc: 0.9180 - val_loss: 0.2776 - val_acc: 0.9081\n",
      "Epoch 366/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2471 - acc: 0.9184 - val_loss: 0.2825 - val_acc: 0.9091\n",
      "Epoch 367/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2542 - acc: 0.9161 - val_loss: 0.2794 - val_acc: 0.9118\n",
      "Epoch 368/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2482 - acc: 0.9194 - val_loss: 0.2752 - val_acc: 0.9125\n",
      "Epoch 369/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2471 - acc: 0.9180 - val_loss: 0.2770 - val_acc: 0.9108\n",
      "Epoch 370/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2471 - acc: 0.9178 - val_loss: 0.2792 - val_acc: 0.9104\n",
      "Epoch 371/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2588 - acc: 0.9145 - val_loss: 0.2743 - val_acc: 0.9091\n",
      "Epoch 372/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2476 - acc: 0.9178 - val_loss: 0.2757 - val_acc: 0.9091\n",
      "Epoch 373/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2476 - acc: 0.9183 - val_loss: 0.2744 - val_acc: 0.9101\n",
      "Epoch 374/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2534 - acc: 0.9186 - val_loss: 0.2813 - val_acc: 0.9118\n",
      "Epoch 375/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2498 - acc: 0.9171 - val_loss: 0.2762 - val_acc: 0.9104\n",
      "Epoch 376/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2531 - acc: 0.9177 - val_loss: 0.2792 - val_acc: 0.9115\n",
      "Epoch 377/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2479 - acc: 0.9177 - val_loss: 0.2806 - val_acc: 0.9084\n",
      "Epoch 378/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2476 - acc: 0.9156 - val_loss: 0.2783 - val_acc: 0.9101\n",
      "Epoch 379/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2477 - acc: 0.9168 - val_loss: 0.2772 - val_acc: 0.9081\n",
      "Epoch 380/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2476 - acc: 0.9183 - val_loss: 0.2799 - val_acc: 0.9118\n",
      "Epoch 381/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2461 - acc: 0.9191 - val_loss: 0.2831 - val_acc: 0.9081\n",
      "Epoch 382/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2462 - acc: 0.9178 - val_loss: 0.2751 - val_acc: 0.9084\n",
      "Epoch 383/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2526 - acc: 0.9170 - val_loss: 0.2859 - val_acc: 0.9101\n",
      "Epoch 384/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2509 - acc: 0.9155 - val_loss: 0.2719 - val_acc: 0.9098\n",
      "Epoch 385/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2461 - acc: 0.9177 - val_loss: 0.2746 - val_acc: 0.9091\n",
      "Epoch 386/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2459 - acc: 0.9194 - val_loss: 0.2936 - val_acc: 0.9101\n",
      "Epoch 387/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2508 - acc: 0.9159 - val_loss: 0.2886 - val_acc: 0.9125\n",
      "Epoch 388/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.2484 - acc: 0.9170 - val_loss: 0.2775 - val_acc: 0.9104\n",
      "Epoch 389/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.2478 - acc: 0.9168 - val_loss: 0.2749 - val_acc: 0.9091\n",
      "Epoch 390/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.2443 - acc: 0.9175 - val_loss: 0.2751 - val_acc: 0.9098\n",
      "Epoch 391/500\n",
      "6876/6876 [==============================] - 0s 26us/step - loss: 0.2466 - acc: 0.9174 - val_loss: 0.2752 - val_acc: 0.9118\n",
      "Epoch 392/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2462 - acc: 0.9170 - val_loss: 0.2809 - val_acc: 0.9091\n",
      "Epoch 393/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2481 - acc: 0.9170 - val_loss: 0.2761 - val_acc: 0.9088\n",
      "Epoch 394/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2455 - acc: 0.9178 - val_loss: 0.2791 - val_acc: 0.9118\n",
      "Epoch 395/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2507 - acc: 0.9159 - val_loss: 0.2805 - val_acc: 0.9098\n",
      "Epoch 396/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2477 - acc: 0.9177 - val_loss: 0.2847 - val_acc: 0.9091\n",
      "Epoch 397/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2460 - acc: 0.9178 - val_loss: 0.2756 - val_acc: 0.9111\n",
      "Epoch 398/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2469 - acc: 0.9177 - val_loss: 0.2794 - val_acc: 0.9111\n",
      "Epoch 399/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2562 - acc: 0.9159 - val_loss: 0.2802 - val_acc: 0.9077\n",
      "Epoch 400/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2493 - acc: 0.9162 - val_loss: 0.2729 - val_acc: 0.9125\n",
      "Epoch 401/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2459 - acc: 0.9170 - val_loss: 0.2759 - val_acc: 0.9098\n",
      "Epoch 402/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2453 - acc: 0.9187 - val_loss: 0.2783 - val_acc: 0.9121\n",
      "Epoch 403/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2453 - acc: 0.9186 - val_loss: 0.2807 - val_acc: 0.9098\n",
      "Epoch 404/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2494 - acc: 0.9165 - val_loss: 0.2734 - val_acc: 0.9121\n",
      "Epoch 405/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2438 - acc: 0.9194 - val_loss: 0.3053 - val_acc: 0.9043\n",
      "Epoch 406/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2587 - acc: 0.9174 - val_loss: 0.2784 - val_acc: 0.9115\n",
      "Epoch 407/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2457 - acc: 0.9170 - val_loss: 0.2725 - val_acc: 0.9111\n",
      "Epoch 408/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2448 - acc: 0.9168 - val_loss: 0.2734 - val_acc: 0.9098\n",
      "Epoch 409/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2436 - acc: 0.9186 - val_loss: 0.2781 - val_acc: 0.9098\n",
      "Epoch 410/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2480 - acc: 0.9159 - val_loss: 0.2750 - val_acc: 0.9088\n",
      "Epoch 411/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2461 - acc: 0.9184 - val_loss: 0.2779 - val_acc: 0.9084\n",
      "Epoch 412/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2451 - acc: 0.9180 - val_loss: 0.2788 - val_acc: 0.9091\n",
      "Epoch 413/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2517 - acc: 0.9154 - val_loss: 0.2849 - val_acc: 0.9094\n",
      "Epoch 414/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2494 - acc: 0.9164 - val_loss: 0.2767 - val_acc: 0.9098\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2440 - acc: 0.9178 - val_loss: 0.2780 - val_acc: 0.9098\n",
      "Epoch 416/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2434 - acc: 0.9199 - val_loss: 0.2790 - val_acc: 0.9098\n",
      "Epoch 417/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2437 - acc: 0.9181 - val_loss: 0.2756 - val_acc: 0.9088\n",
      "Epoch 418/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2443 - acc: 0.9180 - val_loss: 0.2809 - val_acc: 0.9094\n",
      "Epoch 419/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2428 - acc: 0.9194 - val_loss: 0.2784 - val_acc: 0.9091\n",
      "Epoch 420/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2404 - acc: 0.9200 - val_loss: 0.2786 - val_acc: 0.9077\n",
      "Epoch 421/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2448 - acc: 0.9183 - val_loss: 0.2746 - val_acc: 0.9084\n",
      "Epoch 422/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2440 - acc: 0.9184 - val_loss: 0.2796 - val_acc: 0.9098\n",
      "Epoch 423/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2460 - acc: 0.9175 - val_loss: 0.2846 - val_acc: 0.9084\n",
      "Epoch 424/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2468 - acc: 0.9158 - val_loss: 0.2794 - val_acc: 0.9094\n",
      "Epoch 425/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2441 - acc: 0.9171 - val_loss: 0.2756 - val_acc: 0.9088\n",
      "Epoch 426/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2445 - acc: 0.9170 - val_loss: 0.2791 - val_acc: 0.9108\n",
      "Epoch 427/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2470 - acc: 0.9177 - val_loss: 0.2820 - val_acc: 0.9077\n",
      "Epoch 428/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2442 - acc: 0.9187 - val_loss: 0.2790 - val_acc: 0.9081\n",
      "Epoch 429/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2427 - acc: 0.9178 - val_loss: 0.2770 - val_acc: 0.9108\n",
      "Epoch 430/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2441 - acc: 0.9184 - val_loss: 0.2775 - val_acc: 0.9088\n",
      "Epoch 431/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2442 - acc: 0.9177 - val_loss: 0.2745 - val_acc: 0.9094\n",
      "Epoch 432/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2417 - acc: 0.9171 - val_loss: 0.2769 - val_acc: 0.9108\n",
      "Epoch 433/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2434 - acc: 0.9181 - val_loss: 0.2741 - val_acc: 0.9104\n",
      "Epoch 434/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2469 - acc: 0.9188 - val_loss: 0.2845 - val_acc: 0.9091\n",
      "Epoch 435/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2447 - acc: 0.9177 - val_loss: 0.2774 - val_acc: 0.9081\n",
      "Epoch 436/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2407 - acc: 0.9197 - val_loss: 0.2764 - val_acc: 0.9088\n",
      "Epoch 437/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2449 - acc: 0.9180 - val_loss: 0.2865 - val_acc: 0.9091\n",
      "Epoch 438/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2416 - acc: 0.9188 - val_loss: 0.2791 - val_acc: 0.9081\n",
      "Epoch 439/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2421 - acc: 0.9180 - val_loss: 0.2764 - val_acc: 0.9088\n",
      "Epoch 440/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2479 - acc: 0.9167 - val_loss: 0.2916 - val_acc: 0.9098\n",
      "Epoch 441/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2486 - acc: 0.9177 - val_loss: 0.2771 - val_acc: 0.9084\n",
      "Epoch 442/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2430 - acc: 0.9186 - val_loss: 0.2777 - val_acc: 0.9088\n",
      "Epoch 443/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2409 - acc: 0.9191 - val_loss: 0.2780 - val_acc: 0.9071\n",
      "Epoch 444/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2412 - acc: 0.9196 - val_loss: 0.2796 - val_acc: 0.9071\n",
      "Epoch 445/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2419 - acc: 0.9199 - val_loss: 0.2839 - val_acc: 0.9074\n",
      "Epoch 446/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2406 - acc: 0.9199 - val_loss: 0.2806 - val_acc: 0.9074\n",
      "Epoch 447/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2460 - acc: 0.9168 - val_loss: 0.2794 - val_acc: 0.9088\n",
      "Epoch 448/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2407 - acc: 0.9200 - val_loss: 0.2831 - val_acc: 0.9084\n",
      "Epoch 449/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2404 - acc: 0.9190 - val_loss: 0.2806 - val_acc: 0.9067\n",
      "Epoch 450/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2433 - acc: 0.9177 - val_loss: 0.2758 - val_acc: 0.9098\n",
      "Epoch 451/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2421 - acc: 0.9186 - val_loss: 0.2802 - val_acc: 0.9091\n",
      "Epoch 452/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2413 - acc: 0.9181 - val_loss: 0.2790 - val_acc: 0.9071\n",
      "Epoch 453/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2404 - acc: 0.9206 - val_loss: 0.2822 - val_acc: 0.9088\n",
      "Epoch 454/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2418 - acc: 0.9206 - val_loss: 0.2831 - val_acc: 0.9060\n",
      "Epoch 455/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2426 - acc: 0.9191 - val_loss: 0.2834 - val_acc: 0.9101\n",
      "Epoch 456/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2617 - acc: 0.9177 - val_loss: 0.2793 - val_acc: 0.9101\n",
      "Epoch 457/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2445 - acc: 0.9186 - val_loss: 0.2786 - val_acc: 0.9057\n",
      "Epoch 458/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2505 - acc: 0.9159 - val_loss: 0.2808 - val_acc: 0.9084\n",
      "Epoch 459/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2428 - acc: 0.9180 - val_loss: 0.2806 - val_acc: 0.9091\n",
      "Epoch 460/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2445 - acc: 0.9172 - val_loss: 0.2818 - val_acc: 0.9098\n",
      "Epoch 461/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2407 - acc: 0.9183 - val_loss: 0.2860 - val_acc: 0.9091\n",
      "Epoch 462/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2414 - acc: 0.9197 - val_loss: 0.2796 - val_acc: 0.9084\n",
      "Epoch 463/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2399 - acc: 0.9202 - val_loss: 0.2794 - val_acc: 0.9104\n",
      "Epoch 464/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2385 - acc: 0.9202 - val_loss: 0.2846 - val_acc: 0.9084\n",
      "Epoch 465/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2400 - acc: 0.9193 - val_loss: 0.2783 - val_acc: 0.9081\n",
      "Epoch 466/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2452 - acc: 0.9194 - val_loss: 0.2852 - val_acc: 0.9101\n",
      "Epoch 467/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2421 - acc: 0.9188 - val_loss: 0.2834 - val_acc: 0.9077\n",
      "Epoch 468/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2427 - acc: 0.9188 - val_loss: 0.2821 - val_acc: 0.9084\n",
      "Epoch 469/500\n",
      "6876/6876 [==============================] - 0s 25us/step - loss: 0.2430 - acc: 0.9178 - val_loss: 0.2813 - val_acc: 0.9088\n",
      "Epoch 470/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2396 - acc: 0.9200 - val_loss: 0.2808 - val_acc: 0.9094\n",
      "Epoch 471/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2396 - acc: 0.9200 - val_loss: 0.2909 - val_acc: 0.9064\n",
      "Epoch 472/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2459 - acc: 0.9180 - val_loss: 0.2794 - val_acc: 0.9101\n",
      "Epoch 473/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2401 - acc: 0.9191 - val_loss: 0.2805 - val_acc: 0.9108\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2404 - acc: 0.9191 - val_loss: 0.2875 - val_acc: 0.9074\n",
      "Epoch 475/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2430 - acc: 0.9174 - val_loss: 0.2793 - val_acc: 0.9084\n",
      "Epoch 476/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2388 - acc: 0.9188 - val_loss: 0.2878 - val_acc: 0.9091\n",
      "Epoch 477/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2428 - acc: 0.9196 - val_loss: 0.2779 - val_acc: 0.9088\n",
      "Epoch 478/500\n",
      "6876/6876 [==============================] - 0s 14us/step - loss: 0.2479 - acc: 0.9178 - val_loss: 0.2787 - val_acc: 0.9074\n",
      "Epoch 479/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2444 - acc: 0.9172 - val_loss: 0.2793 - val_acc: 0.9081\n",
      "Epoch 480/500\n",
      "6876/6876 [==============================] - 0s 18us/step - loss: 0.2424 - acc: 0.9175 - val_loss: 0.2793 - val_acc: 0.9108\n",
      "Epoch 481/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2443 - acc: 0.9165 - val_loss: 0.2760 - val_acc: 0.9091\n",
      "Epoch 482/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2401 - acc: 0.9184 - val_loss: 0.2810 - val_acc: 0.9088\n",
      "Epoch 483/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2411 - acc: 0.9183 - val_loss: 0.2783 - val_acc: 0.9094\n",
      "Epoch 484/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2413 - acc: 0.9181 - val_loss: 0.2795 - val_acc: 0.9098\n",
      "Epoch 485/500\n",
      "6876/6876 [==============================] - 0s 23us/step - loss: 0.2420 - acc: 0.9167 - val_loss: 0.2777 - val_acc: 0.9101\n",
      "Epoch 486/500\n",
      "6876/6876 [==============================] - 0s 19us/step - loss: 0.2426 - acc: 0.9174 - val_loss: 0.2790 - val_acc: 0.9091\n",
      "Epoch 487/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2421 - acc: 0.9187 - val_loss: 0.2789 - val_acc: 0.9094\n",
      "Epoch 488/500\n",
      "6876/6876 [==============================] - 0s 25us/step - loss: 0.2416 - acc: 0.9174 - val_loss: 0.2779 - val_acc: 0.9111\n",
      "Epoch 489/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2401 - acc: 0.9180 - val_loss: 0.2778 - val_acc: 0.9081\n",
      "Epoch 490/500\n",
      "6876/6876 [==============================] - 0s 15us/step - loss: 0.2468 - acc: 0.9183 - val_loss: 0.2848 - val_acc: 0.9101\n",
      "Epoch 491/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2428 - acc: 0.9193 - val_loss: 0.2799 - val_acc: 0.9115\n",
      "Epoch 492/500\n",
      "6876/6876 [==============================] - 0s 22us/step - loss: 0.2407 - acc: 0.9186 - val_loss: 0.2859 - val_acc: 0.9094\n",
      "Epoch 493/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2404 - acc: 0.9181 - val_loss: 0.2815 - val_acc: 0.9060\n",
      "Epoch 494/500\n",
      "6876/6876 [==============================] - 0s 24us/step - loss: 0.2404 - acc: 0.9200 - val_loss: 0.2789 - val_acc: 0.9098\n",
      "Epoch 495/500\n",
      "6876/6876 [==============================] - 0s 21us/step - loss: 0.2391 - acc: 0.9180 - val_loss: 0.2776 - val_acc: 0.9094\n",
      "Epoch 496/500\n",
      "6876/6876 [==============================] - 0s 20us/step - loss: 0.2425 - acc: 0.9177 - val_loss: 0.2867 - val_acc: 0.9088\n",
      "Epoch 497/500\n",
      "6876/6876 [==============================] - 0s 27us/step - loss: 0.2414 - acc: 0.9171 - val_loss: 0.2787 - val_acc: 0.9098\n",
      "Epoch 498/500\n",
      "6876/6876 [==============================] - 0s 17us/step - loss: 0.2394 - acc: 0.9181 - val_loss: 0.2829 - val_acc: 0.9084\n",
      "Epoch 499/500\n",
      "6876/6876 [==============================] - 0s 16us/step - loss: 0.2378 - acc: 0.9188 - val_loss: 0.2806 - val_acc: 0.9098\n",
      "Epoch 500/500\n",
      "6876/6876 [==============================] - ETA: 0s - loss: 0.2377 - acc: 0.919 - 0s 18us/step - loss: 0.2398 - acc: 0.9186 - val_loss: 0.2800 - val_acc: 0.9088\n",
      "2948/2948 [==============================] - 0s 5us/step\n",
      "50 202 403 403 12494 7633 202 1093 891\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "7633 7633\n",
      "../linkPrediction/dataframes/apnea\n",
      "article (7633, 7, 11) --------------------------------------------------------------------\n",
      "(7633, 11) (7633,)\n",
      "[7633, 11, 1]\n",
      "(5343, 11) (5343,)\n",
      "Train on 5343 samples, validate on 2290 samples\n",
      "Epoch 1/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.9022 - acc: 0.8916 - val_loss: 0.7320 - val_acc: 0.9175\n",
      "Epoch 2/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.6581 - acc: 0.9175 - val_loss: 0.6756 - val_acc: 0.9214\n",
      "Epoch 3/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.6252 - acc: 0.9266 - val_loss: 0.6549 - val_acc: 0.9218\n",
      "Epoch 4/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.5785 - acc: 0.9270 - val_loss: 0.5972 - val_acc: 0.9210\n",
      "Epoch 5/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.5531 - acc: 0.9253 - val_loss: 0.6681 - val_acc: 0.9245\n",
      "Epoch 6/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.5669 - acc: 0.9229 - val_loss: 0.6187 - val_acc: 0.9236\n",
      "Epoch 7/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.5606 - acc: 0.9223 - val_loss: 0.5893 - val_acc: 0.9031\n",
      "Epoch 8/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.5036 - acc: 0.9235 - val_loss: 0.5211 - val_acc: 0.9048\n",
      "Epoch 9/500\n",
      "5343/5343 [==============================] - 0s 14us/step - loss: 0.4819 - acc: 0.9216 - val_loss: 0.5197 - val_acc: 0.9258\n",
      "Epoch 10/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.4855 - acc: 0.9238 - val_loss: 0.4793 - val_acc: 0.9258\n",
      "Epoch 11/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.4275 - acc: 0.9263 - val_loss: 0.5173 - val_acc: 0.9249\n",
      "Epoch 12/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.4098 - acc: 0.9255 - val_loss: 0.4714 - val_acc: 0.9114\n",
      "Epoch 13/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.4485 - acc: 0.9206 - val_loss: 0.3749 - val_acc: 0.9258\n",
      "Epoch 14/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.3987 - acc: 0.9233 - val_loss: 0.4407 - val_acc: 0.9240\n",
      "Epoch 15/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.4756 - acc: 0.9064 - val_loss: 0.5338 - val_acc: 0.9157\n",
      "Epoch 16/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.4141 - acc: 0.9244 - val_loss: 0.4771 - val_acc: 0.9223\n",
      "Epoch 17/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.4105 - acc: 0.9163 - val_loss: 0.4414 - val_acc: 0.9236\n",
      "Epoch 18/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.4164 - acc: 0.9227 - val_loss: 0.4337 - val_acc: 0.9197\n",
      "Epoch 19/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.4048 - acc: 0.9214 - val_loss: 0.8254 - val_acc: 0.8262\n",
      "Epoch 20/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.4273 - acc: 0.9148 - val_loss: 0.4604 - val_acc: 0.9188\n",
      "Epoch 21/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.3943 - acc: 0.9238 - val_loss: 0.3981 - val_acc: 0.9231\n",
      "Epoch 22/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.3990 - acc: 0.9220 - val_loss: 0.3787 - val_acc: 0.9253\n",
      "Epoch 23/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.3573 - acc: 0.9251 - val_loss: 0.4678 - val_acc: 0.9240\n",
      "Epoch 24/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.3918 - acc: 0.9235 - val_loss: 0.4339 - val_acc: 0.9249\n",
      "Epoch 25/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.4186 - acc: 0.9227 - val_loss: 0.4259 - val_acc: 0.9253\n",
      "Epoch 26/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.3518 - acc: 0.9257 - val_loss: 0.3747 - val_acc: 0.9231\n",
      "Epoch 27/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3281 - acc: 0.9278 - val_loss: 0.3591 - val_acc: 0.9258\n",
      "Epoch 28/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3545 - acc: 0.9263 - val_loss: 0.4621 - val_acc: 0.9175\n",
      "Epoch 29/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3411 - acc: 0.9261 - val_loss: 0.3723 - val_acc: 0.9214\n",
      "Epoch 30/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3687 - acc: 0.9225 - val_loss: 0.4288 - val_acc: 0.9249\n",
      "Epoch 31/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.3653 - acc: 0.9197 - val_loss: 0.3858 - val_acc: 0.9223\n",
      "Epoch 32/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.3408 - acc: 0.9246 - val_loss: 0.3872 - val_acc: 0.9236\n",
      "Epoch 33/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.3670 - acc: 0.9220 - val_loss: 0.4380 - val_acc: 0.9214\n",
      "Epoch 34/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3603 - acc: 0.9197 - val_loss: 0.3746 - val_acc: 0.9240\n",
      "Epoch 35/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3329 - acc: 0.9253 - val_loss: 0.3810 - val_acc: 0.9227\n",
      "Epoch 36/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.3325 - acc: 0.9251 - val_loss: 0.3829 - val_acc: 0.9231\n",
      "Epoch 37/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.6587 - acc: 0.8810 - val_loss: 1.2671 - val_acc: 0.8083\n",
      "Epoch 38/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.5344 - acc: 0.9087 - val_loss: 0.4398 - val_acc: 0.9271\n",
      "Epoch 39/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.3910 - acc: 0.9251 - val_loss: 0.4753 - val_acc: 0.9262\n",
      "Epoch 40/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.3592 - acc: 0.9257 - val_loss: 0.4837 - val_acc: 0.9271\n",
      "Epoch 41/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3583 - acc: 0.9240 - val_loss: 0.4012 - val_acc: 0.9157\n",
      "Epoch 42/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.4535 - acc: 0.9255 - val_loss: 0.4857 - val_acc: 0.9153\n",
      "Epoch 43/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3965 - acc: 0.9279 - val_loss: 0.4067 - val_acc: 0.9275\n",
      "Epoch 44/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3739 - acc: 0.9274 - val_loss: 0.4474 - val_acc: 0.9245\n",
      "Epoch 45/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.4266 - acc: 0.9235 - val_loss: 0.3903 - val_acc: 0.9205\n",
      "Epoch 46/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.3341 - acc: 0.9272 - val_loss: 0.3693 - val_acc: 0.9197\n",
      "Epoch 47/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.3380 - acc: 0.9266 - val_loss: 0.3859 - val_acc: 0.9231\n",
      "Epoch 48/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3186 - acc: 0.9266 - val_loss: 0.3893 - val_acc: 0.9240\n",
      "Epoch 49/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3363 - acc: 0.9264 - val_loss: 0.4747 - val_acc: 0.9266\n",
      "Epoch 50/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.3992 - acc: 0.9259 - val_loss: 0.4423 - val_acc: 0.9201\n",
      "Epoch 51/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.3813 - acc: 0.9259 - val_loss: 0.3775 - val_acc: 0.9249\n",
      "Epoch 52/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3073 - acc: 0.9276 - val_loss: 0.3789 - val_acc: 0.9253\n",
      "Epoch 53/500\n",
      "5343/5343 [==============================] - 0s 15us/step - loss: 0.3383 - acc: 0.9233 - val_loss: 0.4318 - val_acc: 0.9223\n",
      "Epoch 54/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.3253 - acc: 0.9263 - val_loss: 0.4025 - val_acc: 0.9162\n",
      "Epoch 55/500\n",
      "5343/5343 [==============================] - 0s 15us/step - loss: 0.3579 - acc: 0.9206 - val_loss: 0.4152 - val_acc: 0.9153\n",
      "Epoch 56/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.3191 - acc: 0.9268 - val_loss: 0.4071 - val_acc: 0.9231\n",
      "Epoch 57/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3018 - acc: 0.9278 - val_loss: 0.3599 - val_acc: 0.9214\n",
      "Epoch 58/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.3039 - acc: 0.9283 - val_loss: 0.4133 - val_acc: 0.9210\n",
      "Epoch 59/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3058 - acc: 0.9272 - val_loss: 0.3985 - val_acc: 0.9279\n",
      "Epoch 60/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3146 - acc: 0.9270 - val_loss: 0.3959 - val_acc: 0.9262\n",
      "Epoch 61/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3187 - acc: 0.9285 - val_loss: 0.3894 - val_acc: 0.9253\n",
      "Epoch 62/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.3184 - acc: 0.9291 - val_loss: 0.3937 - val_acc: 0.9236\n",
      "Epoch 63/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3191 - acc: 0.9266 - val_loss: 0.3853 - val_acc: 0.9218\n",
      "Epoch 64/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.4520 - acc: 0.9092 - val_loss: 0.5253 - val_acc: 0.9022\n",
      "Epoch 65/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.3829 - acc: 0.9270 - val_loss: 0.4826 - val_acc: 0.9253\n",
      "Epoch 66/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.3568 - acc: 0.9253 - val_loss: 0.4793 - val_acc: 0.8969\n",
      "Epoch 67/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.3693 - acc: 0.9263 - val_loss: 0.4445 - val_acc: 0.9144\n",
      "Epoch 68/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3717 - acc: 0.9178 - val_loss: 0.4222 - val_acc: 0.9279\n",
      "Epoch 69/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3550 - acc: 0.9283 - val_loss: 0.4107 - val_acc: 0.9218\n",
      "Epoch 70/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3181 - acc: 0.9270 - val_loss: 0.4479 - val_acc: 0.8978\n",
      "Epoch 71/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.4017 - acc: 0.9278 - val_loss: 0.4662 - val_acc: 0.9170\n",
      "Epoch 72/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3510 - acc: 0.9253 - val_loss: 0.3876 - val_acc: 0.9253\n",
      "Epoch 73/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.3160 - acc: 0.9251 - val_loss: 0.3853 - val_acc: 0.9245\n",
      "Epoch 74/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2991 - acc: 0.9278 - val_loss: 0.3812 - val_acc: 0.9258\n",
      "Epoch 75/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.5076 - acc: 0.8984 - val_loss: 1.0109 - val_acc: 0.8332\n",
      "Epoch 76/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.4650 - acc: 0.9066 - val_loss: 0.3942 - val_acc: 0.9275\n",
      "Epoch 77/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3637 - acc: 0.9270 - val_loss: 0.4617 - val_acc: 0.9197\n",
      "Epoch 78/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3108 - acc: 0.9276 - val_loss: 0.3379 - val_acc: 0.9258\n",
      "Epoch 79/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.3035 - acc: 0.9264 - val_loss: 0.3551 - val_acc: 0.9236\n",
      "Epoch 80/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.3161 - acc: 0.9244 - val_loss: 0.5753 - val_acc: 0.8721\n",
      "Epoch 81/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3433 - acc: 0.9203 - val_loss: 0.3859 - val_acc: 0.9210\n",
      "Epoch 82/500\n",
      "5343/5343 [==============================] - 0s 14us/step - loss: 0.3249 - acc: 0.9276 - val_loss: 0.3663 - val_acc: 0.9253\n",
      "Epoch 83/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2922 - acc: 0.9270 - val_loss: 0.3466 - val_acc: 0.9227\n",
      "Epoch 84/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.3765 - acc: 0.9212 - val_loss: 0.5585 - val_acc: 0.9079\n",
      "Epoch 85/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3780 - acc: 0.9220 - val_loss: 0.4107 - val_acc: 0.9205\n",
      "Epoch 86/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.3730 - acc: 0.9199 - val_loss: 0.5073 - val_acc: 0.9092\n",
      "Epoch 87/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3815 - acc: 0.9208 - val_loss: 0.3742 - val_acc: 0.9245\n",
      "Epoch 88/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3063 - acc: 0.9255 - val_loss: 0.3559 - val_acc: 0.9253\n",
      "Epoch 89/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3225 - acc: 0.9255 - val_loss: 0.3620 - val_acc: 0.9253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3023 - acc: 0.9261 - val_loss: 0.3876 - val_acc: 0.9271\n",
      "Epoch 91/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.3336 - acc: 0.9266 - val_loss: 0.4400 - val_acc: 0.9236\n",
      "Epoch 92/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.3337 - acc: 0.9257 - val_loss: 0.3805 - val_acc: 0.9258\n",
      "Epoch 93/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3130 - acc: 0.9236 - val_loss: 0.3907 - val_acc: 0.9157\n",
      "Epoch 94/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3084 - acc: 0.9293 - val_loss: 0.4361 - val_acc: 0.9271\n",
      "Epoch 95/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.3535 - acc: 0.9281 - val_loss: 0.3860 - val_acc: 0.9279\n",
      "Epoch 96/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.3618 - acc: 0.9276 - val_loss: 0.5155 - val_acc: 0.9253\n",
      "Epoch 97/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3883 - acc: 0.9221 - val_loss: 0.4249 - val_acc: 0.9249\n",
      "Epoch 98/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.3283 - acc: 0.9279 - val_loss: 0.3819 - val_acc: 0.9271\n",
      "Epoch 99/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.3103 - acc: 0.9278 - val_loss: 0.3761 - val_acc: 0.9245\n",
      "Epoch 100/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3453 - acc: 0.9173 - val_loss: 0.4441 - val_acc: 0.9231\n",
      "Epoch 101/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3265 - acc: 0.9279 - val_loss: 0.3499 - val_acc: 0.9240\n",
      "Epoch 102/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.3097 - acc: 0.9281 - val_loss: 0.3458 - val_acc: 0.9236\n",
      "Epoch 103/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2997 - acc: 0.9291 - val_loss: 0.3518 - val_acc: 0.9266\n",
      "Epoch 104/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2945 - acc: 0.9285 - val_loss: 0.3289 - val_acc: 0.9266\n",
      "Epoch 105/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3092 - acc: 0.9270 - val_loss: 0.3604 - val_acc: 0.9170\n",
      "Epoch 106/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2972 - acc: 0.9276 - val_loss: 0.3451 - val_acc: 0.9262\n",
      "Epoch 107/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2801 - acc: 0.9306 - val_loss: 0.3348 - val_acc: 0.9258\n",
      "Epoch 108/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3001 - acc: 0.9253 - val_loss: 0.3654 - val_acc: 0.9271\n",
      "Epoch 109/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2799 - acc: 0.9296 - val_loss: 0.3731 - val_acc: 0.9262\n",
      "Epoch 110/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2740 - acc: 0.9296 - val_loss: 0.3653 - val_acc: 0.9218\n",
      "Epoch 111/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2829 - acc: 0.9293 - val_loss: 0.3462 - val_acc: 0.9240\n",
      "Epoch 112/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2882 - acc: 0.9308 - val_loss: 0.3358 - val_acc: 0.9258\n",
      "Epoch 113/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3017 - acc: 0.9296 - val_loss: 0.3635 - val_acc: 0.9249\n",
      "Epoch 114/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3046 - acc: 0.9276 - val_loss: 0.3527 - val_acc: 0.9236\n",
      "Epoch 115/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2883 - acc: 0.9291 - val_loss: 0.3843 - val_acc: 0.9205\n",
      "Epoch 116/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2924 - acc: 0.9283 - val_loss: 0.3793 - val_acc: 0.9227\n",
      "Epoch 117/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3501 - acc: 0.9291 - val_loss: 0.4098 - val_acc: 0.9253\n",
      "Epoch 118/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3316 - acc: 0.9279 - val_loss: 0.4226 - val_acc: 0.9183\n",
      "Epoch 119/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3328 - acc: 0.9279 - val_loss: 0.4429 - val_acc: 0.9197\n",
      "Epoch 120/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2976 - acc: 0.9287 - val_loss: 0.3571 - val_acc: 0.9240\n",
      "Epoch 121/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2817 - acc: 0.9287 - val_loss: 0.3437 - val_acc: 0.9231\n",
      "Epoch 122/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2864 - acc: 0.9289 - val_loss: 0.4363 - val_acc: 0.9271\n",
      "Epoch 123/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.3090 - acc: 0.9291 - val_loss: 0.3672 - val_acc: 0.9214\n",
      "Epoch 124/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2885 - acc: 0.9294 - val_loss: 0.3431 - val_acc: 0.9245\n",
      "Epoch 125/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2906 - acc: 0.9272 - val_loss: 0.3199 - val_acc: 0.9236\n",
      "Epoch 126/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2782 - acc: 0.9294 - val_loss: 0.3769 - val_acc: 0.9271\n",
      "Epoch 127/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2687 - acc: 0.9291 - val_loss: 0.3256 - val_acc: 0.9210\n",
      "Epoch 128/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2892 - acc: 0.9272 - val_loss: 0.3853 - val_acc: 0.9231\n",
      "Epoch 129/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2970 - acc: 0.9274 - val_loss: 0.3949 - val_acc: 0.9105\n",
      "Epoch 130/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3216 - acc: 0.9261 - val_loss: 0.3528 - val_acc: 0.9258\n",
      "Epoch 131/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3153 - acc: 0.9266 - val_loss: 0.3489 - val_acc: 0.9249\n",
      "Epoch 132/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2819 - acc: 0.9291 - val_loss: 0.3393 - val_acc: 0.9240\n",
      "Epoch 133/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.3256 - acc: 0.9259 - val_loss: 0.4131 - val_acc: 0.9258\n",
      "Epoch 134/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3160 - acc: 0.9263 - val_loss: 0.3851 - val_acc: 0.9201\n",
      "Epoch 135/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2775 - acc: 0.9296 - val_loss: 0.3589 - val_acc: 0.9227\n",
      "Epoch 136/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2979 - acc: 0.9272 - val_loss: 0.4002 - val_acc: 0.9249\n",
      "Epoch 137/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.3264 - acc: 0.9300 - val_loss: 0.3808 - val_acc: 0.9275\n",
      "Epoch 138/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.3177 - acc: 0.9300 - val_loss: 0.3865 - val_acc: 0.9258\n",
      "Epoch 139/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.3240 - acc: 0.9266 - val_loss: 0.4261 - val_acc: 0.9157\n",
      "Epoch 140/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.3302 - acc: 0.9240 - val_loss: 0.4049 - val_acc: 0.9162\n",
      "Epoch 141/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.3315 - acc: 0.9218 - val_loss: 0.4798 - val_acc: 0.9109\n",
      "Epoch 142/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.3448 - acc: 0.9240 - val_loss: 0.3957 - val_acc: 0.9183\n",
      "Epoch 143/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.3070 - acc: 0.9294 - val_loss: 0.3772 - val_acc: 0.9227\n",
      "Epoch 144/500\n",
      "5343/5343 [==============================] - 0s 27us/step - loss: 0.2856 - acc: 0.9272 - val_loss: 0.3433 - val_acc: 0.9179\n",
      "Epoch 145/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2707 - acc: 0.9296 - val_loss: 0.2994 - val_acc: 0.9253\n",
      "Epoch 146/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2690 - acc: 0.9296 - val_loss: 0.3283 - val_acc: 0.9236\n",
      "Epoch 147/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2755 - acc: 0.9278 - val_loss: 0.3605 - val_acc: 0.9240\n",
      "Epoch 148/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2885 - acc: 0.9253 - val_loss: 0.3529 - val_acc: 0.9210\n",
      "Epoch 149/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2775 - acc: 0.9281 - val_loss: 0.3146 - val_acc: 0.9258\n",
      "Epoch 150/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.3012 - acc: 0.9291 - val_loss: 0.3971 - val_acc: 0.9240\n",
      "Epoch 151/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.3176 - acc: 0.9291 - val_loss: 0.4401 - val_acc: 0.9258\n",
      "Epoch 152/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.3607 - acc: 0.9266 - val_loss: 0.3794 - val_acc: 0.9240\n",
      "Epoch 153/500\n",
      "5343/5343 [==============================] - 0s 15us/step - loss: 0.2841 - acc: 0.9283 - val_loss: 0.3256 - val_acc: 0.9275\n",
      "Epoch 154/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.3341 - acc: 0.9216 - val_loss: 0.4462 - val_acc: 0.9175\n",
      "Epoch 155/500\n",
      "5343/5343 [==============================] - 0s 15us/step - loss: 0.3071 - acc: 0.9281 - val_loss: 0.3462 - val_acc: 0.9262\n",
      "Epoch 156/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.3161 - acc: 0.9285 - val_loss: 0.3709 - val_acc: 0.9231\n",
      "Epoch 157/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.3246 - acc: 0.9298 - val_loss: 0.3687 - val_acc: 0.9275\n",
      "Epoch 158/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2911 - acc: 0.9302 - val_loss: 0.3166 - val_acc: 0.9249\n",
      "Epoch 159/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2604 - acc: 0.9319 - val_loss: 0.3387 - val_acc: 0.9245\n",
      "Epoch 160/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2628 - acc: 0.9330 - val_loss: 0.3184 - val_acc: 0.9249\n",
      "Epoch 161/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2751 - acc: 0.9279 - val_loss: 0.3351 - val_acc: 0.9236\n",
      "Epoch 162/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2572 - acc: 0.9315 - val_loss: 0.3119 - val_acc: 0.9258\n",
      "Epoch 163/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.3223 - acc: 0.9251 - val_loss: 0.3254 - val_acc: 0.9227\n",
      "Epoch 164/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2647 - acc: 0.9313 - val_loss: 0.3017 - val_acc: 0.9262\n",
      "Epoch 165/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2572 - acc: 0.9315 - val_loss: 0.2993 - val_acc: 0.9271\n",
      "Epoch 166/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2544 - acc: 0.9315 - val_loss: 0.3217 - val_acc: 0.9249\n",
      "Epoch 167/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2664 - acc: 0.9293 - val_loss: 0.3236 - val_acc: 0.9245\n",
      "Epoch 168/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2615 - acc: 0.9309 - val_loss: 0.3053 - val_acc: 0.9262\n",
      "Epoch 169/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2557 - acc: 0.9294 - val_loss: 0.3203 - val_acc: 0.9271\n",
      "Epoch 170/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2485 - acc: 0.9311 - val_loss: 0.3124 - val_acc: 0.9245\n",
      "Epoch 171/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2615 - acc: 0.9309 - val_loss: 0.3155 - val_acc: 0.9262\n",
      "Epoch 172/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2577 - acc: 0.9311 - val_loss: 0.3132 - val_acc: 0.9258\n",
      "Epoch 173/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2573 - acc: 0.9291 - val_loss: 0.3256 - val_acc: 0.9253\n",
      "Epoch 174/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2819 - acc: 0.9278 - val_loss: 0.3803 - val_acc: 0.9227\n",
      "Epoch 175/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2947 - acc: 0.9278 - val_loss: 0.3787 - val_acc: 0.9262\n",
      "Epoch 176/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.3164 - acc: 0.9248 - val_loss: 0.3768 - val_acc: 0.9201\n",
      "Epoch 177/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3314 - acc: 0.9268 - val_loss: 0.3499 - val_acc: 0.9240\n",
      "Epoch 178/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2875 - acc: 0.9272 - val_loss: 0.3034 - val_acc: 0.9288\n",
      "Epoch 179/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.3216 - acc: 0.9291 - val_loss: 0.4107 - val_acc: 0.9266\n",
      "Epoch 180/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.3193 - acc: 0.9276 - val_loss: 0.4364 - val_acc: 0.9249\n",
      "Epoch 181/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.3295 - acc: 0.9309 - val_loss: 0.3350 - val_acc: 0.9236\n",
      "Epoch 182/500\n",
      "5343/5343 [==============================] - 0s 14us/step - loss: 0.3051 - acc: 0.9218 - val_loss: 0.3462 - val_acc: 0.9231\n",
      "Epoch 183/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2807 - acc: 0.9279 - val_loss: 0.3082 - val_acc: 0.9271\n",
      "Epoch 184/500\n",
      "5343/5343 [==============================] - 0s 15us/step - loss: 0.2598 - acc: 0.9313 - val_loss: 0.3214 - val_acc: 0.9266\n",
      "Epoch 185/500\n",
      "5343/5343 [==============================] - 0s 15us/step - loss: 0.2600 - acc: 0.9319 - val_loss: 0.3176 - val_acc: 0.9227\n",
      "Epoch 186/500\n",
      "5343/5343 [==============================] - 0s 15us/step - loss: 0.3168 - acc: 0.9270 - val_loss: 0.3780 - val_acc: 0.9210\n",
      "Epoch 187/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2879 - acc: 0.9287 - val_loss: 0.3376 - val_acc: 0.9197\n",
      "Epoch 188/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2639 - acc: 0.9281 - val_loss: 0.3003 - val_acc: 0.9245\n",
      "Epoch 189/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2646 - acc: 0.9274 - val_loss: 0.3310 - val_acc: 0.9279\n",
      "Epoch 190/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2504 - acc: 0.9313 - val_loss: 0.3135 - val_acc: 0.9284\n",
      "Epoch 191/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2916 - acc: 0.9266 - val_loss: 0.3447 - val_acc: 0.9249\n",
      "Epoch 192/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2592 - acc: 0.9322 - val_loss: 0.3144 - val_acc: 0.9262\n",
      "Epoch 193/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2481 - acc: 0.9304 - val_loss: 0.3153 - val_acc: 0.9231\n",
      "Epoch 194/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2859 - acc: 0.9272 - val_loss: 0.4752 - val_acc: 0.9236\n",
      "Epoch 195/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3335 - acc: 0.9296 - val_loss: 0.3946 - val_acc: 0.9236\n",
      "Epoch 196/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2742 - acc: 0.9274 - val_loss: 0.3264 - val_acc: 0.9223\n",
      "Epoch 197/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2659 - acc: 0.9308 - val_loss: 0.2858 - val_acc: 0.9288\n",
      "Epoch 198/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2521 - acc: 0.9311 - val_loss: 0.3182 - val_acc: 0.9245\n",
      "Epoch 199/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3010 - acc: 0.9293 - val_loss: 0.3443 - val_acc: 0.9258\n",
      "Epoch 200/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2936 - acc: 0.9308 - val_loss: 0.3323 - val_acc: 0.9249\n",
      "Epoch 201/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2886 - acc: 0.9294 - val_loss: 0.4276 - val_acc: 0.9131\n",
      "Epoch 202/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2978 - acc: 0.9259 - val_loss: 0.3495 - val_acc: 0.9179\n",
      "Epoch 203/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2592 - acc: 0.9296 - val_loss: 0.2989 - val_acc: 0.9266\n",
      "Epoch 204/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2672 - acc: 0.9300 - val_loss: 0.3477 - val_acc: 0.9162\n",
      "Epoch 205/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2939 - acc: 0.9268 - val_loss: 0.3029 - val_acc: 0.9227\n",
      "Epoch 206/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3163 - acc: 0.9274 - val_loss: 0.3450 - val_acc: 0.9271\n",
      "Epoch 207/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.3124 - acc: 0.9304 - val_loss: 0.3591 - val_acc: 0.9262\n",
      "Epoch 208/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2642 - acc: 0.9300 - val_loss: 0.3026 - val_acc: 0.9266\n",
      "Epoch 209/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.3052 - acc: 0.9268 - val_loss: 0.3220 - val_acc: 0.9279\n",
      "Epoch 210/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2492 - acc: 0.9319 - val_loss: 0.2872 - val_acc: 0.9258\n",
      "Epoch 211/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2756 - acc: 0.9296 - val_loss: 0.4234 - val_acc: 0.9266\n",
      "Epoch 212/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2946 - acc: 0.9313 - val_loss: 0.3065 - val_acc: 0.9262\n",
      "Epoch 213/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2716 - acc: 0.9276 - val_loss: 0.3309 - val_acc: 0.9223\n",
      "Epoch 214/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2711 - acc: 0.9293 - val_loss: 0.3312 - val_acc: 0.9205\n",
      "Epoch 215/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.3074 - acc: 0.9285 - val_loss: 0.3262 - val_acc: 0.9227\n",
      "Epoch 216/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2720 - acc: 0.9283 - val_loss: 0.3042 - val_acc: 0.9249\n",
      "Epoch 217/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2501 - acc: 0.9311 - val_loss: 0.3187 - val_acc: 0.9218\n",
      "Epoch 218/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2510 - acc: 0.9287 - val_loss: 0.3289 - val_acc: 0.9249\n",
      "Epoch 219/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2550 - acc: 0.9322 - val_loss: 0.3151 - val_acc: 0.9258\n",
      "Epoch 220/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2580 - acc: 0.9313 - val_loss: 0.2850 - val_acc: 0.9262\n",
      "Epoch 221/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2461 - acc: 0.9317 - val_loss: 0.2916 - val_acc: 0.9249\n",
      "Epoch 222/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2523 - acc: 0.9315 - val_loss: 0.3629 - val_acc: 0.9279\n",
      "Epoch 223/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2774 - acc: 0.9285 - val_loss: 0.3100 - val_acc: 0.9218\n",
      "Epoch 224/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2527 - acc: 0.9300 - val_loss: 0.3116 - val_acc: 0.9258\n",
      "Epoch 225/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2551 - acc: 0.9306 - val_loss: 0.2910 - val_acc: 0.9249\n",
      "Epoch 226/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2475 - acc: 0.9313 - val_loss: 0.3054 - val_acc: 0.9249\n",
      "Epoch 227/500\n",
      "5343/5343 [==============================] - 0s 15us/step - loss: 0.2819 - acc: 0.9308 - val_loss: 0.3936 - val_acc: 0.9140\n",
      "Epoch 228/500\n",
      "5343/5343 [==============================] - 0s 15us/step - loss: 0.2908 - acc: 0.9263 - val_loss: 0.3849 - val_acc: 0.9258\n",
      "Epoch 229/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2808 - acc: 0.9287 - val_loss: 0.3119 - val_acc: 0.9266\n",
      "Epoch 230/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2584 - acc: 0.9302 - val_loss: 0.3210 - val_acc: 0.9240\n",
      "Epoch 231/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2489 - acc: 0.9302 - val_loss: 0.2872 - val_acc: 0.9249\n",
      "Epoch 232/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2530 - acc: 0.9321 - val_loss: 0.2984 - val_acc: 0.9245\n",
      "Epoch 233/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2963 - acc: 0.9309 - val_loss: 0.3819 - val_acc: 0.9210\n",
      "Epoch 234/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2786 - acc: 0.9306 - val_loss: 0.3236 - val_acc: 0.9236\n",
      "Epoch 235/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2553 - acc: 0.9306 - val_loss: 0.3212 - val_acc: 0.9240\n",
      "Epoch 236/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2494 - acc: 0.9321 - val_loss: 0.2918 - val_acc: 0.9271\n",
      "Epoch 237/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2465 - acc: 0.9313 - val_loss: 0.2778 - val_acc: 0.9262\n",
      "Epoch 238/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2557 - acc: 0.9298 - val_loss: 0.3624 - val_acc: 0.9162\n",
      "Epoch 239/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2633 - acc: 0.9274 - val_loss: 0.3272 - val_acc: 0.9262\n",
      "Epoch 240/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2815 - acc: 0.9306 - val_loss: 0.3640 - val_acc: 0.9258\n",
      "Epoch 241/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2575 - acc: 0.9322 - val_loss: 0.2902 - val_acc: 0.9266\n",
      "Epoch 242/500\n",
      "5343/5343 [==============================] - 0s 15us/step - loss: 0.2415 - acc: 0.9319 - val_loss: 0.2814 - val_acc: 0.9275\n",
      "Epoch 243/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2488 - acc: 0.9324 - val_loss: 0.3023 - val_acc: 0.9262\n",
      "Epoch 244/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2587 - acc: 0.9294 - val_loss: 0.2767 - val_acc: 0.9275\n",
      "Epoch 245/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2499 - acc: 0.9315 - val_loss: 0.3202 - val_acc: 0.9236\n",
      "Epoch 246/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2484 - acc: 0.9324 - val_loss: 0.3154 - val_acc: 0.9218\n",
      "Epoch 247/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2670 - acc: 0.9300 - val_loss: 0.3166 - val_acc: 0.9210\n",
      "Epoch 248/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2842 - acc: 0.9296 - val_loss: 0.3314 - val_acc: 0.9223\n",
      "Epoch 249/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.3025 - acc: 0.9251 - val_loss: 0.3200 - val_acc: 0.9249\n",
      "Epoch 250/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2566 - acc: 0.9317 - val_loss: 0.2762 - val_acc: 0.9249\n",
      "Epoch 251/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2631 - acc: 0.9309 - val_loss: 0.3033 - val_acc: 0.9249\n",
      "Epoch 252/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2468 - acc: 0.9319 - val_loss: 0.2837 - val_acc: 0.9258\n",
      "Epoch 253/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2394 - acc: 0.9337 - val_loss: 0.2885 - val_acc: 0.9262\n",
      "Epoch 254/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2569 - acc: 0.9313 - val_loss: 0.3176 - val_acc: 0.9227\n",
      "Epoch 255/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2593 - acc: 0.9294 - val_loss: 0.2917 - val_acc: 0.9279\n",
      "Epoch 256/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2524 - acc: 0.9317 - val_loss: 0.3543 - val_acc: 0.9236\n",
      "Epoch 257/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2662 - acc: 0.9311 - val_loss: 0.2870 - val_acc: 0.9240\n",
      "Epoch 258/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2491 - acc: 0.9315 - val_loss: 0.3051 - val_acc: 0.9231\n",
      "Epoch 259/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2526 - acc: 0.9300 - val_loss: 0.2832 - val_acc: 0.9253\n",
      "Epoch 260/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2398 - acc: 0.9313 - val_loss: 0.3053 - val_acc: 0.9266\n",
      "Epoch 261/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2423 - acc: 0.9326 - val_loss: 0.2839 - val_acc: 0.9245\n",
      "Epoch 262/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2867 - acc: 0.9268 - val_loss: 0.3260 - val_acc: 0.9231\n",
      "Epoch 263/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2835 - acc: 0.9300 - val_loss: 0.3370 - val_acc: 0.9223\n",
      "Epoch 264/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2608 - acc: 0.9306 - val_loss: 0.3005 - val_acc: 0.9266\n",
      "Epoch 265/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2417 - acc: 0.9322 - val_loss: 0.2912 - val_acc: 0.9236\n",
      "Epoch 266/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2379 - acc: 0.9304 - val_loss: 0.2715 - val_acc: 0.9279\n",
      "Epoch 267/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2400 - acc: 0.9319 - val_loss: 0.3003 - val_acc: 0.9284\n",
      "Epoch 268/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2343 - acc: 0.9315 - val_loss: 0.3088 - val_acc: 0.9262\n",
      "Epoch 269/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2354 - acc: 0.9321 - val_loss: 0.3110 - val_acc: 0.9218\n",
      "Epoch 270/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2430 - acc: 0.9308 - val_loss: 0.2888 - val_acc: 0.9275\n",
      "Epoch 271/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2582 - acc: 0.9294 - val_loss: 0.2934 - val_acc: 0.9223\n",
      "Epoch 272/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2461 - acc: 0.9294 - val_loss: 0.2838 - val_acc: 0.9240\n",
      "Epoch 273/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2356 - acc: 0.9328 - val_loss: 0.2793 - val_acc: 0.9253\n",
      "Epoch 274/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2311 - acc: 0.9324 - val_loss: 0.3020 - val_acc: 0.9236\n",
      "Epoch 275/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2532 - acc: 0.9291 - val_loss: 0.3103 - val_acc: 0.9240\n",
      "Epoch 276/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2871 - acc: 0.9300 - val_loss: 0.2907 - val_acc: 0.9253\n",
      "Epoch 277/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2428 - acc: 0.9293 - val_loss: 0.2685 - val_acc: 0.9297\n",
      "Epoch 278/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2409 - acc: 0.9322 - val_loss: 0.2777 - val_acc: 0.9253\n",
      "Epoch 279/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2393 - acc: 0.9319 - val_loss: 0.2941 - val_acc: 0.9279\n",
      "Epoch 280/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2304 - acc: 0.9337 - val_loss: 0.2889 - val_acc: 0.9253\n",
      "Epoch 281/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2325 - acc: 0.9343 - val_loss: 0.2808 - val_acc: 0.9245\n",
      "Epoch 282/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2426 - acc: 0.9317 - val_loss: 0.3406 - val_acc: 0.9249\n",
      "Epoch 283/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2490 - acc: 0.9313 - val_loss: 0.2844 - val_acc: 0.9271\n",
      "Epoch 284/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2321 - acc: 0.9309 - val_loss: 0.2701 - val_acc: 0.9284\n",
      "Epoch 285/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2367 - acc: 0.9345 - val_loss: 0.2726 - val_acc: 0.9249\n",
      "Epoch 286/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2321 - acc: 0.9351 - val_loss: 0.2771 - val_acc: 0.9249\n",
      "Epoch 287/500\n",
      "5343/5343 [==============================] - 0s 15us/step - loss: 0.2310 - acc: 0.9321 - val_loss: 0.2874 - val_acc: 0.9253\n",
      "Epoch 288/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2418 - acc: 0.9308 - val_loss: 0.2686 - val_acc: 0.9271\n",
      "Epoch 289/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2290 - acc: 0.9347 - val_loss: 0.2891 - val_acc: 0.9223\n",
      "Epoch 290/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2363 - acc: 0.9328 - val_loss: 0.2909 - val_acc: 0.9258\n",
      "Epoch 291/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2465 - acc: 0.9319 - val_loss: 0.2680 - val_acc: 0.9275\n",
      "Epoch 292/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2351 - acc: 0.9332 - val_loss: 0.2888 - val_acc: 0.9258\n",
      "Epoch 293/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2367 - acc: 0.9321 - val_loss: 0.3110 - val_acc: 0.9210\n",
      "Epoch 294/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2341 - acc: 0.9319 - val_loss: 0.2829 - val_acc: 0.9262\n",
      "Epoch 295/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2541 - acc: 0.9311 - val_loss: 0.2726 - val_acc: 0.9253\n",
      "Epoch 296/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2518 - acc: 0.9313 - val_loss: 0.3472 - val_acc: 0.9218\n",
      "Epoch 297/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2698 - acc: 0.9317 - val_loss: 0.2824 - val_acc: 0.9266\n",
      "Epoch 298/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2447 - acc: 0.9300 - val_loss: 0.2779 - val_acc: 0.9253\n",
      "Epoch 299/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2290 - acc: 0.9336 - val_loss: 0.2966 - val_acc: 0.9266\n",
      "Epoch 300/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2292 - acc: 0.9337 - val_loss: 0.2930 - val_acc: 0.9284\n",
      "Epoch 301/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2398 - acc: 0.9326 - val_loss: 0.2745 - val_acc: 0.9258\n",
      "Epoch 302/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2527 - acc: 0.9300 - val_loss: 0.2995 - val_acc: 0.9231\n",
      "Epoch 303/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2324 - acc: 0.9332 - val_loss: 0.2908 - val_acc: 0.9271\n",
      "Epoch 304/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2512 - acc: 0.9317 - val_loss: 0.3203 - val_acc: 0.9279\n",
      "Epoch 305/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2579 - acc: 0.9298 - val_loss: 0.3411 - val_acc: 0.9236\n",
      "Epoch 306/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2581 - acc: 0.9322 - val_loss: 0.2725 - val_acc: 0.9271\n",
      "Epoch 307/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2483 - acc: 0.9313 - val_loss: 0.3110 - val_acc: 0.9227\n",
      "Epoch 308/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2561 - acc: 0.9306 - val_loss: 0.2720 - val_acc: 0.9279\n",
      "Epoch 309/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2378 - acc: 0.9324 - val_loss: 0.2696 - val_acc: 0.9275\n",
      "Epoch 310/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2467 - acc: 0.9328 - val_loss: 0.2837 - val_acc: 0.9245\n",
      "Epoch 311/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2339 - acc: 0.9336 - val_loss: 0.2879 - val_acc: 0.9266\n",
      "Epoch 312/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2435 - acc: 0.9309 - val_loss: 0.2845 - val_acc: 0.9236\n",
      "Epoch 313/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2467 - acc: 0.9328 - val_loss: 0.3243 - val_acc: 0.9240\n",
      "Epoch 314/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2667 - acc: 0.9281 - val_loss: 0.3136 - val_acc: 0.9253\n",
      "Epoch 315/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2434 - acc: 0.9319 - val_loss: 0.2747 - val_acc: 0.9271\n",
      "Epoch 316/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2343 - acc: 0.9322 - val_loss: 0.2790 - val_acc: 0.9271\n",
      "Epoch 317/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2281 - acc: 0.9322 - val_loss: 0.2931 - val_acc: 0.9218\n",
      "Epoch 318/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2306 - acc: 0.9319 - val_loss: 0.2735 - val_acc: 0.9262\n",
      "Epoch 319/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2255 - acc: 0.9330 - val_loss: 0.2760 - val_acc: 0.9266\n",
      "Epoch 320/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2275 - acc: 0.9336 - val_loss: 0.2850 - val_acc: 0.9266\n",
      "Epoch 321/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2278 - acc: 0.9343 - val_loss: 0.2963 - val_acc: 0.9253\n",
      "Epoch 322/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2295 - acc: 0.9332 - val_loss: 0.2804 - val_acc: 0.9262\n",
      "Epoch 323/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2510 - acc: 0.9328 - val_loss: 0.2927 - val_acc: 0.9271\n",
      "Epoch 324/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2389 - acc: 0.9330 - val_loss: 0.2710 - val_acc: 0.9266\n",
      "Epoch 325/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2282 - acc: 0.9328 - val_loss: 0.2787 - val_acc: 0.9258\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2249 - acc: 0.9356 - val_loss: 0.2857 - val_acc: 0.9262\n",
      "Epoch 327/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2330 - acc: 0.9321 - val_loss: 0.2798 - val_acc: 0.9271\n",
      "Epoch 328/500\n",
      "5343/5343 [==============================] - 0s 14us/step - loss: 0.2316 - acc: 0.9308 - val_loss: 0.2654 - val_acc: 0.9275\n",
      "Epoch 329/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2295 - acc: 0.9349 - val_loss: 0.2830 - val_acc: 0.9266\n",
      "Epoch 330/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2451 - acc: 0.9317 - val_loss: 0.3442 - val_acc: 0.9214\n",
      "Epoch 331/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2482 - acc: 0.9293 - val_loss: 0.2779 - val_acc: 0.9249\n",
      "Epoch 332/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2419 - acc: 0.9332 - val_loss: 0.2790 - val_acc: 0.9297\n",
      "Epoch 333/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2262 - acc: 0.9352 - val_loss: 0.2745 - val_acc: 0.9262\n",
      "Epoch 334/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2450 - acc: 0.9319 - val_loss: 0.3229 - val_acc: 0.9279\n",
      "Epoch 335/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2701 - acc: 0.9296 - val_loss: 0.2852 - val_acc: 0.9249\n",
      "Epoch 336/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2394 - acc: 0.9336 - val_loss: 0.2776 - val_acc: 0.9262\n",
      "Epoch 337/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2390 - acc: 0.9324 - val_loss: 0.2701 - val_acc: 0.9258\n",
      "Epoch 338/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2355 - acc: 0.9337 - val_loss: 0.2811 - val_acc: 0.9271\n",
      "Epoch 339/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2295 - acc: 0.9339 - val_loss: 0.2658 - val_acc: 0.9275\n",
      "Epoch 340/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2314 - acc: 0.9326 - val_loss: 0.2738 - val_acc: 0.9240\n",
      "Epoch 341/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2628 - acc: 0.9313 - val_loss: 0.3061 - val_acc: 0.9271\n",
      "Epoch 342/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2352 - acc: 0.9321 - val_loss: 0.2746 - val_acc: 0.9284\n",
      "Epoch 343/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2462 - acc: 0.9296 - val_loss: 0.3436 - val_acc: 0.9253\n",
      "Epoch 344/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2569 - acc: 0.9302 - val_loss: 0.2768 - val_acc: 0.9293\n",
      "Epoch 345/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2416 - acc: 0.9302 - val_loss: 0.2787 - val_acc: 0.9275\n",
      "Epoch 346/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2342 - acc: 0.9326 - val_loss: 0.2711 - val_acc: 0.9271\n",
      "Epoch 347/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2259 - acc: 0.9330 - val_loss: 0.2665 - val_acc: 0.9279\n",
      "Epoch 348/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2275 - acc: 0.9336 - val_loss: 0.3194 - val_acc: 0.9253\n",
      "Epoch 349/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2385 - acc: 0.9324 - val_loss: 0.2987 - val_acc: 0.9214\n",
      "Epoch 350/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2468 - acc: 0.9311 - val_loss: 0.2911 - val_acc: 0.9271\n",
      "Epoch 351/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2319 - acc: 0.9339 - val_loss: 0.2753 - val_acc: 0.9249\n",
      "Epoch 352/500\n",
      "5343/5343 [==============================] - 0s 34us/step - loss: 0.2289 - acc: 0.9345 - val_loss: 0.2877 - val_acc: 0.9262\n",
      "Epoch 353/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2330 - acc: 0.9317 - val_loss: 0.2772 - val_acc: 0.9245\n",
      "Epoch 354/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2332 - acc: 0.9339 - val_loss: 0.2718 - val_acc: 0.9258\n",
      "Epoch 355/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2498 - acc: 0.9319 - val_loss: 0.3020 - val_acc: 0.9223\n",
      "Epoch 356/500\n",
      "5343/5343 [==============================] - 0s 16us/step - loss: 0.2575 - acc: 0.9309 - val_loss: 0.2693 - val_acc: 0.9266\n",
      "Epoch 357/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2248 - acc: 0.9334 - val_loss: 0.2984 - val_acc: 0.9262\n",
      "Epoch 358/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2278 - acc: 0.9339 - val_loss: 0.2791 - val_acc: 0.9262\n",
      "Epoch 359/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2237 - acc: 0.9360 - val_loss: 0.2618 - val_acc: 0.9284\n",
      "Epoch 360/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2331 - acc: 0.9367 - val_loss: 0.2659 - val_acc: 0.9288\n",
      "Epoch 361/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2290 - acc: 0.9336 - val_loss: 0.2967 - val_acc: 0.9279\n",
      "Epoch 362/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2345 - acc: 0.9313 - val_loss: 0.2731 - val_acc: 0.9275\n",
      "Epoch 363/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2254 - acc: 0.9349 - val_loss: 0.2708 - val_acc: 0.9258\n",
      "Epoch 364/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2268 - acc: 0.9339 - val_loss: 0.2808 - val_acc: 0.9284\n",
      "Epoch 365/500\n",
      "5343/5343 [==============================] - 0s 31us/step - loss: 0.2291 - acc: 0.9360 - val_loss: 0.2695 - val_acc: 0.9266\n",
      "Epoch 366/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2346 - acc: 0.9309 - val_loss: 0.3037 - val_acc: 0.9192\n",
      "Epoch 367/500\n",
      "5343/5343 [==============================] - 0s 29us/step - loss: 0.2297 - acc: 0.9324 - val_loss: 0.2680 - val_acc: 0.9262\n",
      "Epoch 368/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2253 - acc: 0.9349 - val_loss: 0.2687 - val_acc: 0.9284\n",
      "Epoch 369/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2293 - acc: 0.9337 - val_loss: 0.2533 - val_acc: 0.9275\n",
      "Epoch 370/500\n",
      "5343/5343 [==============================] - 0s 29us/step - loss: 0.2382 - acc: 0.9317 - val_loss: 0.2718 - val_acc: 0.9266\n",
      "Epoch 371/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2268 - acc: 0.9352 - val_loss: 0.2612 - val_acc: 0.9275\n",
      "Epoch 372/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2349 - acc: 0.9332 - val_loss: 0.2642 - val_acc: 0.9262\n",
      "Epoch 373/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2371 - acc: 0.9326 - val_loss: 0.2623 - val_acc: 0.9279\n",
      "Epoch 374/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2223 - acc: 0.9360 - val_loss: 0.3233 - val_acc: 0.9249\n",
      "Epoch 375/500\n",
      "5343/5343 [==============================] - 0s 28us/step - loss: 0.2353 - acc: 0.9324 - val_loss: 0.2831 - val_acc: 0.9245\n",
      "Epoch 376/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2223 - acc: 0.9349 - val_loss: 0.2571 - val_acc: 0.9271\n",
      "Epoch 377/500\n",
      "5343/5343 [==============================] - 0s 29us/step - loss: 0.2402 - acc: 0.9322 - val_loss: 0.2609 - val_acc: 0.9266\n",
      "Epoch 378/500\n",
      "5343/5343 [==============================] - 0s 27us/step - loss: 0.2368 - acc: 0.9336 - val_loss: 0.2763 - val_acc: 0.9271\n",
      "Epoch 379/500\n",
      "5343/5343 [==============================] - 0s 29us/step - loss: 0.2319 - acc: 0.9341 - val_loss: 0.2609 - val_acc: 0.9271\n",
      "Epoch 380/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2213 - acc: 0.9343 - val_loss: 0.2606 - val_acc: 0.9275\n",
      "Epoch 381/500\n",
      "5343/5343 [==============================] - 0s 29us/step - loss: 0.2332 - acc: 0.9345 - val_loss: 0.2676 - val_acc: 0.9262\n",
      "Epoch 382/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2301 - acc: 0.9330 - val_loss: 0.2949 - val_acc: 0.9266\n",
      "Epoch 383/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2341 - acc: 0.9315 - val_loss: 0.2748 - val_acc: 0.9266\n",
      "Epoch 384/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2252 - acc: 0.9332 - val_loss: 0.2683 - val_acc: 0.9245\n",
      "Epoch 385/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2223 - acc: 0.9362 - val_loss: 0.2678 - val_acc: 0.9262\n",
      "Epoch 386/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2309 - acc: 0.9315 - val_loss: 0.2625 - val_acc: 0.9266\n",
      "Epoch 387/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2304 - acc: 0.9330 - val_loss: 0.2643 - val_acc: 0.9279\n",
      "Epoch 388/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2249 - acc: 0.9341 - val_loss: 0.2787 - val_acc: 0.9253\n",
      "Epoch 389/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2231 - acc: 0.9352 - val_loss: 0.2621 - val_acc: 0.9266\n",
      "Epoch 390/500\n",
      "5343/5343 [==============================] - 0s 35us/step - loss: 0.2354 - acc: 0.9334 - val_loss: 0.2691 - val_acc: 0.9266\n",
      "Epoch 391/500\n",
      "5343/5343 [==============================] - 0s 30us/step - loss: 0.2281 - acc: 0.9337 - val_loss: 0.2856 - val_acc: 0.9262\n",
      "Epoch 392/500\n",
      "5343/5343 [==============================] - 0s 31us/step - loss: 0.2240 - acc: 0.9341 - val_loss: 0.2632 - val_acc: 0.9271\n",
      "Epoch 393/500\n",
      "5343/5343 [==============================] - 0s 27us/step - loss: 0.2219 - acc: 0.9341 - val_loss: 0.2610 - val_acc: 0.9271\n",
      "Epoch 394/500\n",
      "5343/5343 [==============================] - 0s 29us/step - loss: 0.2212 - acc: 0.9349 - val_loss: 0.2627 - val_acc: 0.9266\n",
      "Epoch 395/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2177 - acc: 0.9354 - val_loss: 0.2691 - val_acc: 0.9271\n",
      "Epoch 396/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2225 - acc: 0.9343 - val_loss: 0.2633 - val_acc: 0.9288\n",
      "Epoch 397/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2206 - acc: 0.9345 - val_loss: 0.2791 - val_acc: 0.9279\n",
      "Epoch 398/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2206 - acc: 0.9339 - val_loss: 0.2734 - val_acc: 0.9245\n",
      "Epoch 399/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2273 - acc: 0.9319 - val_loss: 0.2793 - val_acc: 0.9262\n",
      "Epoch 400/500\n",
      "5343/5343 [==============================] - 0s 30us/step - loss: 0.2281 - acc: 0.9334 - val_loss: 0.2679 - val_acc: 0.9249\n",
      "Epoch 401/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2236 - acc: 0.9337 - val_loss: 0.2774 - val_acc: 0.9249\n",
      "Epoch 402/500\n",
      "5343/5343 [==============================] - 0s 34us/step - loss: 0.2181 - acc: 0.9364 - val_loss: 0.2707 - val_acc: 0.9266\n",
      "Epoch 403/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2181 - acc: 0.9347 - val_loss: 0.2679 - val_acc: 0.9258\n",
      "Epoch 404/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2228 - acc: 0.9356 - val_loss: 0.2769 - val_acc: 0.9249\n",
      "Epoch 405/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2225 - acc: 0.9352 - val_loss: 0.2695 - val_acc: 0.9258\n",
      "Epoch 406/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2204 - acc: 0.9345 - val_loss: 0.2669 - val_acc: 0.9236\n",
      "Epoch 407/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2179 - acc: 0.9349 - val_loss: 0.2675 - val_acc: 0.9236\n",
      "Epoch 408/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2169 - acc: 0.9354 - val_loss: 0.2665 - val_acc: 0.9279\n",
      "Epoch 409/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2168 - acc: 0.9354 - val_loss: 0.2732 - val_acc: 0.9240\n",
      "Epoch 410/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2232 - acc: 0.9343 - val_loss: 0.2637 - val_acc: 0.9271\n",
      "Epoch 411/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2235 - acc: 0.9343 - val_loss: 0.2733 - val_acc: 0.9262\n",
      "Epoch 412/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2192 - acc: 0.9358 - val_loss: 0.2671 - val_acc: 0.9266\n",
      "Epoch 413/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2204 - acc: 0.9352 - val_loss: 0.2717 - val_acc: 0.9240\n",
      "Epoch 414/500\n",
      "5343/5343 [==============================] - 0s 28us/step - loss: 0.2237 - acc: 0.9347 - val_loss: 0.2936 - val_acc: 0.9266\n",
      "Epoch 415/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2311 - acc: 0.9328 - val_loss: 0.2826 - val_acc: 0.9253\n",
      "Epoch 416/500\n",
      "5343/5343 [==============================] - 0s 29us/step - loss: 0.2365 - acc: 0.9328 - val_loss: 0.2846 - val_acc: 0.9262\n",
      "Epoch 417/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2330 - acc: 0.9322 - val_loss: 0.2764 - val_acc: 0.9245\n",
      "Epoch 418/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2241 - acc: 0.9337 - val_loss: 0.2819 - val_acc: 0.9249\n",
      "Epoch 419/500\n",
      "5343/5343 [==============================] - 0s 28us/step - loss: 0.2273 - acc: 0.9319 - val_loss: 0.2945 - val_acc: 0.9245\n",
      "Epoch 420/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2232 - acc: 0.9347 - val_loss: 0.2666 - val_acc: 0.9284\n",
      "Epoch 421/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2182 - acc: 0.9347 - val_loss: 0.2896 - val_acc: 0.9271\n",
      "Epoch 422/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2245 - acc: 0.9339 - val_loss: 0.2640 - val_acc: 0.9271\n",
      "Epoch 423/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2216 - acc: 0.9345 - val_loss: 0.2872 - val_acc: 0.9249\n",
      "Epoch 424/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2305 - acc: 0.9315 - val_loss: 0.2854 - val_acc: 0.9258\n",
      "Epoch 425/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2162 - acc: 0.9349 - val_loss: 0.2733 - val_acc: 0.9249\n",
      "Epoch 426/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2178 - acc: 0.9360 - val_loss: 0.2771 - val_acc: 0.9245\n",
      "Epoch 427/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2186 - acc: 0.9360 - val_loss: 0.2703 - val_acc: 0.9227\n",
      "Epoch 428/500\n",
      "5343/5343 [==============================] - 0s 33us/step - loss: 0.2206 - acc: 0.9347 - val_loss: 0.2795 - val_acc: 0.9262\n",
      "Epoch 429/500\n",
      "5343/5343 [==============================] - 0s 31us/step - loss: 0.2254 - acc: 0.9334 - val_loss: 0.2783 - val_acc: 0.9223\n",
      "Epoch 430/500\n",
      "5343/5343 [==============================] - 0s 28us/step - loss: 0.2234 - acc: 0.9339 - val_loss: 0.2612 - val_acc: 0.9249\n",
      "Epoch 431/500\n",
      "5343/5343 [==============================] - 0s 29us/step - loss: 0.2238 - acc: 0.9326 - val_loss: 0.2841 - val_acc: 0.9240\n",
      "Epoch 432/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2203 - acc: 0.9352 - val_loss: 0.2639 - val_acc: 0.9253\n",
      "Epoch 433/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2221 - acc: 0.9349 - val_loss: 0.2690 - val_acc: 0.9262\n",
      "Epoch 434/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2246 - acc: 0.9351 - val_loss: 0.2804 - val_acc: 0.9262\n",
      "Epoch 435/500\n",
      "5343/5343 [==============================] - 0s 27us/step - loss: 0.2185 - acc: 0.9354 - val_loss: 0.2669 - val_acc: 0.9271\n",
      "Epoch 436/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2155 - acc: 0.9360 - val_loss: 0.2679 - val_acc: 0.9275\n",
      "Epoch 437/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2157 - acc: 0.9364 - val_loss: 0.2848 - val_acc: 0.9271\n",
      "Epoch 438/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2204 - acc: 0.9351 - val_loss: 0.2640 - val_acc: 0.9266\n",
      "Epoch 439/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2148 - acc: 0.9364 - val_loss: 0.2677 - val_acc: 0.9266\n",
      "Epoch 440/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2150 - acc: 0.9373 - val_loss: 0.2753 - val_acc: 0.9266\n",
      "Epoch 441/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2183 - acc: 0.9343 - val_loss: 0.2694 - val_acc: 0.9279\n",
      "Epoch 442/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2218 - acc: 0.9351 - val_loss: 0.2677 - val_acc: 0.9245\n",
      "Epoch 443/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2231 - acc: 0.9330 - val_loss: 0.2689 - val_acc: 0.9271\n",
      "Epoch 444/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2134 - acc: 0.9369 - val_loss: 0.2733 - val_acc: 0.9266\n",
      "Epoch 445/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2214 - acc: 0.9343 - val_loss: 0.2684 - val_acc: 0.9258\n",
      "Epoch 446/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2375 - acc: 0.9336 - val_loss: 0.2903 - val_acc: 0.9271\n",
      "Epoch 447/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2222 - acc: 0.9351 - val_loss: 0.2834 - val_acc: 0.9253\n",
      "Epoch 448/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2184 - acc: 0.9354 - val_loss: 0.2732 - val_acc: 0.9245\n",
      "Epoch 449/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2174 - acc: 0.9347 - val_loss: 0.2688 - val_acc: 0.9279\n",
      "Epoch 450/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2176 - acc: 0.9351 - val_loss: 0.2764 - val_acc: 0.9240\n",
      "Epoch 451/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2163 - acc: 0.9354 - val_loss: 0.2637 - val_acc: 0.9271\n",
      "Epoch 452/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2168 - acc: 0.9356 - val_loss: 0.2874 - val_acc: 0.9293\n",
      "Epoch 453/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2150 - acc: 0.9364 - val_loss: 0.2733 - val_acc: 0.9245\n",
      "Epoch 454/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2164 - acc: 0.9358 - val_loss: 0.2687 - val_acc: 0.9249\n",
      "Epoch 455/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2161 - acc: 0.9362 - val_loss: 0.2807 - val_acc: 0.9231\n",
      "Epoch 456/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2203 - acc: 0.9356 - val_loss: 0.2805 - val_acc: 0.9231\n",
      "Epoch 457/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2284 - acc: 0.9330 - val_loss: 0.2856 - val_acc: 0.9262\n",
      "Epoch 458/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2181 - acc: 0.9354 - val_loss: 0.2715 - val_acc: 0.9258\n",
      "Epoch 459/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2225 - acc: 0.9341 - val_loss: 0.2710 - val_acc: 0.9271\n",
      "Epoch 460/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2132 - acc: 0.9366 - val_loss: 0.2688 - val_acc: 0.9262\n",
      "Epoch 461/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2237 - acc: 0.9345 - val_loss: 0.2769 - val_acc: 0.9223\n",
      "Epoch 462/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2196 - acc: 0.9347 - val_loss: 0.2737 - val_acc: 0.9249\n",
      "Epoch 463/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2160 - acc: 0.9343 - val_loss: 0.2715 - val_acc: 0.9262\n",
      "Epoch 464/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2194 - acc: 0.9354 - val_loss: 0.2771 - val_acc: 0.9258\n",
      "Epoch 465/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2189 - acc: 0.9356 - val_loss: 0.2675 - val_acc: 0.9262\n",
      "Epoch 466/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2144 - acc: 0.9360 - val_loss: 0.2701 - val_acc: 0.9266\n",
      "Epoch 467/500\n",
      "5343/5343 [==============================] - 0s 26us/step - loss: 0.2199 - acc: 0.9347 - val_loss: 0.2642 - val_acc: 0.9262\n",
      "Epoch 468/500\n",
      "5343/5343 [==============================] - 0s 31us/step - loss: 0.2147 - acc: 0.9352 - val_loss: 0.2749 - val_acc: 0.9271\n",
      "Epoch 469/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2152 - acc: 0.9354 - val_loss: 0.2665 - val_acc: 0.9262\n",
      "Epoch 470/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2172 - acc: 0.9366 - val_loss: 0.2780 - val_acc: 0.9266\n",
      "Epoch 471/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2136 - acc: 0.9354 - val_loss: 0.2836 - val_acc: 0.9262\n",
      "Epoch 472/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2175 - acc: 0.9369 - val_loss: 0.2673 - val_acc: 0.9262\n",
      "Epoch 473/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2176 - acc: 0.9352 - val_loss: 0.2671 - val_acc: 0.9266\n",
      "Epoch 474/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2162 - acc: 0.9352 - val_loss: 0.2819 - val_acc: 0.9275\n",
      "Epoch 475/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2139 - acc: 0.9367 - val_loss: 0.2750 - val_acc: 0.9240\n",
      "Epoch 476/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2128 - acc: 0.9366 - val_loss: 0.2698 - val_acc: 0.9249\n",
      "Epoch 477/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2131 - acc: 0.9373 - val_loss: 0.2691 - val_acc: 0.9271\n",
      "Epoch 478/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2121 - acc: 0.9371 - val_loss: 0.2764 - val_acc: 0.9249\n",
      "Epoch 479/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2194 - acc: 0.9351 - val_loss: 0.2736 - val_acc: 0.9266\n",
      "Epoch 480/500\n",
      "5343/5343 [==============================] - 0s 23us/step - loss: 0.2157 - acc: 0.9349 - val_loss: 0.2661 - val_acc: 0.9266\n",
      "Epoch 481/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2163 - acc: 0.9343 - val_loss: 0.2683 - val_acc: 0.9266\n",
      "Epoch 482/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2154 - acc: 0.9358 - val_loss: 0.2686 - val_acc: 0.9258\n",
      "Epoch 483/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2127 - acc: 0.9358 - val_loss: 0.2754 - val_acc: 0.9236\n",
      "Epoch 484/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2149 - acc: 0.9366 - val_loss: 0.2736 - val_acc: 0.9240\n",
      "Epoch 485/500\n",
      "5343/5343 [==============================] - 0s 25us/step - loss: 0.2147 - acc: 0.9356 - val_loss: 0.2704 - val_acc: 0.9258\n",
      "Epoch 486/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2195 - acc: 0.9324 - val_loss: 0.2774 - val_acc: 0.9258\n",
      "Epoch 487/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2159 - acc: 0.9364 - val_loss: 0.2695 - val_acc: 0.9258\n",
      "Epoch 488/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2240 - acc: 0.9332 - val_loss: 0.2736 - val_acc: 0.9245\n",
      "Epoch 489/500\n",
      "5343/5343 [==============================] - 0s 17us/step - loss: 0.2153 - acc: 0.9349 - val_loss: 0.2760 - val_acc: 0.9236\n",
      "Epoch 490/500\n",
      "5343/5343 [==============================] - 0s 18us/step - loss: 0.2119 - acc: 0.9366 - val_loss: 0.2714 - val_acc: 0.9249\n",
      "Epoch 491/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2198 - acc: 0.9356 - val_loss: 0.2703 - val_acc: 0.9275\n",
      "Epoch 492/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2175 - acc: 0.9356 - val_loss: 0.2876 - val_acc: 0.9275\n",
      "Epoch 493/500\n",
      "5343/5343 [==============================] - 0s 21us/step - loss: 0.2166 - acc: 0.9351 - val_loss: 0.2750 - val_acc: 0.9236\n",
      "Epoch 494/500\n",
      "5343/5343 [==============================] - 0s 24us/step - loss: 0.2118 - acc: 0.9364 - val_loss: 0.2683 - val_acc: 0.9262\n",
      "Epoch 495/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2118 - acc: 0.9377 - val_loss: 0.2693 - val_acc: 0.9266\n",
      "Epoch 496/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2135 - acc: 0.9334 - val_loss: 0.2673 - val_acc: 0.9266\n",
      "Epoch 497/500\n",
      "5343/5343 [==============================] - 0s 22us/step - loss: 0.2124 - acc: 0.9371 - val_loss: 0.2698 - val_acc: 0.9275\n",
      "Epoch 498/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2136 - acc: 0.9364 - val_loss: 0.2737 - val_acc: 0.9258\n",
      "Epoch 499/500\n",
      "5343/5343 [==============================] - 0s 19us/step - loss: 0.2161 - acc: 0.9358 - val_loss: 0.2714 - val_acc: 0.9249\n",
      "Epoch 500/500\n",
      "5343/5343 [==============================] - 0s 20us/step - loss: 0.2140 - acc: 0.9369 - val_loss: 0.2732 - val_acc: 0.9271\n",
      "2290/2290 [==============================] - 0s 4us/step\n",
      "100 403 403 403 12494 4534 403 1093 690\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "4534 4534\n",
      "../linkPrediction/dataframes/apnea\n",
      "article (4534, 7, 11) --------------------------------------------------------------------\n",
      "(4534, 11) (4534,)\n",
      "[4534, 11, 1]\n",
      "(3173, 11) (3173,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3173 samples, validate on 1361 samples\n",
      "Epoch 1/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 1.5135 - acc: 0.7000 - val_loss: 0.5375 - val_acc: 0.9420\n",
      "Epoch 2/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.4964 - acc: 0.9395 - val_loss: 0.5036 - val_acc: 0.9427\n",
      "Epoch 3/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.4542 - acc: 0.9395 - val_loss: 0.4529 - val_acc: 0.9427\n",
      "Epoch 4/500\n",
      "3173/3173 [==============================] - ETA: 0s - loss: 0.4036 - acc: 0.940 - 0s 21us/step - loss: 0.4161 - acc: 0.9382 - val_loss: 0.4204 - val_acc: 0.9420\n",
      "Epoch 5/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.3828 - acc: 0.9398 - val_loss: 0.4125 - val_acc: 0.9405\n",
      "Epoch 6/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.3806 - acc: 0.9408 - val_loss: 0.4223 - val_acc: 0.9427\n",
      "Epoch 7/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.3876 - acc: 0.9401 - val_loss: 0.4022 - val_acc: 0.9427\n",
      "Epoch 8/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.3583 - acc: 0.9408 - val_loss: 0.3737 - val_acc: 0.9427\n",
      "Epoch 9/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.3193 - acc: 0.9395 - val_loss: 0.3387 - val_acc: 0.9420\n",
      "Epoch 10/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.3139 - acc: 0.9382 - val_loss: 0.3335 - val_acc: 0.9427\n",
      "Epoch 11/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2958 - acc: 0.9398 - val_loss: 0.3199 - val_acc: 0.9427\n",
      "Epoch 12/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2896 - acc: 0.9401 - val_loss: 0.3114 - val_acc: 0.9420\n",
      "Epoch 13/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.3275 - acc: 0.9401 - val_loss: 0.3763 - val_acc: 0.9405\n",
      "Epoch 14/500\n",
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.3633 - acc: 0.9398 - val_loss: 0.3529 - val_acc: 0.9412\n",
      "Epoch 15/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.3407 - acc: 0.9382 - val_loss: 0.3184 - val_acc: 0.9427\n",
      "Epoch 16/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2964 - acc: 0.9392 - val_loss: 0.3393 - val_acc: 0.9427\n",
      "Epoch 17/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2992 - acc: 0.9404 - val_loss: 0.3125 - val_acc: 0.9383\n",
      "Epoch 18/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2794 - acc: 0.9392 - val_loss: 0.2844 - val_acc: 0.9398\n",
      "Epoch 19/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2704 - acc: 0.9385 - val_loss: 0.2720 - val_acc: 0.9427\n",
      "Epoch 20/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2787 - acc: 0.9398 - val_loss: 0.3031 - val_acc: 0.9339\n",
      "Epoch 21/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2607 - acc: 0.9392 - val_loss: 0.2725 - val_acc: 0.9383\n",
      "Epoch 22/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2687 - acc: 0.9392 - val_loss: 0.2975 - val_acc: 0.9405\n",
      "Epoch 23/500\n",
      "3173/3173 [==============================] - 0s 28us/step - loss: 0.2773 - acc: 0.9373 - val_loss: 0.2591 - val_acc: 0.9427\n",
      "Epoch 24/500\n",
      "3173/3173 [==============================] - 0s 29us/step - loss: 0.3187 - acc: 0.9401 - val_loss: 0.3104 - val_acc: 0.9427\n",
      "Epoch 25/500\n",
      "3173/3173 [==============================] - 0s 32us/step - loss: 0.2856 - acc: 0.9398 - val_loss: 0.2679 - val_acc: 0.9412\n",
      "Epoch 26/500\n",
      "3173/3173 [==============================] - 0s 28us/step - loss: 0.2446 - acc: 0.9392 - val_loss: 0.2639 - val_acc: 0.9427\n",
      "Epoch 27/500\n",
      "3173/3173 [==============================] - 0s 27us/step - loss: 0.2461 - acc: 0.9401 - val_loss: 0.3183 - val_acc: 0.9427\n",
      "Epoch 28/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2764 - acc: 0.9398 - val_loss: 0.2813 - val_acc: 0.9398\n",
      "Epoch 29/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2474 - acc: 0.9398 - val_loss: 0.2641 - val_acc: 0.9390\n",
      "Epoch 30/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2468 - acc: 0.9404 - val_loss: 0.3115 - val_acc: 0.9412\n",
      "Epoch 31/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2520 - acc: 0.9401 - val_loss: 0.2620 - val_acc: 0.9398\n",
      "Epoch 32/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2421 - acc: 0.9395 - val_loss: 0.2584 - val_acc: 0.9427\n",
      "Epoch 33/500\n",
      "3173/3173 [==============================] - 0s 27us/step - loss: 0.2399 - acc: 0.9398 - val_loss: 0.2558 - val_acc: 0.9412\n",
      "Epoch 34/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2416 - acc: 0.9389 - val_loss: 0.2702 - val_acc: 0.9405\n",
      "Epoch 35/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2563 - acc: 0.9398 - val_loss: 0.3018 - val_acc: 0.9420\n",
      "Epoch 36/500\n",
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.2532 - acc: 0.9395 - val_loss: 0.2730 - val_acc: 0.9390\n",
      "Epoch 37/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.3168 - acc: 0.9392 - val_loss: 0.3233 - val_acc: 0.9427\n",
      "Epoch 38/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2764 - acc: 0.9382 - val_loss: 0.2869 - val_acc: 0.9405\n",
      "Epoch 39/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2482 - acc: 0.9401 - val_loss: 0.2672 - val_acc: 0.9412\n",
      "Epoch 40/500\n",
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.2355 - acc: 0.9408 - val_loss: 0.2928 - val_acc: 0.9339\n",
      "Epoch 41/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.3038 - acc: 0.9395 - val_loss: 0.3461 - val_acc: 0.9398\n",
      "Epoch 42/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2800 - acc: 0.9395 - val_loss: 0.2967 - val_acc: 0.9412\n",
      "Epoch 43/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2559 - acc: 0.9392 - val_loss: 0.2820 - val_acc: 0.9427\n",
      "Epoch 44/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2559 - acc: 0.9401 - val_loss: 0.2966 - val_acc: 0.9405\n",
      "Epoch 45/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2722 - acc: 0.9398 - val_loss: 0.2906 - val_acc: 0.9427\n",
      "Epoch 46/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2494 - acc: 0.9404 - val_loss: 0.2615 - val_acc: 0.9420\n",
      "Epoch 47/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2387 - acc: 0.9404 - val_loss: 0.2562 - val_acc: 0.9412\n",
      "Epoch 48/500\n",
      "3173/3173 [==============================] - 0s 31us/step - loss: 0.2335 - acc: 0.9404 - val_loss: 0.3302 - val_acc: 0.9427\n",
      "Epoch 49/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2914 - acc: 0.9404 - val_loss: 0.3292 - val_acc: 0.9412\n",
      "Epoch 50/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2612 - acc: 0.9404 - val_loss: 0.2703 - val_acc: 0.9412\n",
      "Epoch 51/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2376 - acc: 0.9408 - val_loss: 0.3095 - val_acc: 0.9339\n",
      "Epoch 52/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2405 - acc: 0.9408 - val_loss: 0.2698 - val_acc: 0.9427\n",
      "Epoch 53/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2695 - acc: 0.9398 - val_loss: 0.2933 - val_acc: 0.9427\n",
      "Epoch 54/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2527 - acc: 0.9411 - val_loss: 0.2724 - val_acc: 0.9412\n",
      "Epoch 55/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2353 - acc: 0.9398 - val_loss: 0.2658 - val_acc: 0.9398\n",
      "Epoch 56/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2305 - acc: 0.9404 - val_loss: 0.2570 - val_acc: 0.9405\n",
      "Epoch 57/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2272 - acc: 0.9398 - val_loss: 0.2940 - val_acc: 0.9427\n",
      "Epoch 58/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2749 - acc: 0.9401 - val_loss: 0.3367 - val_acc: 0.9405\n",
      "Epoch 59/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.3411 - acc: 0.9404 - val_loss: 0.3266 - val_acc: 0.9412\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.2756 - acc: 0.9404 - val_loss: 0.3100 - val_acc: 0.9427\n",
      "Epoch 61/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2626 - acc: 0.9404 - val_loss: 0.2810 - val_acc: 0.9420\n",
      "Epoch 62/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2492 - acc: 0.9404 - val_loss: 0.2806 - val_acc: 0.9368\n",
      "Epoch 63/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2441 - acc: 0.9395 - val_loss: 0.2562 - val_acc: 0.9412\n",
      "Epoch 64/500\n",
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.2320 - acc: 0.9408 - val_loss: 0.2507 - val_acc: 0.9412\n",
      "Epoch 65/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2265 - acc: 0.9404 - val_loss: 0.2522 - val_acc: 0.9420\n",
      "Epoch 66/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2282 - acc: 0.9408 - val_loss: 0.2534 - val_acc: 0.9420\n",
      "Epoch 67/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2297 - acc: 0.9401 - val_loss: 0.2626 - val_acc: 0.9420\n",
      "Epoch 68/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2339 - acc: 0.9408 - val_loss: 0.2502 - val_acc: 0.9405\n",
      "Epoch 69/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2242 - acc: 0.9411 - val_loss: 0.2465 - val_acc: 0.9412\n",
      "Epoch 70/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2255 - acc: 0.9398 - val_loss: 0.2523 - val_acc: 0.9398\n",
      "Epoch 71/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2228 - acc: 0.9408 - val_loss: 0.2479 - val_acc: 0.9412\n",
      "Epoch 72/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2254 - acc: 0.9401 - val_loss: 0.2608 - val_acc: 0.9412\n",
      "Epoch 73/500\n",
      "3173/3173 [==============================] - 0s 27us/step - loss: 0.2272 - acc: 0.9404 - val_loss: 0.2596 - val_acc: 0.9412\n",
      "Epoch 74/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2273 - acc: 0.9401 - val_loss: 0.2559 - val_acc: 0.9412\n",
      "Epoch 75/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2256 - acc: 0.9404 - val_loss: 0.2486 - val_acc: 0.9420\n",
      "Epoch 76/500\n",
      "3173/3173 [==============================] - 0s 27us/step - loss: 0.2339 - acc: 0.9404 - val_loss: 0.2956 - val_acc: 0.9420\n",
      "Epoch 77/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2656 - acc: 0.9401 - val_loss: 0.2626 - val_acc: 0.9420\n",
      "Epoch 78/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2246 - acc: 0.9408 - val_loss: 0.2530 - val_acc: 0.9398\n",
      "Epoch 79/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2318 - acc: 0.9398 - val_loss: 0.3051 - val_acc: 0.9427\n",
      "Epoch 80/500\n",
      "3173/3173 [==============================] - 0s 15us/step - loss: 0.2817 - acc: 0.9404 - val_loss: 0.3059 - val_acc: 0.9427\n",
      "Epoch 81/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2537 - acc: 0.9408 - val_loss: 0.2693 - val_acc: 0.9368\n",
      "Epoch 82/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2282 - acc: 0.9414 - val_loss: 0.2459 - val_acc: 0.9420\n",
      "Epoch 83/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2474 - acc: 0.9404 - val_loss: 0.2594 - val_acc: 0.9412\n",
      "Epoch 84/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2355 - acc: 0.9398 - val_loss: 0.2728 - val_acc: 0.9375\n",
      "Epoch 85/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2331 - acc: 0.9401 - val_loss: 0.2533 - val_acc: 0.9405\n",
      "Epoch 86/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2259 - acc: 0.9401 - val_loss: 0.2651 - val_acc: 0.9383\n",
      "Epoch 87/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2305 - acc: 0.9411 - val_loss: 0.2647 - val_acc: 0.9420\n",
      "Epoch 88/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2434 - acc: 0.9401 - val_loss: 0.2572 - val_acc: 0.9412\n",
      "Epoch 89/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2353 - acc: 0.9408 - val_loss: 0.2503 - val_acc: 0.9412\n",
      "Epoch 90/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2253 - acc: 0.9401 - val_loss: 0.2601 - val_acc: 0.9398\n",
      "Epoch 91/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2252 - acc: 0.9404 - val_loss: 0.2461 - val_acc: 0.9420\n",
      "Epoch 92/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2218 - acc: 0.9404 - val_loss: 0.2564 - val_acc: 0.9427\n",
      "Epoch 93/500\n",
      "3173/3173 [==============================] - 0s 28us/step - loss: 0.2333 - acc: 0.9401 - val_loss: 0.3164 - val_acc: 0.9427\n",
      "Epoch 94/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2521 - acc: 0.9395 - val_loss: 0.2621 - val_acc: 0.9390\n",
      "Epoch 95/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2339 - acc: 0.9398 - val_loss: 0.2514 - val_acc: 0.9427\n",
      "Epoch 96/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2204 - acc: 0.9404 - val_loss: 0.2483 - val_acc: 0.9420\n",
      "Epoch 97/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2226 - acc: 0.9408 - val_loss: 0.2666 - val_acc: 0.9398\n",
      "Epoch 98/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2232 - acc: 0.9404 - val_loss: 0.2789 - val_acc: 0.9383\n",
      "Epoch 99/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2272 - acc: 0.9404 - val_loss: 0.2474 - val_acc: 0.9420\n",
      "Epoch 100/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2176 - acc: 0.9408 - val_loss: 0.2613 - val_acc: 0.9353\n",
      "Epoch 101/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2327 - acc: 0.9404 - val_loss: 0.2819 - val_acc: 0.9427\n",
      "Epoch 102/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2425 - acc: 0.9398 - val_loss: 0.2620 - val_acc: 0.9427\n",
      "Epoch 103/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2265 - acc: 0.9411 - val_loss: 0.2504 - val_acc: 0.9420\n",
      "Epoch 104/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2232 - acc: 0.9401 - val_loss: 0.2511 - val_acc: 0.9420\n",
      "Epoch 105/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2207 - acc: 0.9411 - val_loss: 0.2540 - val_acc: 0.9331\n",
      "Epoch 106/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2389 - acc: 0.9398 - val_loss: 0.2610 - val_acc: 0.9420\n",
      "Epoch 107/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2240 - acc: 0.9411 - val_loss: 0.2529 - val_acc: 0.9420\n",
      "Epoch 108/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2327 - acc: 0.9401 - val_loss: 0.2791 - val_acc: 0.9412\n",
      "Epoch 109/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2488 - acc: 0.9395 - val_loss: 0.3130 - val_acc: 0.9405\n",
      "Epoch 110/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2782 - acc: 0.9398 - val_loss: 0.2972 - val_acc: 0.9324\n",
      "Epoch 111/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2425 - acc: 0.9389 - val_loss: 0.2614 - val_acc: 0.9427\n",
      "Epoch 112/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2265 - acc: 0.9404 - val_loss: 0.2553 - val_acc: 0.9427\n",
      "Epoch 113/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2524 - acc: 0.9404 - val_loss: 0.2904 - val_acc: 0.9427\n",
      "Epoch 114/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2372 - acc: 0.9408 - val_loss: 0.2824 - val_acc: 0.9427\n",
      "Epoch 115/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2496 - acc: 0.9404 - val_loss: 0.2920 - val_acc: 0.9427\n",
      "Epoch 116/500\n",
      "3173/3173 [==============================] - 0s 28us/step - loss: 0.2464 - acc: 0.9408 - val_loss: 0.2783 - val_acc: 0.9398\n",
      "Epoch 117/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2478 - acc: 0.9408 - val_loss: 0.3726 - val_acc: 0.9427\n",
      "Epoch 118/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.3317 - acc: 0.9408 - val_loss: 0.3331 - val_acc: 0.9420\n",
      "Epoch 119/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2898 - acc: 0.9408 - val_loss: 0.3141 - val_acc: 0.9383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2542 - acc: 0.9395 - val_loss: 0.3180 - val_acc: 0.9390\n",
      "Epoch 121/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2541 - acc: 0.9401 - val_loss: 0.2768 - val_acc: 0.9405\n",
      "Epoch 122/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2312 - acc: 0.9404 - val_loss: 0.2649 - val_acc: 0.9375\n",
      "Epoch 123/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2250 - acc: 0.9411 - val_loss: 0.2626 - val_acc: 0.9427\n",
      "Epoch 124/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2284 - acc: 0.9395 - val_loss: 0.2716 - val_acc: 0.9390\n",
      "Epoch 125/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2266 - acc: 0.9404 - val_loss: 0.2642 - val_acc: 0.9368\n",
      "Epoch 126/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2193 - acc: 0.9420 - val_loss: 0.2663 - val_acc: 0.9383\n",
      "Epoch 127/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2188 - acc: 0.9417 - val_loss: 0.3139 - val_acc: 0.9251\n",
      "Epoch 128/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2260 - acc: 0.9408 - val_loss: 0.2573 - val_acc: 0.9420\n",
      "Epoch 129/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2263 - acc: 0.9401 - val_loss: 0.2488 - val_acc: 0.9427\n",
      "Epoch 130/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2213 - acc: 0.9411 - val_loss: 0.2521 - val_acc: 0.9427\n",
      "Epoch 131/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2599 - acc: 0.9408 - val_loss: 0.2759 - val_acc: 0.9427\n",
      "Epoch 132/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2320 - acc: 0.9408 - val_loss: 0.2559 - val_acc: 0.9405\n",
      "Epoch 133/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2240 - acc: 0.9408 - val_loss: 0.2580 - val_acc: 0.9375\n",
      "Epoch 134/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2213 - acc: 0.9414 - val_loss: 0.2630 - val_acc: 0.9383\n",
      "Epoch 135/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2495 - acc: 0.9408 - val_loss: 0.3093 - val_acc: 0.9427\n",
      "Epoch 136/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2830 - acc: 0.9401 - val_loss: 0.3515 - val_acc: 0.9405\n",
      "Epoch 137/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2806 - acc: 0.9398 - val_loss: 0.2824 - val_acc: 0.9412\n",
      "Epoch 138/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2402 - acc: 0.9411 - val_loss: 0.2583 - val_acc: 0.9412\n",
      "Epoch 139/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2330 - acc: 0.9401 - val_loss: 0.2579 - val_acc: 0.9375\n",
      "Epoch 140/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2260 - acc: 0.9408 - val_loss: 0.2535 - val_acc: 0.9427\n",
      "Epoch 141/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2219 - acc: 0.9411 - val_loss: 0.2595 - val_acc: 0.9427\n",
      "Epoch 142/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2223 - acc: 0.9401 - val_loss: 0.2490 - val_acc: 0.9405\n",
      "Epoch 143/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2210 - acc: 0.9401 - val_loss: 0.2597 - val_acc: 0.9398\n",
      "Epoch 144/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2224 - acc: 0.9408 - val_loss: 0.2525 - val_acc: 0.9420\n",
      "Epoch 145/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2200 - acc: 0.9408 - val_loss: 0.2542 - val_acc: 0.9427\n",
      "Epoch 146/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2202 - acc: 0.9414 - val_loss: 0.2803 - val_acc: 0.9309\n",
      "Epoch 147/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2202 - acc: 0.9411 - val_loss: 0.2718 - val_acc: 0.9390\n",
      "Epoch 148/500\n",
      "3173/3173 [==============================] - 0s 27us/step - loss: 0.2293 - acc: 0.9404 - val_loss: 0.2502 - val_acc: 0.9405\n",
      "Epoch 149/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2175 - acc: 0.9411 - val_loss: 0.3002 - val_acc: 0.9265\n",
      "Epoch 150/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2194 - acc: 0.9401 - val_loss: 0.2498 - val_acc: 0.9405\n",
      "Epoch 151/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2162 - acc: 0.9408 - val_loss: 0.2525 - val_acc: 0.9412\n",
      "Epoch 152/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2277 - acc: 0.9408 - val_loss: 0.2695 - val_acc: 0.9398\n",
      "Epoch 153/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2275 - acc: 0.9398 - val_loss: 0.2651 - val_acc: 0.9390\n",
      "Epoch 154/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2182 - acc: 0.9414 - val_loss: 0.2569 - val_acc: 0.9346\n",
      "Epoch 155/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2210 - acc: 0.9404 - val_loss: 0.2967 - val_acc: 0.9427\n",
      "Epoch 156/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2663 - acc: 0.9408 - val_loss: 0.3205 - val_acc: 0.9375\n",
      "Epoch 157/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2440 - acc: 0.9401 - val_loss: 0.2634 - val_acc: 0.9405\n",
      "Epoch 158/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2318 - acc: 0.9414 - val_loss: 0.2551 - val_acc: 0.9398\n",
      "Epoch 159/500\n",
      "3173/3173 [==============================] - 0s 32us/step - loss: 0.2298 - acc: 0.9414 - val_loss: 0.2609 - val_acc: 0.9375\n",
      "Epoch 160/500\n",
      "3173/3173 [==============================] - 0s 33us/step - loss: 0.2257 - acc: 0.9408 - val_loss: 0.2512 - val_acc: 0.9405\n",
      "Epoch 161/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2208 - acc: 0.9408 - val_loss: 0.2436 - val_acc: 0.9420\n",
      "Epoch 162/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2254 - acc: 0.9408 - val_loss: 0.2658 - val_acc: 0.9427\n",
      "Epoch 163/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2323 - acc: 0.9404 - val_loss: 0.2818 - val_acc: 0.9361\n",
      "Epoch 164/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2263 - acc: 0.9408 - val_loss: 0.2658 - val_acc: 0.9420\n",
      "Epoch 165/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2189 - acc: 0.9408 - val_loss: 0.2543 - val_acc: 0.9390\n",
      "Epoch 166/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2275 - acc: 0.9404 - val_loss: 0.2707 - val_acc: 0.9420\n",
      "Epoch 167/500\n",
      "3173/3173 [==============================] - 0s 15us/step - loss: 0.2325 - acc: 0.9401 - val_loss: 0.2572 - val_acc: 0.9390\n",
      "Epoch 168/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2275 - acc: 0.9411 - val_loss: 0.2514 - val_acc: 0.9405\n",
      "Epoch 169/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2228 - acc: 0.9411 - val_loss: 0.2562 - val_acc: 0.9420\n",
      "Epoch 170/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2220 - acc: 0.9411 - val_loss: 0.2493 - val_acc: 0.9420\n",
      "Epoch 171/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2180 - acc: 0.9408 - val_loss: 0.2489 - val_acc: 0.9390\n",
      "Epoch 172/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2282 - acc: 0.9411 - val_loss: 0.2660 - val_acc: 0.9383\n",
      "Epoch 173/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2260 - acc: 0.9408 - val_loss: 0.2655 - val_acc: 0.9383\n",
      "Epoch 174/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2223 - acc: 0.9408 - val_loss: 0.2512 - val_acc: 0.9420\n",
      "Epoch 175/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2168 - acc: 0.9408 - val_loss: 0.2448 - val_acc: 0.9412\n",
      "Epoch 176/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2158 - acc: 0.9408 - val_loss: 0.2651 - val_acc: 0.9427\n",
      "Epoch 177/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2165 - acc: 0.9408 - val_loss: 0.2805 - val_acc: 0.9302\n",
      "Epoch 178/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2117 - acc: 0.9420 - val_loss: 0.2461 - val_acc: 0.9398\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2180 - acc: 0.9411 - val_loss: 0.2468 - val_acc: 0.9420\n",
      "Epoch 180/500\n",
      "3173/3173 [==============================] - 0s 28us/step - loss: 0.2393 - acc: 0.9392 - val_loss: 0.2632 - val_acc: 0.9427\n",
      "Epoch 181/500\n",
      "3173/3173 [==============================] - 0s 32us/step - loss: 0.2277 - acc: 0.9401 - val_loss: 0.2581 - val_acc: 0.9405\n",
      "Epoch 182/500\n",
      "3173/3173 [==============================] - 0s 31us/step - loss: 0.2445 - acc: 0.9411 - val_loss: 0.2914 - val_acc: 0.9383\n",
      "Epoch 183/500\n",
      "3173/3173 [==============================] - 0s 30us/step - loss: 0.2482 - acc: 0.9395 - val_loss: 0.2562 - val_acc: 0.9412\n",
      "Epoch 184/500\n",
      "3173/3173 [==============================] - 0s 28us/step - loss: 0.2246 - acc: 0.9401 - val_loss: 0.2530 - val_acc: 0.9412\n",
      "Epoch 185/500\n",
      "3173/3173 [==============================] - 0s 33us/step - loss: 0.2186 - acc: 0.9414 - val_loss: 0.2475 - val_acc: 0.9412\n",
      "Epoch 186/500\n",
      "3173/3173 [==============================] - 0s 28us/step - loss: 0.2168 - acc: 0.9404 - val_loss: 0.2607 - val_acc: 0.9383\n",
      "Epoch 187/500\n",
      "3173/3173 [==============================] - 0s 32us/step - loss: 0.2151 - acc: 0.9404 - val_loss: 0.2503 - val_acc: 0.9375\n",
      "Epoch 188/500\n",
      "3173/3173 [==============================] - 0s 30us/step - loss: 0.2246 - acc: 0.9408 - val_loss: 0.2601 - val_acc: 0.9390\n",
      "Epoch 189/500\n",
      "3173/3173 [==============================] - 0s 29us/step - loss: 0.2156 - acc: 0.9414 - val_loss: 0.2453 - val_acc: 0.9405\n",
      "Epoch 190/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2156 - acc: 0.9414 - val_loss: 0.2492 - val_acc: 0.9390\n",
      "Epoch 191/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2152 - acc: 0.9411 - val_loss: 0.2502 - val_acc: 0.9412\n",
      "Epoch 192/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2165 - acc: 0.9408 - val_loss: 0.2550 - val_acc: 0.9390\n",
      "Epoch 193/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2194 - acc: 0.9408 - val_loss: 0.3042 - val_acc: 0.9427\n",
      "Epoch 194/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2471 - acc: 0.9404 - val_loss: 0.2996 - val_acc: 0.9368\n",
      "Epoch 195/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2318 - acc: 0.9404 - val_loss: 0.2557 - val_acc: 0.9412\n",
      "Epoch 196/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2266 - acc: 0.9408 - val_loss: 0.2600 - val_acc: 0.9427\n",
      "Epoch 197/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2192 - acc: 0.9408 - val_loss: 0.2543 - val_acc: 0.9405\n",
      "Epoch 198/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2196 - acc: 0.9401 - val_loss: 0.2570 - val_acc: 0.9420\n",
      "Epoch 199/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2180 - acc: 0.9408 - val_loss: 0.2586 - val_acc: 0.9383\n",
      "Epoch 200/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2165 - acc: 0.9408 - val_loss: 0.2548 - val_acc: 0.9405\n",
      "Epoch 201/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2147 - acc: 0.9411 - val_loss: 0.2567 - val_acc: 0.9427\n",
      "Epoch 202/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2183 - acc: 0.9414 - val_loss: 0.2487 - val_acc: 0.9427\n",
      "Epoch 203/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2157 - acc: 0.9408 - val_loss: 0.2530 - val_acc: 0.9420\n",
      "Epoch 204/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2167 - acc: 0.9411 - val_loss: 0.2623 - val_acc: 0.9398\n",
      "Epoch 205/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2242 - acc: 0.9404 - val_loss: 0.2603 - val_acc: 0.9405\n",
      "Epoch 206/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2190 - acc: 0.9404 - val_loss: 0.2480 - val_acc: 0.9420\n",
      "Epoch 207/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2153 - acc: 0.9408 - val_loss: 0.2558 - val_acc: 0.9398\n",
      "Epoch 208/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2140 - acc: 0.9404 - val_loss: 0.2508 - val_acc: 0.9390\n",
      "Epoch 209/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2139 - acc: 0.9408 - val_loss: 0.2446 - val_acc: 0.9420\n",
      "Epoch 210/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2154 - acc: 0.9398 - val_loss: 0.2554 - val_acc: 0.9405\n",
      "Epoch 211/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2158 - acc: 0.9404 - val_loss: 0.2599 - val_acc: 0.9353\n",
      "Epoch 212/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2166 - acc: 0.9411 - val_loss: 0.2531 - val_acc: 0.9383\n",
      "Epoch 213/500\n",
      "3173/3173 [==============================] - 0s 15us/step - loss: 0.2115 - acc: 0.9414 - val_loss: 0.2628 - val_acc: 0.9375\n",
      "Epoch 214/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2140 - acc: 0.9408 - val_loss: 0.2481 - val_acc: 0.9368\n",
      "Epoch 215/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2132 - acc: 0.9414 - val_loss: 0.2470 - val_acc: 0.9427\n",
      "Epoch 216/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2121 - acc: 0.9408 - val_loss: 0.2732 - val_acc: 0.9287\n",
      "Epoch 217/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2129 - acc: 0.9411 - val_loss: 0.2679 - val_acc: 0.9295\n",
      "Epoch 218/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2268 - acc: 0.9411 - val_loss: 0.2699 - val_acc: 0.9361\n",
      "Epoch 219/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2233 - acc: 0.9411 - val_loss: 0.2414 - val_acc: 0.9420\n",
      "Epoch 220/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2133 - acc: 0.9411 - val_loss: 0.2497 - val_acc: 0.9375\n",
      "Epoch 221/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2252 - acc: 0.9411 - val_loss: 0.2864 - val_acc: 0.9420\n",
      "Epoch 222/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2279 - acc: 0.9389 - val_loss: 0.2830 - val_acc: 0.9331\n",
      "Epoch 223/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2150 - acc: 0.9404 - val_loss: 0.2653 - val_acc: 0.9353\n",
      "Epoch 224/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2148 - acc: 0.9404 - val_loss: 0.2568 - val_acc: 0.9398\n",
      "Epoch 225/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2120 - acc: 0.9417 - val_loss: 0.2513 - val_acc: 0.9427\n",
      "Epoch 226/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2129 - acc: 0.9401 - val_loss: 0.2764 - val_acc: 0.9427\n",
      "Epoch 227/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2521 - acc: 0.9404 - val_loss: 0.2810 - val_acc: 0.9398\n",
      "Epoch 228/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2480 - acc: 0.9389 - val_loss: 0.2778 - val_acc: 0.9427\n",
      "Epoch 229/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2313 - acc: 0.9404 - val_loss: 0.2586 - val_acc: 0.9412\n",
      "Epoch 230/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2141 - acc: 0.9411 - val_loss: 0.2516 - val_acc: 0.9390\n",
      "Epoch 231/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2184 - acc: 0.9408 - val_loss: 0.2665 - val_acc: 0.9420\n",
      "Epoch 232/500\n",
      "3173/3173 [==============================] - ETA: 0s - loss: 0.2717 - acc: 0.937 - 0s 17us/step - loss: 0.2250 - acc: 0.9408 - val_loss: 0.2737 - val_acc: 0.9427\n",
      "Epoch 233/500\n",
      "3173/3173 [==============================] - 0s 15us/step - loss: 0.2220 - acc: 0.9408 - val_loss: 0.2695 - val_acc: 0.9375\n",
      "Epoch 234/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2181 - acc: 0.9414 - val_loss: 0.2711 - val_acc: 0.9368\n",
      "Epoch 235/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2145 - acc: 0.9414 - val_loss: 0.2563 - val_acc: 0.9390\n",
      "Epoch 236/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2187 - acc: 0.9408 - val_loss: 0.2548 - val_acc: 0.9383\n",
      "Epoch 237/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2172 - acc: 0.9404 - val_loss: 0.2545 - val_acc: 0.9412\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2170 - acc: 0.9408 - val_loss: 0.2507 - val_acc: 0.9420\n",
      "Epoch 239/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2162 - acc: 0.9414 - val_loss: 0.2566 - val_acc: 0.9361\n",
      "Epoch 240/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2430 - acc: 0.9392 - val_loss: 0.2766 - val_acc: 0.9412\n",
      "Epoch 241/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2325 - acc: 0.9408 - val_loss: 0.2724 - val_acc: 0.9353\n",
      "Epoch 242/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2186 - acc: 0.9395 - val_loss: 0.2495 - val_acc: 0.9420\n",
      "Epoch 243/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2150 - acc: 0.9411 - val_loss: 0.2469 - val_acc: 0.9375\n",
      "Epoch 244/500\n",
      "3173/3173 [==============================] - 0s 28us/step - loss: 0.2120 - acc: 0.9408 - val_loss: 0.2534 - val_acc: 0.9368\n",
      "Epoch 245/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2152 - acc: 0.9408 - val_loss: 0.2431 - val_acc: 0.9427\n",
      "Epoch 246/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2114 - acc: 0.9408 - val_loss: 0.2446 - val_acc: 0.9420\n",
      "Epoch 247/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2172 - acc: 0.9408 - val_loss: 0.2728 - val_acc: 0.9427\n",
      "Epoch 248/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2263 - acc: 0.9411 - val_loss: 0.2599 - val_acc: 0.9346\n",
      "Epoch 249/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2109 - acc: 0.9408 - val_loss: 0.2530 - val_acc: 0.9368\n",
      "Epoch 250/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2131 - acc: 0.9408 - val_loss: 0.2565 - val_acc: 0.9390\n",
      "Epoch 251/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2128 - acc: 0.9404 - val_loss: 0.2773 - val_acc: 0.9353\n",
      "Epoch 252/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2104 - acc: 0.9411 - val_loss: 0.2808 - val_acc: 0.9339\n",
      "Epoch 253/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2092 - acc: 0.9423 - val_loss: 0.2526 - val_acc: 0.9353\n",
      "Epoch 254/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2143 - acc: 0.9417 - val_loss: 0.2554 - val_acc: 0.9390\n",
      "Epoch 255/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2108 - acc: 0.9411 - val_loss: 0.2446 - val_acc: 0.9427\n",
      "Epoch 256/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2127 - acc: 0.9408 - val_loss: 0.2463 - val_acc: 0.9383\n",
      "Epoch 257/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2153 - acc: 0.9411 - val_loss: 0.2630 - val_acc: 0.9427\n",
      "Epoch 258/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2105 - acc: 0.9404 - val_loss: 0.2509 - val_acc: 0.9375\n",
      "Epoch 259/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2133 - acc: 0.9411 - val_loss: 0.2864 - val_acc: 0.9420\n",
      "Epoch 260/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2412 - acc: 0.9404 - val_loss: 0.2675 - val_acc: 0.9427\n",
      "Epoch 261/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2186 - acc: 0.9401 - val_loss: 0.2698 - val_acc: 0.9258\n",
      "Epoch 262/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2161 - acc: 0.9411 - val_loss: 0.2578 - val_acc: 0.9427\n",
      "Epoch 263/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2132 - acc: 0.9411 - val_loss: 0.2494 - val_acc: 0.9427\n",
      "Epoch 264/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2157 - acc: 0.9401 - val_loss: 0.2470 - val_acc: 0.9375\n",
      "Epoch 265/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2151 - acc: 0.9414 - val_loss: 0.2421 - val_acc: 0.9383\n",
      "Epoch 266/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2110 - acc: 0.9414 - val_loss: 0.2934 - val_acc: 0.9258\n",
      "Epoch 267/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2134 - acc: 0.9417 - val_loss: 0.2638 - val_acc: 0.9353\n",
      "Epoch 268/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2167 - acc: 0.9404 - val_loss: 0.2601 - val_acc: 0.9412\n",
      "Epoch 269/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2228 - acc: 0.9404 - val_loss: 0.2558 - val_acc: 0.9427\n",
      "Epoch 270/500\n",
      "3173/3173 [==============================] - 0s 27us/step - loss: 0.2163 - acc: 0.9411 - val_loss: 0.2466 - val_acc: 0.9390\n",
      "Epoch 271/500\n",
      "3173/3173 [==============================] - 0s 27us/step - loss: 0.2098 - acc: 0.9414 - val_loss: 0.2432 - val_acc: 0.9412\n",
      "Epoch 272/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2127 - acc: 0.9408 - val_loss: 0.2649 - val_acc: 0.9339\n",
      "Epoch 273/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2102 - acc: 0.9411 - val_loss: 0.2596 - val_acc: 0.9383\n",
      "Epoch 274/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2113 - acc: 0.9408 - val_loss: 0.2451 - val_acc: 0.9412\n",
      "Epoch 275/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2130 - acc: 0.9414 - val_loss: 0.2537 - val_acc: 0.9398\n",
      "Epoch 276/500\n",
      "3173/3173 [==============================] - ETA: 0s - loss: 0.2077 - acc: 0.941 - 0s 20us/step - loss: 0.2095 - acc: 0.9408 - val_loss: 0.2425 - val_acc: 0.9420\n",
      "Epoch 277/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2115 - acc: 0.9401 - val_loss: 0.2542 - val_acc: 0.9427\n",
      "Epoch 278/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2103 - acc: 0.9414 - val_loss: 0.2494 - val_acc: 0.9398\n",
      "Epoch 279/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2124 - acc: 0.9408 - val_loss: 0.2770 - val_acc: 0.9427\n",
      "Epoch 280/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2264 - acc: 0.9401 - val_loss: 0.2522 - val_acc: 0.9427\n",
      "Epoch 281/500\n",
      "3173/3173 [==============================] - 0s 29us/step - loss: 0.2185 - acc: 0.9417 - val_loss: 0.2576 - val_acc: 0.9390\n",
      "Epoch 282/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2128 - acc: 0.9411 - val_loss: 0.2545 - val_acc: 0.9420\n",
      "Epoch 283/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2111 - acc: 0.9408 - val_loss: 0.2547 - val_acc: 0.9398\n",
      "Epoch 284/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2123 - acc: 0.9411 - val_loss: 0.2463 - val_acc: 0.9398\n",
      "Epoch 285/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2147 - acc: 0.9417 - val_loss: 0.2565 - val_acc: 0.9405\n",
      "Epoch 286/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2094 - acc: 0.9414 - val_loss: 0.2596 - val_acc: 0.9375\n",
      "Epoch 287/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2122 - acc: 0.9411 - val_loss: 0.2539 - val_acc: 0.9420\n",
      "Epoch 288/500\n",
      "3173/3173 [==============================] - ETA: 0s - loss: 0.2204 - acc: 0.940 - 0s 21us/step - loss: 0.2206 - acc: 0.9404 - val_loss: 0.2529 - val_acc: 0.9368\n",
      "Epoch 289/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2102 - acc: 0.9411 - val_loss: 0.2519 - val_acc: 0.9405\n",
      "Epoch 290/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2159 - acc: 0.9417 - val_loss: 0.2550 - val_acc: 0.9383\n",
      "Epoch 291/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2105 - acc: 0.9408 - val_loss: 0.2597 - val_acc: 0.9390\n",
      "Epoch 292/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2202 - acc: 0.9404 - val_loss: 0.2572 - val_acc: 0.9398\n",
      "Epoch 293/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2141 - acc: 0.9411 - val_loss: 0.2737 - val_acc: 0.9427\n",
      "Epoch 294/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2245 - acc: 0.9408 - val_loss: 0.2488 - val_acc: 0.9427\n",
      "Epoch 295/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2124 - acc: 0.9414 - val_loss: 0.2625 - val_acc: 0.9331\n",
      "Epoch 296/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2089 - acc: 0.9420 - val_loss: 0.2636 - val_acc: 0.9331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2104 - acc: 0.9414 - val_loss: 0.2550 - val_acc: 0.9390\n",
      "Epoch 298/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2115 - acc: 0.9420 - val_loss: 0.2562 - val_acc: 0.9427\n",
      "Epoch 299/500\n",
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.2151 - acc: 0.9401 - val_loss: 0.2478 - val_acc: 0.9420\n",
      "Epoch 300/500\n",
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.2096 - acc: 0.9398 - val_loss: 0.2598 - val_acc: 0.9353\n",
      "Epoch 301/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2141 - acc: 0.9401 - val_loss: 0.2548 - val_acc: 0.9390\n",
      "Epoch 302/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2094 - acc: 0.9408 - val_loss: 0.2570 - val_acc: 0.9353\n",
      "Epoch 303/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2169 - acc: 0.9395 - val_loss: 0.2572 - val_acc: 0.9420\n",
      "Epoch 304/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2179 - acc: 0.9401 - val_loss: 0.2626 - val_acc: 0.9427\n",
      "Epoch 305/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2543 - acc: 0.9395 - val_loss: 0.2844 - val_acc: 0.9398\n",
      "Epoch 306/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2215 - acc: 0.9408 - val_loss: 0.2760 - val_acc: 0.9353\n",
      "Epoch 307/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2232 - acc: 0.9401 - val_loss: 0.2850 - val_acc: 0.9383\n",
      "Epoch 308/500\n",
      "3173/3173 [==============================] - 0s 27us/step - loss: 0.2433 - acc: 0.9398 - val_loss: 0.2676 - val_acc: 0.9412\n",
      "Epoch 309/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2237 - acc: 0.9414 - val_loss: 0.2578 - val_acc: 0.9427\n",
      "Epoch 310/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2175 - acc: 0.9411 - val_loss: 0.2538 - val_acc: 0.9390\n",
      "Epoch 311/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2124 - acc: 0.9411 - val_loss: 0.2746 - val_acc: 0.9427\n",
      "Epoch 312/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2161 - acc: 0.9404 - val_loss: 0.2716 - val_acc: 0.9302\n",
      "Epoch 313/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2229 - acc: 0.9411 - val_loss: 0.2550 - val_acc: 0.9405\n",
      "Epoch 314/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2123 - acc: 0.9404 - val_loss: 0.2556 - val_acc: 0.9427\n",
      "Epoch 315/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2257 - acc: 0.9411 - val_loss: 0.2561 - val_acc: 0.9390\n",
      "Epoch 316/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2079 - acc: 0.9417 - val_loss: 0.2537 - val_acc: 0.9383\n",
      "Epoch 317/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2087 - acc: 0.9398 - val_loss: 0.2471 - val_acc: 0.9368\n",
      "Epoch 318/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2104 - acc: 0.9417 - val_loss: 0.2874 - val_acc: 0.9353\n",
      "Epoch 319/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2236 - acc: 0.9404 - val_loss: 0.2702 - val_acc: 0.9405\n",
      "Epoch 320/500\n",
      "3173/3173 [==============================] - 0s 28us/step - loss: 0.2280 - acc: 0.9404 - val_loss: 0.2619 - val_acc: 0.9427\n",
      "Epoch 321/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2522 - acc: 0.9401 - val_loss: 0.2795 - val_acc: 0.9420\n",
      "Epoch 322/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2353 - acc: 0.9408 - val_loss: 0.2513 - val_acc: 0.9427\n",
      "Epoch 323/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2202 - acc: 0.9414 - val_loss: 0.2513 - val_acc: 0.9412\n",
      "Epoch 324/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2191 - acc: 0.9404 - val_loss: 0.2415 - val_acc: 0.9427\n",
      "Epoch 325/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2295 - acc: 0.9408 - val_loss: 0.2681 - val_acc: 0.9427\n",
      "Epoch 326/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2203 - acc: 0.9408 - val_loss: 0.2419 - val_acc: 0.9412\n",
      "Epoch 327/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2169 - acc: 0.9414 - val_loss: 0.2465 - val_acc: 0.9412\n",
      "Epoch 328/500\n",
      "3173/3173 [==============================] - 0s 27us/step - loss: 0.2106 - acc: 0.9411 - val_loss: 0.2548 - val_acc: 0.9427\n",
      "Epoch 329/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2137 - acc: 0.9411 - val_loss: 0.2428 - val_acc: 0.9427\n",
      "Epoch 330/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2123 - acc: 0.9408 - val_loss: 0.2433 - val_acc: 0.9412\n",
      "Epoch 331/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2120 - acc: 0.9411 - val_loss: 0.2394 - val_acc: 0.9420\n",
      "Epoch 332/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2121 - acc: 0.9404 - val_loss: 0.2427 - val_acc: 0.9427\n",
      "Epoch 333/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2146 - acc: 0.9404 - val_loss: 0.2481 - val_acc: 0.9420\n",
      "Epoch 334/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2081 - acc: 0.9408 - val_loss: 0.2580 - val_acc: 0.9427\n",
      "Epoch 335/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2107 - acc: 0.9408 - val_loss: 0.2494 - val_acc: 0.9420\n",
      "Epoch 336/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2071 - acc: 0.9411 - val_loss: 0.2574 - val_acc: 0.9353\n",
      "Epoch 337/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2100 - acc: 0.9411 - val_loss: 0.2577 - val_acc: 0.9427\n",
      "Epoch 338/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2132 - acc: 0.9404 - val_loss: 0.2466 - val_acc: 0.9390\n",
      "Epoch 339/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2061 - acc: 0.9411 - val_loss: 0.2579 - val_acc: 0.9390\n",
      "Epoch 340/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2071 - acc: 0.9404 - val_loss: 0.2497 - val_acc: 0.9390\n",
      "Epoch 341/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2102 - acc: 0.9417 - val_loss: 0.2603 - val_acc: 0.9405\n",
      "Epoch 342/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2103 - acc: 0.9404 - val_loss: 0.2593 - val_acc: 0.9375\n",
      "Epoch 343/500\n",
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.2102 - acc: 0.9408 - val_loss: 0.2953 - val_acc: 0.9273\n",
      "Epoch 344/500\n",
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.2387 - acc: 0.9398 - val_loss: 0.2897 - val_acc: 0.9368\n",
      "Epoch 345/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2209 - acc: 0.9414 - val_loss: 0.2636 - val_acc: 0.9368\n",
      "Epoch 346/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2088 - acc: 0.9404 - val_loss: 0.2470 - val_acc: 0.9420\n",
      "Epoch 347/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2126 - acc: 0.9411 - val_loss: 0.2725 - val_acc: 0.9375\n",
      "Epoch 348/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2098 - acc: 0.9404 - val_loss: 0.2627 - val_acc: 0.9339\n",
      "Epoch 349/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2065 - acc: 0.9420 - val_loss: 0.2472 - val_acc: 0.9398\n",
      "Epoch 350/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2181 - acc: 0.9408 - val_loss: 0.2486 - val_acc: 0.9420\n",
      "Epoch 351/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2061 - acc: 0.9408 - val_loss: 0.2549 - val_acc: 0.9412\n",
      "Epoch 352/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2077 - acc: 0.9414 - val_loss: 0.2489 - val_acc: 0.9412\n",
      "Epoch 353/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2089 - acc: 0.9411 - val_loss: 0.2614 - val_acc: 0.9398\n",
      "Epoch 354/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2213 - acc: 0.9408 - val_loss: 0.2687 - val_acc: 0.9346\n",
      "Epoch 355/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2198 - acc: 0.9401 - val_loss: 0.2627 - val_acc: 0.9361\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3173/3173 [==============================] - 0s 28us/step - loss: 0.2099 - acc: 0.9420 - val_loss: 0.2458 - val_acc: 0.9353\n",
      "Epoch 357/500\n",
      "3173/3173 [==============================] - 0s 30us/step - loss: 0.2056 - acc: 0.9417 - val_loss: 0.2491 - val_acc: 0.9412\n",
      "Epoch 358/500\n",
      "3173/3173 [==============================] - 0s 27us/step - loss: 0.2122 - acc: 0.9408 - val_loss: 0.2503 - val_acc: 0.9420\n",
      "Epoch 359/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2117 - acc: 0.9411 - val_loss: 0.2523 - val_acc: 0.9420\n",
      "Epoch 360/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2069 - acc: 0.9414 - val_loss: 0.2472 - val_acc: 0.9398\n",
      "Epoch 361/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2091 - acc: 0.9408 - val_loss: 0.2765 - val_acc: 0.9427\n",
      "Epoch 362/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2424 - acc: 0.9404 - val_loss: 0.2665 - val_acc: 0.9390\n",
      "Epoch 363/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2202 - acc: 0.9401 - val_loss: 0.2575 - val_acc: 0.9390\n",
      "Epoch 364/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2106 - acc: 0.9404 - val_loss: 0.2908 - val_acc: 0.9427\n",
      "Epoch 365/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2403 - acc: 0.9404 - val_loss: 0.2735 - val_acc: 0.9361\n",
      "Epoch 366/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2165 - acc: 0.9411 - val_loss: 0.2552 - val_acc: 0.9427\n",
      "Epoch 367/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2086 - acc: 0.9404 - val_loss: 0.2546 - val_acc: 0.9390\n",
      "Epoch 368/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2095 - acc: 0.9414 - val_loss: 0.2460 - val_acc: 0.9405\n",
      "Epoch 369/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2122 - acc: 0.9414 - val_loss: 0.2431 - val_acc: 0.9390\n",
      "Epoch 370/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2061 - acc: 0.9414 - val_loss: 0.2521 - val_acc: 0.9375\n",
      "Epoch 371/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2109 - acc: 0.9398 - val_loss: 0.2615 - val_acc: 0.9390\n",
      "Epoch 372/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2079 - acc: 0.9411 - val_loss: 0.2597 - val_acc: 0.9398\n",
      "Epoch 373/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2047 - acc: 0.9414 - val_loss: 0.2544 - val_acc: 0.9339\n",
      "Epoch 374/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2049 - acc: 0.9404 - val_loss: 0.2518 - val_acc: 0.9398\n",
      "Epoch 375/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2064 - acc: 0.9414 - val_loss: 0.2554 - val_acc: 0.9390\n",
      "Epoch 376/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2075 - acc: 0.9411 - val_loss: 0.2581 - val_acc: 0.9412\n",
      "Epoch 377/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2090 - acc: 0.9408 - val_loss: 0.2625 - val_acc: 0.9331\n",
      "Epoch 378/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2347 - acc: 0.9398 - val_loss: 0.2984 - val_acc: 0.9390\n",
      "Epoch 379/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2327 - acc: 0.9404 - val_loss: 0.2704 - val_acc: 0.9398\n",
      "Epoch 380/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2210 - acc: 0.9414 - val_loss: 0.2527 - val_acc: 0.9398\n",
      "Epoch 381/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2138 - acc: 0.9414 - val_loss: 0.2587 - val_acc: 0.9420\n",
      "Epoch 382/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2115 - acc: 0.9408 - val_loss: 0.2475 - val_acc: 0.9405\n",
      "Epoch 383/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2085 - acc: 0.9411 - val_loss: 0.2785 - val_acc: 0.9368\n",
      "Epoch 384/500\n",
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.2098 - acc: 0.9398 - val_loss: 0.2547 - val_acc: 0.9427\n",
      "Epoch 385/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2125 - acc: 0.9401 - val_loss: 0.2481 - val_acc: 0.9375\n",
      "Epoch 386/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2052 - acc: 0.9411 - val_loss: 0.2516 - val_acc: 0.9427\n",
      "Epoch 387/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2212 - acc: 0.9404 - val_loss: 0.2833 - val_acc: 0.9412\n",
      "Epoch 388/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2274 - acc: 0.9411 - val_loss: 0.2542 - val_acc: 0.9420\n",
      "Epoch 389/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2147 - acc: 0.9411 - val_loss: 0.2518 - val_acc: 0.9427\n",
      "Epoch 390/500\n",
      "3173/3173 [==============================] - ETA: 0s - loss: 0.2073 - acc: 0.940 - 0s 24us/step - loss: 0.2106 - acc: 0.9401 - val_loss: 0.2587 - val_acc: 0.9427\n",
      "Epoch 391/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2093 - acc: 0.9411 - val_loss: 0.2496 - val_acc: 0.9420\n",
      "Epoch 392/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2059 - acc: 0.9404 - val_loss: 0.2595 - val_acc: 0.9390\n",
      "Epoch 393/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2059 - acc: 0.9414 - val_loss: 0.2542 - val_acc: 0.9427\n",
      "Epoch 394/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2064 - acc: 0.9411 - val_loss: 0.2582 - val_acc: 0.9339\n",
      "Epoch 395/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2053 - acc: 0.9411 - val_loss: 0.2489 - val_acc: 0.9405\n",
      "Epoch 396/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2084 - acc: 0.9408 - val_loss: 0.2592 - val_acc: 0.9420\n",
      "Epoch 397/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2078 - acc: 0.9417 - val_loss: 0.2501 - val_acc: 0.9398\n",
      "Epoch 398/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2062 - acc: 0.9417 - val_loss: 0.2599 - val_acc: 0.9383\n",
      "Epoch 399/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2066 - acc: 0.9411 - val_loss: 0.2489 - val_acc: 0.9383\n",
      "Epoch 400/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2301 - acc: 0.9404 - val_loss: 0.2871 - val_acc: 0.9427\n",
      "Epoch 401/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2289 - acc: 0.9404 - val_loss: 0.2621 - val_acc: 0.9398\n",
      "Epoch 402/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2303 - acc: 0.9404 - val_loss: 0.2760 - val_acc: 0.9375\n",
      "Epoch 403/500\n",
      "3173/3173 [==============================] - 0s 15us/step - loss: 0.2320 - acc: 0.9408 - val_loss: 0.2781 - val_acc: 0.9324\n",
      "Epoch 404/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2132 - acc: 0.9404 - val_loss: 0.2547 - val_acc: 0.9420\n",
      "Epoch 405/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2139 - acc: 0.9417 - val_loss: 0.2486 - val_acc: 0.9390\n",
      "Epoch 406/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2073 - acc: 0.9411 - val_loss: 0.2559 - val_acc: 0.9383\n",
      "Epoch 407/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2102 - acc: 0.9411 - val_loss: 0.2669 - val_acc: 0.9346\n",
      "Epoch 408/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2067 - acc: 0.9414 - val_loss: 0.2585 - val_acc: 0.9390\n",
      "Epoch 409/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2049 - acc: 0.9408 - val_loss: 0.2652 - val_acc: 0.9339\n",
      "Epoch 410/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2059 - acc: 0.9411 - val_loss: 0.2569 - val_acc: 0.9405\n",
      "Epoch 411/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2161 - acc: 0.9404 - val_loss: 0.2563 - val_acc: 0.9427\n",
      "Epoch 412/500\n",
      "3173/3173 [==============================] - 0s 27us/step - loss: 0.2075 - acc: 0.9404 - val_loss: 0.2517 - val_acc: 0.9361\n",
      "Epoch 413/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2063 - acc: 0.9411 - val_loss: 0.2524 - val_acc: 0.9390\n",
      "Epoch 414/500\n",
      "3173/3173 [==============================] - 0s 29us/step - loss: 0.2039 - acc: 0.9411 - val_loss: 0.2526 - val_acc: 0.9398\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2052 - acc: 0.9414 - val_loss: 0.2661 - val_acc: 0.9390\n",
      "Epoch 416/500\n",
      "3173/3173 [==============================] - 0s 32us/step - loss: 0.2077 - acc: 0.9408 - val_loss: 0.2657 - val_acc: 0.9368\n",
      "Epoch 417/500\n",
      "3173/3173 [==============================] - 0s 27us/step - loss: 0.2047 - acc: 0.9404 - val_loss: 0.2712 - val_acc: 0.9295\n",
      "Epoch 418/500\n",
      "3173/3173 [==============================] - 0s 27us/step - loss: 0.2102 - acc: 0.9401 - val_loss: 0.2535 - val_acc: 0.9420\n",
      "Epoch 419/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2057 - acc: 0.9414 - val_loss: 0.2596 - val_acc: 0.9390\n",
      "Epoch 420/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2042 - acc: 0.9414 - val_loss: 0.2532 - val_acc: 0.9405\n",
      "Epoch 421/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2079 - acc: 0.9414 - val_loss: 0.2454 - val_acc: 0.9398\n",
      "Epoch 422/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2057 - acc: 0.9414 - val_loss: 0.2606 - val_acc: 0.9383\n",
      "Epoch 423/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2055 - acc: 0.9420 - val_loss: 0.2616 - val_acc: 0.9390\n",
      "Epoch 424/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2063 - acc: 0.9414 - val_loss: 0.2578 - val_acc: 0.9390\n",
      "Epoch 425/500\n",
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.2055 - acc: 0.9411 - val_loss: 0.2532 - val_acc: 0.9405\n",
      "Epoch 426/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2052 - acc: 0.9411 - val_loss: 0.2516 - val_acc: 0.9427\n",
      "Epoch 427/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2050 - acc: 0.9404 - val_loss: 0.2593 - val_acc: 0.9398\n",
      "Epoch 428/500\n",
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.2062 - acc: 0.9411 - val_loss: 0.2614 - val_acc: 0.9427\n",
      "Epoch 429/500\n",
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.2223 - acc: 0.9401 - val_loss: 0.2766 - val_acc: 0.9427\n",
      "Epoch 430/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2195 - acc: 0.9411 - val_loss: 0.2918 - val_acc: 0.9427\n",
      "Epoch 431/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2440 - acc: 0.9414 - val_loss: 0.2658 - val_acc: 0.9383\n",
      "Epoch 432/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2173 - acc: 0.9414 - val_loss: 0.2478 - val_acc: 0.9398\n",
      "Epoch 433/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2060 - acc: 0.9414 - val_loss: 0.2694 - val_acc: 0.9280\n",
      "Epoch 434/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2140 - acc: 0.9404 - val_loss: 0.2638 - val_acc: 0.9383\n",
      "Epoch 435/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2086 - acc: 0.9404 - val_loss: 0.2548 - val_acc: 0.9368\n",
      "Epoch 436/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2053 - acc: 0.9420 - val_loss: 0.2569 - val_acc: 0.9390\n",
      "Epoch 437/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2048 - acc: 0.9417 - val_loss: 0.2590 - val_acc: 0.9383\n",
      "Epoch 438/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2040 - acc: 0.9420 - val_loss: 0.2634 - val_acc: 0.9353\n",
      "Epoch 439/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2048 - acc: 0.9414 - val_loss: 0.2547 - val_acc: 0.9390\n",
      "Epoch 440/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2045 - acc: 0.9414 - val_loss: 0.2540 - val_acc: 0.9405\n",
      "Epoch 441/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2057 - acc: 0.9417 - val_loss: 0.2616 - val_acc: 0.9412\n",
      "Epoch 442/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2069 - acc: 0.9411 - val_loss: 0.2576 - val_acc: 0.9390\n",
      "Epoch 443/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2044 - acc: 0.9420 - val_loss: 0.2576 - val_acc: 0.9390\n",
      "Epoch 444/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2030 - acc: 0.9420 - val_loss: 0.2659 - val_acc: 0.9412\n",
      "Epoch 445/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2048 - acc: 0.9408 - val_loss: 0.2864 - val_acc: 0.9309\n",
      "Epoch 446/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2049 - acc: 0.9401 - val_loss: 0.2597 - val_acc: 0.9375\n",
      "Epoch 447/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2036 - acc: 0.9414 - val_loss: 0.2620 - val_acc: 0.9383\n",
      "Epoch 448/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2024 - acc: 0.9417 - val_loss: 0.2550 - val_acc: 0.9398\n",
      "Epoch 449/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2140 - acc: 0.9395 - val_loss: 0.2541 - val_acc: 0.9405\n",
      "Epoch 450/500\n",
      "3173/3173 [==============================] - 0s 15us/step - loss: 0.2079 - acc: 0.9411 - val_loss: 0.2537 - val_acc: 0.9383\n",
      "Epoch 451/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2055 - acc: 0.9404 - val_loss: 0.2595 - val_acc: 0.9412\n",
      "Epoch 452/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2031 - acc: 0.9417 - val_loss: 0.2547 - val_acc: 0.9405\n",
      "Epoch 453/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2079 - acc: 0.9404 - val_loss: 0.2897 - val_acc: 0.9361\n",
      "Epoch 454/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2150 - acc: 0.9414 - val_loss: 0.2566 - val_acc: 0.9412\n",
      "Epoch 455/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2060 - acc: 0.9420 - val_loss: 0.2576 - val_acc: 0.9368\n",
      "Epoch 456/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2043 - acc: 0.9417 - val_loss: 0.2712 - val_acc: 0.9302\n",
      "Epoch 457/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2075 - acc: 0.9404 - val_loss: 0.2547 - val_acc: 0.9398\n",
      "Epoch 458/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2112 - acc: 0.9411 - val_loss: 0.2648 - val_acc: 0.9390\n",
      "Epoch 459/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2040 - acc: 0.9411 - val_loss: 0.2608 - val_acc: 0.9427\n",
      "Epoch 460/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2064 - acc: 0.9404 - val_loss: 0.2569 - val_acc: 0.9405\n",
      "Epoch 461/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2028 - acc: 0.9411 - val_loss: 0.2717 - val_acc: 0.9375\n",
      "Epoch 462/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2047 - acc: 0.9417 - val_loss: 0.2649 - val_acc: 0.9375\n",
      "Epoch 463/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2038 - acc: 0.9420 - val_loss: 0.2566 - val_acc: 0.9398\n",
      "Epoch 464/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2088 - acc: 0.9408 - val_loss: 0.2662 - val_acc: 0.9383\n",
      "Epoch 465/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2083 - acc: 0.9404 - val_loss: 0.2554 - val_acc: 0.9420\n",
      "Epoch 466/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2046 - acc: 0.9414 - val_loss: 0.2592 - val_acc: 0.9339\n",
      "Epoch 467/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2053 - acc: 0.9404 - val_loss: 0.2590 - val_acc: 0.9405\n",
      "Epoch 468/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2224 - acc: 0.9408 - val_loss: 0.2753 - val_acc: 0.9390\n",
      "Epoch 469/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2357 - acc: 0.9404 - val_loss: 0.3163 - val_acc: 0.9346\n",
      "Epoch 470/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2177 - acc: 0.9408 - val_loss: 0.2580 - val_acc: 0.9390\n",
      "Epoch 471/500\n",
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.2044 - acc: 0.9404 - val_loss: 0.2617 - val_acc: 0.9420\n",
      "Epoch 472/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2047 - acc: 0.9408 - val_loss: 0.2616 - val_acc: 0.9427\n",
      "Epoch 473/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2043 - acc: 0.9417 - val_loss: 0.2547 - val_acc: 0.9398\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2056 - acc: 0.9411 - val_loss: 0.2568 - val_acc: 0.9398\n",
      "Epoch 475/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2020 - acc: 0.9411 - val_loss: 0.2560 - val_acc: 0.9375\n",
      "Epoch 476/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2055 - acc: 0.9423 - val_loss: 0.2588 - val_acc: 0.9398\n",
      "Epoch 477/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2010 - acc: 0.9420 - val_loss: 0.2581 - val_acc: 0.9383\n",
      "Epoch 478/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2025 - acc: 0.9408 - val_loss: 0.2687 - val_acc: 0.9353\n",
      "Epoch 479/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2044 - acc: 0.9411 - val_loss: 0.2582 - val_acc: 0.9427\n",
      "Epoch 480/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2045 - acc: 0.9401 - val_loss: 0.2663 - val_acc: 0.9398\n",
      "Epoch 481/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2078 - acc: 0.9408 - val_loss: 0.2607 - val_acc: 0.9390\n",
      "Epoch 482/500\n",
      "3173/3173 [==============================] - 0s 34us/step - loss: 0.2043 - acc: 0.9417 - val_loss: 0.2601 - val_acc: 0.9398\n",
      "Epoch 483/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2012 - acc: 0.9408 - val_loss: 0.2682 - val_acc: 0.9383\n",
      "Epoch 484/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2044 - acc: 0.9417 - val_loss: 0.2594 - val_acc: 0.9390\n",
      "Epoch 485/500\n",
      "3173/3173 [==============================] - 0s 25us/step - loss: 0.2016 - acc: 0.9408 - val_loss: 0.2774 - val_acc: 0.9375\n",
      "Epoch 486/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.2007 - acc: 0.9411 - val_loss: 0.2702 - val_acc: 0.9390\n",
      "Epoch 487/500\n",
      "3173/3173 [==============================] - 0s 23us/step - loss: 0.2062 - acc: 0.9414 - val_loss: 0.2625 - val_acc: 0.9346\n",
      "Epoch 488/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2028 - acc: 0.9404 - val_loss: 0.2886 - val_acc: 0.9361\n",
      "Epoch 489/500\n",
      "3173/3173 [==============================] - 0s 26us/step - loss: 0.2042 - acc: 0.9414 - val_loss: 0.2713 - val_acc: 0.9295\n",
      "Epoch 490/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2029 - acc: 0.9420 - val_loss: 0.2653 - val_acc: 0.9390\n",
      "Epoch 491/500\n",
      "3173/3173 [==============================] - 0s 16us/step - loss: 0.2089 - acc: 0.9414 - val_loss: 0.2920 - val_acc: 0.9390\n",
      "Epoch 492/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2124 - acc: 0.9408 - val_loss: 0.2626 - val_acc: 0.9390\n",
      "Epoch 493/500\n",
      "3173/3173 [==============================] - 0s 20us/step - loss: 0.2065 - acc: 0.9430 - val_loss: 0.2660 - val_acc: 0.9427\n",
      "Epoch 494/500\n",
      "3173/3173 [==============================] - 0s 18us/step - loss: 0.2023 - acc: 0.9414 - val_loss: 0.2792 - val_acc: 0.9295\n",
      "Epoch 495/500\n",
      "3173/3173 [==============================] - 0s 19us/step - loss: 0.2015 - acc: 0.9417 - val_loss: 0.2600 - val_acc: 0.9427\n",
      "Epoch 496/500\n",
      "3173/3173 [==============================] - 0s 17us/step - loss: 0.2013 - acc: 0.9414 - val_loss: 0.2694 - val_acc: 0.9375\n",
      "Epoch 497/500\n",
      "3173/3173 [==============================] - 0s 21us/step - loss: 0.1997 - acc: 0.9430 - val_loss: 0.2679 - val_acc: 0.9405\n",
      "Epoch 498/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2182 - acc: 0.9414 - val_loss: 0.2677 - val_acc: 0.9412\n",
      "Epoch 499/500\n",
      "3173/3173 [==============================] - 0s 22us/step - loss: 0.2088 - acc: 0.9417 - val_loss: 0.2574 - val_acc: 0.9383\n",
      "Epoch 500/500\n",
      "3173/3173 [==============================] - 0s 24us/step - loss: 0.2023 - acc: 0.9420 - val_loss: 0.2623 - val_acc: 0.9383\n",
      "1361/1361 [==============================] - 0s 8us/step\n",
      "../linkPrediction/dataframes/apnea\\apnea-results-article-_2008-2015.pkl\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# ps = set(list(test_node[2015][test_node[2015]['node_type_aut']==5]['node_index']))\n",
    "# eds= [ids for ids,ed in enumerate(edge_list) if ((ed[0] not in ps) and (ed[1] not in ps))]\n",
    "# n_eds = np.array(eds)\n",
    "name = \"article\"\n",
    "feature = [1,7,23,13,14,15,16,29,30,31,32]\n",
    "# tot = len(ps)\n",
    "tn = list(test_node[2015]['node_index'])\n",
    "pr = [0,1,5,10,15,20,25,50,100]\n",
    "results = []\n",
    "for a in pr:\n",
    "    ps = list(test_node[2015][test_node[2015]['node_type_art']==5]['node_index'])\n",
    "    tot = len(ps)\n",
    "    dis = math.ceil((a*len(ps))/100)\n",
    "    to_del = set(ps[0:dis])\n",
    "    t_new =  set([nd for nd in tn if nd not in to_del])\n",
    "    eds= [ids for ids,ed in enumerate(edge_list) if ((ed[0] in t_new) and (ed[1] in t_new))]\n",
    "    n_eds = np.array(eds)\n",
    "    print(a,dis,tot,len(ps),len(edge_list),len(n_eds),len(to_del),len(tn),len(t_new))\n",
    "    X = ut.load_data(datapath, domain[select_domain], \"X-features\", times)\n",
    "    y = ut.load_data(datapath, domain[select_domain], \"y-features\", times)\n",
    "    X = X[n_eds]\n",
    "    y = y[n_eds]\n",
    "    print(len(X),len(y))\n",
    "    param = [0.3,64,500,name,times]\n",
    "    m=ut.load_data(datapath, domain[select_domain], \"model-\"+name+\"-\"+str(1000), times)\n",
    "    X1=X[:,:,feature]\n",
    "    X1=X1[:,0:7]\n",
    "    print(name, X1.shape, \"--------------------------------------------------------------------\")\n",
    "    y_pr = m.predict([X1[:,:,0:3],X1[:,:,3:7],X1[:,:,7:11]])\n",
    "    y_pr1 = np.concatenate((y_pr[0],y_pr[1],y_pr[2]),axis=1)\n",
    "    X_test, y_test, model = lstm_classification(y_pr1,y,param)\n",
    "    results.append(cl.model_evaluate(model, X_test, y_test, param[1], name+\"-\"+str(a)))\n",
    "ut.save_data(results, datapath, domain[select_domain], \"results-\"+name+\"-\", times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/obesity\n",
      "article-0 0.7760284745065194 0.901480840669686\n",
      "article-1 0.7779934957063247 0.9055845928200119\n",
      "article-5 0.7711007076715815 0.9160721551607216\n",
      "article-10 0.7669014426313447 0.9217551749504431\n",
      "article-15 0.7481047506935743 0.9289018226374636\n",
      "article-20 0.7466399706731757 0.9332747738838693\n",
      "article-25 0.7368801743245972 0.9363033109794978\n",
      "article-50 0.7126679994489458 0.954644254458755\n",
      "article-100 0.5501371446072334 0.9683695651137311\n"
     ]
    }
   ],
   "source": [
    "#obesity\n",
    "results = ut.load_data(datapath, domain[select_domain], \"results-article-\", times)\n",
    "for result in results:\n",
    "    print(result['model name'], result['auc'], result['test accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/apnea\n",
      "article-0 0.7232182144171371 0.8967724725480841\n",
      "article-1 0.731882056874685 0.900458591467356\n",
      "article-5 0.7392312823322662 0.907204934318827\n",
      "article-10 0.6997916602205102 0.905982905982906\n",
      "article-15 0.7531077612571669 0.9111659466153967\n",
      "article-20 0.7328113695650342 0.9023917259211377\n",
      "article-25 0.7158935668156979 0.908751696065129\n",
      "article-50 0.6590579800137437 0.9270742357037474\n",
      "article-100 0.5086036333113496 0.9382806760173436\n"
     ]
    }
   ],
   "source": [
    "#apnea\n",
    "results = ut.load_data(datapath, domain[select_domain], \"results-article-\", times)\n",
    "for result in results:\n",
    "    print(result['model name'], result['auc'], result['test accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a=np.argmax(y_pr[2], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/apnea\n"
     ]
    }
   ],
   "source": [
    "m=ut.load_data(datapath, domain[select_domain], \"model-author-100\", times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n"
     ]
    }
   ],
   "source": [
    "X_test = ut.load_data(datapath, domain[select_domain], \"X_test-\"+\"author\", times)\n",
    "y_test = ut.load_data(datapath, domain[select_domain], \"y_test-\"+\"author\", times)\n",
    "y_pr = m.predict([X_test[:,:,0:3],X_test[:,:,3:7],X_test[:,:,7:11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "author - 100 : 0.007789745477723985  ---  0.08574771251323544\n",
      "../linkPrediction/dataframes/obesity\n",
      "author - 500 : 0.006582082098884335  ---  0.0784982570496935\n",
      "../linkPrediction/dataframes/obesity\n",
      "author - 1000 : 0.007046621995526154  ---  0.0760265933706484\n",
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "article - 100 : 0.007179165221783262  ---  0.10523204986819167\n",
      "../linkPrediction/dataframes/obesity\n",
      "article - 500 : 0.006257755637214457  ---  0.1006813627823434\n",
      "../linkPrediction/dataframes/obesity\n",
      "article - 1000 : 0.006129572189202695  ---  0.09960253720309245\n",
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "degree - 100 : 0.008613879567759032  ---  0.013030806967621072\n",
      "../linkPrediction/dataframes/obesity\n",
      "degree - 500 : 0.00642446310584163  ---  0.011207035033364263\n",
      "../linkPrediction/dataframes/obesity\n",
      "degree - 1000 : 0.005769636966234313  ---  0.010491071074258968\n",
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "citation - 100 : 0.009123676923668922  ---  0.002369199994304433\n",
      "../linkPrediction/dataframes/obesity\n",
      "citation - 500 : 0.007326928429078254  ---  0.0019149004316109882\n",
      "../linkPrediction/dataframes/obesity\n",
      "citation - 1000 : 0.007244989962065971  ---  0.0018460971854572694\n",
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "pref - 100 : 0.008488070777967642  ---  0.01291064044002397\n",
      "../linkPrediction/dataframes/obesity\n",
      "pref - 500 : 0.008508192973305134  ---  0.010912112007210633\n",
      "../linkPrediction/dataframes/obesity\n",
      "pref - 1000 : 0.009056155020500646  ---  0.010610142092613245\n",
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "cm - 100 : 0.023750216383852656  ---  0.013244867111648403\n",
      "../linkPrediction/dataframes/obesity\n",
      "cm - 500 : 0.02468343245242151  ---  0.011516972312157104\n",
      "../linkPrediction/dataframes/obesity\n",
      "cm - 1000 : 0.025431555274361303  ---  0.011271072153463593\n"
     ]
    }
   ],
   "source": [
    "#obesity\n",
    "feature_names = {\n",
    "'author':[0,6,22,9,10,11,12,25,26,27,28],\n",
    "'article': [1,7,23,13,14,15,16,29,30,31,32],\n",
    "'degree': [2,8,24,17,18,19,20,33,34,35,36],\n",
    "'citation': [3,21,37],\n",
    "'pref': [4,8,24],\n",
    "'cm': [5,8,24]\n",
    "}\n",
    "names1 = set(['author','article','degree'])\n",
    "names2 = set(['citation','pref','cm'])\n",
    "epochs = [100,500,1000]\n",
    "for name,feature in feature_names.items():\n",
    "    X_test = ut.load_data(datapath, domain[select_domain], \"X_test-\"+name, times)\n",
    "    y_test = ut.load_data(datapath, domain[select_domain], \"y_test-\"+name, times)\n",
    "    for ep in epochs:      \n",
    "        if name in names1:\n",
    "            m=ut.load_data(datapath, domain[select_domain], \"model-\"+name+\"-\"+str(ep), times)    \n",
    "            y_pr = m.predict([X_test[:,:,0:3],X_test[:,:,3:7],X_test[:,:,7:11]])\n",
    "            mse = mean_squared_error(y_test[:,0],y_pr[0][:,0])\n",
    "            rmse1 = sqrt(mse)\n",
    "            mse = mean_squared_error(y_test[:,1],y_pr[0][:,1])\n",
    "            rmse2 = sqrt(mse)\n",
    "            print(name,\"-\",ep,\":\",rmse1,\" --- \",rmse2)\n",
    "        if name in names2:\n",
    "            m=ut.load_data(datapath, domain[select_domain], \"model-\"+name+\"-\"+str(ep), times)\n",
    "            y_pr = m.predict(X_test)\n",
    "            mse = mean_squared_error(y_test[:,0],y_pr[:,0])\n",
    "            rmse1 = sqrt(mse)\n",
    "            mse = mean_squared_error(y_test[:,1],y_pr[:,1])\n",
    "            rmse2 = sqrt(mse)\n",
    "            print(name,\"-\",ep,\":\",rmse1,\" --- \",rmse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "author - 100 : 0.029578154405726614  ---  0.11884102479071174\n",
      "../linkPrediction/dataframes/apnea\n",
      "author - 500 : 0.02218262392937712  ---  0.11465263284841977\n",
      "../linkPrediction/dataframes/apnea\n",
      "author - 1000 : 0.022043554315022106  ---  0.11095309028021039\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "article - 100 : 0.028315552974296086  ---  0.13744653754820232\n",
      "../linkPrediction/dataframes/apnea\n",
      "article - 500 : 0.023152065256332323  ---  0.1322993336473282\n",
      "../linkPrediction/dataframes/apnea\n",
      "article - 1000 : 0.02324034348144273  ---  0.12869113822610598\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "degree - 100 : 0.021919176227575103  ---  0.028871314235206388\n",
      "../linkPrediction/dataframes/apnea\n",
      "degree - 500 : 0.0125616929181644  ---  0.023158542287761177\n",
      "../linkPrediction/dataframes/apnea\n",
      "degree - 1000 : 0.01066015117498941  ---  0.0194737284595051\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "citation - 100 : 0.006671330274301607  ---  0.0035346892915190486\n",
      "../linkPrediction/dataframes/apnea\n",
      "citation - 500 : 0.005356249538840386  ---  0.0027970286608145823\n",
      "../linkPrediction/dataframes/apnea\n",
      "citation - 1000 : 0.004913116413292733  ---  0.002498333072078338\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "pref - 100 : 0.013491421874137344  ---  0.02941388006914346\n",
      "../linkPrediction/dataframes/apnea\n",
      "pref - 500 : 0.013476673006668454  ---  0.021007387985829677\n",
      "../linkPrediction/dataframes/apnea\n",
      "pref - 1000 : 0.013778980162291383  ---  0.019128288642963023\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "cm - 100 : 0.07734728952151454  ---  0.02917543744100175\n",
      "../linkPrediction/dataframes/apnea\n",
      "cm - 500 : 0.08219088809157181  ---  0.025835137244719985\n",
      "../linkPrediction/dataframes/apnea\n",
      "cm - 1000 : 0.10105226831757926  ---  0.02698565327368903\n"
     ]
    }
   ],
   "source": [
    "##apnea\n",
    "feature_names = {\n",
    "'author':[0,6,22,9,10,11,12,25,26,27,28],\n",
    "'article': [1,7,23,13,14,15,16,29,30,31,32],\n",
    "'degree': [2,8,24,17,18,19,20,33,34,35,36],\n",
    "'citation': [3,21,37],\n",
    "'pref': [4,8,24],\n",
    "'cm': [5,8,24]\n",
    "}\n",
    "names1 = set(['author','article','degree'])\n",
    "names2 = set(['citation','pref','cm'])\n",
    "epochs = [100,500,1000]\n",
    "for name,feature in feature_names.items():\n",
    "    X_test = ut.load_data(datapath, domain[select_domain], \"X_test-\"+name, times)\n",
    "    y_test = ut.load_data(datapath, domain[select_domain], \"y_test-\"+name, times)\n",
    "    for ep in epochs:      \n",
    "        if name in names1:\n",
    "            m=ut.load_data(datapath, domain[select_domain], \"model-\"+name+\"-\"+str(ep), times)    \n",
    "            y_pr = m.predict([X_test[:,:,0:3],X_test[:,:,3:7],X_test[:,:,7:11]])\n",
    "            mse = mean_squared_error(y_test[:,0],y_pr[0][:,0])\n",
    "            rmse1 = sqrt(mse)\n",
    "            mse = mean_squared_error(y_test[:,1],y_pr[0][:,1])\n",
    "            rmse2 = sqrt(mse)\n",
    "            print(name,\"-\",ep,\":\",rmse1,\" --- \",rmse2)\n",
    "        if name in names2:\n",
    "            m=ut.load_data(datapath, domain[select_domain], \"model-\"+name+\"-\"+str(ep), times)\n",
    "            y_pr = m.predict(X_test)\n",
    "            mse = mean_squared_error(y_test[:,0],y_pr[:,0])\n",
    "            rmse1 = sqrt(mse)\n",
    "            mse = mean_squared_error(y_test[:,1],y_pr[:,1])\n",
    "            rmse2 = sqrt(mse)\n",
    "            print(name,\"-\",ep,\":\",rmse1,\" --- \",rmse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "author\n"
     ]
    }
   ],
   "source": [
    "feature_names = {\n",
    "'author':[0,6,22,9,10,11,12,25,26,27,28],\n",
    "'article': [1,7,23,13,14,15,16,29,30,31,32],\n",
    "'degree': [2,8,24,17,18,19,20,33,34,35,36],\n",
    "'citation': [3,21,37],\n",
    "'pref': [4,8,24],\n",
    "'cm': [5,8,24]\n",
    "}\n",
    "names1 = set(['author','article','degree'])\n",
    "names2 = set(['citation','pref','cm'])\n",
    "X = ut.load_data(datapath, domain[select_domain], \"X-features\", times)\n",
    "y = ut.load_data(datapath, domain[select_domain], \"y-features\", times)\n",
    "\n",
    "for name,feature in feature_names.items():\n",
    "    if name=='author':\n",
    "    m=ut.load_data(datapath, domain[select_domain], \"model-\"+name+\"-\"+str(1000), times)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/apnea\n"
     ]
    }
   ],
   "source": [
    "m=ut.load_data(datapath, domain[select_domain], \"model-\"+'author'+\"-\"+str(1000), times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:7]\n",
    "y_pr = m.predict([X[:,:,0:3],X[:,:,3:7],X[:,:,7:11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pr1 = np.concatenate((y_pr[0],y_pr[1],y_pr[2]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12527, 11)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.argmax(y_pr[2], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_class(param):\n",
    "    inputx = Input(shape=(param[1],))\n",
    "    x = Dense(20, activation='relu')(inputx)\n",
    "    x = Dense(10,activation='relu')(x)\n",
    "    x = Dense(1,activation='sigmoid',name=\"class\")(x)\n",
    "    model = Model(inputs=inputx, outputs=x)\n",
    "    return model\n",
    "\n",
    "def lstm_classification(X,y,param):\n",
    "    batch_size = param[1]\n",
    "    epoch = param[2]\n",
    "    print(X.shape,y.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = param[0], random_state = 0)\n",
    "    class_param = [X.shape[0], X.shape[1], 1]\n",
    "    print(class_param)\n",
    "    \n",
    "    cl = create_class(class_param)\n",
    "    model = Model(inputs=cl.input, outputs=cl.output)\n",
    "    model.compile(loss={'class':'binary_crossentropy'},\n",
    "                      optimizer='Adam',\n",
    "                      metrics={'class':'accuracy'})\n",
    "    print(X_train.shape,y_train.shape)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                        shuffle=True,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epoch,\n",
    "                        verbose=1)\n",
    "    return X_test, y_test, model\n",
    "        \n",
    "# name = 'author'\n",
    "# param = [0.3,64,200,name,times]\n",
    "# X_test, y_test, model = lstm_classification(y_pr1,y,param)\n",
    "# result = cl.model_evaluate(model, X_test, y_test, param[1], name)\n",
    "\n",
    "# if name=='author':\n",
    "# m=ut.load_data(datapath, domain[select_domain], \"model-\"+name+\"-\"+str(1000), times) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n",
      "../linkPrediction/dataframes/apnea\n"
     ]
    }
   ],
   "source": [
    "p = '../linkPrediction/dataframes/apnea'\n",
    "d=0\n",
    "m1=ut.load_data(p, domain[d], \"model-\"+'author'+\"-\"+str(1000), times)\n",
    "X = ut.load_data(p, domain[d], \"X-features\", times)\n",
    "y = ut.load_data(p, domain[d], \"y-features\", times)\n",
    "X=X[:,:,feature_names['author']]\n",
    "X1=X[:,0:7]\n",
    "X1=X1[y==1]\n",
    "y_pr = m1.predict([X1[:,:,0:3],X1[:,:,3:7],X1[:,:,7:11]])\n",
    "y_t = X[:,7]\n",
    "y_t = y_t[y==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "../linkPrediction/dataframes/obesity\n",
      "author (131006, 7, 11) --------------------------------------------------------------------\n",
      "(131006, 11) (131006,)\n",
      "[131006, 11, 1]\n",
      "(91704, 11) (91704,)\n",
      "Train on 91704 samples, validate on 39302 samples\n",
      "Epoch 1/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.4192 - acc: 0.9029 - val_loss: 0.4329 - val_acc: 0.9057\n",
      "Epoch 2/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.4093 - acc: 0.9031 - val_loss: 0.4105 - val_acc: 0.9062\n",
      "Epoch 3/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.4001 - acc: 0.9048 - val_loss: 0.3654 - val_acc: 0.9063\n",
      "Epoch 4/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.4164 - acc: 0.9023 - val_loss: 0.3268 - val_acc: 0.9062\n",
      "Epoch 5/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.4493 - acc: 0.8953 - val_loss: 0.4538 - val_acc: 0.9061\n",
      "Epoch 6/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.4035 - acc: 0.9039 - val_loss: 0.2946 - val_acc: 0.9062\n",
      "Epoch 7/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3353 - acc: 0.9053 - val_loss: 0.3435 - val_acc: 0.9065\n",
      "Epoch 8/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3725 - acc: 0.9058 - val_loss: 0.3841 - val_acc: 0.9064\n",
      "Epoch 9/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.4190 - acc: 0.8977 - val_loss: 1.0948 - val_acc: 0.7991\n",
      "Epoch 10/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.4035 - acc: 0.9028 - val_loss: 0.3046 - val_acc: 0.9063\n",
      "Epoch 11/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.4012 - acc: 0.8992 - val_loss: 0.3415 - val_acc: 0.9062\n",
      "Epoch 12/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.3425 - acc: 0.9076 - val_loss: 0.2910 - val_acc: 0.9064\n",
      "Epoch 13/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3528 - acc: 0.9062 - val_loss: 0.3438 - val_acc: 0.9063\n",
      "Epoch 14/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3343 - acc: 0.9052 - val_loss: 0.3015 - val_acc: 0.9062\n",
      "Epoch 15/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3554 - acc: 0.9030 - val_loss: 0.3093 - val_acc: 0.9053\n",
      "Epoch 16/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3256 - acc: 0.9081 - val_loss: 0.3245 - val_acc: 0.9072\n",
      "Epoch 17/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3211 - acc: 0.9087 - val_loss: 0.3281 - val_acc: 0.9077\n",
      "Epoch 18/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3119 - acc: 0.9070 - val_loss: 0.3220 - val_acc: 0.9081\n",
      "Epoch 19/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3157 - acc: 0.9078 - val_loss: 0.3165 - val_acc: 0.9079\n",
      "Epoch 20/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3031 - acc: 0.9077 - val_loss: 0.3128 - val_acc: 0.9079\n",
      "Epoch 21/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3032 - acc: 0.9087 - val_loss: 0.3211 - val_acc: 0.9078\n",
      "Epoch 22/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2976 - acc: 0.9090 - val_loss: 0.3070 - val_acc: 0.9048\n",
      "Epoch 23/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3079 - acc: 0.9073 - val_loss: 0.2971 - val_acc: 0.9067\n",
      "Epoch 24/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2910 - acc: 0.9091 - val_loss: 0.2852 - val_acc: 0.9072\n",
      "Epoch 25/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2961 - acc: 0.9089 - val_loss: 0.2813 - val_acc: 0.9079\n",
      "Epoch 26/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2840 - acc: 0.9092 - val_loss: 0.2910 - val_acc: 0.9077\n",
      "Epoch 27/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2832 - acc: 0.9093 - val_loss: 0.2969 - val_acc: 0.9061\n",
      "Epoch 28/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2818 - acc: 0.9090 - val_loss: 0.2868 - val_acc: 0.9077\n",
      "Epoch 29/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2746 - acc: 0.9096 - val_loss: 0.2767 - val_acc: 0.9081\n",
      "Epoch 30/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2736 - acc: 0.9096 - val_loss: 0.2814 - val_acc: 0.9076\n",
      "Epoch 31/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2710 - acc: 0.9097 - val_loss: 0.2802 - val_acc: 0.9077\n",
      "Epoch 32/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2722 - acc: 0.9098 - val_loss: 0.2802 - val_acc: 0.9077\n",
      "Epoch 33/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2713 - acc: 0.9098 - val_loss: 0.2751 - val_acc: 0.9081\n",
      "Epoch 34/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2705 - acc: 0.9097 - val_loss: 0.2793 - val_acc: 0.9077\n",
      "Epoch 35/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2715 - acc: 0.9095 - val_loss: 0.2754 - val_acc: 0.9079\n",
      "Epoch 36/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2700 - acc: 0.9099 - val_loss: 0.2789 - val_acc: 0.9078\n",
      "Epoch 37/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2710 - acc: 0.9098 - val_loss: 0.2778 - val_acc: 0.9079\n",
      "Epoch 38/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2698 - acc: 0.9096 - val_loss: 0.2747 - val_acc: 0.9079\n",
      "Epoch 39/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2686 - acc: 0.9098 - val_loss: 0.2748 - val_acc: 0.9077\n",
      "Epoch 40/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2704 - acc: 0.9095 - val_loss: 0.2754 - val_acc: 0.9077\n",
      "Epoch 41/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2687 - acc: 0.9098 - val_loss: 0.2752 - val_acc: 0.9079\n",
      "Epoch 42/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2680 - acc: 0.9098 - val_loss: 0.2760 - val_acc: 0.9076\n",
      "Epoch 43/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2685 - acc: 0.9098 - val_loss: 0.2747 - val_acc: 0.9078\n",
      "Epoch 44/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2691 - acc: 0.9095 - val_loss: 0.2742 - val_acc: 0.9078\n",
      "Epoch 45/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2703 - acc: 0.9096 - val_loss: 0.2800 - val_acc: 0.9075\n",
      "Epoch 46/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2690 - acc: 0.9098 - val_loss: 0.2745 - val_acc: 0.9080\n",
      "Epoch 47/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2690 - acc: 0.9099 - val_loss: 0.2731 - val_acc: 0.9077\n",
      "Epoch 48/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2683 - acc: 0.9097 - val_loss: 0.2775 - val_acc: 0.9080\n",
      "Epoch 49/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2690 - acc: 0.9096 - val_loss: 0.2780 - val_acc: 0.9076\n",
      "Epoch 50/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2674 - acc: 0.9097 - val_loss: 0.2743 - val_acc: 0.9080\n",
      "Epoch 51/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2691 - acc: 0.9097 - val_loss: 0.2744 - val_acc: 0.9077\n",
      "Epoch 52/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2684 - acc: 0.9098 - val_loss: 0.2767 - val_acc: 0.9080\n",
      "Epoch 53/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2700 - acc: 0.9097 - val_loss: 0.2741 - val_acc: 0.9077\n",
      "Epoch 54/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2686 - acc: 0.9098 - val_loss: 0.2754 - val_acc: 0.9078\n",
      "Epoch 55/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2678 - acc: 0.9098 - val_loss: 0.2744 - val_acc: 0.9078\n",
      "Epoch 56/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2670 - acc: 0.9098 - val_loss: 0.2734 - val_acc: 0.9078\n",
      "Epoch 57/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2672 - acc: 0.9097 - val_loss: 0.2782 - val_acc: 0.9076\n",
      "Epoch 58/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2685 - acc: 0.9096 - val_loss: 0.2736 - val_acc: 0.9079\n",
      "Epoch 59/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2676 - acc: 0.9098 - val_loss: 0.2743 - val_acc: 0.9080\n",
      "Epoch 60/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2671 - acc: 0.9096 - val_loss: 0.2736 - val_acc: 0.9077\n",
      "Epoch 61/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2673 - acc: 0.9097 - val_loss: 0.2742 - val_acc: 0.9077\n",
      "Epoch 62/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2675 - acc: 0.9097 - val_loss: 0.2732 - val_acc: 0.9079\n",
      "Epoch 63/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2673 - acc: 0.9096 - val_loss: 0.2740 - val_acc: 0.9079\n",
      "Epoch 64/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2664 - acc: 0.9098 - val_loss: 0.2740 - val_acc: 0.9079\n",
      "Epoch 65/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2667 - acc: 0.9095 - val_loss: 0.2753 - val_acc: 0.9077\n",
      "Epoch 66/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2668 - acc: 0.9098 - val_loss: 0.2752 - val_acc: 0.9078\n",
      "Epoch 67/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2660 - acc: 0.9098 - val_loss: 0.2749 - val_acc: 0.9077\n",
      "Epoch 68/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2667 - acc: 0.9096 - val_loss: 0.2735 - val_acc: 0.9080\n",
      "Epoch 69/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2660 - acc: 0.9098 - val_loss: 0.2727 - val_acc: 0.9077\n",
      "Epoch 70/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2700 - acc: 0.9096 - val_loss: 0.2748 - val_acc: 0.9078\n",
      "Epoch 71/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2663 - acc: 0.9098 - val_loss: 0.2725 - val_acc: 0.9078\n",
      "Epoch 72/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2655 - acc: 0.9097 - val_loss: 0.2759 - val_acc: 0.9076\n",
      "Epoch 73/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2666 - acc: 0.9097 - val_loss: 0.2735 - val_acc: 0.9080\n",
      "Epoch 74/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2672 - acc: 0.9098 - val_loss: 0.2764 - val_acc: 0.9075\n",
      "Epoch 75/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2669 - acc: 0.9097 - val_loss: 0.2748 - val_acc: 0.9075\n",
      "Epoch 76/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2668 - acc: 0.9099 - val_loss: 0.2727 - val_acc: 0.9077\n",
      "Epoch 77/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2666 - acc: 0.9097 - val_loss: 0.2724 - val_acc: 0.9079\n",
      "Epoch 78/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2657 - acc: 0.9098 - val_loss: 0.2750 - val_acc: 0.9076\n",
      "Epoch 79/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2664 - acc: 0.9098 - val_loss: 0.2732 - val_acc: 0.9079\n",
      "Epoch 80/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2661 - acc: 0.9098 - val_loss: 0.2741 - val_acc: 0.9079\n",
      "Epoch 81/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2660 - acc: 0.9098 - val_loss: 0.2735 - val_acc: 0.9077\n",
      "Epoch 82/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2655 - acc: 0.9099 - val_loss: 0.2728 - val_acc: 0.9079\n",
      "Epoch 83/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2666 - acc: 0.9098 - val_loss: 0.2730 - val_acc: 0.9079\n",
      "Epoch 84/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2653 - acc: 0.9098 - val_loss: 0.2747 - val_acc: 0.9077\n",
      "Epoch 85/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2679 - acc: 0.9099 - val_loss: 0.2738 - val_acc: 0.9075\n",
      "Epoch 86/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2664 - acc: 0.9098 - val_loss: 0.2730 - val_acc: 0.9078\n",
      "Epoch 87/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2661 - acc: 0.9097 - val_loss: 0.2737 - val_acc: 0.9078\n",
      "Epoch 88/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2663 - acc: 0.9097 - val_loss: 0.2738 - val_acc: 0.9078\n",
      "Epoch 89/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2658 - acc: 0.9099 - val_loss: 0.2737 - val_acc: 0.9079\n",
      "Epoch 90/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2666 - acc: 0.9098 - val_loss: 0.2728 - val_acc: 0.9077\n",
      "Epoch 91/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2653 - acc: 0.9099 - val_loss: 0.2726 - val_acc: 0.9078\n",
      "Epoch 92/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2653 - acc: 0.9098 - val_loss: 0.2723 - val_acc: 0.9079\n",
      "Epoch 93/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2662 - acc: 0.9100 - val_loss: 0.2725 - val_acc: 0.9080\n",
      "Epoch 94/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2655 - acc: 0.9098 - val_loss: 0.2751 - val_acc: 0.9074\n",
      "Epoch 95/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2651 - acc: 0.9099 - val_loss: 0.2720 - val_acc: 0.9078\n",
      "Epoch 96/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2661 - acc: 0.9098 - val_loss: 0.2732 - val_acc: 0.9078\n",
      "Epoch 97/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2670 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9078\n",
      "Epoch 98/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2658 - acc: 0.9099 - val_loss: 0.2730 - val_acc: 0.9077\n",
      "Epoch 99/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2666 - acc: 0.9098 - val_loss: 0.2724 - val_acc: 0.9079\n",
      "Epoch 100/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2656 - acc: 0.9098 - val_loss: 0.2718 - val_acc: 0.9079\n",
      "Epoch 101/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2664 - acc: 0.9096 - val_loss: 0.2730 - val_acc: 0.9076\n",
      "Epoch 102/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2654 - acc: 0.9099 - val_loss: 0.2729 - val_acc: 0.9079\n",
      "Epoch 103/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2662 - acc: 0.9098 - val_loss: 0.2720 - val_acc: 0.9078\n",
      "Epoch 104/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2663 - acc: 0.9098 - val_loss: 0.2728 - val_acc: 0.9078\n",
      "Epoch 105/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2662 - acc: 0.9098 - val_loss: 0.2790 - val_acc: 0.9077\n",
      "Epoch 106/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2671 - acc: 0.9099 - val_loss: 0.2727 - val_acc: 0.9079\n",
      "Epoch 107/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2657 - acc: 0.9098 - val_loss: 0.2723 - val_acc: 0.9079\n",
      "Epoch 108/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2652 - acc: 0.9099 - val_loss: 0.2730 - val_acc: 0.9078\n",
      "Epoch 109/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2654 - acc: 0.9099 - val_loss: 0.2753 - val_acc: 0.9077\n",
      "Epoch 110/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2658 - acc: 0.9098 - val_loss: 0.2725 - val_acc: 0.9079\n",
      "Epoch 111/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2654 - acc: 0.9099 - val_loss: 0.2716 - val_acc: 0.9079\n",
      "Epoch 112/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2654 - acc: 0.9098 - val_loss: 0.2730 - val_acc: 0.9079\n",
      "Epoch 113/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2666 - acc: 0.9098 - val_loss: 0.2718 - val_acc: 0.9079\n",
      "Epoch 114/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2660 - acc: 0.9097 - val_loss: 0.2719 - val_acc: 0.9076\n",
      "Epoch 115/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2648 - acc: 0.9098 - val_loss: 0.2729 - val_acc: 0.9079\n",
      "Epoch 116/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2648 - acc: 0.9098 - val_loss: 0.2735 - val_acc: 0.9078\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2657 - acc: 0.9099 - val_loss: 0.2732 - val_acc: 0.9077\n",
      "Epoch 118/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2655 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9078\n",
      "Epoch 119/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2655 - acc: 0.9097 - val_loss: 0.2729 - val_acc: 0.9080\n",
      "Epoch 120/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2646 - acc: 0.9098 - val_loss: 0.2744 - val_acc: 0.9078\n",
      "Epoch 121/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2658 - acc: 0.9098 - val_loss: 0.2731 - val_acc: 0.9078\n",
      "Epoch 122/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2650 - acc: 0.9098 - val_loss: 0.2726 - val_acc: 0.9079\n",
      "Epoch 123/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2651 - acc: 0.9098 - val_loss: 0.2747 - val_acc: 0.9078\n",
      "Epoch 124/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2653 - acc: 0.9098 - val_loss: 0.2725 - val_acc: 0.9079\n",
      "Epoch 125/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2653 - acc: 0.9098 - val_loss: 0.2743 - val_acc: 0.9077\n",
      "Epoch 126/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2651 - acc: 0.9099 - val_loss: 0.2778 - val_acc: 0.9079\n",
      "Epoch 127/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2665 - acc: 0.9098 - val_loss: 0.2727 - val_acc: 0.9079\n",
      "Epoch 128/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2649 - acc: 0.9100 - val_loss: 0.2729 - val_acc: 0.9078\n",
      "Epoch 129/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2658 - acc: 0.9096 - val_loss: 0.2740 - val_acc: 0.9078\n",
      "Epoch 130/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2656 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9077\n",
      "Epoch 131/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2646 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9077\n",
      "Epoch 132/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2647 - acc: 0.9099 - val_loss: 0.2756 - val_acc: 0.9079\n",
      "Epoch 133/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2654 - acc: 0.9098 - val_loss: 0.2731 - val_acc: 0.9079\n",
      "Epoch 134/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2649 - acc: 0.9099 - val_loss: 0.2722 - val_acc: 0.9079\n",
      "Epoch 135/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2654 - acc: 0.9099 - val_loss: 0.2749 - val_acc: 0.9079\n",
      "Epoch 136/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2652 - acc: 0.9099 - val_loss: 0.2726 - val_acc: 0.9078\n",
      "Epoch 137/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2661 - acc: 0.9098 - val_loss: 0.2733 - val_acc: 0.9076\n",
      "Epoch 138/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2646 - acc: 0.9098 - val_loss: 0.2720 - val_acc: 0.9079\n",
      "Epoch 139/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2648 - acc: 0.9098 - val_loss: 0.2717 - val_acc: 0.9079\n",
      "Epoch 140/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2646 - acc: 0.9098 - val_loss: 0.2719 - val_acc: 0.9079\n",
      "Epoch 141/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2668 - acc: 0.9098 - val_loss: 0.2775 - val_acc: 0.9076\n",
      "Epoch 142/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2670 - acc: 0.9098 - val_loss: 0.2720 - val_acc: 0.9080\n",
      "Epoch 143/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2650 - acc: 0.9098 - val_loss: 0.2746 - val_acc: 0.9077\n",
      "Epoch 144/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2652 - acc: 0.9099 - val_loss: 0.2726 - val_acc: 0.9077\n",
      "Epoch 145/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2646 - acc: 0.9098 - val_loss: 0.2721 - val_acc: 0.9076\n",
      "Epoch 146/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2644 - acc: 0.9097 - val_loss: 0.2734 - val_acc: 0.9077\n",
      "Epoch 147/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2640 - acc: 0.9099 - val_loss: 0.2712 - val_acc: 0.9080\n",
      "Epoch 148/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2650 - acc: 0.9100 - val_loss: 0.2729 - val_acc: 0.9078\n",
      "Epoch 149/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2643 - acc: 0.9100 - val_loss: 0.2724 - val_acc: 0.9076\n",
      "Epoch 150/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2651 - acc: 0.9101 - val_loss: 0.2720 - val_acc: 0.9079\n",
      "Epoch 151/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2648 - acc: 0.9099 - val_loss: 0.2721 - val_acc: 0.9080\n",
      "Epoch 152/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2644 - acc: 0.9100 - val_loss: 0.2729 - val_acc: 0.9078\n",
      "Epoch 153/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2648 - acc: 0.9099 - val_loss: 0.2731 - val_acc: 0.9078\n",
      "Epoch 154/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2638 - acc: 0.9099 - val_loss: 0.2766 - val_acc: 0.9078\n",
      "Epoch 155/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2644 - acc: 0.9100 - val_loss: 0.2760 - val_acc: 0.9077\n",
      "Epoch 156/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2642 - acc: 0.9100 - val_loss: 0.2718 - val_acc: 0.9077\n",
      "Epoch 157/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2645 - acc: 0.9102 - val_loss: 0.2720 - val_acc: 0.9076\n",
      "Epoch 158/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2637 - acc: 0.9100 - val_loss: 0.2730 - val_acc: 0.9078\n",
      "Epoch 159/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2644 - acc: 0.9100 - val_loss: 0.2728 - val_acc: 0.9079\n",
      "Epoch 160/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2651 - acc: 0.9100 - val_loss: 0.2718 - val_acc: 0.9079\n",
      "Epoch 161/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2643 - acc: 0.9100 - val_loss: 0.2725 - val_acc: 0.9079\n",
      "Epoch 162/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2647 - acc: 0.9100 - val_loss: 0.2726 - val_acc: 0.9077\n",
      "Epoch 163/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2645 - acc: 0.9099 - val_loss: 0.2736 - val_acc: 0.9077\n",
      "Epoch 164/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2647 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9077\n",
      "Epoch 165/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2650 - acc: 0.9100 - val_loss: 0.2724 - val_acc: 0.9076\n",
      "Epoch 166/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2644 - acc: 0.9100 - val_loss: 0.2721 - val_acc: 0.9078\n",
      "Epoch 167/500\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 0.2646 - acc: 0.909 - 1s 8us/step - loss: 0.2640 - acc: 0.9100 - val_loss: 0.2735 - val_acc: 0.9078\n",
      "Epoch 168/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2649 - acc: 0.9099 - val_loss: 0.2729 - val_acc: 0.9078\n",
      "Epoch 169/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2656 - acc: 0.9098 - val_loss: 0.2741 - val_acc: 0.9077\n",
      "Epoch 170/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2640 - acc: 0.9100 - val_loss: 0.2722 - val_acc: 0.9077\n",
      "Epoch 171/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2636 - acc: 0.9100 - val_loss: 0.2723 - val_acc: 0.9079\n",
      "Epoch 172/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2638 - acc: 0.9100 - val_loss: 0.2746 - val_acc: 0.9078\n",
      "Epoch 173/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2646 - acc: 0.9100 - val_loss: 0.2726 - val_acc: 0.9077\n",
      "Epoch 174/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2645 - acc: 0.9101 - val_loss: 0.2733 - val_acc: 0.9077\n",
      "Epoch 175/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2656 - acc: 0.9098 - val_loss: 0.2734 - val_acc: 0.9078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2637 - acc: 0.9099 - val_loss: 0.2731 - val_acc: 0.9079\n",
      "Epoch 177/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2643 - acc: 0.9099 - val_loss: 0.2720 - val_acc: 0.9079\n",
      "Epoch 178/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2644 - acc: 0.9100 - val_loss: 0.2721 - val_acc: 0.9080\n",
      "Epoch 179/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2639 - acc: 0.9101 - val_loss: 0.2780 - val_acc: 0.9073\n",
      "Epoch 180/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2645 - acc: 0.9100 - val_loss: 0.2747 - val_acc: 0.9079\n",
      "Epoch 181/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2640 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9077\n",
      "Epoch 182/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2643 - acc: 0.9099 - val_loss: 0.2726 - val_acc: 0.9079\n",
      "Epoch 183/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2644 - acc: 0.9100 - val_loss: 0.2733 - val_acc: 0.9078\n",
      "Epoch 184/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2635 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9078\n",
      "Epoch 185/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2634 - acc: 0.9099 - val_loss: 0.2740 - val_acc: 0.9077\n",
      "Epoch 186/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2633 - acc: 0.9099 - val_loss: 0.2726 - val_acc: 0.9078\n",
      "Epoch 187/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2634 - acc: 0.9100 - val_loss: 0.2717 - val_acc: 0.9079\n",
      "Epoch 188/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2639 - acc: 0.9100 - val_loss: 0.2720 - val_acc: 0.9080\n",
      "Epoch 189/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2639 - acc: 0.9100 - val_loss: 0.2738 - val_acc: 0.9076\n",
      "Epoch 190/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2638 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9077\n",
      "Epoch 191/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2638 - acc: 0.9100 - val_loss: 0.2716 - val_acc: 0.9076\n",
      "Epoch 192/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2645 - acc: 0.9100 - val_loss: 0.2721 - val_acc: 0.9076\n",
      "Epoch 193/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2634 - acc: 0.9100 - val_loss: 0.2740 - val_acc: 0.9081\n",
      "Epoch 194/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2636 - acc: 0.9100 - val_loss: 0.2725 - val_acc: 0.9079\n",
      "Epoch 195/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2642 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9078\n",
      "Epoch 196/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2642 - acc: 0.9099 - val_loss: 0.2792 - val_acc: 0.9076\n",
      "Epoch 197/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2640 - acc: 0.9101 - val_loss: 0.2726 - val_acc: 0.9080\n",
      "Epoch 198/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2642 - acc: 0.9099 - val_loss: 0.2733 - val_acc: 0.9080\n",
      "Epoch 199/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2636 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9077\n",
      "Epoch 200/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2641 - acc: 0.9100 - val_loss: 0.2716 - val_acc: 0.9080\n",
      "Epoch 201/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2635 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9076\n",
      "Epoch 202/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2640 - acc: 0.9099 - val_loss: 0.2732 - val_acc: 0.9078\n",
      "Epoch 203/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2637 - acc: 0.9101 - val_loss: 0.2727 - val_acc: 0.9075\n",
      "Epoch 204/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2638 - acc: 0.9100 - val_loss: 0.2726 - val_acc: 0.9075\n",
      "Epoch 205/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2639 - acc: 0.9099 - val_loss: 0.2754 - val_acc: 0.9076\n",
      "Epoch 206/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2641 - acc: 0.9098 - val_loss: 0.2723 - val_acc: 0.9079\n",
      "Epoch 207/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2649 - acc: 0.9099 - val_loss: 0.2744 - val_acc: 0.9077\n",
      "Epoch 208/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2638 - acc: 0.9100 - val_loss: 0.2724 - val_acc: 0.9080\n",
      "Epoch 209/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2633 - acc: 0.9101 - val_loss: 0.2733 - val_acc: 0.9077\n",
      "Epoch 210/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2634 - acc: 0.9099 - val_loss: 0.2719 - val_acc: 0.9078\n",
      "Epoch 211/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2636 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9076\n",
      "Epoch 212/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2661 - acc: 0.9100 - val_loss: 0.2747 - val_acc: 0.9078\n",
      "Epoch 213/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2638 - acc: 0.9099 - val_loss: 0.2774 - val_acc: 0.9077\n",
      "Epoch 214/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2645 - acc: 0.9100 - val_loss: 0.2746 - val_acc: 0.9079\n",
      "Epoch 215/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2634 - acc: 0.9100 - val_loss: 0.2728 - val_acc: 0.9079\n",
      "Epoch 216/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2635 - acc: 0.9100 - val_loss: 0.2717 - val_acc: 0.9080\n",
      "Epoch 217/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2632 - acc: 0.9100 - val_loss: 0.2720 - val_acc: 0.9078\n",
      "Epoch 218/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2633 - acc: 0.9100 - val_loss: 0.2728 - val_acc: 0.9074\n",
      "Epoch 219/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2632 - acc: 0.9101 - val_loss: 0.2727 - val_acc: 0.9074\n",
      "Epoch 220/500\n",
      "91704/91704 [==============================] - 1s 15us/step - loss: 0.2634 - acc: 0.9101 - val_loss: 0.2722 - val_acc: 0.9078\n",
      "Epoch 221/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2630 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9076\n",
      "Epoch 222/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2639 - acc: 0.9100 - val_loss: 0.2733 - val_acc: 0.9078\n",
      "Epoch 223/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2640 - acc: 0.9099 - val_loss: 0.2717 - val_acc: 0.9078\n",
      "Epoch 224/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2640 - acc: 0.9100 - val_loss: 0.2722 - val_acc: 0.9078\n",
      "Epoch 225/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2632 - acc: 0.9102 - val_loss: 0.2726 - val_acc: 0.9074\n",
      "Epoch 226/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2636 - acc: 0.9101 - val_loss: 0.2719 - val_acc: 0.9078\n",
      "Epoch 227/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2638 - acc: 0.9100 - val_loss: 0.2732 - val_acc: 0.9081\n",
      "Epoch 228/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2646 - acc: 0.9098 - val_loss: 0.2722 - val_acc: 0.9081\n",
      "Epoch 229/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2634 - acc: 0.9100 - val_loss: 0.2724 - val_acc: 0.9079\n",
      "Epoch 230/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2630 - acc: 0.9101 - val_loss: 0.2734 - val_acc: 0.9076\n",
      "Epoch 231/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2636 - acc: 0.9100 - val_loss: 0.2725 - val_acc: 0.9079\n",
      "Epoch 232/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2639 - acc: 0.9100 - val_loss: 0.2733 - val_acc: 0.9079\n",
      "Epoch 233/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2631 - acc: 0.9100 - val_loss: 0.2722 - val_acc: 0.9077\n",
      "Epoch 234/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2645 - acc: 0.9100 - val_loss: 0.2725 - val_acc: 0.9079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2635 - acc: 0.9100 - val_loss: 0.2725 - val_acc: 0.9080\n",
      "Epoch 236/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2628 - acc: 0.9100 - val_loss: 0.2737 - val_acc: 0.9077\n",
      "Epoch 237/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2630 - acc: 0.9100 - val_loss: 0.2738 - val_acc: 0.9076\n",
      "Epoch 238/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2652 - acc: 0.9098 - val_loss: 0.2755 - val_acc: 0.9075\n",
      "Epoch 239/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2637 - acc: 0.9100 - val_loss: 0.2819 - val_acc: 0.8956\n",
      "Epoch 240/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2637 - acc: 0.9099 - val_loss: 0.2719 - val_acc: 0.9078\n",
      "Epoch 241/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2637 - acc: 0.9101 - val_loss: 0.2720 - val_acc: 0.9078\n",
      "Epoch 242/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2631 - acc: 0.9101 - val_loss: 0.2730 - val_acc: 0.9079\n",
      "Epoch 243/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2637 - acc: 0.9099 - val_loss: 0.2722 - val_acc: 0.9079\n",
      "Epoch 244/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2632 - acc: 0.9100 - val_loss: 0.2724 - val_acc: 0.9078\n",
      "Epoch 245/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2640 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9078\n",
      "Epoch 246/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2641 - acc: 0.9099 - val_loss: 0.2716 - val_acc: 0.9079\n",
      "Epoch 247/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2630 - acc: 0.9100 - val_loss: 0.2729 - val_acc: 0.9078\n",
      "Epoch 248/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2635 - acc: 0.9099 - val_loss: 0.2721 - val_acc: 0.9080\n",
      "Epoch 249/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2642 - acc: 0.9100 - val_loss: 0.2726 - val_acc: 0.9081\n",
      "Epoch 250/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2637 - acc: 0.9100 - val_loss: 0.2715 - val_acc: 0.9077\n",
      "Epoch 251/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2639 - acc: 0.9100 - val_loss: 0.2740 - val_acc: 0.9080\n",
      "Epoch 252/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2639 - acc: 0.9101 - val_loss: 0.2726 - val_acc: 0.9079\n",
      "Epoch 253/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2634 - acc: 0.9100 - val_loss: 0.2723 - val_acc: 0.9078\n",
      "Epoch 254/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2631 - acc: 0.9100 - val_loss: 0.2719 - val_acc: 0.9078\n",
      "Epoch 255/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2635 - acc: 0.9100 - val_loss: 0.2716 - val_acc: 0.9078\n",
      "Epoch 256/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2625 - acc: 0.9101 - val_loss: 0.2718 - val_acc: 0.9079\n",
      "Epoch 257/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2629 - acc: 0.9102 - val_loss: 0.2735 - val_acc: 0.9077\n",
      "Epoch 258/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2639 - acc: 0.9100 - val_loss: 0.2726 - val_acc: 0.9076\n",
      "Epoch 259/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2636 - acc: 0.9099 - val_loss: 0.2724 - val_acc: 0.9077\n",
      "Epoch 260/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2634 - acc: 0.9100 - val_loss: 0.2733 - val_acc: 0.9079\n",
      "Epoch 261/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2649 - acc: 0.9101 - val_loss: 0.2722 - val_acc: 0.9079\n",
      "Epoch 262/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2629 - acc: 0.9101 - val_loss: 0.2719 - val_acc: 0.9076\n",
      "Epoch 263/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2626 - acc: 0.9100 - val_loss: 0.2713 - val_acc: 0.9078\n",
      "Epoch 264/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2659 - acc: 0.9099 - val_loss: 0.2724 - val_acc: 0.9079\n",
      "Epoch 265/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2634 - acc: 0.9100 - val_loss: 0.2721 - val_acc: 0.9078\n",
      "Epoch 266/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2632 - acc: 0.9100 - val_loss: 0.2714 - val_acc: 0.9080\n",
      "Epoch 267/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2635 - acc: 0.9100 - val_loss: 0.2727 - val_acc: 0.9079\n",
      "Epoch 268/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2639 - acc: 0.9100 - val_loss: 0.2728 - val_acc: 0.9077\n",
      "Epoch 269/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2642 - acc: 0.9101 - val_loss: 0.2734 - val_acc: 0.9077\n",
      "Epoch 270/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2632 - acc: 0.9099 - val_loss: 0.2730 - val_acc: 0.9077\n",
      "Epoch 271/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2638 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9078\n",
      "Epoch 272/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2635 - acc: 0.9100 - val_loss: 0.2719 - val_acc: 0.9077\n",
      "Epoch 273/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2629 - acc: 0.9100 - val_loss: 0.2747 - val_acc: 0.9076\n",
      "Epoch 274/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2630 - acc: 0.9100 - val_loss: 0.2712 - val_acc: 0.9077\n",
      "Epoch 275/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2628 - acc: 0.9099 - val_loss: 0.2730 - val_acc: 0.9079\n",
      "Epoch 276/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2635 - acc: 0.9100 - val_loss: 0.2733 - val_acc: 0.9078\n",
      "Epoch 277/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2630 - acc: 0.9100 - val_loss: 0.2724 - val_acc: 0.9078\n",
      "Epoch 278/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2630 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9078\n",
      "Epoch 279/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2632 - acc: 0.9099 - val_loss: 0.2721 - val_acc: 0.9077\n",
      "Epoch 280/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2635 - acc: 0.9100 - val_loss: 0.2743 - val_acc: 0.9079\n",
      "Epoch 281/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2638 - acc: 0.9100 - val_loss: 0.2747 - val_acc: 0.9077\n",
      "Epoch 282/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2639 - acc: 0.9099 - val_loss: 0.2739 - val_acc: 0.9078\n",
      "Epoch 283/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2656 - acc: 0.9100 - val_loss: 0.2762 - val_acc: 0.9078\n",
      "Epoch 284/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2654 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9078\n",
      "Epoch 285/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2631 - acc: 0.9100 - val_loss: 0.2739 - val_acc: 0.9080\n",
      "Epoch 286/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2628 - acc: 0.9099 - val_loss: 0.2713 - val_acc: 0.9080\n",
      "Epoch 287/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2625 - acc: 0.9100 - val_loss: 0.2725 - val_acc: 0.9078\n",
      "Epoch 288/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2628 - acc: 0.9100 - val_loss: 0.2719 - val_acc: 0.9079\n",
      "Epoch 289/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2634 - acc: 0.9100 - val_loss: 0.2717 - val_acc: 0.9080\n",
      "Epoch 290/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2628 - acc: 0.9100 - val_loss: 0.2736 - val_acc: 0.9078\n",
      "Epoch 291/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2629 - acc: 0.9099 - val_loss: 0.2729 - val_acc: 0.9079\n",
      "Epoch 292/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2628 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9078\n",
      "Epoch 293/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2633 - acc: 0.9097 - val_loss: 0.2722 - val_acc: 0.9078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2628 - acc: 0.9100 - val_loss: 0.2716 - val_acc: 0.9079\n",
      "Epoch 295/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2644 - acc: 0.9099 - val_loss: 0.2733 - val_acc: 0.9079\n",
      "Epoch 296/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2625 - acc: 0.9100 - val_loss: 0.2713 - val_acc: 0.9080\n",
      "Epoch 297/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2627 - acc: 0.9101 - val_loss: 0.2712 - val_acc: 0.9080\n",
      "Epoch 298/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2635 - acc: 0.9100 - val_loss: 0.2740 - val_acc: 0.9078\n",
      "Epoch 299/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2625 - acc: 0.9099 - val_loss: 0.2719 - val_acc: 0.9080\n",
      "Epoch 300/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2625 - acc: 0.9101 - val_loss: 0.2715 - val_acc: 0.9077\n",
      "Epoch 301/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2626 - acc: 0.9101 - val_loss: 0.2712 - val_acc: 0.9078\n",
      "Epoch 302/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2626 - acc: 0.9099 - val_loss: 0.2719 - val_acc: 0.9077\n",
      "Epoch 303/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2622 - acc: 0.9100 - val_loss: 0.2745 - val_acc: 0.9080\n",
      "Epoch 304/500\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 0.2627 - acc: 0.909 - 1s 9us/step - loss: 0.2628 - acc: 0.9099 - val_loss: 0.2717 - val_acc: 0.9079\n",
      "Epoch 305/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2628 - acc: 0.9100 - val_loss: 0.2718 - val_acc: 0.9078\n",
      "Epoch 306/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2626 - acc: 0.9099 - val_loss: 0.2726 - val_acc: 0.9078\n",
      "Epoch 307/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2628 - acc: 0.9101 - val_loss: 0.2722 - val_acc: 0.9078\n",
      "Epoch 308/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2630 - acc: 0.9099 - val_loss: 0.2716 - val_acc: 0.9079\n",
      "Epoch 309/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2626 - acc: 0.9100 - val_loss: 0.2717 - val_acc: 0.9078\n",
      "Epoch 310/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2641 - acc: 0.9098 - val_loss: 0.2722 - val_acc: 0.9079\n",
      "Epoch 311/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2628 - acc: 0.9099 - val_loss: 0.2741 - val_acc: 0.9081\n",
      "Epoch 312/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2638 - acc: 0.9100 - val_loss: 0.2713 - val_acc: 0.9078\n",
      "Epoch 313/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2631 - acc: 0.9099 - val_loss: 0.2731 - val_acc: 0.9080\n",
      "Epoch 314/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2629 - acc: 0.9100 - val_loss: 0.2732 - val_acc: 0.9079\n",
      "Epoch 315/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2626 - acc: 0.9100 - val_loss: 0.2723 - val_acc: 0.9079\n",
      "Epoch 316/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2626 - acc: 0.9100 - val_loss: 0.2717 - val_acc: 0.9081\n",
      "Epoch 317/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2623 - acc: 0.9100 - val_loss: 0.2718 - val_acc: 0.9079\n",
      "Epoch 318/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2627 - acc: 0.9099 - val_loss: 0.2726 - val_acc: 0.9078\n",
      "Epoch 319/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2623 - acc: 0.9100 - val_loss: 0.2721 - val_acc: 0.9079\n",
      "Epoch 320/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2630 - acc: 0.9099 - val_loss: 0.2715 - val_acc: 0.9078\n",
      "Epoch 321/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2624 - acc: 0.9099 - val_loss: 0.2713 - val_acc: 0.9079\n",
      "Epoch 322/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2625 - acc: 0.9099 - val_loss: 0.2721 - val_acc: 0.9080\n",
      "Epoch 323/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2626 - acc: 0.9099 - val_loss: 0.2729 - val_acc: 0.9075\n",
      "Epoch 324/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2642 - acc: 0.9098 - val_loss: 0.2726 - val_acc: 0.9078\n",
      "Epoch 325/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2624 - acc: 0.9101 - val_loss: 0.2724 - val_acc: 0.9079\n",
      "Epoch 326/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2630 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9080\n",
      "Epoch 327/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2632 - acc: 0.9099 - val_loss: 0.2715 - val_acc: 0.9077\n",
      "Epoch 328/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2623 - acc: 0.9100 - val_loss: 0.2708 - val_acc: 0.9078\n",
      "Epoch 329/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2633 - acc: 0.9099 - val_loss: 0.2718 - val_acc: 0.9078\n",
      "Epoch 330/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2630 - acc: 0.9100 - val_loss: 0.2717 - val_acc: 0.9079\n",
      "Epoch 331/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2621 - acc: 0.9100 - val_loss: 0.2751 - val_acc: 0.9078\n",
      "Epoch 332/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2628 - acc: 0.9099 - val_loss: 0.2750 - val_acc: 0.9079\n",
      "Epoch 333/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2624 - acc: 0.9100 - val_loss: 0.2723 - val_acc: 0.9080\n",
      "Epoch 334/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2626 - acc: 0.9100 - val_loss: 0.2722 - val_acc: 0.9079\n",
      "Epoch 335/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2625 - acc: 0.9098 - val_loss: 0.2730 - val_acc: 0.9078\n",
      "Epoch 336/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2636 - acc: 0.9100 - val_loss: 0.2723 - val_acc: 0.9080\n",
      "Epoch 337/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2623 - acc: 0.9098 - val_loss: 0.2708 - val_acc: 0.9080\n",
      "Epoch 338/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2620 - acc: 0.9100 - val_loss: 0.2714 - val_acc: 0.9078\n",
      "Epoch 339/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2622 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9078\n",
      "Epoch 340/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2622 - acc: 0.9100 - val_loss: 0.2724 - val_acc: 0.9079\n",
      "Epoch 341/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2649 - acc: 0.9098 - val_loss: 0.2723 - val_acc: 0.9078\n",
      "Epoch 342/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2622 - acc: 0.9099 - val_loss: 0.2719 - val_acc: 0.9080\n",
      "Epoch 343/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2625 - acc: 0.9100 - val_loss: 0.2715 - val_acc: 0.9077\n",
      "Epoch 344/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2624 - acc: 0.9099 - val_loss: 0.2718 - val_acc: 0.9079\n",
      "Epoch 345/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2627 - acc: 0.9102 - val_loss: 0.2732 - val_acc: 0.9077\n",
      "Epoch 346/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2620 - acc: 0.9099 - val_loss: 0.2719 - val_acc: 0.9077\n",
      "Epoch 347/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2626 - acc: 0.9099 - val_loss: 0.2724 - val_acc: 0.9080\n",
      "Epoch 348/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2630 - acc: 0.9099 - val_loss: 0.2728 - val_acc: 0.9078\n",
      "Epoch 349/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2631 - acc: 0.9100 - val_loss: 0.2716 - val_acc: 0.9078\n",
      "Epoch 350/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2622 - acc: 0.9101 - val_loss: 0.2717 - val_acc: 0.9079\n",
      "Epoch 351/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2619 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9078\n",
      "Epoch 352/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2621 - acc: 0.9099 - val_loss: 0.2722 - val_acc: 0.9078\n",
      "Epoch 353/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2625 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9075\n",
      "Epoch 354/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2623 - acc: 0.9099 - val_loss: 0.2716 - val_acc: 0.9078\n",
      "Epoch 355/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2619 - acc: 0.9099 - val_loss: 0.2738 - val_acc: 0.9078\n",
      "Epoch 356/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2621 - acc: 0.9100 - val_loss: 0.2722 - val_acc: 0.9078\n",
      "Epoch 357/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2618 - acc: 0.9101 - val_loss: 0.2723 - val_acc: 0.9077\n",
      "Epoch 358/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2624 - acc: 0.9098 - val_loss: 0.2884 - val_acc: 0.9066\n",
      "Epoch 359/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2636 - acc: 0.9098 - val_loss: 0.2721 - val_acc: 0.9078\n",
      "Epoch 360/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2637 - acc: 0.9100 - val_loss: 0.2721 - val_acc: 0.9078\n",
      "Epoch 361/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2625 - acc: 0.9099 - val_loss: 0.2721 - val_acc: 0.9078\n",
      "Epoch 362/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2624 - acc: 0.9099 - val_loss: 0.2719 - val_acc: 0.9078\n",
      "Epoch 363/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2621 - acc: 0.9098 - val_loss: 0.2717 - val_acc: 0.9079\n",
      "Epoch 364/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2621 - acc: 0.9099 - val_loss: 0.2732 - val_acc: 0.9076\n",
      "Epoch 365/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2625 - acc: 0.9100 - val_loss: 0.2721 - val_acc: 0.9077\n",
      "Epoch 366/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2626 - acc: 0.9100 - val_loss: 0.2728 - val_acc: 0.9079\n",
      "Epoch 367/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2621 - acc: 0.9099 - val_loss: 0.2715 - val_acc: 0.9080\n",
      "Epoch 368/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2619 - acc: 0.9100 - val_loss: 0.2717 - val_acc: 0.9079\n",
      "Epoch 369/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2647 - acc: 0.9099 - val_loss: 0.2734 - val_acc: 0.9077\n",
      "Epoch 370/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2625 - acc: 0.9097 - val_loss: 0.2728 - val_acc: 0.9079\n",
      "Epoch 371/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2629 - acc: 0.9098 - val_loss: 0.2712 - val_acc: 0.9079\n",
      "Epoch 372/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2626 - acc: 0.9098 - val_loss: 0.2718 - val_acc: 0.9080\n",
      "Epoch 373/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2619 - acc: 0.9100 - val_loss: 0.2737 - val_acc: 0.9079\n",
      "Epoch 374/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2620 - acc: 0.9100 - val_loss: 0.2720 - val_acc: 0.9079\n",
      "Epoch 375/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2626 - acc: 0.9101 - val_loss: 0.2734 - val_acc: 0.9079\n",
      "Epoch 376/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2627 - acc: 0.9099 - val_loss: 0.2727 - val_acc: 0.9077\n",
      "Epoch 377/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2623 - acc: 0.9097 - val_loss: 0.2719 - val_acc: 0.9078\n",
      "Epoch 378/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2624 - acc: 0.9099 - val_loss: 0.2715 - val_acc: 0.9079\n",
      "Epoch 379/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2626 - acc: 0.9101 - val_loss: 0.2725 - val_acc: 0.9077\n",
      "Epoch 380/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2631 - acc: 0.9099 - val_loss: 0.2736 - val_acc: 0.9078\n",
      "Epoch 381/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2623 - acc: 0.9098 - val_loss: 0.2729 - val_acc: 0.9077\n",
      "Epoch 382/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2618 - acc: 0.9098 - val_loss: 0.2721 - val_acc: 0.9078\n",
      "Epoch 383/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2622 - acc: 0.9100 - val_loss: 0.2710 - val_acc: 0.9079\n",
      "Epoch 384/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2617 - acc: 0.9100 - val_loss: 0.2714 - val_acc: 0.9078\n",
      "Epoch 385/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2627 - acc: 0.9102 - val_loss: 0.2724 - val_acc: 0.9078\n",
      "Epoch 386/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2622 - acc: 0.9099 - val_loss: 0.2728 - val_acc: 0.9078\n",
      "Epoch 387/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2624 - acc: 0.9099 - val_loss: 0.2771 - val_acc: 0.9078\n",
      "Epoch 388/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2627 - acc: 0.9099 - val_loss: 0.2728 - val_acc: 0.9080\n",
      "Epoch 389/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2622 - acc: 0.9100 - val_loss: 0.2739 - val_acc: 0.9079\n",
      "Epoch 390/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2621 - acc: 0.9100 - val_loss: 0.2715 - val_acc: 0.9080\n",
      "Epoch 391/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2623 - acc: 0.9100 - val_loss: 0.2722 - val_acc: 0.9080\n",
      "Epoch 392/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2620 - acc: 0.9099 - val_loss: 0.2735 - val_acc: 0.9078\n",
      "Epoch 393/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2637 - acc: 0.9100 - val_loss: 0.2717 - val_acc: 0.9080\n",
      "Epoch 394/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2620 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9079\n",
      "Epoch 395/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2624 - acc: 0.9101 - val_loss: 0.2717 - val_acc: 0.9079\n",
      "Epoch 396/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2623 - acc: 0.9101 - val_loss: 0.2734 - val_acc: 0.9079\n",
      "Epoch 397/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2625 - acc: 0.9100 - val_loss: 0.2732 - val_acc: 0.9078\n",
      "Epoch 398/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2620 - acc: 0.9100 - val_loss: 0.2725 - val_acc: 0.9080\n",
      "Epoch 399/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2630 - acc: 0.9101 - val_loss: 0.2735 - val_acc: 0.9076\n",
      "Epoch 400/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2634 - acc: 0.9099 - val_loss: 0.2749 - val_acc: 0.9077\n",
      "Epoch 401/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2625 - acc: 0.9101 - val_loss: 0.2737 - val_acc: 0.9079\n",
      "Epoch 402/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2622 - acc: 0.9099 - val_loss: 0.2736 - val_acc: 0.9076\n",
      "Epoch 403/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2617 - acc: 0.9101 - val_loss: 0.2711 - val_acc: 0.9079\n",
      "Epoch 404/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2622 - acc: 0.9099 - val_loss: 0.2752 - val_acc: 0.9076\n",
      "Epoch 405/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2622 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9080\n",
      "Epoch 406/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2627 - acc: 0.9101 - val_loss: 0.2721 - val_acc: 0.9079\n",
      "Epoch 407/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2619 - acc: 0.9099 - val_loss: 0.2721 - val_acc: 0.9078\n",
      "Epoch 408/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2628 - acc: 0.9100 - val_loss: 0.2814 - val_acc: 0.9071\n",
      "Epoch 409/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2627 - acc: 0.9099 - val_loss: 0.2730 - val_acc: 0.9081\n",
      "Epoch 410/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2627 - acc: 0.9098 - val_loss: 0.2715 - val_acc: 0.9079\n",
      "Epoch 411/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2620 - acc: 0.9098 - val_loss: 0.2725 - val_acc: 0.9077\n",
      "Epoch 412/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2624 - acc: 0.9100 - val_loss: 0.2740 - val_acc: 0.9077\n",
      "Epoch 413/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2623 - acc: 0.9099 - val_loss: 0.2859 - val_acc: 0.9078\n",
      "Epoch 414/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2631 - acc: 0.9099 - val_loss: 0.2735 - val_acc: 0.9078\n",
      "Epoch 415/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2619 - acc: 0.9099 - val_loss: 0.2722 - val_acc: 0.9079\n",
      "Epoch 416/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2626 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9079\n",
      "Epoch 417/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2621 - acc: 0.9099 - val_loss: 0.2723 - val_acc: 0.9077\n",
      "Epoch 418/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2624 - acc: 0.9099 - val_loss: 0.2728 - val_acc: 0.9078\n",
      "Epoch 419/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2623 - acc: 0.9100 - val_loss: 0.2728 - val_acc: 0.9082\n",
      "Epoch 420/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2618 - acc: 0.9099 - val_loss: 0.2724 - val_acc: 0.9080\n",
      "Epoch 421/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2627 - acc: 0.9099 - val_loss: 0.2724 - val_acc: 0.9078\n",
      "Epoch 422/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2619 - acc: 0.9099 - val_loss: 0.2731 - val_acc: 0.9079\n",
      "Epoch 423/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2619 - acc: 0.9099 - val_loss: 0.2722 - val_acc: 0.9082\n",
      "Epoch 424/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2615 - acc: 0.9100 - val_loss: 0.2725 - val_acc: 0.9078\n",
      "Epoch 425/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2624 - acc: 0.9100 - val_loss: 0.2710 - val_acc: 0.9079\n",
      "Epoch 426/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2635 - acc: 0.9098 - val_loss: 0.2722 - val_acc: 0.9077\n",
      "Epoch 427/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2620 - acc: 0.9099 - val_loss: 0.2721 - val_acc: 0.9079\n",
      "Epoch 428/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2630 - acc: 0.9098 - val_loss: 0.2757 - val_acc: 0.9080\n",
      "Epoch 429/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2622 - acc: 0.9099 - val_loss: 0.2718 - val_acc: 0.9077\n",
      "Epoch 430/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2614 - acc: 0.9100 - val_loss: 0.2724 - val_acc: 0.9078\n",
      "Epoch 431/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2615 - acc: 0.9100 - val_loss: 0.2795 - val_acc: 0.9010\n",
      "Epoch 432/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2642 - acc: 0.9098 - val_loss: 0.2724 - val_acc: 0.9079\n",
      "Epoch 433/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2629 - acc: 0.9100 - val_loss: 0.2715 - val_acc: 0.9080\n",
      "Epoch 434/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2631 - acc: 0.9100 - val_loss: 0.2719 - val_acc: 0.9079\n",
      "Epoch 435/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2634 - acc: 0.9101 - val_loss: 0.2732 - val_acc: 0.9074\n",
      "Epoch 436/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2631 - acc: 0.9097 - val_loss: 0.2724 - val_acc: 0.9078\n",
      "Epoch 437/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2650 - acc: 0.9098 - val_loss: 0.2713 - val_acc: 0.9081\n",
      "Epoch 438/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2627 - acc: 0.9100 - val_loss: 0.2710 - val_acc: 0.9079\n",
      "Epoch 439/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2630 - acc: 0.9100 - val_loss: 0.2726 - val_acc: 0.9078\n",
      "Epoch 440/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2620 - acc: 0.9100 - val_loss: 0.2712 - val_acc: 0.9078\n",
      "Epoch 441/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2623 - acc: 0.9100 - val_loss: 0.2710 - val_acc: 0.9079\n",
      "Epoch 442/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2623 - acc: 0.9099 - val_loss: 0.2715 - val_acc: 0.9080\n",
      "Epoch 443/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2620 - acc: 0.9100 - val_loss: 0.2736 - val_acc: 0.9077\n",
      "Epoch 444/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2615 - acc: 0.9099 - val_loss: 0.2718 - val_acc: 0.9079\n",
      "Epoch 445/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2618 - acc: 0.9099 - val_loss: 0.2717 - val_acc: 0.9076\n",
      "Epoch 446/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2618 - acc: 0.9100 - val_loss: 0.2729 - val_acc: 0.9078\n",
      "Epoch 447/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2624 - acc: 0.9099 - val_loss: 0.2728 - val_acc: 0.9078\n",
      "Epoch 448/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2619 - acc: 0.9100 - val_loss: 0.2722 - val_acc: 0.9080\n",
      "Epoch 449/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2619 - acc: 0.9101 - val_loss: 0.2724 - val_acc: 0.9080\n",
      "Epoch 450/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2618 - acc: 0.9100 - val_loss: 0.2710 - val_acc: 0.9078\n",
      "Epoch 451/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2632 - acc: 0.9100 - val_loss: 0.2732 - val_acc: 0.9075\n",
      "Epoch 452/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2632 - acc: 0.9097 - val_loss: 0.2718 - val_acc: 0.9077\n",
      "Epoch 453/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2631 - acc: 0.9098 - val_loss: 0.2788 - val_acc: 0.9075\n",
      "Epoch 454/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2621 - acc: 0.9101 - val_loss: 0.2715 - val_acc: 0.9079\n",
      "Epoch 455/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2623 - acc: 0.9099 - val_loss: 0.2717 - val_acc: 0.9078\n",
      "Epoch 456/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2618 - acc: 0.9100 - val_loss: 0.2716 - val_acc: 0.9078\n",
      "Epoch 457/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2623 - acc: 0.9099 - val_loss: 0.2718 - val_acc: 0.9080\n",
      "Epoch 458/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2618 - acc: 0.9099 - val_loss: 0.2718 - val_acc: 0.9080\n",
      "Epoch 459/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2623 - acc: 0.9099 - val_loss: 0.2727 - val_acc: 0.9078\n",
      "Epoch 460/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2629 - acc: 0.9100 - val_loss: 0.2730 - val_acc: 0.9078\n",
      "Epoch 461/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2620 - acc: 0.9101 - val_loss: 0.2722 - val_acc: 0.9080\n",
      "Epoch 462/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2619 - acc: 0.9100 - val_loss: 0.2720 - val_acc: 0.9078\n",
      "Epoch 463/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2616 - acc: 0.9099 - val_loss: 0.2718 - val_acc: 0.9078\n",
      "Epoch 464/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2625 - acc: 0.9099 - val_loss: 0.2733 - val_acc: 0.9080\n",
      "Epoch 465/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2622 - acc: 0.9100 - val_loss: 0.2713 - val_acc: 0.9078\n",
      "Epoch 466/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2616 - acc: 0.9100 - val_loss: 0.2715 - val_acc: 0.9078\n",
      "Epoch 467/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2620 - acc: 0.9099 - val_loss: 0.2730 - val_acc: 0.9079\n",
      "Epoch 468/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2618 - acc: 0.9099 - val_loss: 0.2712 - val_acc: 0.9079\n",
      "Epoch 469/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2615 - acc: 0.9100 - val_loss: 0.2717 - val_acc: 0.9076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2617 - acc: 0.9099 - val_loss: 0.2718 - val_acc: 0.9077\n",
      "Epoch 471/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2615 - acc: 0.9100 - val_loss: 0.2730 - val_acc: 0.9078\n",
      "Epoch 472/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2618 - acc: 0.9099 - val_loss: 0.2711 - val_acc: 0.9079\n",
      "Epoch 473/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2614 - acc: 0.9100 - val_loss: 0.2711 - val_acc: 0.9079\n",
      "Epoch 474/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2682 - acc: 0.9099 - val_loss: 0.2740 - val_acc: 0.9077\n",
      "Epoch 475/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2626 - acc: 0.9099 - val_loss: 0.2736 - val_acc: 0.9078\n",
      "Epoch 476/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2619 - acc: 0.9100 - val_loss: 0.2725 - val_acc: 0.9081\n",
      "Epoch 477/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2623 - acc: 0.9100 - val_loss: 0.2722 - val_acc: 0.9077\n",
      "Epoch 478/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2622 - acc: 0.9097 - val_loss: 0.2714 - val_acc: 0.9078\n",
      "Epoch 479/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2639 - acc: 0.9096 - val_loss: 0.2725 - val_acc: 0.9078\n",
      "Epoch 480/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2618 - acc: 0.9099 - val_loss: 0.2725 - val_acc: 0.9080\n",
      "Epoch 481/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2618 - acc: 0.9099 - val_loss: 0.2718 - val_acc: 0.9079\n",
      "Epoch 482/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2611 - acc: 0.9099 - val_loss: 0.2708 - val_acc: 0.9080\n",
      "Epoch 483/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2625 - acc: 0.9097 - val_loss: 0.2722 - val_acc: 0.9079\n",
      "Epoch 484/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2617 - acc: 0.9099 - val_loss: 0.2720 - val_acc: 0.9078\n",
      "Epoch 485/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2616 - acc: 0.9100 - val_loss: 0.2712 - val_acc: 0.9080\n",
      "Epoch 486/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2617 - acc: 0.9099 - val_loss: 0.2737 - val_acc: 0.9079\n",
      "Epoch 487/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2617 - acc: 0.9099 - val_loss: 0.2718 - val_acc: 0.9078\n",
      "Epoch 488/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2622 - acc: 0.9099 - val_loss: 0.2934 - val_acc: 0.9062\n",
      "Epoch 489/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2631 - acc: 0.9097 - val_loss: 0.2717 - val_acc: 0.9077\n",
      "Epoch 490/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2616 - acc: 0.9099 - val_loss: 0.2727 - val_acc: 0.9077\n",
      "Epoch 491/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2618 - acc: 0.9099 - val_loss: 0.2719 - val_acc: 0.9079\n",
      "Epoch 492/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2624 - acc: 0.9098 - val_loss: 0.2715 - val_acc: 0.9081\n",
      "Epoch 493/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2621 - acc: 0.9098 - val_loss: 0.2737 - val_acc: 0.9046\n",
      "Epoch 494/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2618 - acc: 0.9099 - val_loss: 0.2753 - val_acc: 0.9073\n",
      "Epoch 495/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2624 - acc: 0.9100 - val_loss: 0.2716 - val_acc: 0.9080\n",
      "Epoch 496/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2618 - acc: 0.9098 - val_loss: 0.2717 - val_acc: 0.9079\n",
      "Epoch 497/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2620 - acc: 0.9100 - val_loss: 0.2725 - val_acc: 0.9081\n",
      "Epoch 498/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2620 - acc: 0.9101 - val_loss: 0.2717 - val_acc: 0.9079\n",
      "Epoch 499/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2617 - acc: 0.9099 - val_loss: 0.2728 - val_acc: 0.9077\n",
      "Epoch 500/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2616 - acc: 0.9099 - val_loss: 0.2734 - val_acc: 0.9080\n",
      "39302/39302 [==============================] - 0s 3us/step\n",
      "../linkPrediction/dataframes/obesity\n",
      "article (131006, 7, 11) --------------------------------------------------------------------\n",
      "(131006, 11) (131006,)\n",
      "[131006, 11, 1]\n",
      "(91704, 11) (91704,)\n",
      "Train on 91704 samples, validate on 39302 samples\n",
      "Epoch 1/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3110 - acc: 0.8968 - val_loss: 0.2815 - val_acc: 0.9063\n",
      "Epoch 2/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2750 - acc: 0.9085 - val_loss: 0.2795 - val_acc: 0.9063\n",
      "Epoch 3/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2735 - acc: 0.9085 - val_loss: 0.2783 - val_acc: 0.9066\n",
      "Epoch 4/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2727 - acc: 0.9088 - val_loss: 0.2774 - val_acc: 0.9070\n",
      "Epoch 5/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2721 - acc: 0.9089 - val_loss: 0.2784 - val_acc: 0.9066\n",
      "Epoch 6/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2713 - acc: 0.9092 - val_loss: 0.2783 - val_acc: 0.9069\n",
      "Epoch 7/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2711 - acc: 0.9093 - val_loss: 0.2810 - val_acc: 0.9057\n",
      "Epoch 8/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2709 - acc: 0.9094 - val_loss: 0.2764 - val_acc: 0.9073\n",
      "Epoch 9/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2705 - acc: 0.9098 - val_loss: 0.2761 - val_acc: 0.9076\n",
      "Epoch 10/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2702 - acc: 0.9101 - val_loss: 0.2774 - val_acc: 0.9075\n",
      "Epoch 11/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2701 - acc: 0.9098 - val_loss: 0.2761 - val_acc: 0.9080\n",
      "Epoch 12/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2697 - acc: 0.9098 - val_loss: 0.2756 - val_acc: 0.9076\n",
      "Epoch 13/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2693 - acc: 0.9099 - val_loss: 0.2759 - val_acc: 0.9081\n",
      "Epoch 14/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2693 - acc: 0.9102 - val_loss: 0.2753 - val_acc: 0.9078\n",
      "Epoch 15/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2689 - acc: 0.9100 - val_loss: 0.2758 - val_acc: 0.9076\n",
      "Epoch 16/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2684 - acc: 0.9101 - val_loss: 0.2754 - val_acc: 0.9078\n",
      "Epoch 17/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2683 - acc: 0.9100 - val_loss: 0.2746 - val_acc: 0.9075\n",
      "Epoch 18/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2681 - acc: 0.9102 - val_loss: 0.2745 - val_acc: 0.9078\n",
      "Epoch 19/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2677 - acc: 0.9100 - val_loss: 0.2748 - val_acc: 0.9080\n",
      "Epoch 20/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2674 - acc: 0.9102 - val_loss: 0.2747 - val_acc: 0.9075\n",
      "Epoch 21/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2674 - acc: 0.9103 - val_loss: 0.2730 - val_acc: 0.9077\n",
      "Epoch 22/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2670 - acc: 0.9102 - val_loss: 0.2734 - val_acc: 0.9079\n",
      "Epoch 23/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2668 - acc: 0.9103 - val_loss: 0.2719 - val_acc: 0.9079\n",
      "Epoch 24/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2664 - acc: 0.9103 - val_loss: 0.2730 - val_acc: 0.9077\n",
      "Epoch 25/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2662 - acc: 0.9103 - val_loss: 0.2742 - val_acc: 0.9079\n",
      "Epoch 26/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2660 - acc: 0.9104 - val_loss: 0.2718 - val_acc: 0.9078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2654 - acc: 0.9103 - val_loss: 0.2723 - val_acc: 0.9080\n",
      "Epoch 28/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2655 - acc: 0.9104 - val_loss: 0.2717 - val_acc: 0.9077\n",
      "Epoch 29/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2649 - acc: 0.9104 - val_loss: 0.2711 - val_acc: 0.9079\n",
      "Epoch 30/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2647 - acc: 0.9104 - val_loss: 0.2718 - val_acc: 0.9080\n",
      "Epoch 31/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2646 - acc: 0.9103 - val_loss: 0.2713 - val_acc: 0.9080\n",
      "Epoch 32/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2645 - acc: 0.9104 - val_loss: 0.2721 - val_acc: 0.9076\n",
      "Epoch 33/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2643 - acc: 0.9104 - val_loss: 0.2727 - val_acc: 0.9079\n",
      "Epoch 34/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2640 - acc: 0.9104 - val_loss: 0.2717 - val_acc: 0.9079\n",
      "Epoch 35/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2640 - acc: 0.9104 - val_loss: 0.2709 - val_acc: 0.9077\n",
      "Epoch 36/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2636 - acc: 0.9104 - val_loss: 0.2708 - val_acc: 0.9079\n",
      "Epoch 37/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2635 - acc: 0.9102 - val_loss: 0.2723 - val_acc: 0.9078\n",
      "Epoch 38/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2635 - acc: 0.9104 - val_loss: 0.2696 - val_acc: 0.9078\n",
      "Epoch 39/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2632 - acc: 0.9105 - val_loss: 0.2714 - val_acc: 0.9081\n",
      "Epoch 40/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2635 - acc: 0.9103 - val_loss: 0.2725 - val_acc: 0.9077\n",
      "Epoch 41/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2631 - acc: 0.9105 - val_loss: 0.2692 - val_acc: 0.9080\n",
      "Epoch 42/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2629 - acc: 0.9107 - val_loss: 0.2701 - val_acc: 0.9079\n",
      "Epoch 43/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2631 - acc: 0.9107 - val_loss: 0.2698 - val_acc: 0.9086\n",
      "Epoch 44/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2626 - acc: 0.9105 - val_loss: 0.2706 - val_acc: 0.9080\n",
      "Epoch 45/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2625 - acc: 0.9109 - val_loss: 0.2715 - val_acc: 0.9081\n",
      "Epoch 46/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2626 - acc: 0.9108 - val_loss: 0.2701 - val_acc: 0.9079\n",
      "Epoch 47/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2627 - acc: 0.9107 - val_loss: 0.2697 - val_acc: 0.9079\n",
      "Epoch 48/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2626 - acc: 0.9108 - val_loss: 0.2700 - val_acc: 0.9085\n",
      "Epoch 49/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2624 - acc: 0.9108 - val_loss: 0.2725 - val_acc: 0.9077\n",
      "Epoch 50/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2626 - acc: 0.9109 - val_loss: 0.2697 - val_acc: 0.9085\n",
      "Epoch 51/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2626 - acc: 0.9107 - val_loss: 0.2702 - val_acc: 0.9084\n",
      "Epoch 52/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2623 - acc: 0.9111 - val_loss: 0.2699 - val_acc: 0.9083\n",
      "Epoch 53/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2622 - acc: 0.9111 - val_loss: 0.2702 - val_acc: 0.9085\n",
      "Epoch 54/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2621 - acc: 0.9110 - val_loss: 0.2740 - val_acc: 0.9080\n",
      "Epoch 55/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2621 - acc: 0.9113 - val_loss: 0.2695 - val_acc: 0.9084\n",
      "Epoch 56/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2620 - acc: 0.9110 - val_loss: 0.2691 - val_acc: 0.9086\n",
      "Epoch 57/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2620 - acc: 0.9111 - val_loss: 0.2731 - val_acc: 0.9079\n",
      "Epoch 58/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2619 - acc: 0.9112 - val_loss: 0.2712 - val_acc: 0.9079\n",
      "Epoch 59/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2616 - acc: 0.9112 - val_loss: 0.2702 - val_acc: 0.9086\n",
      "Epoch 60/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2620 - acc: 0.9110 - val_loss: 0.2689 - val_acc: 0.9082\n",
      "Epoch 61/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2619 - acc: 0.9112 - val_loss: 0.2697 - val_acc: 0.9083\n",
      "Epoch 62/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2619 - acc: 0.9113 - val_loss: 0.2695 - val_acc: 0.9084\n",
      "Epoch 63/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2617 - acc: 0.9114 - val_loss: 0.2695 - val_acc: 0.9089\n",
      "Epoch 64/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2616 - acc: 0.9113 - val_loss: 0.2700 - val_acc: 0.9091\n",
      "Epoch 65/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2618 - acc: 0.9112 - val_loss: 0.2690 - val_acc: 0.9082\n",
      "Epoch 66/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2618 - acc: 0.9114 - val_loss: 0.2693 - val_acc: 0.9082\n",
      "Epoch 67/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2618 - acc: 0.9111 - val_loss: 0.2688 - val_acc: 0.9090\n",
      "Epoch 68/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2613 - acc: 0.9113 - val_loss: 0.2686 - val_acc: 0.9084\n",
      "Epoch 69/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2617 - acc: 0.9114 - val_loss: 0.2707 - val_acc: 0.9088\n",
      "Epoch 70/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2616 - acc: 0.9113 - val_loss: 0.2689 - val_acc: 0.9090\n",
      "Epoch 71/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2617 - acc: 0.9112 - val_loss: 0.2702 - val_acc: 0.9085\n",
      "Epoch 72/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2616 - acc: 0.9114 - val_loss: 0.2696 - val_acc: 0.9084\n",
      "Epoch 73/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2617 - acc: 0.9114 - val_loss: 0.2688 - val_acc: 0.9084\n",
      "Epoch 74/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2617 - acc: 0.9113 - val_loss: 0.2697 - val_acc: 0.9082\n",
      "Epoch 75/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2613 - acc: 0.9115 - val_loss: 0.2689 - val_acc: 0.9084\n",
      "Epoch 76/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2614 - acc: 0.9114 - val_loss: 0.2694 - val_acc: 0.9085\n",
      "Epoch 77/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2615 - acc: 0.9113 - val_loss: 0.2689 - val_acc: 0.9083\n",
      "Epoch 78/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2617 - acc: 0.9113 - val_loss: 0.2693 - val_acc: 0.9083\n",
      "Epoch 79/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2613 - acc: 0.9113 - val_loss: 0.2687 - val_acc: 0.9086\n",
      "Epoch 80/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2614 - acc: 0.9114 - val_loss: 0.2695 - val_acc: 0.9087\n",
      "Epoch 81/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2616 - acc: 0.9112 - val_loss: 0.2693 - val_acc: 0.9089\n",
      "Epoch 82/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2611 - acc: 0.9113 - val_loss: 0.2687 - val_acc: 0.9084\n",
      "Epoch 83/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2613 - acc: 0.9115 - val_loss: 0.2694 - val_acc: 0.9089\n",
      "Epoch 84/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2614 - acc: 0.9112 - val_loss: 0.2688 - val_acc: 0.9084\n",
      "Epoch 85/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2612 - acc: 0.9112 - val_loss: 0.2687 - val_acc: 0.9084\n",
      "Epoch 86/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2610 - acc: 0.9112 - val_loss: 0.2707 - val_acc: 0.9090\n",
      "Epoch 87/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2611 - acc: 0.9112 - val_loss: 0.2686 - val_acc: 0.9087\n",
      "Epoch 88/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2609 - acc: 0.9114 - val_loss: 0.2688 - val_acc: 0.9084\n",
      "Epoch 89/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2611 - acc: 0.9113 - val_loss: 0.2694 - val_acc: 0.9090\n",
      "Epoch 90/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2613 - acc: 0.9115 - val_loss: 0.2693 - val_acc: 0.9082\n",
      "Epoch 91/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2608 - acc: 0.9114 - val_loss: 0.2694 - val_acc: 0.9089\n",
      "Epoch 92/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2609 - acc: 0.9116 - val_loss: 0.2688 - val_acc: 0.9084\n",
      "Epoch 93/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2608 - acc: 0.9113 - val_loss: 0.2697 - val_acc: 0.9080\n",
      "Epoch 94/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2609 - acc: 0.9113 - val_loss: 0.2692 - val_acc: 0.9084\n",
      "Epoch 95/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2610 - acc: 0.9113 - val_loss: 0.2693 - val_acc: 0.9084\n",
      "Epoch 96/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2610 - acc: 0.9113 - val_loss: 0.2692 - val_acc: 0.9087\n",
      "Epoch 97/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2608 - acc: 0.9113 - val_loss: 0.2692 - val_acc: 0.9083\n",
      "Epoch 98/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2611 - acc: 0.9114 - val_loss: 0.2696 - val_acc: 0.9082\n",
      "Epoch 99/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2608 - acc: 0.9114 - val_loss: 0.2719 - val_acc: 0.9082\n",
      "Epoch 100/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2607 - acc: 0.9112 - val_loss: 0.2689 - val_acc: 0.9083\n",
      "Epoch 101/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2611 - acc: 0.9114 - val_loss: 0.2690 - val_acc: 0.9090\n",
      "Epoch 102/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2607 - acc: 0.9112 - val_loss: 0.2689 - val_acc: 0.9084\n",
      "Epoch 103/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2607 - acc: 0.9114 - val_loss: 0.2694 - val_acc: 0.9089\n",
      "Epoch 104/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2607 - acc: 0.9115 - val_loss: 0.2705 - val_acc: 0.9084\n",
      "Epoch 105/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2609 - acc: 0.9114 - val_loss: 0.2696 - val_acc: 0.9087\n",
      "Epoch 106/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2608 - acc: 0.9114 - val_loss: 0.2686 - val_acc: 0.9083\n",
      "Epoch 107/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2608 - acc: 0.9115 - val_loss: 0.2689 - val_acc: 0.9083\n",
      "Epoch 108/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2607 - acc: 0.9114 - val_loss: 0.2686 - val_acc: 0.9085\n",
      "Epoch 109/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2606 - acc: 0.9115 - val_loss: 0.2684 - val_acc: 0.9083\n",
      "Epoch 110/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2608 - acc: 0.9113 - val_loss: 0.2704 - val_acc: 0.9086\n",
      "Epoch 111/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2607 - acc: 0.9113 - val_loss: 0.2684 - val_acc: 0.9087\n",
      "Epoch 112/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2608 - acc: 0.9117 - val_loss: 0.2694 - val_acc: 0.9084\n",
      "Epoch 113/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2605 - acc: 0.9115 - val_loss: 0.2689 - val_acc: 0.9087\n",
      "Epoch 114/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2606 - acc: 0.9114 - val_loss: 0.2685 - val_acc: 0.9087\n",
      "Epoch 115/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2607 - acc: 0.9114 - val_loss: 0.2700 - val_acc: 0.9089\n",
      "Epoch 116/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2605 - acc: 0.9114 - val_loss: 0.2689 - val_acc: 0.9084\n",
      "Epoch 117/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2605 - acc: 0.9115 - val_loss: 0.2688 - val_acc: 0.9089\n",
      "Epoch 118/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2606 - acc: 0.9115 - val_loss: 0.2688 - val_acc: 0.9082\n",
      "Epoch 119/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2607 - acc: 0.9114 - val_loss: 0.2695 - val_acc: 0.9087\n",
      "Epoch 120/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2605 - acc: 0.9116 - val_loss: 0.2690 - val_acc: 0.9087\n",
      "Epoch 121/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2607 - acc: 0.9115 - val_loss: 0.2696 - val_acc: 0.9088\n",
      "Epoch 122/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2603 - acc: 0.9115 - val_loss: 0.2693 - val_acc: 0.9088\n",
      "Epoch 123/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2604 - acc: 0.9114 - val_loss: 0.2701 - val_acc: 0.9082\n",
      "Epoch 124/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2606 - acc: 0.9115 - val_loss: 0.2688 - val_acc: 0.9088\n",
      "Epoch 125/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2604 - acc: 0.9114 - val_loss: 0.2696 - val_acc: 0.9087\n",
      "Epoch 126/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2603 - acc: 0.9116 - val_loss: 0.2690 - val_acc: 0.9084\n",
      "Epoch 127/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2604 - acc: 0.9114 - val_loss: 0.2692 - val_acc: 0.9089\n",
      "Epoch 128/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2603 - acc: 0.9114 - val_loss: 0.2695 - val_acc: 0.9089\n",
      "Epoch 129/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2602 - acc: 0.9116 - val_loss: 0.2695 - val_acc: 0.9084\n",
      "Epoch 130/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2604 - acc: 0.9114 - val_loss: 0.2701 - val_acc: 0.9083\n",
      "Epoch 131/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2602 - acc: 0.9116 - val_loss: 0.2687 - val_acc: 0.9088\n",
      "Epoch 132/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2605 - acc: 0.9115 - val_loss: 0.2692 - val_acc: 0.9089\n",
      "Epoch 133/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2604 - acc: 0.9114 - val_loss: 0.2701 - val_acc: 0.9090\n",
      "Epoch 134/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2604 - acc: 0.9113 - val_loss: 0.2696 - val_acc: 0.9089\n",
      "Epoch 135/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2603 - acc: 0.9115 - val_loss: 0.2691 - val_acc: 0.9088\n",
      "Epoch 136/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2604 - acc: 0.9115 - val_loss: 0.2689 - val_acc: 0.9082\n",
      "Epoch 137/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2604 - acc: 0.9115 - val_loss: 0.2696 - val_acc: 0.9089\n",
      "Epoch 138/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2603 - acc: 0.9116 - val_loss: 0.2692 - val_acc: 0.9084\n",
      "Epoch 139/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2602 - acc: 0.9114 - val_loss: 0.2691 - val_acc: 0.9086\n",
      "Epoch 140/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2602 - acc: 0.9114 - val_loss: 0.2691 - val_acc: 0.9084\n",
      "Epoch 141/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2603 - acc: 0.9114 - val_loss: 0.2700 - val_acc: 0.9084\n",
      "Epoch 142/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2603 - acc: 0.9115 - val_loss: 0.2700 - val_acc: 0.9085\n",
      "Epoch 143/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2604 - acc: 0.9115 - val_loss: 0.2698 - val_acc: 0.9083\n",
      "Epoch 144/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2604 - acc: 0.9115 - val_loss: 0.2703 - val_acc: 0.9084\n",
      "Epoch 145/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2600 - acc: 0.9115 - val_loss: 0.2688 - val_acc: 0.9085\n",
      "Epoch 146/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2603 - acc: 0.9114 - val_loss: 0.2692 - val_acc: 0.9088\n",
      "Epoch 147/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2603 - acc: 0.9115 - val_loss: 0.2686 - val_acc: 0.9085\n",
      "Epoch 148/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2602 - acc: 0.9115 - val_loss: 0.2692 - val_acc: 0.9081\n",
      "Epoch 149/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2601 - acc: 0.9115 - val_loss: 0.2717 - val_acc: 0.9082\n",
      "Epoch 150/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2603 - acc: 0.9115 - val_loss: 0.2702 - val_acc: 0.9087\n",
      "Epoch 151/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2603 - acc: 0.9117 - val_loss: 0.2698 - val_acc: 0.9086\n",
      "Epoch 152/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2603 - acc: 0.9113 - val_loss: 0.2684 - val_acc: 0.9089\n",
      "Epoch 153/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2602 - acc: 0.9117 - val_loss: 0.2689 - val_acc: 0.9082\n",
      "Epoch 154/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2601 - acc: 0.9117 - val_loss: 0.2690 - val_acc: 0.9086\n",
      "Epoch 155/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2602 - acc: 0.9115 - val_loss: 0.2688 - val_acc: 0.9089\n",
      "Epoch 156/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2601 - acc: 0.9116 - val_loss: 0.2691 - val_acc: 0.9082\n",
      "Epoch 157/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2604 - acc: 0.9113 - val_loss: 0.2697 - val_acc: 0.9089\n",
      "Epoch 158/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2602 - acc: 0.9114 - val_loss: 0.2687 - val_acc: 0.9083\n",
      "Epoch 159/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2601 - acc: 0.9116 - val_loss: 0.2690 - val_acc: 0.9089\n",
      "Epoch 160/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2601 - acc: 0.9116 - val_loss: 0.2692 - val_acc: 0.9086\n",
      "Epoch 161/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2602 - acc: 0.9115 - val_loss: 0.2695 - val_acc: 0.9087\n",
      "Epoch 162/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2601 - acc: 0.9114 - val_loss: 0.2702 - val_acc: 0.9084\n",
      "Epoch 163/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2601 - acc: 0.9114 - val_loss: 0.2713 - val_acc: 0.9084\n",
      "Epoch 164/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2602 - acc: 0.9117 - val_loss: 0.2682 - val_acc: 0.9090\n",
      "Epoch 165/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2600 - acc: 0.9116 - val_loss: 0.2693 - val_acc: 0.9085\n",
      "Epoch 166/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2603 - acc: 0.9117 - val_loss: 0.2699 - val_acc: 0.9084\n",
      "Epoch 167/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2601 - acc: 0.9116 - val_loss: 0.2692 - val_acc: 0.9085\n",
      "Epoch 168/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2601 - acc: 0.9114 - val_loss: 0.2702 - val_acc: 0.9083\n",
      "Epoch 169/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2603 - acc: 0.9115 - val_loss: 0.2686 - val_acc: 0.9085\n",
      "Epoch 170/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2601 - acc: 0.9113 - val_loss: 0.2696 - val_acc: 0.9088\n",
      "Epoch 171/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2601 - acc: 0.9117 - val_loss: 0.2727 - val_acc: 0.9084\n",
      "Epoch 172/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2600 - acc: 0.9117 - val_loss: 0.2686 - val_acc: 0.9083\n",
      "Epoch 173/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2601 - acc: 0.9115 - val_loss: 0.2685 - val_acc: 0.9088\n",
      "Epoch 174/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2601 - acc: 0.9114 - val_loss: 0.2697 - val_acc: 0.9093\n",
      "Epoch 175/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2601 - acc: 0.9115 - val_loss: 0.2695 - val_acc: 0.9092\n",
      "Epoch 176/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2601 - acc: 0.9114 - val_loss: 0.2700 - val_acc: 0.9086\n",
      "Epoch 177/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2600 - acc: 0.9116 - val_loss: 0.2711 - val_acc: 0.9089\n",
      "Epoch 178/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2601 - acc: 0.9117 - val_loss: 0.2700 - val_acc: 0.9090\n",
      "Epoch 179/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2600 - acc: 0.9116 - val_loss: 0.2735 - val_acc: 0.9083\n",
      "Epoch 180/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2602 - acc: 0.9115 - val_loss: 0.2693 - val_acc: 0.9085\n",
      "Epoch 181/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2600 - acc: 0.9116 - val_loss: 0.2692 - val_acc: 0.9090\n",
      "Epoch 182/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2598 - acc: 0.9116 - val_loss: 0.2690 - val_acc: 0.9091\n",
      "Epoch 183/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2599 - acc: 0.9116 - val_loss: 0.2705 - val_acc: 0.9089\n",
      "Epoch 184/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2600 - acc: 0.9116 - val_loss: 0.2688 - val_acc: 0.9086\n",
      "Epoch 185/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2601 - acc: 0.9117 - val_loss: 0.2694 - val_acc: 0.9086\n",
      "Epoch 186/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2599 - acc: 0.9113 - val_loss: 0.2699 - val_acc: 0.9089\n",
      "Epoch 187/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2601 - acc: 0.9115 - val_loss: 0.2712 - val_acc: 0.9092\n",
      "Epoch 188/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2600 - acc: 0.9114 - val_loss: 0.2685 - val_acc: 0.9089\n",
      "Epoch 189/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2600 - acc: 0.9115 - val_loss: 0.2690 - val_acc: 0.9088\n",
      "Epoch 190/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2599 - acc: 0.9116 - val_loss: 0.2690 - val_acc: 0.9089\n",
      "Epoch 191/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2597 - acc: 0.9115 - val_loss: 0.2686 - val_acc: 0.9087\n",
      "Epoch 192/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2599 - acc: 0.9115 - val_loss: 0.2684 - val_acc: 0.9086\n",
      "Epoch 193/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2599 - acc: 0.9115 - val_loss: 0.2699 - val_acc: 0.9088\n",
      "Epoch 194/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2599 - acc: 0.9115 - val_loss: 0.2688 - val_acc: 0.9084\n",
      "Epoch 195/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2601 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9088\n",
      "Epoch 196/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9117 - val_loss: 0.2694 - val_acc: 0.9086\n",
      "Epoch 197/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2601 - acc: 0.9116 - val_loss: 0.2685 - val_acc: 0.9089\n",
      "Epoch 198/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2600 - acc: 0.9116 - val_loss: 0.2699 - val_acc: 0.9090\n",
      "Epoch 199/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2599 - acc: 0.9116 - val_loss: 0.2691 - val_acc: 0.9089\n",
      "Epoch 200/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2600 - acc: 0.9117 - val_loss: 0.2684 - val_acc: 0.9091\n",
      "Epoch 201/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2599 - acc: 0.9116 - val_loss: 0.2690 - val_acc: 0.9087\n",
      "Epoch 202/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2599 - acc: 0.9115 - val_loss: 0.2684 - val_acc: 0.9092\n",
      "Epoch 203/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2599 - acc: 0.9117 - val_loss: 0.2700 - val_acc: 0.9085\n",
      "Epoch 204/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9116 - val_loss: 0.2689 - val_acc: 0.9084\n",
      "Epoch 205/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9119 - val_loss: 0.2697 - val_acc: 0.9086\n",
      "Epoch 206/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9117 - val_loss: 0.2692 - val_acc: 0.9087\n",
      "Epoch 207/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2599 - acc: 0.9115 - val_loss: 0.2695 - val_acc: 0.9089\n",
      "Epoch 208/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9116 - val_loss: 0.2687 - val_acc: 0.9087\n",
      "Epoch 209/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2599 - acc: 0.9117 - val_loss: 0.2697 - val_acc: 0.9092\n",
      "Epoch 210/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9117 - val_loss: 0.2703 - val_acc: 0.9084\n",
      "Epoch 211/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9116 - val_loss: 0.2695 - val_acc: 0.9088\n",
      "Epoch 212/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9118 - val_loss: 0.2697 - val_acc: 0.9087\n",
      "Epoch 213/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9116 - val_loss: 0.2694 - val_acc: 0.9090\n",
      "Epoch 214/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2599 - acc: 0.9116 - val_loss: 0.2692 - val_acc: 0.9085\n",
      "Epoch 215/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2599 - acc: 0.9116 - val_loss: 0.2691 - val_acc: 0.9089\n",
      "Epoch 216/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9117 - val_loss: 0.2692 - val_acc: 0.9082\n",
      "Epoch 217/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9116 - val_loss: 0.2690 - val_acc: 0.9089\n",
      "Epoch 218/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2599 - acc: 0.9116 - val_loss: 0.2698 - val_acc: 0.9085\n",
      "Epoch 219/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2600 - acc: 0.9115 - val_loss: 0.2686 - val_acc: 0.9087\n",
      "Epoch 220/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9117 - val_loss: 0.2684 - val_acc: 0.9091\n",
      "Epoch 221/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9118 - val_loss: 0.2708 - val_acc: 0.9085\n",
      "Epoch 222/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2600 - acc: 0.9115 - val_loss: 0.2705 - val_acc: 0.9083\n",
      "Epoch 223/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2597 - acc: 0.9116 - val_loss: 0.2694 - val_acc: 0.9092\n",
      "Epoch 224/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2600 - acc: 0.9117 - val_loss: 0.2690 - val_acc: 0.9089\n",
      "Epoch 225/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9116 - val_loss: 0.2691 - val_acc: 0.9084\n",
      "Epoch 226/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2600 - acc: 0.9116 - val_loss: 0.2687 - val_acc: 0.9084\n",
      "Epoch 227/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2599 - acc: 0.9116 - val_loss: 0.2691 - val_acc: 0.9087\n",
      "Epoch 228/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9118 - val_loss: 0.2690 - val_acc: 0.9086\n",
      "Epoch 229/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2599 - acc: 0.9116 - val_loss: 0.2691 - val_acc: 0.9091\n",
      "Epoch 230/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9118 - val_loss: 0.2690 - val_acc: 0.9090\n",
      "Epoch 231/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2596 - acc: 0.9115 - val_loss: 0.2698 - val_acc: 0.9089\n",
      "Epoch 232/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2599 - acc: 0.9116 - val_loss: 0.2692 - val_acc: 0.9089\n",
      "Epoch 233/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9117 - val_loss: 0.2689 - val_acc: 0.9090\n",
      "Epoch 234/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2599 - acc: 0.9117 - val_loss: 0.2689 - val_acc: 0.9090\n",
      "Epoch 235/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2599 - acc: 0.9118 - val_loss: 0.2688 - val_acc: 0.9087\n",
      "Epoch 236/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2599 - acc: 0.9116 - val_loss: 0.2697 - val_acc: 0.9091\n",
      "Epoch 237/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9117 - val_loss: 0.2694 - val_acc: 0.9094\n",
      "Epoch 238/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9116 - val_loss: 0.2689 - val_acc: 0.9088\n",
      "Epoch 239/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9115 - val_loss: 0.2691 - val_acc: 0.9083\n",
      "Epoch 240/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9116 - val_loss: 0.2696 - val_acc: 0.9089\n",
      "Epoch 241/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2600 - acc: 0.9119 - val_loss: 0.2695 - val_acc: 0.9084\n",
      "Epoch 242/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2597 - acc: 0.9116 - val_loss: 0.2689 - val_acc: 0.9089\n",
      "Epoch 243/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2598 - acc: 0.9119 - val_loss: 0.2687 - val_acc: 0.9091\n",
      "Epoch 244/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9118 - val_loss: 0.2686 - val_acc: 0.9086\n",
      "Epoch 245/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9116 - val_loss: 0.2691 - val_acc: 0.9088\n",
      "Epoch 246/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9116 - val_loss: 0.2690 - val_acc: 0.9092\n",
      "Epoch 247/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9118 - val_loss: 0.2687 - val_acc: 0.9090\n",
      "Epoch 248/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9117 - val_loss: 0.2704 - val_acc: 0.9089\n",
      "Epoch 249/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2597 - acc: 0.9116 - val_loss: 0.2696 - val_acc: 0.9091\n",
      "Epoch 250/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2599 - acc: 0.9119 - val_loss: 0.2691 - val_acc: 0.9083\n",
      "Epoch 251/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2596 - acc: 0.9116 - val_loss: 0.2691 - val_acc: 0.9085\n",
      "Epoch 252/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2598 - acc: 0.9118 - val_loss: 0.2697 - val_acc: 0.9088\n",
      "Epoch 253/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9116 - val_loss: 0.2695 - val_acc: 0.9082\n",
      "Epoch 254/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9090\n",
      "Epoch 255/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9116 - val_loss: 0.2694 - val_acc: 0.9090\n",
      "Epoch 256/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9117 - val_loss: 0.2692 - val_acc: 0.9091\n",
      "Epoch 257/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9118 - val_loss: 0.2703 - val_acc: 0.9093\n",
      "Epoch 258/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9117 - val_loss: 0.2704 - val_acc: 0.9092\n",
      "Epoch 259/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9116 - val_loss: 0.2692 - val_acc: 0.9090\n",
      "Epoch 260/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9115 - val_loss: 0.2690 - val_acc: 0.9091\n",
      "Epoch 261/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9090\n",
      "Epoch 262/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9116 - val_loss: 0.2707 - val_acc: 0.9087\n",
      "Epoch 263/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9117 - val_loss: 0.2693 - val_acc: 0.9090\n",
      "Epoch 264/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9117 - val_loss: 0.2688 - val_acc: 0.9091\n",
      "Epoch 265/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9118 - val_loss: 0.2686 - val_acc: 0.9091\n",
      "Epoch 266/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9117 - val_loss: 0.2702 - val_acc: 0.9089\n",
      "Epoch 267/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9115 - val_loss: 0.2697 - val_acc: 0.9089\n",
      "Epoch 268/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2598 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9089\n",
      "Epoch 269/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2597 - acc: 0.9116 - val_loss: 0.2689 - val_acc: 0.9089\n",
      "Epoch 270/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2597 - acc: 0.9116 - val_loss: 0.2687 - val_acc: 0.9089\n",
      "Epoch 271/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2596 - acc: 0.9118 - val_loss: 0.2688 - val_acc: 0.9092\n",
      "Epoch 272/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9118 - val_loss: 0.2696 - val_acc: 0.9087\n",
      "Epoch 273/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2595 - acc: 0.9117 - val_loss: 0.2696 - val_acc: 0.9088\n",
      "Epoch 274/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9117 - val_loss: 0.2688 - val_acc: 0.9091\n",
      "Epoch 275/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9115 - val_loss: 0.2685 - val_acc: 0.9089\n",
      "Epoch 276/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9118 - val_loss: 0.2687 - val_acc: 0.9089\n",
      "Epoch 277/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9117 - val_loss: 0.2695 - val_acc: 0.9089\n",
      "Epoch 278/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9116 - val_loss: 0.2684 - val_acc: 0.9091\n",
      "Epoch 279/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9119 - val_loss: 0.2693 - val_acc: 0.9091\n",
      "Epoch 280/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9115 - val_loss: 0.2696 - val_acc: 0.9091\n",
      "Epoch 281/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9117 - val_loss: 0.2688 - val_acc: 0.9091\n",
      "Epoch 282/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9116 - val_loss: 0.2687 - val_acc: 0.9094\n",
      "Epoch 283/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9116 - val_loss: 0.2698 - val_acc: 0.9084\n",
      "Epoch 284/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9117 - val_loss: 0.2692 - val_acc: 0.9090\n",
      "Epoch 285/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9117 - val_loss: 0.2686 - val_acc: 0.9089\n",
      "Epoch 286/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9118 - val_loss: 0.2694 - val_acc: 0.9090\n",
      "Epoch 287/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9118 - val_loss: 0.2689 - val_acc: 0.9091\n",
      "Epoch 288/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9116 - val_loss: 0.2688 - val_acc: 0.9090\n",
      "Epoch 289/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9118 - val_loss: 0.2704 - val_acc: 0.9089\n",
      "Epoch 290/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9118 - val_loss: 0.2686 - val_acc: 0.9089\n",
      "Epoch 291/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9117 - val_loss: 0.2693 - val_acc: 0.9090\n",
      "Epoch 292/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9117 - val_loss: 0.2693 - val_acc: 0.9090\n",
      "Epoch 293/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9119 - val_loss: 0.2690 - val_acc: 0.9090\n",
      "Epoch 294/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9116 - val_loss: 0.2691 - val_acc: 0.9091\n",
      "Epoch 295/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9116 - val_loss: 0.2690 - val_acc: 0.9091\n",
      "Epoch 296/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9118 - val_loss: 0.2689 - val_acc: 0.9091\n",
      "Epoch 297/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9118 - val_loss: 0.2688 - val_acc: 0.9090\n",
      "Epoch 298/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9117 - val_loss: 0.2703 - val_acc: 0.9086\n",
      "Epoch 299/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9118 - val_loss: 0.2689 - val_acc: 0.9088\n",
      "Epoch 300/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9117 - val_loss: 0.2688 - val_acc: 0.9091\n",
      "Epoch 301/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9116 - val_loss: 0.2689 - val_acc: 0.9091\n",
      "Epoch 302/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9118 - val_loss: 0.2695 - val_acc: 0.9090\n",
      "Epoch 303/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9117 - val_loss: 0.2693 - val_acc: 0.9084\n",
      "Epoch 304/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9116 - val_loss: 0.2683 - val_acc: 0.9091\n",
      "Epoch 305/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9116 - val_loss: 0.2685 - val_acc: 0.9091\n",
      "Epoch 306/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9118 - val_loss: 0.2712 - val_acc: 0.9085\n",
      "Epoch 307/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9117 - val_loss: 0.2688 - val_acc: 0.9091\n",
      "Epoch 308/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9116 - val_loss: 0.2690 - val_acc: 0.9090\n",
      "Epoch 309/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9117 - val_loss: 0.2693 - val_acc: 0.9090\n",
      "Epoch 310/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9117 - val_loss: 0.2695 - val_acc: 0.9093\n",
      "Epoch 311/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9118 - val_loss: 0.2685 - val_acc: 0.9092\n",
      "Epoch 312/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2597 - acc: 0.9116 - val_loss: 0.2700 - val_acc: 0.9085\n",
      "Epoch 313/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9118 - val_loss: 0.2695 - val_acc: 0.9089\n",
      "Epoch 314/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2595 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9088\n",
      "Epoch 315/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9118 - val_loss: 0.2686 - val_acc: 0.9087\n",
      "Epoch 316/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9117 - val_loss: 0.2687 - val_acc: 0.9092\n",
      "Epoch 317/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2598 - acc: 0.9118 - val_loss: 0.2691 - val_acc: 0.9085\n",
      "Epoch 318/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9118 - val_loss: 0.2739 - val_acc: 0.9083\n",
      "Epoch 319/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9117 - val_loss: 0.2688 - val_acc: 0.9088\n",
      "Epoch 320/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9116 - val_loss: 0.2700 - val_acc: 0.9091\n",
      "Epoch 321/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9092\n",
      "Epoch 322/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9118 - val_loss: 0.2689 - val_acc: 0.9090\n",
      "Epoch 323/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9117 - val_loss: 0.2702 - val_acc: 0.9090\n",
      "Epoch 324/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9118 - val_loss: 0.2687 - val_acc: 0.9090\n",
      "Epoch 325/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9116 - val_loss: 0.2690 - val_acc: 0.9089\n",
      "Epoch 326/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9118 - val_loss: 0.2689 - val_acc: 0.9090\n",
      "Epoch 327/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9118 - val_loss: 0.2687 - val_acc: 0.9088\n",
      "Epoch 328/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9114 - val_loss: 0.2689 - val_acc: 0.9090\n",
      "Epoch 329/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9118 - val_loss: 0.2689 - val_acc: 0.9091\n",
      "Epoch 330/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2596 - acc: 0.9118 - val_loss: 0.2688 - val_acc: 0.9091\n",
      "Epoch 331/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2594 - acc: 0.9118 - val_loss: 0.2692 - val_acc: 0.9081\n",
      "Epoch 332/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9117 - val_loss: 0.2700 - val_acc: 0.9088\n",
      "Epoch 333/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9116 - val_loss: 0.2691 - val_acc: 0.9089\n",
      "Epoch 334/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9116 - val_loss: 0.2690 - val_acc: 0.9090\n",
      "Epoch 335/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9119 - val_loss: 0.2693 - val_acc: 0.9086\n",
      "Epoch 336/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2594 - acc: 0.9119 - val_loss: 0.2689 - val_acc: 0.9088\n",
      "Epoch 337/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2594 - acc: 0.9118 - val_loss: 0.2691 - val_acc: 0.9090\n",
      "Epoch 338/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2594 - acc: 0.9118 - val_loss: 0.2689 - val_acc: 0.9087\n",
      "Epoch 339/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2596 - acc: 0.9116 - val_loss: 0.2716 - val_acc: 0.9090\n",
      "Epoch 340/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.2687 - val_acc: 0.9091\n",
      "Epoch 341/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2594 - acc: 0.9117 - val_loss: 0.2686 - val_acc: 0.9091\n",
      "Epoch 342/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9116 - val_loss: 0.2693 - val_acc: 0.9088\n",
      "Epoch 343/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2595 - acc: 0.9118 - val_loss: 0.2688 - val_acc: 0.9091\n",
      "Epoch 344/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2594 - acc: 0.9117 - val_loss: 0.2689 - val_acc: 0.9091\n",
      "Epoch 345/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.2689 - val_acc: 0.9089\n",
      "Epoch 346/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9118 - val_loss: 0.2685 - val_acc: 0.9092\n",
      "Epoch 347/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9116 - val_loss: 0.2692 - val_acc: 0.9091\n",
      "Epoch 348/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9117 - val_loss: 0.2687 - val_acc: 0.9089\n",
      "Epoch 349/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9117 - val_loss: 0.2689 - val_acc: 0.9092\n",
      "Epoch 350/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9120 - val_loss: 0.2688 - val_acc: 0.9091\n",
      "Epoch 351/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9117 - val_loss: 0.2689 - val_acc: 0.9090\n",
      "Epoch 352/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9117 - val_loss: 0.2693 - val_acc: 0.9090\n",
      "Epoch 353/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2594 - acc: 0.9117 - val_loss: 0.2692 - val_acc: 0.9091\n",
      "Epoch 354/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.2690 - val_acc: 0.9092\n",
      "Epoch 355/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.2686 - val_acc: 0.9091\n",
      "Epoch 356/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.2698 - val_acc: 0.9095\n",
      "Epoch 357/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2593 - acc: 0.9117 - val_loss: 0.2710 - val_acc: 0.9095\n",
      "Epoch 358/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2592 - acc: 0.9119 - val_loss: 0.2701 - val_acc: 0.9095\n",
      "Epoch 359/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2593 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9091\n",
      "Epoch 360/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2694 - val_acc: 0.9089\n",
      "Epoch 361/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2688 - val_acc: 0.9092\n",
      "Epoch 362/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9116 - val_loss: 0.2693 - val_acc: 0.9090\n",
      "Epoch 363/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9117 - val_loss: 0.2686 - val_acc: 0.9091\n",
      "Epoch 364/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2688 - val_acc: 0.9090\n",
      "Epoch 365/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9117 - val_loss: 0.2687 - val_acc: 0.9086\n",
      "Epoch 366/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9117 - val_loss: 0.2696 - val_acc: 0.9091\n",
      "Epoch 367/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9119 - val_loss: 0.2685 - val_acc: 0.9090\n",
      "Epoch 368/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2685 - val_acc: 0.9090\n",
      "Epoch 369/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9118 - val_loss: 0.2694 - val_acc: 0.9091\n",
      "Epoch 370/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9117 - val_loss: 0.2697 - val_acc: 0.9092\n",
      "Epoch 371/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.2686 - val_acc: 0.9090\n",
      "Epoch 372/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9118 - val_loss: 0.2696 - val_acc: 0.9091\n",
      "Epoch 373/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9117 - val_loss: 0.2700 - val_acc: 0.9091\n",
      "Epoch 374/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2690 - val_acc: 0.9090\n",
      "Epoch 375/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2715 - val_acc: 0.9096\n",
      "Epoch 376/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9117 - val_loss: 0.2689 - val_acc: 0.9090\n",
      "Epoch 377/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9117 - val_loss: 0.2687 - val_acc: 0.9092\n",
      "Epoch 378/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2596 - acc: 0.9118 - val_loss: 0.2690 - val_acc: 0.9090\n",
      "Epoch 379/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2709 - val_acc: 0.9088\n",
      "Epoch 380/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9117 - val_loss: 0.2685 - val_acc: 0.9091\n",
      "Epoch 381/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9115 - val_loss: 0.2697 - val_acc: 0.9092\n",
      "Epoch 382/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2694 - val_acc: 0.9092\n",
      "Epoch 383/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2686 - val_acc: 0.9089\n",
      "Epoch 384/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9116 - val_loss: 0.2690 - val_acc: 0.9090\n",
      "Epoch 385/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2688 - val_acc: 0.9091\n",
      "Epoch 386/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2687 - val_acc: 0.9091\n",
      "Epoch 387/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2698 - val_acc: 0.9091\n",
      "Epoch 388/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.2684 - val_acc: 0.9091\n",
      "Epoch 389/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2593 - acc: 0.9116 - val_loss: 0.2693 - val_acc: 0.9092\n",
      "Epoch 390/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.2690 - val_acc: 0.9091\n",
      "Epoch 391/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2594 - acc: 0.9116 - val_loss: 0.2688 - val_acc: 0.9091\n",
      "Epoch 392/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9085\n",
      "Epoch 393/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9117 - val_loss: 0.2686 - val_acc: 0.9089\n",
      "Epoch 394/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2700 - val_acc: 0.9092\n",
      "Epoch 395/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2690 - val_acc: 0.9091\n",
      "Epoch 396/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2594 - acc: 0.9117 - val_loss: 0.2692 - val_acc: 0.9089\n",
      "Epoch 397/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2697 - val_acc: 0.9091\n",
      "Epoch 398/500\n",
      "91704/91704 [==============================] - 1s 16us/step - loss: 0.2593 - acc: 0.9116 - val_loss: 0.2689 - val_acc: 0.9092\n",
      "Epoch 399/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2695 - val_acc: 0.9092\n",
      "Epoch 400/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2692 - val_acc: 0.9093\n",
      "Epoch 401/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9091\n",
      "Epoch 402/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2686 - val_acc: 0.9091\n",
      "Epoch 403/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2691 - val_acc: 0.9085\n",
      "Epoch 404/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.2692 - val_acc: 0.9091\n",
      "Epoch 405/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2687 - val_acc: 0.9091\n",
      "Epoch 406/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2699 - val_acc: 0.9091\n",
      "Epoch 407/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2684 - val_acc: 0.9090\n",
      "Epoch 408/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2689 - val_acc: 0.9093\n",
      "Epoch 409/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2687 - val_acc: 0.9091\n",
      "Epoch 410/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2705 - val_acc: 0.9090\n",
      "Epoch 411/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9090\n",
      "Epoch 412/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2590 - acc: 0.9119 - val_loss: 0.2695 - val_acc: 0.9091\n",
      "Epoch 413/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9119 - val_loss: 0.2715 - val_acc: 0.9090\n",
      "Epoch 414/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2694 - val_acc: 0.9089\n",
      "Epoch 415/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2698 - val_acc: 0.9090\n",
      "Epoch 416/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2690 - val_acc: 0.9092\n",
      "Epoch 417/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2700 - val_acc: 0.9084\n",
      "Epoch 418/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2688 - val_acc: 0.9090\n",
      "Epoch 419/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2704 - val_acc: 0.9092\n",
      "Epoch 420/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2593 - acc: 0.9115 - val_loss: 0.2695 - val_acc: 0.9092\n",
      "Epoch 421/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2695 - val_acc: 0.9090\n",
      "Epoch 422/500\n",
      "91704/91704 [==============================] - 1s 16us/step - loss: 0.2594 - acc: 0.9117 - val_loss: 0.2685 - val_acc: 0.9090\n",
      "Epoch 423/500\n",
      "91704/91704 [==============================] - 2s 17us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2687 - val_acc: 0.9092\n",
      "Epoch 424/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.2696 - val_acc: 0.9090\n",
      "Epoch 425/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2707 - val_acc: 0.9093\n",
      "Epoch 426/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2592 - acc: 0.9119 - val_loss: 0.2687 - val_acc: 0.9088\n",
      "Epoch 427/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2592 - acc: 0.9116 - val_loss: 0.2689 - val_acc: 0.9090\n",
      "Epoch 428/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9092\n",
      "Epoch 429/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2590 - acc: 0.9117 - val_loss: 0.2693 - val_acc: 0.9087\n",
      "Epoch 430/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2593 - acc: 0.9117 - val_loss: 0.2690 - val_acc: 0.9090\n",
      "Epoch 431/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2593 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9091\n",
      "Epoch 432/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2593 - acc: 0.9119 - val_loss: 0.2708 - val_acc: 0.9093\n",
      "Epoch 433/500\n",
      "91704/91704 [==============================] - 2s 21us/step - loss: 0.2591 - acc: 0.9119 - val_loss: 0.2697 - val_acc: 0.9090\n",
      "Epoch 434/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.2688 - val_acc: 0.9086\n",
      "Epoch 435/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2593 - acc: 0.9116 - val_loss: 0.2687 - val_acc: 0.9093\n",
      "Epoch 436/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2696 - val_acc: 0.9090\n",
      "Epoch 437/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2592 - acc: 0.9119 - val_loss: 0.2690 - val_acc: 0.9092\n",
      "Epoch 438/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2688 - val_acc: 0.9090\n",
      "Epoch 439/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2695 - val_acc: 0.9090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.2690 - val_acc: 0.9091\n",
      "Epoch 441/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.2687 - val_acc: 0.9092\n",
      "Epoch 442/500\n",
      "91704/91704 [==============================] - 2s 18us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2689 - val_acc: 0.9091\n",
      "Epoch 443/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2591 - acc: 0.9119 - val_loss: 0.2687 - val_acc: 0.9093\n",
      "Epoch 444/500\n",
      "91704/91704 [==============================] - 1s 15us/step - loss: 0.2589 - acc: 0.9116 - val_loss: 0.2712 - val_acc: 0.9090\n",
      "Epoch 445/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2592 - acc: 0.9119 - val_loss: 0.2687 - val_acc: 0.9090\n",
      "Epoch 446/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2588 - acc: 0.9118 - val_loss: 0.2688 - val_acc: 0.9092\n",
      "Epoch 447/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2688 - val_acc: 0.9092\n",
      "Epoch 448/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2590 - acc: 0.9118 - val_loss: 0.2691 - val_acc: 0.9090\n",
      "Epoch 449/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2690 - val_acc: 0.9091\n",
      "Epoch 450/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9091\n",
      "Epoch 451/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2692 - val_acc: 0.9090\n",
      "Epoch 452/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2591 - acc: 0.9119 - val_loss: 0.2690 - val_acc: 0.9091\n",
      "Epoch 453/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2689 - val_acc: 0.9092\n",
      "Epoch 454/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2591 - acc: 0.9119 - val_loss: 0.2690 - val_acc: 0.9093\n",
      "Epoch 455/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2690 - val_acc: 0.9094\n",
      "Epoch 456/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2593 - acc: 0.9118 - val_loss: 0.2690 - val_acc: 0.9093\n",
      "Epoch 457/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2592 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9092\n",
      "Epoch 458/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2590 - acc: 0.9117 - val_loss: 0.2694 - val_acc: 0.9093\n",
      "Epoch 459/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2700 - val_acc: 0.9092\n",
      "Epoch 460/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2701 - val_acc: 0.9084\n",
      "Epoch 461/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2593 - acc: 0.9115 - val_loss: 0.2691 - val_acc: 0.9091\n",
      "Epoch 462/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2697 - val_acc: 0.9089\n",
      "Epoch 463/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2693 - val_acc: 0.9085\n",
      "Epoch 464/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2590 - acc: 0.9116 - val_loss: 0.2688 - val_acc: 0.9092\n",
      "Epoch 465/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2590 - acc: 0.9118 - val_loss: 0.2697 - val_acc: 0.9092\n",
      "Epoch 466/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2688 - val_acc: 0.9093\n",
      "Epoch 467/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2693 - val_acc: 0.9092\n",
      "Epoch 468/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9115 - val_loss: 0.2703 - val_acc: 0.9091\n",
      "Epoch 469/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9119 - val_loss: 0.2689 - val_acc: 0.9091\n",
      "Epoch 470/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2689 - val_acc: 0.9093\n",
      "Epoch 471/500\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 0.2594 - acc: 0.911 - 1s 9us/step - loss: 0.2591 - acc: 0.9119 - val_loss: 0.2691 - val_acc: 0.9092\n",
      "Epoch 472/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2691 - val_acc: 0.9092\n",
      "Epoch 473/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2692 - val_acc: 0.9089\n",
      "Epoch 474/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2710 - val_acc: 0.9091\n",
      "Epoch 475/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2696 - val_acc: 0.9088\n",
      "Epoch 476/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2590 - acc: 0.9118 - val_loss: 0.2683 - val_acc: 0.9091\n",
      "Epoch 477/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2690 - val_acc: 0.9092\n",
      "Epoch 478/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2590 - acc: 0.9118 - val_loss: 0.2687 - val_acc: 0.9093\n",
      "Epoch 479/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2590 - acc: 0.9119 - val_loss: 0.2687 - val_acc: 0.9091\n",
      "Epoch 480/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2589 - acc: 0.9117 - val_loss: 0.2714 - val_acc: 0.9090\n",
      "Epoch 481/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9119 - val_loss: 0.2699 - val_acc: 0.9090\n",
      "Epoch 482/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2686 - val_acc: 0.9088\n",
      "Epoch 483/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2690 - val_acc: 0.9094\n",
      "Epoch 484/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2590 - acc: 0.9118 - val_loss: 0.2707 - val_acc: 0.9090\n",
      "Epoch 485/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9119 - val_loss: 0.2687 - val_acc: 0.9089\n",
      "Epoch 486/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9119 - val_loss: 0.2688 - val_acc: 0.9092\n",
      "Epoch 487/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2691 - val_acc: 0.9091\n",
      "Epoch 488/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9117 - val_loss: 0.2695 - val_acc: 0.9090\n",
      "Epoch 489/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2687 - val_acc: 0.9090\n",
      "Epoch 490/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2590 - acc: 0.9117 - val_loss: 0.2695 - val_acc: 0.9092\n",
      "Epoch 491/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2589 - acc: 0.9118 - val_loss: 0.2697 - val_acc: 0.9093\n",
      "Epoch 492/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9118 - val_loss: 0.2696 - val_acc: 0.9091\n",
      "Epoch 493/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2590 - acc: 0.9121 - val_loss: 0.2688 - val_acc: 0.9090\n",
      "Epoch 494/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2592 - acc: 0.9119 - val_loss: 0.2693 - val_acc: 0.9090\n",
      "Epoch 495/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2591 - acc: 0.9119 - val_loss: 0.2692 - val_acc: 0.9092\n",
      "Epoch 496/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2590 - acc: 0.9119 - val_loss: 0.2696 - val_acc: 0.9091\n",
      "Epoch 497/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2592 - acc: 0.9121 - val_loss: 0.2690 - val_acc: 0.9093\n",
      "Epoch 498/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2591 - acc: 0.9118 - val_loss: 0.2690 - val_acc: 0.9092\n",
      "Epoch 499/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2589 - acc: 0.9118 - val_loss: 0.2690 - val_acc: 0.9088\n",
      "Epoch 500/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2591 - acc: 0.9120 - val_loss: 0.2693 - val_acc: 0.9092\n",
      "39302/39302 [==============================] - 0s 2us/step\n",
      "../linkPrediction/dataframes/obesity\n",
      "degree (131006, 7, 11) --------------------------------------------------------------------\n",
      "(131006, 11) (131006,)\n",
      "[131006, 11, 1]\n",
      "(91704, 11) (91704,)\n",
      "Train on 91704 samples, validate on 39302 samples\n",
      "Epoch 1/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.6212 - acc: 0.8693 - val_loss: 0.6277 - val_acc: 0.8650\n",
      "Epoch 2/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.4335 - acc: 0.8949 - val_loss: 0.5385 - val_acc: 0.8739\n",
      "Epoch 3/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3788 - acc: 0.8985 - val_loss: 0.3392 - val_acc: 0.8981\n",
      "Epoch 4/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3310 - acc: 0.9016 - val_loss: 0.3257 - val_acc: 0.9009\n",
      "Epoch 5/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3143 - acc: 0.9022 - val_loss: 0.3099 - val_acc: 0.9003\n",
      "Epoch 6/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.3037 - acc: 0.9028 - val_loss: 0.3024 - val_acc: 0.9000\n",
      "Epoch 7/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2913 - acc: 0.9035 - val_loss: 0.3002 - val_acc: 0.9005\n",
      "Epoch 8/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2896 - acc: 0.9038 - val_loss: 0.2950 - val_acc: 0.9011\n",
      "Epoch 9/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2870 - acc: 0.9041 - val_loss: 0.2911 - val_acc: 0.9014\n",
      "Epoch 10/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2841 - acc: 0.9042 - val_loss: 0.2877 - val_acc: 0.9023\n",
      "Epoch 11/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2834 - acc: 0.9042 - val_loss: 0.2904 - val_acc: 0.9012\n",
      "Epoch 12/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2855 - acc: 0.9045 - val_loss: 0.2910 - val_acc: 0.9012\n",
      "Epoch 13/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2831 - acc: 0.9044 - val_loss: 0.2913 - val_acc: 0.9017\n",
      "Epoch 14/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2830 - acc: 0.9044 - val_loss: 0.2851 - val_acc: 0.9025\n",
      "Epoch 15/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2826 - acc: 0.9043 - val_loss: 0.2857 - val_acc: 0.9015\n",
      "Epoch 16/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2812 - acc: 0.9047 - val_loss: 0.2865 - val_acc: 0.9021\n",
      "Epoch 17/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2817 - acc: 0.9045 - val_loss: 0.2900 - val_acc: 0.9017\n",
      "Epoch 18/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2789 - acc: 0.9049 - val_loss: 0.2885 - val_acc: 0.9021\n",
      "Epoch 19/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2810 - acc: 0.9047 - val_loss: 0.2881 - val_acc: 0.9020\n",
      "Epoch 20/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2772 - acc: 0.9049 - val_loss: 0.2852 - val_acc: 0.9022\n",
      "Epoch 21/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2784 - acc: 0.9047 - val_loss: 0.2844 - val_acc: 0.9015\n",
      "Epoch 22/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2775 - acc: 0.9047 - val_loss: 0.2818 - val_acc: 0.9017\n",
      "Epoch 23/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2764 - acc: 0.9050 - val_loss: 0.2825 - val_acc: 0.9019\n",
      "Epoch 24/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2778 - acc: 0.9048 - val_loss: 0.2833 - val_acc: 0.9017\n",
      "Epoch 25/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2776 - acc: 0.9048 - val_loss: 0.2829 - val_acc: 0.9019\n",
      "Epoch 26/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2769 - acc: 0.9046 - val_loss: 0.2849 - val_acc: 0.9021\n",
      "Epoch 27/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2776 - acc: 0.9050 - val_loss: 0.2858 - val_acc: 0.9019\n",
      "Epoch 28/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2771 - acc: 0.9052 - val_loss: 0.2832 - val_acc: 0.9018\n",
      "Epoch 29/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2776 - acc: 0.9050 - val_loss: 0.2824 - val_acc: 0.9020\n",
      "Epoch 30/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2770 - acc: 0.9050 - val_loss: 0.2813 - val_acc: 0.9021\n",
      "Epoch 31/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2758 - acc: 0.9049 - val_loss: 0.2851 - val_acc: 0.9023\n",
      "Epoch 32/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2760 - acc: 0.9050 - val_loss: 0.2807 - val_acc: 0.9021\n",
      "Epoch 33/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2761 - acc: 0.9050 - val_loss: 0.2848 - val_acc: 0.9022\n",
      "Epoch 34/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2789 - acc: 0.9046 - val_loss: 0.2810 - val_acc: 0.9015\n",
      "Epoch 35/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2747 - acc: 0.9050 - val_loss: 0.2792 - val_acc: 0.9019\n",
      "Epoch 36/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2815 - acc: 0.9050 - val_loss: 0.2826 - val_acc: 0.9019\n",
      "Epoch 37/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2745 - acc: 0.9049 - val_loss: 0.2796 - val_acc: 0.9023\n",
      "Epoch 38/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2741 - acc: 0.9050 - val_loss: 0.2792 - val_acc: 0.9024\n",
      "Epoch 39/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2777 - acc: 0.9051 - val_loss: 0.2808 - val_acc: 0.9019\n",
      "Epoch 40/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2740 - acc: 0.9051 - val_loss: 0.2801 - val_acc: 0.9022\n",
      "Epoch 41/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2746 - acc: 0.9049 - val_loss: 0.2867 - val_acc: 0.9022\n",
      "Epoch 42/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2746 - acc: 0.9051 - val_loss: 0.2814 - val_acc: 0.9019\n",
      "Epoch 43/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2734 - acc: 0.9051 - val_loss: 0.2791 - val_acc: 0.9020\n",
      "Epoch 44/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2762 - acc: 0.9052 - val_loss: 0.2811 - val_acc: 0.9021\n",
      "Epoch 45/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2749 - acc: 0.9051 - val_loss: 0.2791 - val_acc: 0.9023\n",
      "Epoch 46/500\n",
      "91704/91704 [==============================] - 1s 14us/step - loss: 0.2732 - acc: 0.9052 - val_loss: 0.2786 - val_acc: 0.9029\n",
      "Epoch 47/500\n",
      "91704/91704 [==============================] - 2s 18us/step - loss: 0.2730 - acc: 0.9052 - val_loss: 0.2786 - val_acc: 0.9022\n",
      "Epoch 48/500\n",
      "91704/91704 [==============================] - 2s 16us/step - loss: 0.2734 - acc: 0.9052 - val_loss: 0.2779 - val_acc: 0.9025\n",
      "Epoch 49/500\n",
      "91704/91704 [==============================] - 2s 18us/step - loss: 0.2747 - acc: 0.9051 - val_loss: 0.2785 - val_acc: 0.9021\n",
      "Epoch 50/500\n",
      "91704/91704 [==============================] - 2s 16us/step - loss: 0.2722 - acc: 0.9051 - val_loss: 0.2825 - val_acc: 0.9026\n",
      "Epoch 51/500\n",
      "91704/91704 [==============================] - 1s 14us/step - loss: 0.2730 - acc: 0.9053 - val_loss: 0.2816 - val_acc: 0.9020\n",
      "Epoch 52/500\n",
      "91704/91704 [==============================] - 1s 14us/step - loss: 0.2722 - acc: 0.9051 - val_loss: 0.2778 - val_acc: 0.9024\n",
      "Epoch 53/500\n",
      "91704/91704 [==============================] - 1s 15us/step - loss: 0.2729 - acc: 0.9057 - val_loss: 0.2832 - val_acc: 0.9025\n",
      "Epoch 54/500\n",
      "91704/91704 [==============================] - 1s 15us/step - loss: 0.2724 - acc: 0.9053 - val_loss: 0.2796 - val_acc: 0.9025\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 15us/step - loss: 0.2729 - acc: 0.9053 - val_loss: 0.2781 - val_acc: 0.9029\n",
      "Epoch 56/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2721 - acc: 0.9052 - val_loss: 0.2795 - val_acc: 0.9025\n",
      "Epoch 57/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2778 - acc: 0.9051 - val_loss: 0.2815 - val_acc: 0.9026\n",
      "Epoch 58/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2730 - acc: 0.9053 - val_loss: 0.2784 - val_acc: 0.9024\n",
      "Epoch 59/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2716 - acc: 0.9054 - val_loss: 0.2780 - val_acc: 0.9025\n",
      "Epoch 60/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2716 - acc: 0.9056 - val_loss: 0.2777 - val_acc: 0.9027\n",
      "Epoch 61/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2725 - acc: 0.9056 - val_loss: 0.2804 - val_acc: 0.9022\n",
      "Epoch 62/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2714 - acc: 0.9056 - val_loss: 0.2766 - val_acc: 0.9031\n",
      "Epoch 63/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2719 - acc: 0.9055 - val_loss: 0.2835 - val_acc: 0.9023\n",
      "Epoch 64/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2712 - acc: 0.9057 - val_loss: 0.2766 - val_acc: 0.9026\n",
      "Epoch 65/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2721 - acc: 0.9059 - val_loss: 0.2777 - val_acc: 0.9027\n",
      "Epoch 66/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2708 - acc: 0.9057 - val_loss: 0.2763 - val_acc: 0.9027\n",
      "Epoch 67/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2710 - acc: 0.9059 - val_loss: 0.2760 - val_acc: 0.9032\n",
      "Epoch 68/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2724 - acc: 0.9056 - val_loss: 0.2770 - val_acc: 0.9023\n",
      "Epoch 69/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2711 - acc: 0.9056 - val_loss: 0.2777 - val_acc: 0.9033\n",
      "Epoch 70/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2726 - acc: 0.9058 - val_loss: 0.2783 - val_acc: 0.9030\n",
      "Epoch 71/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2720 - acc: 0.9056 - val_loss: 0.2772 - val_acc: 0.9030\n",
      "Epoch 72/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2702 - acc: 0.9057 - val_loss: 0.2775 - val_acc: 0.9028\n",
      "Epoch 73/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2706 - acc: 0.9057 - val_loss: 0.2758 - val_acc: 0.9028\n",
      "Epoch 74/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2715 - acc: 0.9056 - val_loss: 0.2808 - val_acc: 0.9031\n",
      "Epoch 75/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2711 - acc: 0.9054 - val_loss: 0.2776 - val_acc: 0.9028\n",
      "Epoch 76/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2713 - acc: 0.9062 - val_loss: 0.2858 - val_acc: 0.9010\n",
      "Epoch 77/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2705 - acc: 0.9056 - val_loss: 0.2774 - val_acc: 0.9032\n",
      "Epoch 78/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2701 - acc: 0.9059 - val_loss: 0.2752 - val_acc: 0.9027\n",
      "Epoch 79/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2716 - acc: 0.9058 - val_loss: 0.2768 - val_acc: 0.9032\n",
      "Epoch 80/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2706 - acc: 0.9059 - val_loss: 0.2752 - val_acc: 0.9032\n",
      "Epoch 81/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2700 - acc: 0.9059 - val_loss: 0.2753 - val_acc: 0.9033\n",
      "Epoch 82/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2702 - acc: 0.9057 - val_loss: 0.2765 - val_acc: 0.9024\n",
      "Epoch 83/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2697 - acc: 0.9057 - val_loss: 0.2776 - val_acc: 0.9034\n",
      "Epoch 84/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2699 - acc: 0.9062 - val_loss: 0.2760 - val_acc: 0.9033\n",
      "Epoch 85/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2704 - acc: 0.9058 - val_loss: 0.2757 - val_acc: 0.9028\n",
      "Epoch 86/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2700 - acc: 0.9057 - val_loss: 0.2832 - val_acc: 0.9030\n",
      "Epoch 87/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2705 - acc: 0.9059 - val_loss: 0.2758 - val_acc: 0.9030\n",
      "Epoch 88/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2702 - acc: 0.9059 - val_loss: 0.2762 - val_acc: 0.9032\n",
      "Epoch 89/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2724 - acc: 0.9057 - val_loss: 0.2758 - val_acc: 0.9033\n",
      "Epoch 90/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2691 - acc: 0.9059 - val_loss: 0.2758 - val_acc: 0.9036\n",
      "Epoch 91/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2696 - acc: 0.9060 - val_loss: 0.2771 - val_acc: 0.9030\n",
      "Epoch 92/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2699 - acc: 0.9061 - val_loss: 0.2770 - val_acc: 0.9033\n",
      "Epoch 93/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2699 - acc: 0.9058 - val_loss: 0.2771 - val_acc: 0.9025\n",
      "Epoch 94/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2694 - acc: 0.9060 - val_loss: 0.2762 - val_acc: 0.9032\n",
      "Epoch 95/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2697 - acc: 0.9060 - val_loss: 0.2751 - val_acc: 0.9033\n",
      "Epoch 96/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2704 - acc: 0.9057 - val_loss: 0.2755 - val_acc: 0.9033\n",
      "Epoch 97/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2713 - acc: 0.9058 - val_loss: 0.2806 - val_acc: 0.9033\n",
      "Epoch 98/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2701 - acc: 0.9061 - val_loss: 0.2757 - val_acc: 0.9031\n",
      "Epoch 99/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2693 - acc: 0.9058 - val_loss: 0.2751 - val_acc: 0.9032\n",
      "Epoch 100/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2706 - acc: 0.9058 - val_loss: 0.2774 - val_acc: 0.9028\n",
      "Epoch 101/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2691 - acc: 0.9059 - val_loss: 0.2765 - val_acc: 0.9032\n",
      "Epoch 102/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2690 - acc: 0.9061 - val_loss: 0.2769 - val_acc: 0.9030\n",
      "Epoch 103/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2695 - acc: 0.9062 - val_loss: 0.2758 - val_acc: 0.9033\n",
      "Epoch 104/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2696 - acc: 0.9058 - val_loss: 0.2766 - val_acc: 0.9033\n",
      "Epoch 105/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2697 - acc: 0.9058 - val_loss: 0.2759 - val_acc: 0.9027\n",
      "Epoch 106/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2692 - acc: 0.9060 - val_loss: 0.2757 - val_acc: 0.9027\n",
      "Epoch 107/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2696 - acc: 0.9058 - val_loss: 0.2774 - val_acc: 0.9033\n",
      "Epoch 108/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2694 - acc: 0.9061 - val_loss: 0.2753 - val_acc: 0.9035\n",
      "Epoch 109/500\n",
      "91704/91704 [==============================] - 1s 14us/step - loss: 0.2704 - acc: 0.9060 - val_loss: 0.2752 - val_acc: 0.9028\n",
      "Epoch 110/500\n",
      "91704/91704 [==============================] - 1s 15us/step - loss: 0.2696 - acc: 0.9059 - val_loss: 0.2748 - val_acc: 0.9039\n",
      "Epoch 111/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2686 - acc: 0.9063 - val_loss: 0.2750 - val_acc: 0.9035\n",
      "Epoch 112/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2695 - acc: 0.9062 - val_loss: 0.2753 - val_acc: 0.9037\n",
      "Epoch 113/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2691 - acc: 0.9063 - val_loss: 0.2761 - val_acc: 0.9034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2687 - acc: 0.9065 - val_loss: 0.2767 - val_acc: 0.9029\n",
      "Epoch 115/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2693 - acc: 0.9064 - val_loss: 0.2749 - val_acc: 0.9031\n",
      "Epoch 116/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2693 - acc: 0.9062 - val_loss: 0.2775 - val_acc: 0.9031\n",
      "Epoch 117/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2696 - acc: 0.9061 - val_loss: 0.2814 - val_acc: 0.9031\n",
      "Epoch 118/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2696 - acc: 0.9064 - val_loss: 0.2758 - val_acc: 0.9035\n",
      "Epoch 119/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2686 - acc: 0.9064 - val_loss: 0.2769 - val_acc: 0.9025\n",
      "Epoch 120/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2701 - acc: 0.9059 - val_loss: 0.2758 - val_acc: 0.9038\n",
      "Epoch 121/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2684 - acc: 0.9064 - val_loss: 0.2852 - val_acc: 0.9035\n",
      "Epoch 122/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2695 - acc: 0.9061 - val_loss: 0.2765 - val_acc: 0.9035\n",
      "Epoch 123/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2682 - acc: 0.9064 - val_loss: 0.2757 - val_acc: 0.9037\n",
      "Epoch 124/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2691 - acc: 0.9061 - val_loss: 0.2747 - val_acc: 0.9035\n",
      "Epoch 125/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2695 - acc: 0.9061 - val_loss: 0.2758 - val_acc: 0.9033\n",
      "Epoch 126/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2691 - acc: 0.9063 - val_loss: 0.2758 - val_acc: 0.9032\n",
      "Epoch 127/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2736 - acc: 0.9062 - val_loss: 0.2757 - val_acc: 0.9038\n",
      "Epoch 128/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2686 - acc: 0.9067 - val_loss: 0.2751 - val_acc: 0.9036\n",
      "Epoch 129/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2687 - acc: 0.9063 - val_loss: 0.2748 - val_acc: 0.9036\n",
      "Epoch 130/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2684 - acc: 0.9063 - val_loss: 0.2758 - val_acc: 0.9033\n",
      "Epoch 131/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2708 - acc: 0.9061 - val_loss: 0.2771 - val_acc: 0.9032\n",
      "Epoch 132/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2685 - acc: 0.9063 - val_loss: 0.2767 - val_acc: 0.9036\n",
      "Epoch 133/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2689 - acc: 0.9063 - val_loss: 0.2764 - val_acc: 0.9035\n",
      "Epoch 134/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2687 - acc: 0.9063 - val_loss: 0.2770 - val_acc: 0.9029\n",
      "Epoch 135/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2683 - acc: 0.9063 - val_loss: 0.2753 - val_acc: 0.9030\n",
      "Epoch 136/500\n",
      "91704/91704 [==============================] - 1s 14us/step - loss: 0.2690 - acc: 0.9064 - val_loss: 0.2761 - val_acc: 0.9035\n",
      "Epoch 137/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2683 - acc: 0.9064 - val_loss: 0.2757 - val_acc: 0.9036\n",
      "Epoch 138/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2704 - acc: 0.9061 - val_loss: 0.2775 - val_acc: 0.9037\n",
      "Epoch 139/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2683 - acc: 0.9064 - val_loss: 0.2767 - val_acc: 0.9032\n",
      "Epoch 140/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2680 - acc: 0.9063 - val_loss: 0.2749 - val_acc: 0.9033\n",
      "Epoch 141/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2684 - acc: 0.9060 - val_loss: 0.2749 - val_acc: 0.9036\n",
      "Epoch 142/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2690 - acc: 0.9063 - val_loss: 0.2756 - val_acc: 0.9034\n",
      "Epoch 143/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2686 - acc: 0.9062 - val_loss: 0.2788 - val_acc: 0.9028\n",
      "Epoch 144/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2680 - acc: 0.9060 - val_loss: 0.2749 - val_acc: 0.9030\n",
      "Epoch 145/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2697 - acc: 0.9063 - val_loss: 0.2755 - val_acc: 0.9031\n",
      "Epoch 146/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2677 - acc: 0.9065 - val_loss: 0.2746 - val_acc: 0.9039\n",
      "Epoch 147/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2684 - acc: 0.9065 - val_loss: 0.2771 - val_acc: 0.9034\n",
      "Epoch 148/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2691 - acc: 0.9067 - val_loss: 0.2757 - val_acc: 0.9032\n",
      "Epoch 149/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2677 - acc: 0.9061 - val_loss: 0.2759 - val_acc: 0.9035\n",
      "Epoch 150/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2680 - acc: 0.9063 - val_loss: 0.2748 - val_acc: 0.9032\n",
      "Epoch 151/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2671 - acc: 0.9064 - val_loss: 0.2786 - val_acc: 0.9019\n",
      "Epoch 152/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2685 - acc: 0.9063 - val_loss: 0.2755 - val_acc: 0.9033\n",
      "Epoch 153/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2714 - acc: 0.9058 - val_loss: 0.2817 - val_acc: 0.9034\n",
      "Epoch 154/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2674 - acc: 0.9062 - val_loss: 0.2743 - val_acc: 0.9040\n",
      "Epoch 155/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2675 - acc: 0.9063 - val_loss: 0.2781 - val_acc: 0.9033\n",
      "Epoch 156/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2685 - acc: 0.9063 - val_loss: 0.2755 - val_acc: 0.9030\n",
      "Epoch 157/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2682 - acc: 0.9061 - val_loss: 0.2754 - val_acc: 0.9032\n",
      "Epoch 158/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2676 - acc: 0.9061 - val_loss: 0.2763 - val_acc: 0.9031\n",
      "Epoch 159/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2693 - acc: 0.9061 - val_loss: 0.2748 - val_acc: 0.9031\n",
      "Epoch 160/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2686 - acc: 0.9062 - val_loss: 0.2762 - val_acc: 0.9030\n",
      "Epoch 161/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2676 - acc: 0.9061 - val_loss: 0.2754 - val_acc: 0.9028\n",
      "Epoch 162/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2680 - acc: 0.9058 - val_loss: 0.2766 - val_acc: 0.9031\n",
      "Epoch 163/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2684 - acc: 0.9059 - val_loss: 0.2749 - val_acc: 0.9032\n",
      "Epoch 164/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2676 - acc: 0.9062 - val_loss: 0.2746 - val_acc: 0.9035\n",
      "Epoch 165/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2678 - acc: 0.9064 - val_loss: 0.2758 - val_acc: 0.9034\n",
      "Epoch 166/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2674 - acc: 0.9062 - val_loss: 0.2766 - val_acc: 0.9037\n",
      "Epoch 167/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2681 - acc: 0.9064 - val_loss: 0.2738 - val_acc: 0.9034\n",
      "Epoch 168/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2670 - acc: 0.9065 - val_loss: 0.2745 - val_acc: 0.9039\n",
      "Epoch 169/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2682 - acc: 0.9063 - val_loss: 0.2753 - val_acc: 0.9034\n",
      "Epoch 170/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2671 - acc: 0.9066 - val_loss: 0.2745 - val_acc: 0.9033\n",
      "Epoch 171/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2683 - acc: 0.9058 - val_loss: 0.2751 - val_acc: 0.9027\n",
      "Epoch 172/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2670 - acc: 0.9062 - val_loss: 0.2738 - val_acc: 0.9032\n",
      "Epoch 173/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2687 - acc: 0.9064 - val_loss: 0.2745 - val_acc: 0.9034\n",
      "Epoch 174/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2674 - acc: 0.9064 - val_loss: 0.2837 - val_acc: 0.9033\n",
      "Epoch 175/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2675 - acc: 0.9065 - val_loss: 0.2759 - val_acc: 0.9032\n",
      "Epoch 176/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2668 - acc: 0.9061 - val_loss: 0.2748 - val_acc: 0.9032\n",
      "Epoch 177/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2687 - acc: 0.9061 - val_loss: 0.2750 - val_acc: 0.9034\n",
      "Epoch 178/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2671 - acc: 0.9063 - val_loss: 0.2761 - val_acc: 0.9034\n",
      "Epoch 179/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2698 - acc: 0.9063 - val_loss: 0.2754 - val_acc: 0.9040\n",
      "Epoch 180/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2670 - acc: 0.9065 - val_loss: 0.2736 - val_acc: 0.9035\n",
      "Epoch 181/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2682 - acc: 0.9062 - val_loss: 0.2744 - val_acc: 0.9037\n",
      "Epoch 182/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2672 - acc: 0.9065 - val_loss: 0.2769 - val_acc: 0.9032\n",
      "Epoch 183/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2667 - acc: 0.9065 - val_loss: 0.2763 - val_acc: 0.9036\n",
      "Epoch 184/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2677 - acc: 0.9065 - val_loss: 0.2749 - val_acc: 0.9039\n",
      "Epoch 185/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2672 - acc: 0.9063 - val_loss: 0.2757 - val_acc: 0.9031\n",
      "Epoch 186/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2667 - acc: 0.9066 - val_loss: 0.2750 - val_acc: 0.9038\n",
      "Epoch 187/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2669 - acc: 0.9065 - val_loss: 0.2756 - val_acc: 0.9035\n",
      "Epoch 188/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2666 - acc: 0.9064 - val_loss: 0.2789 - val_acc: 0.9038\n",
      "Epoch 189/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2670 - acc: 0.9068 - val_loss: 0.2837 - val_acc: 0.9036\n",
      "Epoch 190/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2666 - acc: 0.9066 - val_loss: 0.2744 - val_acc: 0.9038\n",
      "Epoch 191/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2668 - acc: 0.9065 - val_loss: 0.2764 - val_acc: 0.9032\n",
      "Epoch 192/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2675 - acc: 0.9065 - val_loss: 0.2744 - val_acc: 0.9038\n",
      "Epoch 193/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2666 - acc: 0.9062 - val_loss: 0.2751 - val_acc: 0.9040\n",
      "Epoch 194/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2666 - acc: 0.9065 - val_loss: 0.2745 - val_acc: 0.9037\n",
      "Epoch 195/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2671 - acc: 0.9064 - val_loss: 0.2747 - val_acc: 0.9038\n",
      "Epoch 196/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2676 - acc: 0.9067 - val_loss: 0.2763 - val_acc: 0.9030\n",
      "Epoch 197/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2670 - acc: 0.9065 - val_loss: 0.2757 - val_acc: 0.9039\n",
      "Epoch 198/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2674 - acc: 0.9064 - val_loss: 0.2737 - val_acc: 0.9034\n",
      "Epoch 199/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2663 - acc: 0.9063 - val_loss: 0.2749 - val_acc: 0.9036\n",
      "Epoch 200/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2669 - acc: 0.9065 - val_loss: 0.2760 - val_acc: 0.9036\n",
      "Epoch 201/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2671 - acc: 0.9061 - val_loss: 0.2748 - val_acc: 0.9034\n",
      "Epoch 202/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2668 - acc: 0.9065 - val_loss: 0.2748 - val_acc: 0.9038\n",
      "Epoch 203/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2670 - acc: 0.9063 - val_loss: 0.2751 - val_acc: 0.9036\n",
      "Epoch 204/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2669 - acc: 0.9067 - val_loss: 0.2746 - val_acc: 0.9038\n",
      "Epoch 205/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2665 - acc: 0.9066 - val_loss: 0.2811 - val_acc: 0.9040\n",
      "Epoch 206/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2672 - acc: 0.9062 - val_loss: 0.2750 - val_acc: 0.9041\n",
      "Epoch 207/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2663 - acc: 0.9068 - val_loss: 0.2748 - val_acc: 0.9038\n",
      "Epoch 208/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2667 - acc: 0.9066 - val_loss: 0.2759 - val_acc: 0.9032\n",
      "Epoch 209/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2666 - acc: 0.9063 - val_loss: 0.2751 - val_acc: 0.9037\n",
      "Epoch 210/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2666 - acc: 0.9065 - val_loss: 0.2748 - val_acc: 0.9035\n",
      "Epoch 211/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2665 - acc: 0.9066 - val_loss: 0.2750 - val_acc: 0.9037\n",
      "Epoch 212/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2669 - acc: 0.9062 - val_loss: 0.2754 - val_acc: 0.9037\n",
      "Epoch 213/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2673 - acc: 0.9063 - val_loss: 0.2761 - val_acc: 0.9028\n",
      "Epoch 214/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2674 - acc: 0.9062 - val_loss: 0.2757 - val_acc: 0.9035\n",
      "Epoch 215/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2662 - acc: 0.9061 - val_loss: 0.2743 - val_acc: 0.9035\n",
      "Epoch 216/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2663 - acc: 0.9065 - val_loss: 0.2743 - val_acc: 0.9031\n",
      "Epoch 217/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2687 - acc: 0.9061 - val_loss: 0.2754 - val_acc: 0.9027\n",
      "Epoch 218/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2657 - acc: 0.9064 - val_loss: 0.2865 - val_acc: 0.9037\n",
      "Epoch 219/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2662 - acc: 0.9066 - val_loss: 0.2750 - val_acc: 0.9033\n",
      "Epoch 220/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2668 - acc: 0.9064 - val_loss: 0.2745 - val_acc: 0.9034\n",
      "Epoch 221/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2667 - acc: 0.9064 - val_loss: 0.2767 - val_acc: 0.9035\n",
      "Epoch 222/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2673 - acc: 0.9064 - val_loss: 0.2745 - val_acc: 0.9037\n",
      "Epoch 223/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2663 - acc: 0.9064 - val_loss: 0.2764 - val_acc: 0.9035\n",
      "Epoch 224/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2661 - acc: 0.9066 - val_loss: 0.2760 - val_acc: 0.9034\n",
      "Epoch 225/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2662 - acc: 0.9065 - val_loss: 0.2744 - val_acc: 0.9036\n",
      "Epoch 226/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2660 - acc: 0.9065 - val_loss: 0.2776 - val_acc: 0.9028\n",
      "Epoch 227/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2674 - acc: 0.9065 - val_loss: 0.2898 - val_acc: 0.9038\n",
      "Epoch 228/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2680 - acc: 0.9063 - val_loss: 0.2749 - val_acc: 0.9034\n",
      "Epoch 229/500\n",
      "91704/91704 [==============================] - 1s 15us/step - loss: 0.2656 - acc: 0.9064 - val_loss: 0.2773 - val_acc: 0.9038\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2683 - acc: 0.9062 - val_loss: 0.2749 - val_acc: 0.9035\n",
      "Epoch 231/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2653 - acc: 0.9064 - val_loss: 0.2743 - val_acc: 0.9039\n",
      "Epoch 232/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2659 - acc: 0.9065 - val_loss: 0.2760 - val_acc: 0.9038\n",
      "Epoch 233/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2663 - acc: 0.9066 - val_loss: 0.2760 - val_acc: 0.9035\n",
      "Epoch 234/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2657 - acc: 0.9063 - val_loss: 0.2762 - val_acc: 0.9035\n",
      "Epoch 235/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2664 - acc: 0.9064 - val_loss: 0.2750 - val_acc: 0.9036\n",
      "Epoch 236/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2664 - acc: 0.9064 - val_loss: 0.2774 - val_acc: 0.9032\n",
      "Epoch 237/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2657 - acc: 0.9064 - val_loss: 0.2750 - val_acc: 0.9040\n",
      "Epoch 238/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2699 - acc: 0.9058 - val_loss: 0.2762 - val_acc: 0.9028\n",
      "Epoch 239/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2659 - acc: 0.9058 - val_loss: 0.2745 - val_acc: 0.9028\n",
      "Epoch 240/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2661 - acc: 0.9063 - val_loss: 0.2868 - val_acc: 0.9031\n",
      "Epoch 241/500\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 0.2671 - acc: 0.906 - 1s 11us/step - loss: 0.2670 - acc: 0.9062 - val_loss: 0.2791 - val_acc: 0.9036\n",
      "Epoch 242/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2687 - acc: 0.9059 - val_loss: 0.2761 - val_acc: 0.9030\n",
      "Epoch 243/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2662 - acc: 0.9062 - val_loss: 0.2768 - val_acc: 0.9031\n",
      "Epoch 244/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2658 - acc: 0.9063 - val_loss: 0.2753 - val_acc: 0.9035\n",
      "Epoch 245/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2660 - acc: 0.9064 - val_loss: 0.2745 - val_acc: 0.9034\n",
      "Epoch 246/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2668 - acc: 0.9064 - val_loss: 0.2765 - val_acc: 0.9031\n",
      "Epoch 247/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2674 - acc: 0.9064 - val_loss: 0.2748 - val_acc: 0.9034\n",
      "Epoch 248/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2660 - acc: 0.9063 - val_loss: 0.2756 - val_acc: 0.9034\n",
      "Epoch 249/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2657 - acc: 0.9064 - val_loss: 0.2756 - val_acc: 0.9034\n",
      "Epoch 250/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2662 - acc: 0.9063 - val_loss: 0.2753 - val_acc: 0.9037\n",
      "Epoch 251/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2659 - acc: 0.9063 - val_loss: 0.2756 - val_acc: 0.9035\n",
      "Epoch 252/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2659 - acc: 0.9064 - val_loss: 0.2746 - val_acc: 0.9035\n",
      "Epoch 253/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2659 - acc: 0.9063 - val_loss: 0.2744 - val_acc: 0.9034\n",
      "Epoch 254/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2672 - acc: 0.9062 - val_loss: 0.2744 - val_acc: 0.9035\n",
      "Epoch 255/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2657 - acc: 0.9067 - val_loss: 0.2756 - val_acc: 0.9037\n",
      "Epoch 256/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2662 - acc: 0.9066 - val_loss: 0.2754 - val_acc: 0.9038\n",
      "Epoch 257/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2655 - acc: 0.9065 - val_loss: 0.2795 - val_acc: 0.9027\n",
      "Epoch 258/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2660 - acc: 0.9068 - val_loss: 0.2735 - val_acc: 0.9038\n",
      "Epoch 259/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2671 - acc: 0.9065 - val_loss: 0.2749 - val_acc: 0.9033\n",
      "Epoch 260/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2654 - acc: 0.9065 - val_loss: 0.2755 - val_acc: 0.9037\n",
      "Epoch 261/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2656 - acc: 0.9066 - val_loss: 0.2753 - val_acc: 0.9036\n",
      "Epoch 262/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2667 - acc: 0.9063 - val_loss: 0.2775 - val_acc: 0.9020\n",
      "Epoch 263/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2662 - acc: 0.9064 - val_loss: 0.2737 - val_acc: 0.9032\n",
      "Epoch 264/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2657 - acc: 0.9065 - val_loss: 0.2744 - val_acc: 0.9036\n",
      "Epoch 265/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2658 - acc: 0.9064 - val_loss: 0.2847 - val_acc: 0.9016\n",
      "Epoch 266/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2673 - acc: 0.9065 - val_loss: 0.2739 - val_acc: 0.9032\n",
      "Epoch 267/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2657 - acc: 0.9066 - val_loss: 0.2747 - val_acc: 0.9031\n",
      "Epoch 268/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2656 - acc: 0.9064 - val_loss: 0.2744 - val_acc: 0.9034\n",
      "Epoch 269/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2662 - acc: 0.9064 - val_loss: 0.2749 - val_acc: 0.9036\n",
      "Epoch 270/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2654 - acc: 0.9067 - val_loss: 0.2737 - val_acc: 0.9036\n",
      "Epoch 271/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2653 - acc: 0.9065 - val_loss: 0.2765 - val_acc: 0.9027\n",
      "Epoch 272/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2662 - acc: 0.9065 - val_loss: 0.2754 - val_acc: 0.9035\n",
      "Epoch 273/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2659 - acc: 0.9063 - val_loss: 0.2748 - val_acc: 0.9036\n",
      "Epoch 274/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2654 - acc: 0.9065 - val_loss: 0.2743 - val_acc: 0.9034\n",
      "Epoch 275/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2656 - acc: 0.9065 - val_loss: 0.2805 - val_acc: 0.9030\n",
      "Epoch 276/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2656 - acc: 0.9067 - val_loss: 0.2734 - val_acc: 0.9038\n",
      "Epoch 277/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2660 - acc: 0.9066 - val_loss: 0.2753 - val_acc: 0.9037\n",
      "Epoch 278/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2654 - acc: 0.9068 - val_loss: 0.2742 - val_acc: 0.9034\n",
      "Epoch 279/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2659 - acc: 0.9062 - val_loss: 0.2734 - val_acc: 0.9033\n",
      "Epoch 280/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2656 - acc: 0.9066 - val_loss: 0.2755 - val_acc: 0.9034\n",
      "Epoch 281/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2651 - acc: 0.9067 - val_loss: 0.2744 - val_acc: 0.9036\n",
      "Epoch 282/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2655 - acc: 0.9067 - val_loss: 0.2767 - val_acc: 0.9028\n",
      "Epoch 283/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2667 - acc: 0.9065 - val_loss: 0.2738 - val_acc: 0.9035\n",
      "Epoch 284/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2660 - acc: 0.9063 - val_loss: 0.2762 - val_acc: 0.9027\n",
      "Epoch 285/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2664 - acc: 0.9066 - val_loss: 0.2759 - val_acc: 0.9037\n",
      "Epoch 286/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2658 - acc: 0.9065 - val_loss: 0.2755 - val_acc: 0.9037\n",
      "Epoch 287/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2655 - acc: 0.9066 - val_loss: 0.2778 - val_acc: 0.9034\n",
      "Epoch 288/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2651 - acc: 0.9068 - val_loss: 0.2753 - val_acc: 0.9038\n",
      "Epoch 289/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2652 - acc: 0.9066 - val_loss: 0.2744 - val_acc: 0.9035\n",
      "Epoch 290/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2660 - acc: 0.9064 - val_loss: 0.2741 - val_acc: 0.9035\n",
      "Epoch 291/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2666 - acc: 0.9067 - val_loss: 0.2750 - val_acc: 0.9035\n",
      "Epoch 292/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2651 - acc: 0.9064 - val_loss: 0.2752 - val_acc: 0.9033\n",
      "Epoch 293/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2656 - acc: 0.9067 - val_loss: 0.2755 - val_acc: 0.9034\n",
      "Epoch 294/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2654 - acc: 0.9067 - val_loss: 0.2743 - val_acc: 0.9037\n",
      "Epoch 295/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2669 - acc: 0.9062 - val_loss: 0.2746 - val_acc: 0.9035\n",
      "Epoch 296/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2653 - acc: 0.9066 - val_loss: 0.2744 - val_acc: 0.9036\n",
      "Epoch 297/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2653 - acc: 0.9067 - val_loss: 0.2738 - val_acc: 0.9037\n",
      "Epoch 298/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2673 - acc: 0.9065 - val_loss: 0.2762 - val_acc: 0.9037\n",
      "Epoch 299/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2652 - acc: 0.9068 - val_loss: 0.2732 - val_acc: 0.9034\n",
      "Epoch 300/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2652 - acc: 0.9067 - val_loss: 0.2752 - val_acc: 0.9037\n",
      "Epoch 301/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2658 - acc: 0.9065 - val_loss: 0.2757 - val_acc: 0.9035\n",
      "Epoch 302/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2652 - acc: 0.9065 - val_loss: 0.2832 - val_acc: 0.9034\n",
      "Epoch 303/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2650 - acc: 0.9068 - val_loss: 0.2740 - val_acc: 0.9035\n",
      "Epoch 304/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2672 - acc: 0.9062 - val_loss: 0.2749 - val_acc: 0.9029\n",
      "Epoch 305/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2662 - acc: 0.9063 - val_loss: 0.2748 - val_acc: 0.9034\n",
      "Epoch 306/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2651 - acc: 0.9063 - val_loss: 0.2743 - val_acc: 0.9033\n",
      "Epoch 307/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2650 - acc: 0.9065 - val_loss: 0.2734 - val_acc: 0.9038\n",
      "Epoch 308/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2662 - acc: 0.9065 - val_loss: 0.2746 - val_acc: 0.9036\n",
      "Epoch 309/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2656 - acc: 0.9066 - val_loss: 0.2743 - val_acc: 0.9034\n",
      "Epoch 310/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2650 - acc: 0.9065 - val_loss: 0.2739 - val_acc: 0.9036\n",
      "Epoch 311/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2657 - acc: 0.9065 - val_loss: 0.2754 - val_acc: 0.9035\n",
      "Epoch 312/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2652 - acc: 0.9065 - val_loss: 0.2804 - val_acc: 0.9029\n",
      "Epoch 313/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2656 - acc: 0.9064 - val_loss: 0.2742 - val_acc: 0.9030\n",
      "Epoch 314/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2661 - acc: 0.9063 - val_loss: 0.2770 - val_acc: 0.9032\n",
      "Epoch 315/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2652 - acc: 0.9065 - val_loss: 0.2769 - val_acc: 0.9027\n",
      "Epoch 316/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2667 - acc: 0.9066 - val_loss: 0.2750 - val_acc: 0.9035\n",
      "Epoch 317/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2650 - acc: 0.9065 - val_loss: 0.2774 - val_acc: 0.9036\n",
      "Epoch 318/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2661 - acc: 0.9067 - val_loss: 0.2738 - val_acc: 0.9036\n",
      "Epoch 319/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2655 - acc: 0.9068 - val_loss: 0.2743 - val_acc: 0.9032\n",
      "Epoch 320/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2654 - acc: 0.9067 - val_loss: 0.2760 - val_acc: 0.9033\n",
      "Epoch 321/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2672 - acc: 0.9062 - val_loss: 0.2729 - val_acc: 0.9036\n",
      "Epoch 322/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2658 - acc: 0.9062 - val_loss: 0.2742 - val_acc: 0.9034\n",
      "Epoch 323/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2666 - acc: 0.9067 - val_loss: 0.2742 - val_acc: 0.9036\n",
      "Epoch 324/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2651 - acc: 0.9067 - val_loss: 0.2767 - val_acc: 0.9035\n",
      "Epoch 325/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2653 - acc: 0.9067 - val_loss: 0.2742 - val_acc: 0.9036\n",
      "Epoch 326/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2651 - acc: 0.9066 - val_loss: 0.2735 - val_acc: 0.9037\n",
      "Epoch 327/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2673 - acc: 0.9064 - val_loss: 0.2735 - val_acc: 0.9036\n",
      "Epoch 328/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2649 - acc: 0.9064 - val_loss: 0.2754 - val_acc: 0.9036\n",
      "Epoch 329/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2652 - acc: 0.9065 - val_loss: 0.2803 - val_acc: 0.9031\n",
      "Epoch 330/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2665 - acc: 0.9063 - val_loss: 0.2748 - val_acc: 0.9038\n",
      "Epoch 331/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2667 - acc: 0.9064 - val_loss: 0.2754 - val_acc: 0.9032\n",
      "Epoch 332/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2658 - acc: 0.9064 - val_loss: 0.2739 - val_acc: 0.9035\n",
      "Epoch 333/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2650 - acc: 0.9064 - val_loss: 0.2751 - val_acc: 0.9035\n",
      "Epoch 334/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2650 - acc: 0.9066 - val_loss: 0.2765 - val_acc: 0.9032\n",
      "Epoch 335/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2649 - acc: 0.9066 - val_loss: 0.2737 - val_acc: 0.9038\n",
      "Epoch 336/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2651 - acc: 0.9066 - val_loss: 0.2750 - val_acc: 0.9033\n",
      "Epoch 337/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2650 - acc: 0.9068 - val_loss: 0.2746 - val_acc: 0.9035\n",
      "Epoch 338/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2663 - acc: 0.9066 - val_loss: 0.2796 - val_acc: 0.9030\n",
      "Epoch 339/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2655 - acc: 0.9063 - val_loss: 0.2741 - val_acc: 0.9036\n",
      "Epoch 340/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2657 - acc: 0.9067 - val_loss: 0.2737 - val_acc: 0.9038\n",
      "Epoch 341/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2659 - acc: 0.9064 - val_loss: 0.2759 - val_acc: 0.9037\n",
      "Epoch 342/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2650 - acc: 0.9064 - val_loss: 0.2753 - val_acc: 0.9034\n",
      "Epoch 343/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2655 - acc: 0.9064 - val_loss: 0.2743 - val_acc: 0.9035\n",
      "Epoch 344/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2659 - acc: 0.9065 - val_loss: 0.2772 - val_acc: 0.9031\n",
      "Epoch 345/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2659 - acc: 0.9062 - val_loss: 0.2747 - val_acc: 0.9028\n",
      "Epoch 346/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2654 - acc: 0.9065 - val_loss: 0.2755 - val_acc: 0.9035\n",
      "Epoch 347/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2653 - acc: 0.9065 - val_loss: 0.2733 - val_acc: 0.9037\n",
      "Epoch 348/500\n",
      "91704/91704 [==============================] - 1s 15us/step - loss: 0.2651 - acc: 0.9065 - val_loss: 0.2733 - val_acc: 0.9037\n",
      "Epoch 349/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2647 - acc: 0.9067 - val_loss: 0.2778 - val_acc: 0.9033\n",
      "Epoch 350/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2662 - acc: 0.9066 - val_loss: 0.2750 - val_acc: 0.9034\n",
      "Epoch 351/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2659 - acc: 0.9065 - val_loss: 0.2746 - val_acc: 0.9031\n",
      "Epoch 352/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2668 - acc: 0.9065 - val_loss: 0.2740 - val_acc: 0.9036\n",
      "Epoch 353/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2645 - acc: 0.9067 - val_loss: 0.2736 - val_acc: 0.9034\n",
      "Epoch 354/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2656 - acc: 0.9065 - val_loss: 0.2756 - val_acc: 0.9036\n",
      "Epoch 355/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2652 - acc: 0.9067 - val_loss: 0.2737 - val_acc: 0.9037\n",
      "Epoch 356/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2653 - acc: 0.9067 - val_loss: 0.2742 - val_acc: 0.9036\n",
      "Epoch 357/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2650 - acc: 0.9066 - val_loss: 0.2741 - val_acc: 0.9037\n",
      "Epoch 358/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2650 - acc: 0.9067 - val_loss: 0.2748 - val_acc: 0.9035\n",
      "Epoch 359/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2654 - acc: 0.9066 - val_loss: 0.2755 - val_acc: 0.9038\n",
      "Epoch 360/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2658 - acc: 0.9065 - val_loss: 0.2842 - val_acc: 0.9030\n",
      "Epoch 361/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2679 - acc: 0.9065 - val_loss: 0.2740 - val_acc: 0.9034\n",
      "Epoch 362/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2646 - acc: 0.9066 - val_loss: 0.2742 - val_acc: 0.9036\n",
      "Epoch 363/500\n",
      "91704/91704 [==============================] - 1s 14us/step - loss: 0.2649 - acc: 0.9067 - val_loss: 0.2752 - val_acc: 0.9038\n",
      "Epoch 364/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2685 - acc: 0.9062 - val_loss: 0.2772 - val_acc: 0.9033\n",
      "Epoch 365/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2657 - acc: 0.9064 - val_loss: 0.2753 - val_acc: 0.9035\n",
      "Epoch 366/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2645 - acc: 0.9069 - val_loss: 0.2749 - val_acc: 0.9036\n",
      "Epoch 367/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2655 - acc: 0.9067 - val_loss: 0.2732 - val_acc: 0.9032\n",
      "Epoch 368/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2647 - acc: 0.9064 - val_loss: 0.2731 - val_acc: 0.9036\n",
      "Epoch 369/500\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 0.2662 - acc: 0.906 - 1s 11us/step - loss: 0.2662 - acc: 0.9066 - val_loss: 0.2755 - val_acc: 0.9038\n",
      "Epoch 370/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2649 - acc: 0.9067 - val_loss: 0.2735 - val_acc: 0.9033\n",
      "Epoch 371/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2665 - acc: 0.9064 - val_loss: 0.2744 - val_acc: 0.9033\n",
      "Epoch 372/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2653 - acc: 0.9065 - val_loss: 0.2749 - val_acc: 0.9037\n",
      "Epoch 373/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2646 - acc: 0.9066 - val_loss: 0.2743 - val_acc: 0.9032\n",
      "Epoch 374/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2659 - acc: 0.9068 - val_loss: 0.2759 - val_acc: 0.9034\n",
      "Epoch 375/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2651 - acc: 0.9067 - val_loss: 0.2763 - val_acc: 0.9036\n",
      "Epoch 376/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2650 - acc: 0.9067 - val_loss: 0.2755 - val_acc: 0.9036\n",
      "Epoch 377/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2659 - acc: 0.9066 - val_loss: 0.2737 - val_acc: 0.9036\n",
      "Epoch 378/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2648 - acc: 0.9065 - val_loss: 0.2729 - val_acc: 0.9035\n",
      "Epoch 379/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2648 - acc: 0.9068 - val_loss: 0.2747 - val_acc: 0.9035\n",
      "Epoch 380/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2652 - acc: 0.9065 - val_loss: 0.2750 - val_acc: 0.9040\n",
      "Epoch 381/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2652 - acc: 0.9066 - val_loss: 0.2735 - val_acc: 0.9036\n",
      "Epoch 382/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2659 - acc: 0.9064 - val_loss: 0.2765 - val_acc: 0.9037\n",
      "Epoch 383/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2648 - acc: 0.9067 - val_loss: 0.2753 - val_acc: 0.9035\n",
      "Epoch 384/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2649 - acc: 0.9066 - val_loss: 0.2752 - val_acc: 0.9037\n",
      "Epoch 385/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2650 - acc: 0.9063 - val_loss: 0.2739 - val_acc: 0.9036\n",
      "Epoch 386/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2660 - acc: 0.9067 - val_loss: 0.2746 - val_acc: 0.9034\n",
      "Epoch 387/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2645 - acc: 0.9066 - val_loss: 0.2740 - val_acc: 0.9035\n",
      "Epoch 388/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2653 - acc: 0.9067 - val_loss: 0.2736 - val_acc: 0.9036\n",
      "Epoch 389/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2651 - acc: 0.9066 - val_loss: 0.2760 - val_acc: 0.9031\n",
      "Epoch 390/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2656 - acc: 0.9066 - val_loss: 0.2742 - val_acc: 0.9031\n",
      "Epoch 391/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2650 - acc: 0.9063 - val_loss: 0.2795 - val_acc: 0.9023\n",
      "Epoch 392/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2648 - acc: 0.9069 - val_loss: 0.2732 - val_acc: 0.9032\n",
      "Epoch 393/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2655 - acc: 0.9067 - val_loss: 0.2778 - val_acc: 0.9036\n",
      "Epoch 394/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2655 - acc: 0.9066 - val_loss: 0.2751 - val_acc: 0.9036\n",
      "Epoch 395/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2650 - acc: 0.9068 - val_loss: 0.2748 - val_acc: 0.9033\n",
      "Epoch 396/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2658 - acc: 0.9065 - val_loss: 0.2752 - val_acc: 0.9035\n",
      "Epoch 397/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2654 - acc: 0.9066 - val_loss: 0.2752 - val_acc: 0.9035\n",
      "Epoch 398/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2645 - acc: 0.9068 - val_loss: 0.2762 - val_acc: 0.9035\n",
      "Epoch 399/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2655 - acc: 0.9066 - val_loss: 0.2755 - val_acc: 0.9037\n",
      "Epoch 400/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2649 - acc: 0.9067 - val_loss: 0.2755 - val_acc: 0.9033\n",
      "Epoch 401/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2652 - acc: 0.9066 - val_loss: 0.2750 - val_acc: 0.9035\n",
      "Epoch 402/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2655 - acc: 0.9066 - val_loss: 0.2751 - val_acc: 0.9035\n",
      "Epoch 403/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2646 - acc: 0.9067 - val_loss: 0.2748 - val_acc: 0.9033\n",
      "Epoch 404/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2662 - acc: 0.9064 - val_loss: 0.2749 - val_acc: 0.9030\n",
      "Epoch 405/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2648 - acc: 0.9065 - val_loss: 0.2737 - val_acc: 0.9036\n",
      "Epoch 406/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2646 - acc: 0.9069 - val_loss: 0.2742 - val_acc: 0.9038\n",
      "Epoch 407/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2651 - acc: 0.9064 - val_loss: 0.2736 - val_acc: 0.9034\n",
      "Epoch 408/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2647 - acc: 0.9067 - val_loss: 0.2750 - val_acc: 0.9036\n",
      "Epoch 409/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2652 - acc: 0.9068 - val_loss: 0.2755 - val_acc: 0.9037\n",
      "Epoch 410/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2651 - acc: 0.9065 - val_loss: 0.2740 - val_acc: 0.9035\n",
      "Epoch 411/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2662 - acc: 0.9068 - val_loss: 0.2754 - val_acc: 0.9032\n",
      "Epoch 412/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2648 - acc: 0.9067 - val_loss: 0.2737 - val_acc: 0.9032\n",
      "Epoch 413/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2648 - acc: 0.9067 - val_loss: 0.2743 - val_acc: 0.9037\n",
      "Epoch 414/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2643 - acc: 0.9066 - val_loss: 0.2741 - val_acc: 0.9035\n",
      "Epoch 415/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2648 - acc: 0.9067 - val_loss: 0.2758 - val_acc: 0.9032\n",
      "Epoch 416/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2655 - acc: 0.9067 - val_loss: 0.2744 - val_acc: 0.9037\n",
      "Epoch 417/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2646 - acc: 0.9067 - val_loss: 0.2744 - val_acc: 0.9037\n",
      "Epoch 418/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2659 - acc: 0.9068 - val_loss: 0.2770 - val_acc: 0.9034\n",
      "Epoch 419/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2648 - acc: 0.9067 - val_loss: 0.2735 - val_acc: 0.9036\n",
      "Epoch 420/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2641 - acc: 0.9069 - val_loss: 0.2739 - val_acc: 0.9038\n",
      "Epoch 421/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2647 - acc: 0.9069 - val_loss: 0.2739 - val_acc: 0.9037\n",
      "Epoch 422/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2667 - acc: 0.9068 - val_loss: 0.2772 - val_acc: 0.9035\n",
      "Epoch 423/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2645 - acc: 0.9067 - val_loss: 0.2743 - val_acc: 0.9038\n",
      "Epoch 424/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2654 - acc: 0.9068 - val_loss: 0.2756 - val_acc: 0.9037\n",
      "Epoch 425/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2648 - acc: 0.9068 - val_loss: 0.2743 - val_acc: 0.9034\n",
      "Epoch 426/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2644 - acc: 0.9067 - val_loss: 0.2828 - val_acc: 0.9033\n",
      "Epoch 427/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2651 - acc: 0.9069 - val_loss: 0.2760 - val_acc: 0.9036\n",
      "Epoch 428/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2648 - acc: 0.9067 - val_loss: 0.2758 - val_acc: 0.9038\n",
      "Epoch 429/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2654 - acc: 0.9065 - val_loss: 0.2768 - val_acc: 0.9036\n",
      "Epoch 430/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2647 - acc: 0.9065 - val_loss: 0.2745 - val_acc: 0.9033\n",
      "Epoch 431/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2647 - acc: 0.9065 - val_loss: 0.2767 - val_acc: 0.9035\n",
      "Epoch 432/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2661 - acc: 0.9067 - val_loss: 0.2747 - val_acc: 0.9033\n",
      "Epoch 433/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2647 - acc: 0.9068 - val_loss: 0.2869 - val_acc: 0.9038\n",
      "Epoch 434/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2646 - acc: 0.9066 - val_loss: 0.2744 - val_acc: 0.9035\n",
      "Epoch 435/500\n",
      "91704/91704 [==============================] - 1s 14us/step - loss: 0.2650 - acc: 0.9065 - val_loss: 0.2732 - val_acc: 0.9038\n",
      "Epoch 436/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2676 - acc: 0.9059 - val_loss: 0.2815 - val_acc: 0.9023\n",
      "Epoch 437/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2658 - acc: 0.9060 - val_loss: 0.2752 - val_acc: 0.9027\n",
      "Epoch 438/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2648 - acc: 0.9061 - val_loss: 0.2739 - val_acc: 0.9033\n",
      "Epoch 439/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2650 - acc: 0.9064 - val_loss: 0.2748 - val_acc: 0.9032\n",
      "Epoch 440/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2650 - acc: 0.9061 - val_loss: 0.2753 - val_acc: 0.9034\n",
      "Epoch 441/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2649 - acc: 0.9062 - val_loss: 0.2756 - val_acc: 0.9035\n",
      "Epoch 442/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2644 - acc: 0.9068 - val_loss: 0.2948 - val_acc: 0.9034\n",
      "Epoch 443/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2645 - acc: 0.9068 - val_loss: 0.2741 - val_acc: 0.9035\n",
      "Epoch 444/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2659 - acc: 0.9065 - val_loss: 0.2765 - val_acc: 0.9035\n",
      "Epoch 445/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2645 - acc: 0.9069 - val_loss: 0.2741 - val_acc: 0.9037\n",
      "Epoch 446/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2681 - acc: 0.9065 - val_loss: 0.2752 - val_acc: 0.9034\n",
      "Epoch 447/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2658 - acc: 0.9068 - val_loss: 0.2750 - val_acc: 0.9034\n",
      "Epoch 448/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2659 - acc: 0.9066 - val_loss: 0.2747 - val_acc: 0.9037\n",
      "Epoch 449/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2644 - acc: 0.9068 - val_loss: 0.2750 - val_acc: 0.9033\n",
      "Epoch 450/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2653 - acc: 0.9064 - val_loss: 0.2800 - val_acc: 0.9030\n",
      "Epoch 451/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2650 - acc: 0.9067 - val_loss: 0.2745 - val_acc: 0.9037\n",
      "Epoch 452/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2661 - acc: 0.9065 - val_loss: 0.2742 - val_acc: 0.9033\n",
      "Epoch 453/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2648 - acc: 0.9066 - val_loss: 0.2751 - val_acc: 0.9031\n",
      "Epoch 454/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2655 - acc: 0.9061 - val_loss: 0.2748 - val_acc: 0.9033\n",
      "Epoch 455/500\n",
      "91704/91704 [==============================] - 1s 15us/step - loss: 0.2650 - acc: 0.9064 - val_loss: 0.2857 - val_acc: 0.9035\n",
      "Epoch 456/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2658 - acc: 0.9067 - val_loss: 0.2760 - val_acc: 0.9036\n",
      "Epoch 457/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2643 - acc: 0.9067 - val_loss: 0.2730 - val_acc: 0.9036\n",
      "Epoch 458/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2642 - acc: 0.9068 - val_loss: 0.2745 - val_acc: 0.9036\n",
      "Epoch 459/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2640 - acc: 0.9070 - val_loss: 0.2739 - val_acc: 0.9033\n",
      "Epoch 460/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2653 - acc: 0.9065 - val_loss: 0.2741 - val_acc: 0.9038\n",
      "Epoch 461/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2652 - acc: 0.9065 - val_loss: 0.2746 - val_acc: 0.9034\n",
      "Epoch 462/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2642 - acc: 0.9068 - val_loss: 0.2730 - val_acc: 0.9038\n",
      "Epoch 463/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2642 - acc: 0.9067 - val_loss: 0.2767 - val_acc: 0.9032\n",
      "Epoch 464/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2649 - acc: 0.9067 - val_loss: 0.2777 - val_acc: 0.9036\n",
      "Epoch 465/500\n",
      "91704/91704 [==============================] - 1s 14us/step - loss: 0.2645 - acc: 0.9066 - val_loss: 0.2747 - val_acc: 0.9036\n",
      "Epoch 466/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2644 - acc: 0.9067 - val_loss: 0.2738 - val_acc: 0.9037\n",
      "Epoch 467/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2652 - acc: 0.9064 - val_loss: 0.2743 - val_acc: 0.9037\n",
      "Epoch 468/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2666 - acc: 0.9068 - val_loss: 0.2782 - val_acc: 0.9039\n",
      "Epoch 469/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2648 - acc: 0.9067 - val_loss: 0.2747 - val_acc: 0.9033\n",
      "Epoch 470/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2640 - acc: 0.9067 - val_loss: 0.2814 - val_acc: 0.9038\n",
      "Epoch 471/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2655 - acc: 0.9068 - val_loss: 0.2748 - val_acc: 0.9037\n",
      "Epoch 472/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2655 - acc: 0.9067 - val_loss: 0.2757 - val_acc: 0.9030\n",
      "Epoch 473/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2646 - acc: 0.9066 - val_loss: 0.2755 - val_acc: 0.9034\n",
      "Epoch 474/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2640 - acc: 0.9067 - val_loss: 0.2738 - val_acc: 0.9039\n",
      "Epoch 475/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2651 - acc: 0.9069 - val_loss: 0.2733 - val_acc: 0.9035\n",
      "Epoch 476/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2652 - acc: 0.9067 - val_loss: 0.2744 - val_acc: 0.9036\n",
      "Epoch 477/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2644 - acc: 0.9068 - val_loss: 0.2743 - val_acc: 0.9039\n",
      "Epoch 478/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2644 - acc: 0.9069 - val_loss: 0.2743 - val_acc: 0.9035\n",
      "Epoch 479/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2651 - acc: 0.9067 - val_loss: 0.2752 - val_acc: 0.9036\n",
      "Epoch 480/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2644 - acc: 0.9070 - val_loss: 0.2750 - val_acc: 0.9031\n",
      "Epoch 481/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2644 - acc: 0.9067 - val_loss: 0.2749 - val_acc: 0.9031\n",
      "Epoch 482/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2653 - acc: 0.9069 - val_loss: 0.2744 - val_acc: 0.9037\n",
      "Epoch 483/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2653 - acc: 0.9068 - val_loss: 0.2781 - val_acc: 0.9039\n",
      "Epoch 484/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2643 - acc: 0.9068 - val_loss: 0.2736 - val_acc: 0.9034\n",
      "Epoch 485/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2643 - acc: 0.9066 - val_loss: 0.2733 - val_acc: 0.9032\n",
      "Epoch 486/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2648 - acc: 0.9068 - val_loss: 0.2744 - val_acc: 0.9037\n",
      "Epoch 487/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2641 - acc: 0.9066 - val_loss: 0.2742 - val_acc: 0.9037\n",
      "Epoch 488/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2643 - acc: 0.9067 - val_loss: 0.2773 - val_acc: 0.9033\n",
      "Epoch 489/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2647 - acc: 0.9070 - val_loss: 0.2742 - val_acc: 0.9028\n",
      "Epoch 490/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2642 - acc: 0.9066 - val_loss: 0.2735 - val_acc: 0.9034\n",
      "Epoch 491/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2664 - acc: 0.9066 - val_loss: 0.2747 - val_acc: 0.9032\n",
      "Epoch 492/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2646 - acc: 0.9068 - val_loss: 0.2746 - val_acc: 0.9033\n",
      "Epoch 493/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2640 - acc: 0.9069 - val_loss: 0.2763 - val_acc: 0.9035\n",
      "Epoch 494/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2646 - acc: 0.9068 - val_loss: 0.2744 - val_acc: 0.9036\n",
      "Epoch 495/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2660 - acc: 0.9069 - val_loss: 0.2758 - val_acc: 0.9035\n",
      "Epoch 496/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2640 - acc: 0.9069 - val_loss: 0.2742 - val_acc: 0.9034\n",
      "Epoch 497/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2641 - acc: 0.9068 - val_loss: 0.2748 - val_acc: 0.9037\n",
      "Epoch 498/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2651 - acc: 0.9066 - val_loss: 0.2742 - val_acc: 0.9036\n",
      "Epoch 499/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2647 - acc: 0.9071 - val_loss: 0.2771 - val_acc: 0.9036\n",
      "Epoch 500/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2645 - acc: 0.9067 - val_loss: 0.2763 - val_acc: 0.9028\n",
      "39302/39302 [==============================] - 0s 3us/step\n",
      "../linkPrediction/dataframes/obesity\n",
      "citation (131006, 7, 3) --------------------------------------------------------------------\n",
      "(131006, 3) (131006,)\n",
      "[131006, 3, 1]\n",
      "(91704, 3) (91704,)\n",
      "Train on 91704 samples, validate on 39302 samples\n",
      "Epoch 1/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.9776 - acc: 0.8692 - val_loss: 0.5689 - val_acc: 0.8799\n",
      "Epoch 2/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.6859 - acc: 0.8843 - val_loss: 0.5756 - val_acc: 0.8677\n",
      "Epoch 3/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.5263 - acc: 0.8945 - val_loss: 0.4607 - val_acc: 0.8847\n",
      "Epoch 4/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.5204 - acc: 0.8927 - val_loss: 0.4701 - val_acc: 0.8808\n",
      "Epoch 5/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.5056 - acc: 0.8914 - val_loss: 0.4534 - val_acc: 0.8831\n",
      "Epoch 6/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.4570 - acc: 0.8957 - val_loss: 0.4041 - val_acc: 0.9004\n",
      "Epoch 7/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.4767 - acc: 0.8941 - val_loss: 0.5389 - val_acc: 0.8636\n",
      "Epoch 8/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.4224 - acc: 0.8953 - val_loss: 0.4639 - val_acc: 0.9008\n",
      "Epoch 9/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.4170 - acc: 0.8981 - val_loss: 0.4899 - val_acc: 0.9008\n",
      "Epoch 10/500\n",
      "91704/91704 [==============================] - 2s 21us/step - loss: 0.3948 - acc: 0.8977 - val_loss: 0.3516 - val_acc: 0.9007\n",
      "Epoch 11/500\n",
      "91704/91704 [==============================] - 2s 17us/step - loss: 0.3728 - acc: 0.8989 - val_loss: 0.3388 - val_acc: 0.9012\n",
      "Epoch 12/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.3665 - acc: 0.8998 - val_loss: 0.3237 - val_acc: 0.9001\n",
      "Epoch 13/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.3652 - acc: 0.8992 - val_loss: 0.3229 - val_acc: 0.9011\n",
      "Epoch 14/500\n",
      "91704/91704 [==============================] - 1s 16us/step - loss: 0.3401 - acc: 0.9004 - val_loss: 0.3161 - val_acc: 0.9002\n",
      "Epoch 15/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.3417 - acc: 0.9001 - val_loss: 0.3281 - val_acc: 0.9008\n",
      "Epoch 16/500\n",
      "91704/91704 [==============================] - 2s 24us/step - loss: 0.3185 - acc: 0.9023 - val_loss: 0.3745 - val_acc: 0.9009\n",
      "Epoch 17/500\n",
      "91704/91704 [==============================] - 1s 15us/step - loss: 0.3114 - acc: 0.9029 - val_loss: 0.3469 - val_acc: 0.9010\n",
      "Epoch 18/500\n",
      "91704/91704 [==============================] - 2s 26us/step - loss: 0.3062 - acc: 0.9035 - val_loss: 0.3256 - val_acc: 0.8965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/500\n",
      "91704/91704 [==============================] - 1s 16us/step - loss: 0.2995 - acc: 0.9042 - val_loss: 0.3104 - val_acc: 0.9018\n",
      "Epoch 20/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2903 - acc: 0.9054 - val_loss: 0.2938 - val_acc: 0.9025\n",
      "Epoch 21/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2878 - acc: 0.9054 - val_loss: 0.2917 - val_acc: 0.9024\n",
      "Epoch 22/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2879 - acc: 0.9048 - val_loss: 0.2912 - val_acc: 0.9022\n",
      "Epoch 23/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2884 - acc: 0.9050 - val_loss: 0.2914 - val_acc: 0.9027\n",
      "Epoch 24/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2871 - acc: 0.9052 - val_loss: 0.2924 - val_acc: 0.9027\n",
      "Epoch 25/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2872 - acc: 0.9050 - val_loss: 0.2926 - val_acc: 0.9021\n",
      "Epoch 26/500\n",
      "91704/91704 [==============================] - 2s 18us/step - loss: 0.2886 - acc: 0.9047 - val_loss: 0.2922 - val_acc: 0.9017\n",
      "Epoch 27/500\n",
      "91704/91704 [==============================] - 2s 22us/step - loss: 0.2869 - acc: 0.9050 - val_loss: 0.2901 - val_acc: 0.9023\n",
      "Epoch 28/500\n",
      "91704/91704 [==============================] - 2s 25us/step - loss: 0.2879 - acc: 0.9050 - val_loss: 0.2910 - val_acc: 0.9023\n",
      "Epoch 29/500\n",
      "91704/91704 [==============================] - 1s 15us/step - loss: 0.2869 - acc: 0.9049 - val_loss: 0.2911 - val_acc: 0.9022\n",
      "Epoch 30/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2873 - acc: 0.9049 - val_loss: 0.2907 - val_acc: 0.9021\n",
      "Epoch 31/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2867 - acc: 0.9050 - val_loss: 0.2909 - val_acc: 0.9020\n",
      "Epoch 32/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2862 - acc: 0.9050 - val_loss: 0.2908 - val_acc: 0.9021\n",
      "Epoch 33/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2858 - acc: 0.9052 - val_loss: 0.2902 - val_acc: 0.9025\n",
      "Epoch 34/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2875 - acc: 0.9045 - val_loss: 0.2899 - val_acc: 0.9023\n",
      "Epoch 35/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2854 - acc: 0.9049 - val_loss: 0.2886 - val_acc: 0.9028\n",
      "Epoch 36/500\n",
      "91704/91704 [==============================] - 1s 14us/step - loss: 0.2857 - acc: 0.9049 - val_loss: 0.2886 - val_acc: 0.9025\n",
      "Epoch 37/500\n",
      "91704/91704 [==============================] - 2s 23us/step - loss: 0.2857 - acc: 0.9048 - val_loss: 0.2889 - val_acc: 0.9026\n",
      "Epoch 38/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2852 - acc: 0.9052 - val_loss: 0.2898 - val_acc: 0.9022\n",
      "Epoch 39/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2867 - acc: 0.9048 - val_loss: 0.2891 - val_acc: 0.9020\n",
      "Epoch 40/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2870 - acc: 0.9047 - val_loss: 0.2916 - val_acc: 0.9018\n",
      "Epoch 41/500\n",
      "91704/91704 [==============================] - 1s 15us/step - loss: 0.2854 - acc: 0.9048 - val_loss: 0.2893 - val_acc: 0.9023\n",
      "Epoch 42/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2879 - acc: 0.9044 - val_loss: 0.2887 - val_acc: 0.9026\n",
      "Epoch 43/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2865 - acc: 0.9045 - val_loss: 0.2890 - val_acc: 0.9021\n",
      "Epoch 44/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2852 - acc: 0.9049 - val_loss: 0.2903 - val_acc: 0.9024\n",
      "Epoch 45/500\n",
      "91704/91704 [==============================] - 2s 19us/step - loss: 0.2882 - acc: 0.9043 - val_loss: 0.2924 - val_acc: 0.9015\n",
      "Epoch 46/500\n",
      "91704/91704 [==============================] - 2s 18us/step - loss: 0.2872 - acc: 0.9045 - val_loss: 0.2905 - val_acc: 0.9012\n",
      "Epoch 47/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2869 - acc: 0.9043 - val_loss: 0.2921 - val_acc: 0.9011\n",
      "Epoch 48/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2872 - acc: 0.9043 - val_loss: 0.2914 - val_acc: 0.9018\n",
      "Epoch 49/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2856 - acc: 0.9044 - val_loss: 0.2918 - val_acc: 0.9017\n",
      "Epoch 50/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2857 - acc: 0.9046 - val_loss: 0.2888 - val_acc: 0.9019\n",
      "Epoch 51/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2853 - acc: 0.9046 - val_loss: 0.2888 - val_acc: 0.9018\n",
      "Epoch 52/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2851 - acc: 0.9046 - val_loss: 0.2891 - val_acc: 0.9016\n",
      "Epoch 53/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2847 - acc: 0.9045 - val_loss: 0.2895 - val_acc: 0.9013\n",
      "Epoch 54/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2842 - acc: 0.9045 - val_loss: 0.2895 - val_acc: 0.9021\n",
      "Epoch 55/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2843 - acc: 0.9049 - val_loss: 0.2905 - val_acc: 0.9019\n",
      "Epoch 56/500\n",
      "91704/91704 [==============================] - 1s 15us/step - loss: 0.2841 - acc: 0.9049 - val_loss: 0.2886 - val_acc: 0.9024\n",
      "Epoch 57/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2845 - acc: 0.9051 - val_loss: 0.2912 - val_acc: 0.9019\n",
      "Epoch 58/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2843 - acc: 0.9049 - val_loss: 0.2905 - val_acc: 0.9023\n",
      "Epoch 59/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2845 - acc: 0.9050 - val_loss: 0.2886 - val_acc: 0.9022\n",
      "Epoch 60/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2844 - acc: 0.9047 - val_loss: 0.2904 - val_acc: 0.9019\n",
      "Epoch 61/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2839 - acc: 0.9048 - val_loss: 0.2913 - val_acc: 0.9020\n",
      "Epoch 62/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2841 - acc: 0.9051 - val_loss: 0.2891 - val_acc: 0.9019\n",
      "Epoch 63/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2833 - acc: 0.9052 - val_loss: 0.2874 - val_acc: 0.9023\n",
      "Epoch 64/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2837 - acc: 0.9050 - val_loss: 0.2899 - val_acc: 0.9017\n",
      "Epoch 65/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2836 - acc: 0.9050 - val_loss: 0.2874 - val_acc: 0.9020\n",
      "Epoch 66/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2831 - acc: 0.9052 - val_loss: 0.2872 - val_acc: 0.9023\n",
      "Epoch 67/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2834 - acc: 0.9052 - val_loss: 0.2884 - val_acc: 0.9022\n",
      "Epoch 68/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2831 - acc: 0.9050 - val_loss: 0.2894 - val_acc: 0.9021\n",
      "Epoch 69/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2830 - acc: 0.9052 - val_loss: 0.2960 - val_acc: 0.9019\n",
      "Epoch 70/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2830 - acc: 0.9053 - val_loss: 0.2903 - val_acc: 0.9023\n",
      "Epoch 71/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2833 - acc: 0.9053 - val_loss: 0.2889 - val_acc: 0.9018\n",
      "Epoch 72/500\n",
      "91704/91704 [==============================] - 1s 14us/step - loss: 0.2829 - acc: 0.9052 - val_loss: 0.2881 - val_acc: 0.9022\n",
      "Epoch 73/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2826 - acc: 0.9049 - val_loss: 0.2873 - val_acc: 0.9021\n",
      "Epoch 74/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2827 - acc: 0.9053 - val_loss: 0.2875 - val_acc: 0.9025\n",
      "Epoch 75/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2835 - acc: 0.9049 - val_loss: 0.2910 - val_acc: 0.9025\n",
      "Epoch 76/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2824 - acc: 0.9051 - val_loss: 0.2865 - val_acc: 0.9023\n",
      "Epoch 77/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2827 - acc: 0.9052 - val_loss: 0.2868 - val_acc: 0.9018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2827 - acc: 0.9048 - val_loss: 0.2863 - val_acc: 0.9021\n",
      "Epoch 79/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2825 - acc: 0.9051 - val_loss: 0.2870 - val_acc: 0.9021\n",
      "Epoch 80/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2830 - acc: 0.9051 - val_loss: 0.2890 - val_acc: 0.9022\n",
      "Epoch 81/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2825 - acc: 0.9052 - val_loss: 0.2887 - val_acc: 0.9020\n",
      "Epoch 82/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2820 - acc: 0.9051 - val_loss: 0.2866 - val_acc: 0.9020\n",
      "Epoch 83/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2825 - acc: 0.9052 - val_loss: 0.2867 - val_acc: 0.9021\n",
      "Epoch 84/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2819 - acc: 0.9052 - val_loss: 0.2874 - val_acc: 0.9028\n",
      "Epoch 85/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2847 - acc: 0.9047 - val_loss: 0.2880 - val_acc: 0.9017\n",
      "Epoch 86/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2832 - acc: 0.9047 - val_loss: 0.2903 - val_acc: 0.9012\n",
      "Epoch 87/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2826 - acc: 0.9050 - val_loss: 0.2895 - val_acc: 0.9016\n",
      "Epoch 88/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2814 - acc: 0.9051 - val_loss: 0.2868 - val_acc: 0.9019\n",
      "Epoch 89/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2814 - acc: 0.9049 - val_loss: 0.2863 - val_acc: 0.9021\n",
      "Epoch 90/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2811 - acc: 0.9049 - val_loss: 0.2888 - val_acc: 0.9008\n",
      "Epoch 91/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2834 - acc: 0.9048 - val_loss: 0.2860 - val_acc: 0.9028\n",
      "Epoch 92/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2816 - acc: 0.9049 - val_loss: 0.2877 - val_acc: 0.9017\n",
      "Epoch 93/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2819 - acc: 0.9052 - val_loss: 0.2943 - val_acc: 0.9006\n",
      "Epoch 94/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2817 - acc: 0.9049 - val_loss: 0.2869 - val_acc: 0.9021\n",
      "Epoch 95/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2810 - acc: 0.9052 - val_loss: 0.2868 - val_acc: 0.9018\n",
      "Epoch 96/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2808 - acc: 0.9049 - val_loss: 0.2882 - val_acc: 0.9010\n",
      "Epoch 97/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2814 - acc: 0.9050 - val_loss: 0.2844 - val_acc: 0.9017\n",
      "Epoch 98/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2805 - acc: 0.9046 - val_loss: 0.2850 - val_acc: 0.9009\n",
      "Epoch 99/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2806 - acc: 0.9047 - val_loss: 0.2841 - val_acc: 0.9028\n",
      "Epoch 100/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2800 - acc: 0.9049 - val_loss: 0.2885 - val_acc: 0.9009\n",
      "Epoch 101/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2809 - acc: 0.9043 - val_loss: 0.2883 - val_acc: 0.9012\n",
      "Epoch 102/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2803 - acc: 0.9044 - val_loss: 0.2840 - val_acc: 0.9019\n",
      "Epoch 103/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2806 - acc: 0.9046 - val_loss: 0.2848 - val_acc: 0.9029\n",
      "Epoch 104/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2806 - acc: 0.9048 - val_loss: 0.2844 - val_acc: 0.9029\n",
      "Epoch 105/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2808 - acc: 0.9046 - val_loss: 0.2860 - val_acc: 0.9009\n",
      "Epoch 106/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2808 - acc: 0.9046 - val_loss: 0.2836 - val_acc: 0.9029\n",
      "Epoch 107/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2799 - acc: 0.9048 - val_loss: 0.2840 - val_acc: 0.9034\n",
      "Epoch 108/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2804 - acc: 0.9047 - val_loss: 0.2836 - val_acc: 0.9021\n",
      "Epoch 109/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2797 - acc: 0.9049 - val_loss: 0.2845 - val_acc: 0.9023\n",
      "Epoch 110/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2804 - acc: 0.9049 - val_loss: 0.2864 - val_acc: 0.9023\n",
      "Epoch 111/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2798 - acc: 0.9049 - val_loss: 0.2848 - val_acc: 0.9029\n",
      "Epoch 112/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2799 - acc: 0.9046 - val_loss: 0.2841 - val_acc: 0.9016\n",
      "Epoch 113/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9051 - val_loss: 0.2839 - val_acc: 0.9028\n",
      "Epoch 114/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9049 - val_loss: 0.2864 - val_acc: 0.9024\n",
      "Epoch 115/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2798 - acc: 0.9049 - val_loss: 0.2823 - val_acc: 0.9032\n",
      "Epoch 116/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2799 - acc: 0.9046 - val_loss: 0.2855 - val_acc: 0.9019\n",
      "Epoch 117/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2800 - acc: 0.9043 - val_loss: 0.2834 - val_acc: 0.9016\n",
      "Epoch 118/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2802 - acc: 0.9043 - val_loss: 0.2824 - val_acc: 0.9033\n",
      "Epoch 119/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2791 - acc: 0.9048 - val_loss: 0.2885 - val_acc: 0.9004\n",
      "Epoch 120/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2798 - acc: 0.9048 - val_loss: 0.2866 - val_acc: 0.9032\n",
      "Epoch 121/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2798 - acc: 0.9046 - val_loss: 0.2856 - val_acc: 0.9009\n",
      "Epoch 122/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2789 - acc: 0.9052 - val_loss: 0.2896 - val_acc: 0.9003\n",
      "Epoch 123/500\n",
      "91704/91704 [==============================] - 2s 18us/step - loss: 0.2808 - acc: 0.9043 - val_loss: 0.2847 - val_acc: 0.9033\n",
      "Epoch 124/500\n",
      "91704/91704 [==============================] - 1s 16us/step - loss: 0.2801 - acc: 0.9043 - val_loss: 0.2848 - val_acc: 0.9032\n",
      "Epoch 125/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2794 - acc: 0.9046 - val_loss: 0.2857 - val_acc: 0.9014\n",
      "Epoch 126/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2794 - acc: 0.9048 - val_loss: 0.2872 - val_acc: 0.9023\n",
      "Epoch 127/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2795 - acc: 0.9050 - val_loss: 0.2843 - val_acc: 0.9025\n",
      "Epoch 128/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2788 - acc: 0.9051 - val_loss: 0.2849 - val_acc: 0.9008\n",
      "Epoch 129/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2789 - acc: 0.9049 - val_loss: 0.2831 - val_acc: 0.9016\n",
      "Epoch 130/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2786 - acc: 0.9053 - val_loss: 0.2845 - val_acc: 0.9019\n",
      "Epoch 131/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2794 - acc: 0.9054 - val_loss: 0.2832 - val_acc: 0.9020\n",
      "Epoch 132/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2793 - acc: 0.9049 - val_loss: 0.2848 - val_acc: 0.9034\n",
      "Epoch 133/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2800 - acc: 0.9050 - val_loss: 0.2871 - val_acc: 0.9010\n",
      "Epoch 134/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2804 - acc: 0.9046 - val_loss: 0.2850 - val_acc: 0.9030\n",
      "Epoch 135/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2799 - acc: 0.9050 - val_loss: 0.2864 - val_acc: 0.9015\n",
      "Epoch 136/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2789 - acc: 0.9050 - val_loss: 0.2864 - val_acc: 0.9032\n",
      "Epoch 137/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2796 - acc: 0.9048 - val_loss: 0.2845 - val_acc: 0.9032\n",
      "Epoch 138/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2789 - acc: 0.9047 - val_loss: 0.2831 - val_acc: 0.9033\n",
      "Epoch 139/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2795 - acc: 0.9050 - val_loss: 0.2860 - val_acc: 0.9027\n",
      "Epoch 140/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2788 - acc: 0.9052 - val_loss: 0.2837 - val_acc: 0.9021\n",
      "Epoch 141/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2803 - acc: 0.9046 - val_loss: 0.2827 - val_acc: 0.9033\n",
      "Epoch 142/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2794 - acc: 0.9050 - val_loss: 0.2853 - val_acc: 0.9029\n",
      "Epoch 143/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2791 - acc: 0.9050 - val_loss: 0.2827 - val_acc: 0.9024\n",
      "Epoch 144/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2795 - acc: 0.9047 - val_loss: 0.2855 - val_acc: 0.9029\n",
      "Epoch 145/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2799 - acc: 0.9047 - val_loss: 0.2865 - val_acc: 0.9032\n",
      "Epoch 146/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2798 - acc: 0.9048 - val_loss: 0.2839 - val_acc: 0.9030\n",
      "Epoch 147/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2797 - acc: 0.9049 - val_loss: 0.2852 - val_acc: 0.9010\n",
      "Epoch 148/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2785 - acc: 0.9052 - val_loss: 0.2834 - val_acc: 0.9031\n",
      "Epoch 149/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9051 - val_loss: 0.2856 - val_acc: 0.9022\n",
      "Epoch 150/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9050 - val_loss: 0.2840 - val_acc: 0.9034\n",
      "Epoch 151/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2791 - acc: 0.9048 - val_loss: 0.2836 - val_acc: 0.9016\n",
      "Epoch 152/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2794 - acc: 0.9049 - val_loss: 0.2867 - val_acc: 0.9022\n",
      "Epoch 153/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2808 - acc: 0.9045 - val_loss: 0.2842 - val_acc: 0.9028\n",
      "Epoch 154/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2797 - acc: 0.9051 - val_loss: 0.2843 - val_acc: 0.9028\n",
      "Epoch 155/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2795 - acc: 0.9045 - val_loss: 0.2849 - val_acc: 0.9010\n",
      "Epoch 156/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2789 - acc: 0.9052 - val_loss: 0.2829 - val_acc: 0.9020\n",
      "Epoch 157/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2805 - acc: 0.9045 - val_loss: 0.2911 - val_acc: 0.9007\n",
      "Epoch 158/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2806 - acc: 0.9047 - val_loss: 0.2839 - val_acc: 0.9021\n",
      "Epoch 159/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2794 - acc: 0.9050 - val_loss: 0.2835 - val_acc: 0.9027\n",
      "Epoch 160/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9047 - val_loss: 0.2842 - val_acc: 0.9019\n",
      "Epoch 161/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2787 - acc: 0.9048 - val_loss: 0.2871 - val_acc: 0.9005\n",
      "Epoch 162/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2790 - acc: 0.9048 - val_loss: 0.2825 - val_acc: 0.9032\n",
      "Epoch 163/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2810 - acc: 0.9042 - val_loss: 0.2843 - val_acc: 0.9014\n",
      "Epoch 164/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2795 - acc: 0.9044 - val_loss: 0.2853 - val_acc: 0.9015\n",
      "Epoch 165/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9049 - val_loss: 0.2833 - val_acc: 0.9026\n",
      "Epoch 166/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2790 - acc: 0.9050 - val_loss: 0.2839 - val_acc: 0.9020\n",
      "Epoch 167/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2788 - acc: 0.9051 - val_loss: 0.2860 - val_acc: 0.9021\n",
      "Epoch 168/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2798 - acc: 0.9047 - val_loss: 0.2841 - val_acc: 0.9033\n",
      "Epoch 169/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2785 - acc: 0.9051 - val_loss: 0.2836 - val_acc: 0.9029\n",
      "Epoch 170/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2784 - acc: 0.9054 - val_loss: 0.2839 - val_acc: 0.9009\n",
      "Epoch 171/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2779 - acc: 0.9052 - val_loss: 0.2835 - val_acc: 0.9027\n",
      "Epoch 172/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2790 - acc: 0.9048 - val_loss: 0.2832 - val_acc: 0.9035\n",
      "Epoch 173/500\n",
      "91704/91704 [==============================] - 2s 16us/step - loss: 0.2780 - acc: 0.9052 - val_loss: 0.2861 - val_acc: 0.9021\n",
      "Epoch 174/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2797 - acc: 0.9050 - val_loss: 0.2845 - val_acc: 0.9022\n",
      "Epoch 175/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2810 - acc: 0.9044 - val_loss: 0.2848 - val_acc: 0.9033\n",
      "Epoch 176/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2796 - acc: 0.9045 - val_loss: 0.2836 - val_acc: 0.9021\n",
      "Epoch 177/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2781 - acc: 0.9051 - val_loss: 0.2845 - val_acc: 0.9017\n",
      "Epoch 178/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2794 - acc: 0.9050 - val_loss: 0.2866 - val_acc: 0.9019\n",
      "Epoch 179/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9047 - val_loss: 0.2837 - val_acc: 0.9034\n",
      "Epoch 180/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2794 - acc: 0.9049 - val_loss: 0.2874 - val_acc: 0.9023\n",
      "Epoch 181/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9046 - val_loss: 0.2832 - val_acc: 0.9023\n",
      "Epoch 182/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2793 - acc: 0.9050 - val_loss: 0.2830 - val_acc: 0.9024\n",
      "Epoch 183/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2784 - acc: 0.9052 - val_loss: 0.2827 - val_acc: 0.9028\n",
      "Epoch 184/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2794 - acc: 0.9048 - val_loss: 0.2869 - val_acc: 0.9013\n",
      "Epoch 185/500\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 0.2789 - acc: 0.904 - 1s 12us/step - loss: 0.2789 - acc: 0.9050 - val_loss: 0.2838 - val_acc: 0.9021\n",
      "Epoch 186/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2795 - acc: 0.9050 - val_loss: 0.2848 - val_acc: 0.9018\n",
      "Epoch 187/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2798 - acc: 0.9045 - val_loss: 0.2847 - val_acc: 0.9012\n",
      "Epoch 188/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2800 - acc: 0.9048 - val_loss: 0.2845 - val_acc: 0.9028\n",
      "Epoch 189/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2781 - acc: 0.9049 - val_loss: 0.2828 - val_acc: 0.9032\n",
      "Epoch 190/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2783 - acc: 0.9052 - val_loss: 0.2840 - val_acc: 0.9036\n",
      "Epoch 191/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2790 - acc: 0.9049 - val_loss: 0.2823 - val_acc: 0.9033\n",
      "Epoch 192/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2788 - acc: 0.9049 - val_loss: 0.2826 - val_acc: 0.9015\n",
      "Epoch 193/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2793 - acc: 0.9046 - val_loss: 0.2844 - val_acc: 0.9010\n",
      "Epoch 194/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2790 - acc: 0.9048 - val_loss: 0.2839 - val_acc: 0.9029\n",
      "Epoch 195/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2795 - acc: 0.9047 - val_loss: 0.2829 - val_acc: 0.9030\n",
      "Epoch 196/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2818 - acc: 0.9040 - val_loss: 0.2837 - val_acc: 0.9025\n",
      "Epoch 197/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2782 - acc: 0.9053 - val_loss: 0.2824 - val_acc: 0.9029\n",
      "Epoch 198/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2798 - acc: 0.9048 - val_loss: 0.2846 - val_acc: 0.9030\n",
      "Epoch 199/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2796 - acc: 0.9049 - val_loss: 0.2838 - val_acc: 0.9020\n",
      "Epoch 200/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2791 - acc: 0.9049 - val_loss: 0.2871 - val_acc: 0.9019\n",
      "Epoch 201/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2791 - acc: 0.9049 - val_loss: 0.2837 - val_acc: 0.9036\n",
      "Epoch 202/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2798 - acc: 0.9049 - val_loss: 0.2880 - val_acc: 0.9021\n",
      "Epoch 203/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2791 - acc: 0.9051 - val_loss: 0.2840 - val_acc: 0.9018\n",
      "Epoch 204/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2801 - acc: 0.9045 - val_loss: 0.2836 - val_acc: 0.9024\n",
      "Epoch 205/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2795 - acc: 0.9049 - val_loss: 0.2829 - val_acc: 0.9024\n",
      "Epoch 206/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2795 - acc: 0.9047 - val_loss: 0.2846 - val_acc: 0.9016\n",
      "Epoch 207/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2792 - acc: 0.9046 - val_loss: 0.2855 - val_acc: 0.9011\n",
      "Epoch 208/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2803 - acc: 0.9042 - val_loss: 0.2837 - val_acc: 0.9023\n",
      "Epoch 209/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2793 - acc: 0.9048 - val_loss: 0.2853 - val_acc: 0.9019\n",
      "Epoch 210/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9047 - val_loss: 0.2846 - val_acc: 0.9015\n",
      "Epoch 211/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2786 - acc: 0.9048 - val_loss: 0.2852 - val_acc: 0.9020\n",
      "Epoch 212/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9048 - val_loss: 0.2849 - val_acc: 0.9003\n",
      "Epoch 213/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2788 - acc: 0.9048 - val_loss: 0.2836 - val_acc: 0.9023\n",
      "Epoch 214/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2795 - acc: 0.9050 - val_loss: 0.2855 - val_acc: 0.9013\n",
      "Epoch 215/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9047 - val_loss: 0.2835 - val_acc: 0.9033\n",
      "Epoch 216/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2780 - acc: 0.9051 - val_loss: 0.2831 - val_acc: 0.9025\n",
      "Epoch 217/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2789 - acc: 0.9049 - val_loss: 0.2842 - val_acc: 0.9031\n",
      "Epoch 218/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2787 - acc: 0.9052 - val_loss: 0.2827 - val_acc: 0.9024\n",
      "Epoch 219/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2797 - acc: 0.9046 - val_loss: 0.2843 - val_acc: 0.9023\n",
      "Epoch 220/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2786 - acc: 0.9047 - val_loss: 0.2832 - val_acc: 0.9022\n",
      "Epoch 221/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2783 - acc: 0.9047 - val_loss: 0.2837 - val_acc: 0.9029\n",
      "Epoch 222/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2788 - acc: 0.9047 - val_loss: 0.2872 - val_acc: 0.9019\n",
      "Epoch 223/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2786 - acc: 0.9050 - val_loss: 0.2830 - val_acc: 0.9024\n",
      "Epoch 224/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2781 - acc: 0.9051 - val_loss: 0.2835 - val_acc: 0.9017\n",
      "Epoch 225/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2780 - acc: 0.9050 - val_loss: 0.2830 - val_acc: 0.9036\n",
      "Epoch 226/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2786 - acc: 0.9047 - val_loss: 0.2828 - val_acc: 0.9021\n",
      "Epoch 227/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2781 - acc: 0.9051 - val_loss: 0.2856 - val_acc: 0.9017\n",
      "Epoch 228/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2789 - acc: 0.9048 - val_loss: 0.2924 - val_acc: 0.9011\n",
      "Epoch 229/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2856 - acc: 0.9042 - val_loss: 0.2884 - val_acc: 0.9016\n",
      "Epoch 230/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2840 - acc: 0.9046 - val_loss: 0.2957 - val_acc: 0.9018\n",
      "Epoch 231/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2843 - acc: 0.9044 - val_loss: 0.2890 - val_acc: 0.9014\n",
      "Epoch 232/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2836 - acc: 0.9045 - val_loss: 0.2885 - val_acc: 0.9020\n",
      "Epoch 233/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2827 - acc: 0.9048 - val_loss: 0.2886 - val_acc: 0.9021\n",
      "Epoch 234/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2827 - acc: 0.9046 - val_loss: 0.2864 - val_acc: 0.9032\n",
      "Epoch 235/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2813 - acc: 0.9046 - val_loss: 0.2842 - val_acc: 0.9026\n",
      "Epoch 236/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2791 - acc: 0.9053 - val_loss: 0.2858 - val_acc: 0.9033\n",
      "Epoch 237/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2795 - acc: 0.9048 - val_loss: 0.2835 - val_acc: 0.9033\n",
      "Epoch 238/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2791 - acc: 0.9049 - val_loss: 0.2836 - val_acc: 0.9023\n",
      "Epoch 239/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2789 - acc: 0.9052 - val_loss: 0.2848 - val_acc: 0.9022\n",
      "Epoch 240/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2786 - acc: 0.9052 - val_loss: 0.2881 - val_acc: 0.9018\n",
      "Epoch 241/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2787 - acc: 0.9049 - val_loss: 0.2855 - val_acc: 0.9025\n",
      "Epoch 242/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9048 - val_loss: 0.2836 - val_acc: 0.9033\n",
      "Epoch 243/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2788 - acc: 0.9051 - val_loss: 0.2826 - val_acc: 0.9024\n",
      "Epoch 244/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2782 - acc: 0.9050 - val_loss: 0.2833 - val_acc: 0.9027\n",
      "Epoch 245/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2806 - acc: 0.9050 - val_loss: 0.2856 - val_acc: 0.9025\n",
      "Epoch 246/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2817 - acc: 0.9047 - val_loss: 0.2869 - val_acc: 0.9021\n",
      "Epoch 247/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2804 - acc: 0.9049 - val_loss: 0.2841 - val_acc: 0.9033\n",
      "Epoch 248/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2798 - acc: 0.9050 - val_loss: 0.2826 - val_acc: 0.9025\n",
      "Epoch 249/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2793 - acc: 0.9048 - val_loss: 0.2826 - val_acc: 0.9022\n",
      "Epoch 250/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2783 - acc: 0.9052 - val_loss: 0.2817 - val_acc: 0.9035\n",
      "Epoch 251/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2779 - acc: 0.9052 - val_loss: 0.2837 - val_acc: 0.9031\n",
      "Epoch 252/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9048 - val_loss: 0.2850 - val_acc: 0.9019\n",
      "Epoch 253/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2781 - acc: 0.9050 - val_loss: 0.2834 - val_acc: 0.9016\n",
      "Epoch 254/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2786 - acc: 0.9052 - val_loss: 0.2838 - val_acc: 0.9013\n",
      "Epoch 255/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2796 - acc: 0.9051 - val_loss: 0.2846 - val_acc: 0.9036\n",
      "Epoch 256/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2780 - acc: 0.9051 - val_loss: 0.2832 - val_acc: 0.9024\n",
      "Epoch 257/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2782 - acc: 0.9055 - val_loss: 0.2838 - val_acc: 0.9019\n",
      "Epoch 258/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2779 - acc: 0.9053 - val_loss: 0.2834 - val_acc: 0.9026\n",
      "Epoch 259/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2777 - acc: 0.9052 - val_loss: 0.2828 - val_acc: 0.9025\n",
      "Epoch 260/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9049 - val_loss: 0.2844 - val_acc: 0.9019\n",
      "Epoch 261/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2791 - acc: 0.9051 - val_loss: 0.2838 - val_acc: 0.9032\n",
      "Epoch 262/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2785 - acc: 0.9049 - val_loss: 0.2831 - val_acc: 0.9029\n",
      "Epoch 263/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2780 - acc: 0.9057 - val_loss: 0.2833 - val_acc: 0.9023\n",
      "Epoch 264/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2780 - acc: 0.9051 - val_loss: 0.2845 - val_acc: 0.9027\n",
      "Epoch 265/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2780 - acc: 0.9047 - val_loss: 0.2828 - val_acc: 0.9030\n",
      "Epoch 266/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2780 - acc: 0.9048 - val_loss: 0.2844 - val_acc: 0.9021\n",
      "Epoch 267/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2780 - acc: 0.9052 - val_loss: 0.2817 - val_acc: 0.9034\n",
      "Epoch 268/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2776 - acc: 0.9053 - val_loss: 0.2841 - val_acc: 0.9016\n",
      "Epoch 269/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2790 - acc: 0.9049 - val_loss: 0.2865 - val_acc: 0.9014\n",
      "Epoch 270/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2793 - acc: 0.9048 - val_loss: 0.2827 - val_acc: 0.9025\n",
      "Epoch 271/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2785 - acc: 0.9049 - val_loss: 0.2843 - val_acc: 0.9012\n",
      "Epoch 272/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2807 - acc: 0.9034 - val_loss: 0.2849 - val_acc: 0.9017\n",
      "Epoch 273/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2790 - acc: 0.9046 - val_loss: 0.2830 - val_acc: 0.9036\n",
      "Epoch 274/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2773 - acc: 0.9054 - val_loss: 0.2825 - val_acc: 0.9037\n",
      "Epoch 275/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2776 - acc: 0.9048 - val_loss: 0.2834 - val_acc: 0.9022\n",
      "Epoch 276/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2793 - acc: 0.9051 - val_loss: 0.2894 - val_acc: 0.9025\n",
      "Epoch 277/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2811 - acc: 0.9050 - val_loss: 0.2860 - val_acc: 0.9032\n",
      "Epoch 278/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2777 - acc: 0.9052 - val_loss: 0.2816 - val_acc: 0.9021\n",
      "Epoch 279/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2768 - acc: 0.9052 - val_loss: 0.2823 - val_acc: 0.9028\n",
      "Epoch 280/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2772 - acc: 0.9051 - val_loss: 0.2835 - val_acc: 0.9019\n",
      "Epoch 281/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2779 - acc: 0.9052 - val_loss: 0.2833 - val_acc: 0.9031\n",
      "Epoch 282/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2770 - acc: 0.9053 - val_loss: 0.2831 - val_acc: 0.9032\n",
      "Epoch 283/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2775 - acc: 0.9052 - val_loss: 0.2818 - val_acc: 0.9032\n",
      "Epoch 284/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2785 - acc: 0.9048 - val_loss: 0.2842 - val_acc: 0.9028\n",
      "Epoch 285/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2789 - acc: 0.9045 - val_loss: 0.2846 - val_acc: 0.9013\n",
      "Epoch 286/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2792 - acc: 0.9046 - val_loss: 0.2825 - val_acc: 0.9033\n",
      "Epoch 287/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2787 - acc: 0.9048 - val_loss: 0.2835 - val_acc: 0.9012\n",
      "Epoch 288/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2790 - acc: 0.9044 - val_loss: 0.2833 - val_acc: 0.9014\n",
      "Epoch 289/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2788 - acc: 0.9046 - val_loss: 0.2861 - val_acc: 0.9018\n",
      "Epoch 290/500\n",
      "91704/91704 [==============================] - 1s 14us/step - loss: 0.2790 - acc: 0.9047 - val_loss: 0.2849 - val_acc: 0.9015\n",
      "Epoch 291/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2785 - acc: 0.9052 - val_loss: 0.2852 - val_acc: 0.9021\n",
      "Epoch 292/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2797 - acc: 0.9044 - val_loss: 0.2863 - val_acc: 0.9020\n",
      "Epoch 293/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2787 - acc: 0.9051 - val_loss: 0.2852 - val_acc: 0.9013\n",
      "Epoch 294/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2789 - acc: 0.9042 - val_loss: 0.2832 - val_acc: 0.9014\n",
      "Epoch 295/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2785 - acc: 0.9043 - val_loss: 0.2837 - val_acc: 0.9027\n",
      "Epoch 296/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2790 - acc: 0.9046 - val_loss: 0.2820 - val_acc: 0.9033\n",
      "Epoch 297/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2795 - acc: 0.9043 - val_loss: 0.2835 - val_acc: 0.9030\n",
      "Epoch 298/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2789 - acc: 0.9048 - val_loss: 0.2844 - val_acc: 0.9012\n",
      "Epoch 299/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2793 - acc: 0.9050 - val_loss: 0.2852 - val_acc: 0.9019\n",
      "Epoch 300/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2797 - acc: 0.9045 - val_loss: 0.2865 - val_acc: 0.9014\n",
      "Epoch 301/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2784 - acc: 0.9047 - val_loss: 0.2828 - val_acc: 0.9015\n",
      "Epoch 302/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2791 - acc: 0.9047 - val_loss: 0.2849 - val_acc: 0.9012\n",
      "Epoch 303/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2800 - acc: 0.9046 - val_loss: 0.2874 - val_acc: 0.9024\n",
      "Epoch 304/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2798 - acc: 0.9046 - val_loss: 0.2836 - val_acc: 0.9030\n",
      "Epoch 305/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2788 - acc: 0.9043 - val_loss: 0.2837 - val_acc: 0.9031\n",
      "Epoch 306/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9048 - val_loss: 0.2852 - val_acc: 0.9011\n",
      "Epoch 307/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2779 - acc: 0.9048 - val_loss: 0.2919 - val_acc: 0.9011\n",
      "Epoch 308/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2806 - acc: 0.9047 - val_loss: 0.2833 - val_acc: 0.9015\n",
      "Epoch 309/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2773 - acc: 0.9047 - val_loss: 0.2819 - val_acc: 0.9024\n",
      "Epoch 310/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2771 - acc: 0.9049 - val_loss: 0.2811 - val_acc: 0.9034\n",
      "Epoch 311/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2787 - acc: 0.9045 - val_loss: 0.2820 - val_acc: 0.9014\n",
      "Epoch 312/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2788 - acc: 0.9045 - val_loss: 0.2822 - val_acc: 0.9015\n",
      "Epoch 313/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2783 - acc: 0.9045 - val_loss: 0.2851 - val_acc: 0.9021\n",
      "Epoch 314/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2800 - acc: 0.9044 - val_loss: 0.2846 - val_acc: 0.9021\n",
      "Epoch 315/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2770 - acc: 0.9045 - val_loss: 0.2819 - val_acc: 0.9029\n",
      "Epoch 316/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2773 - acc: 0.9046 - val_loss: 0.2829 - val_acc: 0.9014\n",
      "Epoch 317/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2769 - acc: 0.9047 - val_loss: 0.2823 - val_acc: 0.9018\n",
      "Epoch 318/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2785 - acc: 0.9043 - val_loss: 0.2833 - val_acc: 0.9015\n",
      "Epoch 319/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2781 - acc: 0.9042 - val_loss: 0.2836 - val_acc: 0.9018\n",
      "Epoch 320/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2792 - acc: 0.9042 - val_loss: 0.2850 - val_acc: 0.9016\n",
      "Epoch 321/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2786 - acc: 0.9043 - val_loss: 0.2822 - val_acc: 0.9018\n",
      "Epoch 322/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2771 - acc: 0.9044 - val_loss: 0.2828 - val_acc: 0.9014\n",
      "Epoch 323/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2772 - acc: 0.9044 - val_loss: 0.2834 - val_acc: 0.9025\n",
      "Epoch 324/500\n",
      "91704/91704 [==============================] - 3s 34us/step - loss: 0.2806 - acc: 0.9038 - val_loss: 0.2852 - val_acc: 0.9008\n",
      "Epoch 325/500\n",
      "91704/91704 [==============================] - 2s 19us/step - loss: 0.2797 - acc: 0.9037 - val_loss: 0.2842 - val_acc: 0.9017\n",
      "Epoch 326/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2793 - acc: 0.9038 - val_loss: 0.2827 - val_acc: 0.9031\n",
      "Epoch 327/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2778 - acc: 0.9042 - val_loss: 0.2824 - val_acc: 0.9024\n",
      "Epoch 328/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2789 - acc: 0.9041 - val_loss: 0.2823 - val_acc: 0.9026\n",
      "Epoch 329/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2770 - acc: 0.9042 - val_loss: 0.2863 - val_acc: 0.9014\n",
      "Epoch 330/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2770 - acc: 0.9047 - val_loss: 0.2858 - val_acc: 0.9021\n",
      "Epoch 331/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2781 - acc: 0.9043 - val_loss: 0.2839 - val_acc: 0.9038\n",
      "Epoch 332/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2775 - acc: 0.9046 - val_loss: 0.2856 - val_acc: 0.9021\n",
      "Epoch 333/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2780 - acc: 0.9042 - val_loss: 0.2850 - val_acc: 0.9009\n",
      "Epoch 334/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2772 - acc: 0.9046 - val_loss: 0.2831 - val_acc: 0.9017\n",
      "Epoch 335/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2779 - acc: 0.9041 - val_loss: 0.2847 - val_acc: 0.9015\n",
      "Epoch 336/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2788 - acc: 0.9041 - val_loss: 0.2833 - val_acc: 0.9021\n",
      "Epoch 337/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2784 - acc: 0.9041 - val_loss: 0.2844 - val_acc: 0.9013\n",
      "Epoch 338/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2781 - acc: 0.9042 - val_loss: 0.2846 - val_acc: 0.9016\n",
      "Epoch 339/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2802 - acc: 0.9041 - val_loss: 0.2832 - val_acc: 0.9018\n",
      "Epoch 340/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2774 - acc: 0.9045 - val_loss: 0.2827 - val_acc: 0.9013\n",
      "Epoch 341/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2772 - acc: 0.9041 - val_loss: 0.2819 - val_acc: 0.9017\n",
      "Epoch 342/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2786 - acc: 0.9042 - val_loss: 0.2832 - val_acc: 0.9016\n",
      "Epoch 343/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2771 - acc: 0.9044 - val_loss: 0.2838 - val_acc: 0.9014\n",
      "Epoch 344/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2774 - acc: 0.9044 - val_loss: 0.2843 - val_acc: 0.9029\n",
      "Epoch 345/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2774 - acc: 0.9045 - val_loss: 0.2854 - val_acc: 0.9007\n",
      "Epoch 346/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2783 - acc: 0.9041 - val_loss: 0.2836 - val_acc: 0.9018\n",
      "Epoch 347/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2777 - acc: 0.9044 - val_loss: 0.2825 - val_acc: 0.9027\n",
      "Epoch 348/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2780 - acc: 0.9046 - val_loss: 0.2836 - val_acc: 0.9024\n",
      "Epoch 349/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2791 - acc: 0.9038 - val_loss: 0.2845 - val_acc: 0.9012\n",
      "Epoch 350/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2769 - acc: 0.9042 - val_loss: 0.2852 - val_acc: 0.9024\n",
      "Epoch 351/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2777 - acc: 0.9042 - val_loss: 0.2821 - val_acc: 0.9020\n",
      "Epoch 352/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2775 - acc: 0.9042 - val_loss: 0.2852 - val_acc: 0.9019\n",
      "Epoch 353/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2785 - acc: 0.9040 - val_loss: 0.2874 - val_acc: 0.9017\n",
      "Epoch 354/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2794 - acc: 0.9040 - val_loss: 0.2851 - val_acc: 0.9028\n",
      "Epoch 355/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2794 - acc: 0.9045 - val_loss: 0.2853 - val_acc: 0.9021\n",
      "Epoch 356/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2802 - acc: 0.9039 - val_loss: 0.2835 - val_acc: 0.9027\n",
      "Epoch 357/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2793 - acc: 0.9041 - val_loss: 0.2832 - val_acc: 0.9019\n",
      "Epoch 358/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2800 - acc: 0.9042 - val_loss: 0.2845 - val_acc: 0.9009\n",
      "Epoch 359/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2798 - acc: 0.9037 - val_loss: 0.2830 - val_acc: 0.9030\n",
      "Epoch 360/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2788 - acc: 0.9041 - val_loss: 0.2830 - val_acc: 0.9020\n",
      "Epoch 361/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2789 - acc: 0.9041 - val_loss: 0.2846 - val_acc: 0.9013\n",
      "Epoch 362/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2778 - acc: 0.9039 - val_loss: 0.2827 - val_acc: 0.9028\n",
      "Epoch 363/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2778 - acc: 0.9041 - val_loss: 0.2831 - val_acc: 0.9017\n",
      "Epoch 364/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2780 - acc: 0.9044 - val_loss: 0.2850 - val_acc: 0.9013\n",
      "Epoch 365/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2778 - acc: 0.9042 - val_loss: 0.2804 - val_acc: 0.9022\n",
      "Epoch 366/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2771 - acc: 0.9042 - val_loss: 0.2826 - val_acc: 0.9009\n",
      "Epoch 367/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2792 - acc: 0.9041 - val_loss: 0.2845 - val_acc: 0.9016\n",
      "Epoch 368/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2799 - acc: 0.9039 - val_loss: 0.2816 - val_acc: 0.9030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2781 - acc: 0.9041 - val_loss: 0.2833 - val_acc: 0.9010\n",
      "Epoch 370/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2774 - acc: 0.9040 - val_loss: 0.2809 - val_acc: 0.9027\n",
      "Epoch 371/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2788 - acc: 0.9043 - val_loss: 0.2817 - val_acc: 0.9019\n",
      "Epoch 372/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2772 - acc: 0.9042 - val_loss: 0.2869 - val_acc: 0.9015\n",
      "Epoch 373/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2771 - acc: 0.9048 - val_loss: 0.2818 - val_acc: 0.9031\n",
      "Epoch 374/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2776 - acc: 0.9046 - val_loss: 0.2833 - val_acc: 0.9013\n",
      "Epoch 375/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2773 - acc: 0.9039 - val_loss: 0.2840 - val_acc: 0.9024\n",
      "Epoch 376/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2780 - acc: 0.9041 - val_loss: 0.2827 - val_acc: 0.9027\n",
      "Epoch 377/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2773 - acc: 0.9041 - val_loss: 0.2833 - val_acc: 0.9010\n",
      "Epoch 378/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2775 - acc: 0.9041 - val_loss: 0.2813 - val_acc: 0.9025\n",
      "Epoch 379/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2777 - acc: 0.9043 - val_loss: 0.2817 - val_acc: 0.9030\n",
      "Epoch 380/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2772 - acc: 0.9044 - val_loss: 0.2831 - val_acc: 0.9022\n",
      "Epoch 381/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2771 - acc: 0.9045 - val_loss: 0.2826 - val_acc: 0.9021\n",
      "Epoch 382/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2772 - acc: 0.9036 - val_loss: 0.2809 - val_acc: 0.9020\n",
      "Epoch 383/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2779 - acc: 0.9041 - val_loss: 0.2809 - val_acc: 0.9023\n",
      "Epoch 384/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2763 - acc: 0.9045 - val_loss: 0.2825 - val_acc: 0.9025\n",
      "Epoch 385/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2781 - acc: 0.9046 - val_loss: 0.2803 - val_acc: 0.9032\n",
      "Epoch 386/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2775 - acc: 0.9046 - val_loss: 0.2813 - val_acc: 0.9031\n",
      "Epoch 387/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2777 - acc: 0.9042 - val_loss: 0.2824 - val_acc: 0.9028\n",
      "Epoch 388/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2771 - acc: 0.9046 - val_loss: 0.2860 - val_acc: 0.9019\n",
      "Epoch 389/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2783 - acc: 0.9045 - val_loss: 0.2813 - val_acc: 0.9033\n",
      "Epoch 390/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2767 - acc: 0.9048 - val_loss: 0.2805 - val_acc: 0.9026\n",
      "Epoch 391/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2771 - acc: 0.9043 - val_loss: 0.2811 - val_acc: 0.9028\n",
      "Epoch 392/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2776 - acc: 0.9048 - val_loss: 0.2838 - val_acc: 0.9014\n",
      "Epoch 393/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2776 - acc: 0.9046 - val_loss: 0.2879 - val_acc: 0.9002\n",
      "Epoch 394/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2780 - acc: 0.9043 - val_loss: 0.2876 - val_acc: 0.9010\n",
      "Epoch 395/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2770 - acc: 0.9048 - val_loss: 0.2851 - val_acc: 0.9029\n",
      "Epoch 396/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2769 - acc: 0.9049 - val_loss: 0.2831 - val_acc: 0.9024\n",
      "Epoch 397/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2776 - acc: 0.9045 - val_loss: 0.2843 - val_acc: 0.9015\n",
      "Epoch 398/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2775 - acc: 0.9036 - val_loss: 0.2813 - val_acc: 0.9019\n",
      "Epoch 399/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2772 - acc: 0.9046 - val_loss: 0.2817 - val_acc: 0.9020\n",
      "Epoch 400/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2767 - acc: 0.9046 - val_loss: 0.2816 - val_acc: 0.9028\n",
      "Epoch 401/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2779 - acc: 0.9045 - val_loss: 0.2818 - val_acc: 0.9023\n",
      "Epoch 402/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2767 - acc: 0.9044 - val_loss: 0.2797 - val_acc: 0.9037\n",
      "Epoch 403/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2770 - acc: 0.9046 - val_loss: 0.2810 - val_acc: 0.9024\n",
      "Epoch 404/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2766 - acc: 0.9047 - val_loss: 0.2811 - val_acc: 0.9028\n",
      "Epoch 405/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2766 - acc: 0.9045 - val_loss: 0.2807 - val_acc: 0.9025\n",
      "Epoch 406/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2761 - acc: 0.9050 - val_loss: 0.2819 - val_acc: 0.9023\n",
      "Epoch 407/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2763 - acc: 0.9049 - val_loss: 0.2804 - val_acc: 0.9034\n",
      "Epoch 408/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2768 - acc: 0.9049 - val_loss: 0.2911 - val_acc: 0.9008\n",
      "Epoch 409/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2780 - acc: 0.9047 - val_loss: 0.2884 - val_acc: 0.9031\n",
      "Epoch 410/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2768 - acc: 0.9045 - val_loss: 0.2812 - val_acc: 0.9029\n",
      "Epoch 411/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2783 - acc: 0.9045 - val_loss: 0.2835 - val_acc: 0.9010\n",
      "Epoch 412/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2774 - acc: 0.9046 - val_loss: 0.2814 - val_acc: 0.9034\n",
      "Epoch 413/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2768 - acc: 0.9047 - val_loss: 0.2838 - val_acc: 0.9011\n",
      "Epoch 414/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2776 - acc: 0.9045 - val_loss: 0.2827 - val_acc: 0.9020\n",
      "Epoch 415/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2763 - acc: 0.9050 - val_loss: 0.2813 - val_acc: 0.9018\n",
      "Epoch 416/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2773 - acc: 0.9046 - val_loss: 0.2807 - val_acc: 0.9022\n",
      "Epoch 417/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2771 - acc: 0.9045 - val_loss: 0.2820 - val_acc: 0.9017\n",
      "Epoch 418/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2778 - acc: 0.9039 - val_loss: 0.2821 - val_acc: 0.9016\n",
      "Epoch 419/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2796 - acc: 0.9041 - val_loss: 0.2833 - val_acc: 0.9014\n",
      "Epoch 420/500\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 0.2782 - acc: 0.904 - 1s 9us/step - loss: 0.2781 - acc: 0.9042 - val_loss: 0.2833 - val_acc: 0.9021\n",
      "Epoch 421/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2777 - acc: 0.9042 - val_loss: 0.2838 - val_acc: 0.9013\n",
      "Epoch 422/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2780 - acc: 0.9045 - val_loss: 0.2825 - val_acc: 0.9013\n",
      "Epoch 423/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2771 - acc: 0.9048 - val_loss: 0.2824 - val_acc: 0.9019\n",
      "Epoch 424/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2768 - acc: 0.9049 - val_loss: 0.2804 - val_acc: 0.9031\n",
      "Epoch 425/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2768 - acc: 0.9047 - val_loss: 0.2842 - val_acc: 0.9015\n",
      "Epoch 426/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2777 - acc: 0.9044 - val_loss: 0.2814 - val_acc: 0.9017\n",
      "Epoch 427/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2764 - acc: 0.9050 - val_loss: 0.2810 - val_acc: 0.9022\n",
      "Epoch 428/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2762 - acc: 0.9047 - val_loss: 0.2822 - val_acc: 0.9031\n",
      "Epoch 429/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2769 - acc: 0.9042 - val_loss: 0.2851 - val_acc: 0.9012\n",
      "Epoch 430/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2774 - acc: 0.9045 - val_loss: 0.2820 - val_acc: 0.9027\n",
      "Epoch 431/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2785 - acc: 0.9044 - val_loss: 0.2810 - val_acc: 0.9032\n",
      "Epoch 432/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2771 - acc: 0.9044 - val_loss: 0.2830 - val_acc: 0.9019\n",
      "Epoch 433/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2769 - acc: 0.9047 - val_loss: 0.2919 - val_acc: 0.9014\n",
      "Epoch 434/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2777 - acc: 0.9042 - val_loss: 0.2825 - val_acc: 0.9019\n",
      "Epoch 435/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2772 - acc: 0.9046 - val_loss: 0.2865 - val_acc: 0.9013\n",
      "Epoch 436/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2769 - acc: 0.9046 - val_loss: 0.2813 - val_acc: 0.9032\n",
      "Epoch 437/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2769 - acc: 0.9046 - val_loss: 0.2812 - val_acc: 0.9030\n",
      "Epoch 438/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2765 - acc: 0.9048 - val_loss: 0.2824 - val_acc: 0.9024\n",
      "Epoch 439/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2766 - acc: 0.9050 - val_loss: 0.2813 - val_acc: 0.9033\n",
      "Epoch 440/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2769 - acc: 0.9047 - val_loss: 0.2841 - val_acc: 0.9022\n",
      "Epoch 441/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2765 - acc: 0.9049 - val_loss: 0.2833 - val_acc: 0.9016\n",
      "Epoch 442/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2765 - acc: 0.9047 - val_loss: 0.2832 - val_acc: 0.9016\n",
      "Epoch 443/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2769 - acc: 0.9045 - val_loss: 0.2829 - val_acc: 0.9015\n",
      "Epoch 444/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2778 - acc: 0.9045 - val_loss: 0.2818 - val_acc: 0.9031\n",
      "Epoch 445/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2760 - acc: 0.9051 - val_loss: 0.2837 - val_acc: 0.9025\n",
      "Epoch 446/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2784 - acc: 0.9046 - val_loss: 0.2833 - val_acc: 0.9029\n",
      "Epoch 447/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2782 - acc: 0.9041 - val_loss: 0.2859 - val_acc: 0.9018\n",
      "Epoch 448/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2770 - acc: 0.9045 - val_loss: 0.2828 - val_acc: 0.9014\n",
      "Epoch 449/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2769 - acc: 0.9045 - val_loss: 0.2814 - val_acc: 0.9027\n",
      "Epoch 450/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2768 - acc: 0.9047 - val_loss: 0.2802 - val_acc: 0.9034\n",
      "Epoch 451/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2766 - acc: 0.9048 - val_loss: 0.2822 - val_acc: 0.9021\n",
      "Epoch 452/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2778 - acc: 0.9043 - val_loss: 0.2818 - val_acc: 0.9033\n",
      "Epoch 453/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2765 - acc: 0.9047 - val_loss: 0.2817 - val_acc: 0.9031\n",
      "Epoch 454/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2764 - acc: 0.9047 - val_loss: 0.2805 - val_acc: 0.9033\n",
      "Epoch 455/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2781 - acc: 0.9046 - val_loss: 0.2829 - val_acc: 0.9019\n",
      "Epoch 456/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2783 - acc: 0.9043 - val_loss: 0.2833 - val_acc: 0.9029\n",
      "Epoch 457/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2767 - acc: 0.9047 - val_loss: 0.2808 - val_acc: 0.9025\n",
      "Epoch 458/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2762 - acc: 0.9050 - val_loss: 0.2802 - val_acc: 0.9034\n",
      "Epoch 459/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2767 - acc: 0.9048 - val_loss: 0.2836 - val_acc: 0.9023\n",
      "Epoch 460/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2776 - acc: 0.9044 - val_loss: 0.2815 - val_acc: 0.9023\n",
      "Epoch 461/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2764 - acc: 0.9046 - val_loss: 0.2836 - val_acc: 0.9010\n",
      "Epoch 462/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2774 - acc: 0.9045 - val_loss: 0.2824 - val_acc: 0.9021\n",
      "Epoch 463/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2770 - acc: 0.9041 - val_loss: 0.2843 - val_acc: 0.9009\n",
      "Epoch 464/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2771 - acc: 0.9041 - val_loss: 0.2845 - val_acc: 0.9018\n",
      "Epoch 465/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2769 - acc: 0.9040 - val_loss: 0.2845 - val_acc: 0.9015\n",
      "Epoch 466/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2770 - acc: 0.9043 - val_loss: 0.2832 - val_acc: 0.9030\n",
      "Epoch 467/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2779 - acc: 0.9038 - val_loss: 0.2819 - val_acc: 0.9011\n",
      "Epoch 468/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2765 - acc: 0.9042 - val_loss: 0.2829 - val_acc: 0.9036\n",
      "Epoch 469/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2769 - acc: 0.9043 - val_loss: 0.2811 - val_acc: 0.9018\n",
      "Epoch 470/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2761 - acc: 0.9046 - val_loss: 0.2812 - val_acc: 0.9035\n",
      "Epoch 471/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2767 - acc: 0.9046 - val_loss: 0.2821 - val_acc: 0.9030\n",
      "Epoch 472/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2763 - acc: 0.9048 - val_loss: 0.2821 - val_acc: 0.9013\n",
      "Epoch 473/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2762 - acc: 0.9046 - val_loss: 0.2834 - val_acc: 0.9019\n",
      "Epoch 474/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2772 - acc: 0.9048 - val_loss: 0.2805 - val_acc: 0.9020\n",
      "Epoch 475/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2766 - acc: 0.9045 - val_loss: 0.2802 - val_acc: 0.9035\n",
      "Epoch 476/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2765 - acc: 0.9049 - val_loss: 0.2820 - val_acc: 0.9018\n",
      "Epoch 477/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2762 - acc: 0.9049 - val_loss: 0.2803 - val_acc: 0.9032\n",
      "Epoch 478/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2773 - acc: 0.9043 - val_loss: 0.2815 - val_acc: 0.9016\n",
      "Epoch 479/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2771 - acc: 0.9042 - val_loss: 0.2832 - val_acc: 0.9019\n",
      "Epoch 480/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2770 - acc: 0.9042 - val_loss: 0.2831 - val_acc: 0.9029\n",
      "Epoch 481/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2766 - acc: 0.9042 - val_loss: 0.2809 - val_acc: 0.9022\n",
      "Epoch 482/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2773 - acc: 0.9045 - val_loss: 0.2822 - val_acc: 0.9012\n",
      "Epoch 483/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2768 - acc: 0.9043 - val_loss: 0.2837 - val_acc: 0.9012\n",
      "Epoch 484/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2771 - acc: 0.9045 - val_loss: 0.2867 - val_acc: 0.9016\n",
      "Epoch 485/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2787 - acc: 0.9040 - val_loss: 0.2815 - val_acc: 0.9034\n",
      "Epoch 486/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2771 - acc: 0.9046 - val_loss: 0.2809 - val_acc: 0.9035\n",
      "Epoch 487/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2781 - acc: 0.9043 - val_loss: 0.2846 - val_acc: 0.9013\n",
      "Epoch 488/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2770 - acc: 0.9043 - val_loss: 0.2818 - val_acc: 0.9016\n",
      "Epoch 489/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2770 - acc: 0.9046 - val_loss: 0.2840 - val_acc: 0.9013\n",
      "Epoch 490/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2772 - acc: 0.9045 - val_loss: 0.2802 - val_acc: 0.9035\n",
      "Epoch 491/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2767 - acc: 0.9046 - val_loss: 0.2805 - val_acc: 0.9033\n",
      "Epoch 492/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2771 - acc: 0.9043 - val_loss: 0.2820 - val_acc: 0.9018\n",
      "Epoch 493/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2764 - acc: 0.9043 - val_loss: 0.2835 - val_acc: 0.9018\n",
      "Epoch 494/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2778 - acc: 0.9043 - val_loss: 0.2822 - val_acc: 0.9018\n",
      "Epoch 495/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2770 - acc: 0.9049 - val_loss: 0.2830 - val_acc: 0.9011\n",
      "Epoch 496/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2764 - acc: 0.9051 - val_loss: 0.2812 - val_acc: 0.9031\n",
      "Epoch 497/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2767 - acc: 0.9048 - val_loss: 0.2830 - val_acc: 0.9017\n",
      "Epoch 498/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2765 - acc: 0.9051 - val_loss: 0.2818 - val_acc: 0.9026\n",
      "Epoch 499/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2761 - acc: 0.9047 - val_loss: 0.2816 - val_acc: 0.9020\n",
      "Epoch 500/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2768 - acc: 0.9042 - val_loss: 0.2810 - val_acc: 0.9019\n",
      "39302/39302 [==============================] - 0s 2us/step\n",
      "../linkPrediction/dataframes/obesity\n",
      "pref (131006, 7, 3) --------------------------------------------------------------------\n",
      "(131006, 3) (131006,)\n",
      "[131006, 3, 1]\n",
      "(91704, 3) (91704,)\n",
      "Train on 91704 samples, validate on 39302 samples\n",
      "Epoch 1/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 1.5194 - acc: 0.8689 - val_loss: 1.1584 - val_acc: 0.8999\n",
      "Epoch 2/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 1.1207 - acc: 0.8892 - val_loss: 1.1590 - val_acc: 0.8954\n",
      "Epoch 3/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 1.1006 - acc: 0.8905 - val_loss: 1.1515 - val_acc: 0.9008\n",
      "Epoch 4/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 1.0780 - acc: 0.8909 - val_loss: 1.0462 - val_acc: 0.8872\n",
      "Epoch 5/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 1.0642 - acc: 0.8853 - val_loss: 1.1519 - val_acc: 0.8771\n",
      "Epoch 6/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 1.0771 - acc: 0.8789 - val_loss: 1.0418 - val_acc: 0.8874\n",
      "Epoch 7/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.7726 - acc: 0.8866 - val_loss: 0.7222 - val_acc: 0.8899\n",
      "Epoch 8/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.7520 - acc: 0.8873 - val_loss: 0.6081 - val_acc: 0.8983\n",
      "Epoch 9/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.6554 - acc: 0.8928 - val_loss: 0.8232 - val_acc: 0.8861\n",
      "Epoch 10/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.5792 - acc: 0.8911 - val_loss: 0.4553 - val_acc: 0.8993\n",
      "Epoch 11/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.4618 - acc: 0.8966 - val_loss: 0.4333 - val_acc: 0.8963\n",
      "Epoch 12/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.4229 - acc: 0.8989 - val_loss: 0.4030 - val_acc: 0.9007\n",
      "Epoch 13/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.4053 - acc: 0.8997 - val_loss: 0.3833 - val_acc: 0.8982\n",
      "Epoch 14/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3897 - acc: 0.8988 - val_loss: 0.3608 - val_acc: 0.9016\n",
      "Epoch 15/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.3632 - acc: 0.9013 - val_loss: 0.4079 - val_acc: 0.8836\n",
      "Epoch 16/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3599 - acc: 0.9000 - val_loss: 0.3644 - val_acc: 0.9021\n",
      "Epoch 17/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3498 - acc: 0.8998 - val_loss: 0.3605 - val_acc: 0.9013\n",
      "Epoch 18/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3282 - acc: 0.9024 - val_loss: 0.3000 - val_acc: 0.9014\n",
      "Epoch 19/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.3270 - acc: 0.9018 - val_loss: 0.3093 - val_acc: 0.9012\n",
      "Epoch 20/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3203 - acc: 0.9026 - val_loss: 0.3068 - val_acc: 0.9023\n",
      "Epoch 21/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3064 - acc: 0.9029 - val_loss: 0.3088 - val_acc: 0.8988\n",
      "Epoch 22/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3024 - acc: 0.9031 - val_loss: 0.2914 - val_acc: 0.9015\n",
      "Epoch 23/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3022 - acc: 0.9032 - val_loss: 0.3144 - val_acc: 0.9019\n",
      "Epoch 24/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3116 - acc: 0.9020 - val_loss: 0.3035 - val_acc: 0.9012\n",
      "Epoch 25/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2988 - acc: 0.9029 - val_loss: 0.3003 - val_acc: 0.9007\n",
      "Epoch 26/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2948 - acc: 0.9033 - val_loss: 0.2998 - val_acc: 0.9008\n",
      "Epoch 27/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2956 - acc: 0.9030 - val_loss: 0.3198 - val_acc: 0.8983\n",
      "Epoch 28/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2942 - acc: 0.9034 - val_loss: 0.3019 - val_acc: 0.8999\n",
      "Epoch 29/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3001 - acc: 0.9028 - val_loss: 0.3023 - val_acc: 0.9014\n",
      "Epoch 30/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2917 - acc: 0.9035 - val_loss: 0.2948 - val_acc: 0.9007\n",
      "Epoch 31/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2925 - acc: 0.9034 - val_loss: 0.2918 - val_acc: 0.9012\n",
      "Epoch 32/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2900 - acc: 0.9038 - val_loss: 0.2896 - val_acc: 0.9020\n",
      "Epoch 33/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2895 - acc: 0.9036 - val_loss: 0.3041 - val_acc: 0.9010\n",
      "Epoch 34/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2884 - acc: 0.9041 - val_loss: 0.2947 - val_acc: 0.9009\n",
      "Epoch 35/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2860 - acc: 0.9044 - val_loss: 0.2888 - val_acc: 0.9022\n",
      "Epoch 36/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2859 - acc: 0.9045 - val_loss: 0.2880 - val_acc: 0.9031\n",
      "Epoch 37/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2856 - acc: 0.9043 - val_loss: 0.2892 - val_acc: 0.9014\n",
      "Epoch 38/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2861 - acc: 0.9041 - val_loss: 0.2896 - val_acc: 0.9018\n",
      "Epoch 39/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2844 - acc: 0.9041 - val_loss: 0.2875 - val_acc: 0.9023\n",
      "Epoch 40/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2847 - acc: 0.9041 - val_loss: 0.2889 - val_acc: 0.9025\n",
      "Epoch 41/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2864 - acc: 0.9040 - val_loss: 0.2872 - val_acc: 0.9019\n",
      "Epoch 42/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2838 - acc: 0.9044 - val_loss: 0.2879 - val_acc: 0.9020\n",
      "Epoch 43/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2837 - acc: 0.9042 - val_loss: 0.2874 - val_acc: 0.9017\n",
      "Epoch 44/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2829 - acc: 0.9042 - val_loss: 0.2856 - val_acc: 0.9021\n",
      "Epoch 45/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2832 - acc: 0.9043 - val_loss: 0.2870 - val_acc: 0.9020\n",
      "Epoch 46/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2829 - acc: 0.9044 - val_loss: 0.2866 - val_acc: 0.9017\n",
      "Epoch 47/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2831 - acc: 0.9043 - val_loss: 0.2865 - val_acc: 0.9022\n",
      "Epoch 48/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2828 - acc: 0.9043 - val_loss: 0.2863 - val_acc: 0.9025\n",
      "Epoch 49/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2825 - acc: 0.9044 - val_loss: 0.2868 - val_acc: 0.9015\n",
      "Epoch 50/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2827 - acc: 0.9042 - val_loss: 0.2863 - val_acc: 0.9025\n",
      "Epoch 51/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2829 - acc: 0.9044 - val_loss: 0.2860 - val_acc: 0.9024\n",
      "Epoch 52/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2830 - acc: 0.9040 - val_loss: 0.2880 - val_acc: 0.9018\n",
      "Epoch 53/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2825 - acc: 0.9043 - val_loss: 0.2881 - val_acc: 0.9018\n",
      "Epoch 54/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2823 - acc: 0.9041 - val_loss: 0.2860 - val_acc: 0.9025\n",
      "Epoch 55/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2827 - acc: 0.9044 - val_loss: 0.2869 - val_acc: 0.9015\n",
      "Epoch 56/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2825 - acc: 0.9045 - val_loss: 0.2876 - val_acc: 0.9028\n",
      "Epoch 57/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2820 - acc: 0.9045 - val_loss: 0.2866 - val_acc: 0.9025\n",
      "Epoch 58/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2833 - acc: 0.9041 - val_loss: 0.2868 - val_acc: 0.9026\n",
      "Epoch 59/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2827 - acc: 0.9041 - val_loss: 0.2875 - val_acc: 0.9025\n",
      "Epoch 60/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2821 - acc: 0.9042 - val_loss: 0.2850 - val_acc: 0.9024\n",
      "Epoch 61/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2821 - acc: 0.9042 - val_loss: 0.2862 - val_acc: 0.9029\n",
      "Epoch 62/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2820 - acc: 0.9046 - val_loss: 0.2855 - val_acc: 0.9019\n",
      "Epoch 63/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2820 - acc: 0.9041 - val_loss: 0.2889 - val_acc: 0.9023\n",
      "Epoch 64/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2816 - acc: 0.9043 - val_loss: 0.2859 - val_acc: 0.9021\n",
      "Epoch 65/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2823 - acc: 0.9043 - val_loss: 0.2858 - val_acc: 0.9016\n",
      "Epoch 66/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2819 - acc: 0.9042 - val_loss: 0.2861 - val_acc: 0.9018\n",
      "Epoch 67/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2825 - acc: 0.9043 - val_loss: 0.2862 - val_acc: 0.9022\n",
      "Epoch 68/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2822 - acc: 0.9043 - val_loss: 0.2860 - val_acc: 0.9018\n",
      "Epoch 69/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2817 - acc: 0.9044 - val_loss: 0.2871 - val_acc: 0.9015\n",
      "Epoch 70/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2819 - acc: 0.9045 - val_loss: 0.2863 - val_acc: 0.9017\n",
      "Epoch 71/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2822 - acc: 0.9043 - val_loss: 0.2871 - val_acc: 0.9027\n",
      "Epoch 72/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2819 - acc: 0.9042 - val_loss: 0.2861 - val_acc: 0.9023\n",
      "Epoch 73/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2823 - acc: 0.9046 - val_loss: 0.2885 - val_acc: 0.9024\n",
      "Epoch 74/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2818 - acc: 0.9041 - val_loss: 0.2855 - val_acc: 0.9025\n",
      "Epoch 75/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2821 - acc: 0.9041 - val_loss: 0.2855 - val_acc: 0.9018\n",
      "Epoch 76/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2834 - acc: 0.9043 - val_loss: 0.2868 - val_acc: 0.9018\n",
      "Epoch 77/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2819 - acc: 0.9042 - val_loss: 0.2856 - val_acc: 0.9023\n",
      "Epoch 78/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2818 - acc: 0.9042 - val_loss: 0.2859 - val_acc: 0.9024\n",
      "Epoch 79/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2816 - acc: 0.9043 - val_loss: 0.2855 - val_acc: 0.9017\n",
      "Epoch 80/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2819 - acc: 0.9042 - val_loss: 0.2878 - val_acc: 0.9018\n",
      "Epoch 81/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2817 - acc: 0.9042 - val_loss: 0.2909 - val_acc: 0.9016\n",
      "Epoch 82/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2821 - acc: 0.9043 - val_loss: 0.2850 - val_acc: 0.9016\n",
      "Epoch 83/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2817 - acc: 0.9041 - val_loss: 0.2865 - val_acc: 0.9013\n",
      "Epoch 84/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2816 - acc: 0.9043 - val_loss: 0.2858 - val_acc: 0.9024\n",
      "Epoch 85/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2816 - acc: 0.9044 - val_loss: 0.2883 - val_acc: 0.9013\n",
      "Epoch 86/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2817 - acc: 0.9044 - val_loss: 0.2863 - val_acc: 0.9015\n",
      "Epoch 87/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2816 - acc: 0.9043 - val_loss: 0.2860 - val_acc: 0.9015\n",
      "Epoch 88/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2813 - acc: 0.9044 - val_loss: 0.2861 - val_acc: 0.9018\n",
      "Epoch 89/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2820 - acc: 0.9043 - val_loss: 0.2874 - val_acc: 0.9017\n",
      "Epoch 90/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2819 - acc: 0.9041 - val_loss: 0.2856 - val_acc: 0.9016\n",
      "Epoch 91/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2811 - acc: 0.9042 - val_loss: 0.2876 - val_acc: 0.9016\n",
      "Epoch 92/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2814 - acc: 0.9045 - val_loss: 0.2857 - val_acc: 0.9021\n",
      "Epoch 93/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2815 - acc: 0.9042 - val_loss: 0.2856 - val_acc: 0.9020\n",
      "Epoch 94/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2813 - acc: 0.9043 - val_loss: 0.2860 - val_acc: 0.9014\n",
      "Epoch 95/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2817 - acc: 0.9041 - val_loss: 0.2855 - val_acc: 0.9018\n",
      "Epoch 96/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2814 - acc: 0.9042 - val_loss: 0.2857 - val_acc: 0.9015\n",
      "Epoch 97/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2811 - acc: 0.9043 - val_loss: 0.2866 - val_acc: 0.9010\n",
      "Epoch 98/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9043 - val_loss: 0.2858 - val_acc: 0.9026\n",
      "Epoch 99/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2819 - acc: 0.9045 - val_loss: 0.2855 - val_acc: 0.9015\n",
      "Epoch 100/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2809 - acc: 0.9043 - val_loss: 0.2867 - val_acc: 0.9019\n",
      "Epoch 101/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2810 - acc: 0.9042 - val_loss: 0.2854 - val_acc: 0.9018\n",
      "Epoch 102/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2820 - acc: 0.9047 - val_loss: 0.2856 - val_acc: 0.9017\n",
      "Epoch 103/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2809 - acc: 0.9044 - val_loss: 0.2854 - val_acc: 0.9015\n",
      "Epoch 104/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2809 - acc: 0.9043 - val_loss: 0.2851 - val_acc: 0.9021\n",
      "Epoch 105/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2815 - acc: 0.9044 - val_loss: 0.2855 - val_acc: 0.9022\n",
      "Epoch 106/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2810 - acc: 0.9043 - val_loss: 0.2850 - val_acc: 0.9025\n",
      "Epoch 107/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2810 - acc: 0.9045 - val_loss: 0.2853 - val_acc: 0.9024\n",
      "Epoch 108/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2807 - acc: 0.9046 - val_loss: 0.2850 - val_acc: 0.9023\n",
      "Epoch 109/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2808 - acc: 0.9044 - val_loss: 0.2865 - val_acc: 0.9012\n",
      "Epoch 110/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2808 - acc: 0.9045 - val_loss: 0.2850 - val_acc: 0.9016\n",
      "Epoch 111/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2819 - acc: 0.9045 - val_loss: 0.2850 - val_acc: 0.9023\n",
      "Epoch 112/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2811 - acc: 0.9043 - val_loss: 0.2870 - val_acc: 0.9010\n",
      "Epoch 113/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2815 - acc: 0.9042 - val_loss: 0.2854 - val_acc: 0.9023\n",
      "Epoch 114/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2808 - acc: 0.9044 - val_loss: 0.2851 - val_acc: 0.9017\n",
      "Epoch 115/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9045 - val_loss: 0.2856 - val_acc: 0.9013\n",
      "Epoch 116/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2812 - acc: 0.9043 - val_loss: 0.2853 - val_acc: 0.9026\n",
      "Epoch 117/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2808 - acc: 0.9045 - val_loss: 0.2853 - val_acc: 0.9015\n",
      "Epoch 118/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2814 - acc: 0.9043 - val_loss: 0.2864 - val_acc: 0.9017\n",
      "Epoch 119/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2809 - acc: 0.9045 - val_loss: 0.2855 - val_acc: 0.9019\n",
      "Epoch 120/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9042 - val_loss: 0.2885 - val_acc: 0.9025\n",
      "Epoch 121/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2811 - acc: 0.9045 - val_loss: 0.2858 - val_acc: 0.9016\n",
      "Epoch 122/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9043 - val_loss: 0.2851 - val_acc: 0.9023\n",
      "Epoch 123/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2809 - acc: 0.9047 - val_loss: 0.2862 - val_acc: 0.9014\n",
      "Epoch 124/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9044 - val_loss: 0.2848 - val_acc: 0.9016\n",
      "Epoch 125/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9046 - val_loss: 0.2864 - val_acc: 0.9013\n",
      "Epoch 126/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2810 - acc: 0.9043 - val_loss: 0.2862 - val_acc: 0.9013\n",
      "Epoch 127/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9045 - val_loss: 0.2859 - val_acc: 0.9026\n",
      "Epoch 128/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2811 - acc: 0.9043 - val_loss: 0.2852 - val_acc: 0.9014\n",
      "Epoch 129/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2811 - acc: 0.9041 - val_loss: 0.2855 - val_acc: 0.9013\n",
      "Epoch 130/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2810 - acc: 0.9045 - val_loss: 0.2852 - val_acc: 0.9025\n",
      "Epoch 131/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9044 - val_loss: 0.2852 - val_acc: 0.9015\n",
      "Epoch 132/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2810 - acc: 0.9042 - val_loss: 0.2850 - val_acc: 0.9016\n",
      "Epoch 133/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2813 - acc: 0.9045 - val_loss: 0.2850 - val_acc: 0.9023\n",
      "Epoch 134/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2809 - acc: 0.9042 - val_loss: 0.2852 - val_acc: 0.9026\n",
      "Epoch 135/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2815 - acc: 0.9041 - val_loss: 0.2854 - val_acc: 0.9023\n",
      "Epoch 136/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9044 - val_loss: 0.2845 - val_acc: 0.9027\n",
      "Epoch 137/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2812 - acc: 0.9041 - val_loss: 0.2854 - val_acc: 0.9014\n",
      "Epoch 138/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2810 - acc: 0.9044 - val_loss: 0.2858 - val_acc: 0.9018\n",
      "Epoch 139/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9044 - val_loss: 0.2875 - val_acc: 0.9014\n",
      "Epoch 140/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2815 - acc: 0.9045 - val_loss: 0.3385 - val_acc: 0.9011\n",
      "Epoch 141/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2820 - acc: 0.9043 - val_loss: 0.2850 - val_acc: 0.9023\n",
      "Epoch 142/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2812 - acc: 0.9042 - val_loss: 0.2855 - val_acc: 0.9024\n",
      "Epoch 143/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9044 - val_loss: 0.2862 - val_acc: 0.9027\n",
      "Epoch 144/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2811 - acc: 0.9047 - val_loss: 0.2854 - val_acc: 0.9018\n",
      "Epoch 145/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2816 - acc: 0.9043 - val_loss: 0.2851 - val_acc: 0.9020\n",
      "Epoch 146/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2807 - acc: 0.9045 - val_loss: 0.2850 - val_acc: 0.9017\n",
      "Epoch 147/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9044 - val_loss: 0.2853 - val_acc: 0.9016\n",
      "Epoch 148/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2811 - acc: 0.9044 - val_loss: 0.2854 - val_acc: 0.9016\n",
      "Epoch 149/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2805 - acc: 0.9044 - val_loss: 0.2851 - val_acc: 0.9018\n",
      "Epoch 150/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2808 - acc: 0.9043 - val_loss: 0.2852 - val_acc: 0.9022\n",
      "Epoch 151/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2805 - acc: 0.9045 - val_loss: 0.2858 - val_acc: 0.9015\n",
      "Epoch 152/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2810 - acc: 0.9042 - val_loss: 0.2871 - val_acc: 0.9016\n",
      "Epoch 153/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2807 - acc: 0.9043 - val_loss: 0.2847 - val_acc: 0.9027\n",
      "Epoch 154/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9045 - val_loss: 0.2854 - val_acc: 0.9011\n",
      "Epoch 155/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9042 - val_loss: 0.2907 - val_acc: 0.9014\n",
      "Epoch 156/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9044 - val_loss: 0.2848 - val_acc: 0.9024\n",
      "Epoch 157/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9045 - val_loss: 0.2852 - val_acc: 0.9019\n",
      "Epoch 158/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2808 - acc: 0.9045 - val_loss: 0.2872 - val_acc: 0.9013\n",
      "Epoch 159/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2813 - acc: 0.9045 - val_loss: 0.2854 - val_acc: 0.9015\n",
      "Epoch 160/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2810 - acc: 0.9043 - val_loss: 0.2856 - val_acc: 0.9027\n",
      "Epoch 161/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9043 - val_loss: 0.2861 - val_acc: 0.9026\n",
      "Epoch 162/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9045 - val_loss: 0.2845 - val_acc: 0.9026\n",
      "Epoch 163/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2807 - acc: 0.9042 - val_loss: 0.2848 - val_acc: 0.9021\n",
      "Epoch 164/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2806 - acc: 0.9041 - val_loss: 0.2893 - val_acc: 0.9016\n",
      "Epoch 165/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2810 - acc: 0.9043 - val_loss: 0.2849 - val_acc: 0.9017\n",
      "Epoch 166/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2806 - acc: 0.9042 - val_loss: 0.2848 - val_acc: 0.9016\n",
      "Epoch 167/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2810 - acc: 0.9043 - val_loss: 0.2855 - val_acc: 0.9024\n",
      "Epoch 168/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2804 - acc: 0.9045 - val_loss: 0.2852 - val_acc: 0.9013\n",
      "Epoch 169/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2808 - acc: 0.9045 - val_loss: 0.2850 - val_acc: 0.9017\n",
      "Epoch 170/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9044 - val_loss: 0.2865 - val_acc: 0.9015\n",
      "Epoch 171/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2808 - acc: 0.9043 - val_loss: 0.2859 - val_acc: 0.9017\n",
      "Epoch 172/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2802 - acc: 0.9042 - val_loss: 0.2863 - val_acc: 0.9014\n",
      "Epoch 173/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2806 - acc: 0.9043 - val_loss: 0.2859 - val_acc: 0.9017\n",
      "Epoch 174/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9044 - val_loss: 0.2852 - val_acc: 0.9024\n",
      "Epoch 175/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2812 - acc: 0.9043 - val_loss: 0.2855 - val_acc: 0.9024\n",
      "Epoch 176/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9043 - val_loss: 0.2849 - val_acc: 0.9015\n",
      "Epoch 177/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9044 - val_loss: 0.2854 - val_acc: 0.9021\n",
      "Epoch 178/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9045 - val_loss: 0.2861 - val_acc: 0.9028\n",
      "Epoch 179/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2810 - acc: 0.9044 - val_loss: 0.2849 - val_acc: 0.9019\n",
      "Epoch 180/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2808 - acc: 0.9045 - val_loss: 0.2851 - val_acc: 0.9022\n",
      "Epoch 181/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2804 - acc: 0.9044 - val_loss: 0.2848 - val_acc: 0.9015\n",
      "Epoch 182/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9045 - val_loss: 0.2856 - val_acc: 0.9013\n",
      "Epoch 183/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2808 - acc: 0.9044 - val_loss: 0.2852 - val_acc: 0.9016\n",
      "Epoch 184/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2803 - acc: 0.9045 - val_loss: 0.2852 - val_acc: 0.9015\n",
      "Epoch 185/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2812 - acc: 0.9045 - val_loss: 0.2849 - val_acc: 0.9018\n",
      "Epoch 186/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2805 - acc: 0.9044 - val_loss: 0.2854 - val_acc: 0.9022\n",
      "Epoch 187/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2806 - acc: 0.9045 - val_loss: 0.2874 - val_acc: 0.9017\n",
      "Epoch 188/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9044 - val_loss: 0.2857 - val_acc: 0.9012\n",
      "Epoch 189/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2807 - acc: 0.9043 - val_loss: 0.2856 - val_acc: 0.9020\n",
      "Epoch 190/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2813 - acc: 0.9043 - val_loss: 0.2847 - val_acc: 0.9018\n",
      "Epoch 191/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9044 - val_loss: 0.2859 - val_acc: 0.9013\n",
      "Epoch 192/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2805 - acc: 0.9043 - val_loss: 0.2863 - val_acc: 0.9015\n",
      "Epoch 193/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9043 - val_loss: 0.2854 - val_acc: 0.9017\n",
      "Epoch 194/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9044 - val_loss: 0.2853 - val_acc: 0.9016\n",
      "Epoch 195/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9044 - val_loss: 0.2859 - val_acc: 0.9018\n",
      "Epoch 196/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2810 - acc: 0.9040 - val_loss: 0.2924 - val_acc: 0.9016\n",
      "Epoch 197/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9043 - val_loss: 0.2856 - val_acc: 0.9010\n",
      "Epoch 198/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2811 - acc: 0.9042 - val_loss: 0.2856 - val_acc: 0.9016\n",
      "Epoch 199/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9044 - val_loss: 0.2850 - val_acc: 0.9015\n",
      "Epoch 200/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2811 - acc: 0.9043 - val_loss: 0.2871 - val_acc: 0.9015\n",
      "Epoch 201/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9044 - val_loss: 0.2859 - val_acc: 0.9028\n",
      "Epoch 202/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9043 - val_loss: 0.2846 - val_acc: 0.9018\n",
      "Epoch 203/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2803 - acc: 0.9044 - val_loss: 0.2850 - val_acc: 0.9018\n",
      "Epoch 204/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9043 - val_loss: 0.2846 - val_acc: 0.9023\n",
      "Epoch 205/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9042 - val_loss: 0.2869 - val_acc: 0.9019\n",
      "Epoch 206/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2806 - acc: 0.9043 - val_loss: 0.2846 - val_acc: 0.9022\n",
      "Epoch 207/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2803 - acc: 0.9043 - val_loss: 0.2851 - val_acc: 0.9022\n",
      "Epoch 208/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9044 - val_loss: 0.2873 - val_acc: 0.9014\n",
      "Epoch 209/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2806 - acc: 0.9043 - val_loss: 0.2850 - val_acc: 0.9018\n",
      "Epoch 210/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9041 - val_loss: 0.2855 - val_acc: 0.9016\n",
      "Epoch 211/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2803 - acc: 0.9044 - val_loss: 0.2847 - val_acc: 0.9020\n",
      "Epoch 212/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9044 - val_loss: 0.2858 - val_acc: 0.9015\n",
      "Epoch 213/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9045 - val_loss: 0.2842 - val_acc: 0.9021\n",
      "Epoch 214/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2846 - val_acc: 0.9014\n",
      "Epoch 215/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2807 - acc: 0.9043 - val_loss: 0.2854 - val_acc: 0.9028\n",
      "Epoch 216/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2805 - acc: 0.9043 - val_loss: 0.2849 - val_acc: 0.9023\n",
      "Epoch 217/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2809 - acc: 0.9042 - val_loss: 0.2850 - val_acc: 0.9020\n",
      "Epoch 218/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9043 - val_loss: 0.2852 - val_acc: 0.9011\n",
      "Epoch 219/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9045 - val_loss: 0.2855 - val_acc: 0.9017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9045 - val_loss: 0.2847 - val_acc: 0.9023\n",
      "Epoch 221/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2808 - acc: 0.9043 - val_loss: 0.2847 - val_acc: 0.9018\n",
      "Epoch 222/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9043 - val_loss: 0.2849 - val_acc: 0.9023\n",
      "Epoch 223/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9045 - val_loss: 0.2850 - val_acc: 0.9020\n",
      "Epoch 224/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9046 - val_loss: 0.2850 - val_acc: 0.9015\n",
      "Epoch 225/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9043 - val_loss: 0.2856 - val_acc: 0.9022\n",
      "Epoch 226/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9045 - val_loss: 0.2873 - val_acc: 0.9015\n",
      "Epoch 227/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9042 - val_loss: 0.2843 - val_acc: 0.9024\n",
      "Epoch 228/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2812 - acc: 0.9041 - val_loss: 0.2851 - val_acc: 0.9015\n",
      "Epoch 229/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9042 - val_loss: 0.2846 - val_acc: 0.9016\n",
      "Epoch 230/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2856 - val_acc: 0.9027\n",
      "Epoch 231/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9042 - val_loss: 0.2853 - val_acc: 0.9023\n",
      "Epoch 232/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9045 - val_loss: 0.2855 - val_acc: 0.9013\n",
      "Epoch 233/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9045 - val_loss: 0.2851 - val_acc: 0.9015\n",
      "Epoch 234/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9042 - val_loss: 0.2872 - val_acc: 0.9021\n",
      "Epoch 235/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9042 - val_loss: 0.2845 - val_acc: 0.9015\n",
      "Epoch 236/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9043 - val_loss: 0.2850 - val_acc: 0.9025\n",
      "Epoch 237/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9043 - val_loss: 0.2876 - val_acc: 0.9024\n",
      "Epoch 238/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9042 - val_loss: 0.2850 - val_acc: 0.9016\n",
      "Epoch 239/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9043 - val_loss: 0.2847 - val_acc: 0.9025\n",
      "Epoch 240/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9041 - val_loss: 0.2854 - val_acc: 0.9015\n",
      "Epoch 241/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2826 - acc: 0.9043 - val_loss: 0.2857 - val_acc: 0.9016\n",
      "Epoch 242/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2808 - acc: 0.9045 - val_loss: 0.2852 - val_acc: 0.9018\n",
      "Epoch 243/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9046 - val_loss: 0.2855 - val_acc: 0.9013\n",
      "Epoch 244/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9046 - val_loss: 0.2859 - val_acc: 0.9021\n",
      "Epoch 245/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9042 - val_loss: 0.2851 - val_acc: 0.9014\n",
      "Epoch 246/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2800 - acc: 0.9045 - val_loss: 0.2852 - val_acc: 0.9027\n",
      "Epoch 247/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2805 - acc: 0.9046 - val_loss: 0.2847 - val_acc: 0.9016\n",
      "Epoch 248/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2803 - acc: 0.9040 - val_loss: 0.2849 - val_acc: 0.9026\n",
      "Epoch 249/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2804 - acc: 0.9045 - val_loss: 0.2844 - val_acc: 0.9022\n",
      "Epoch 250/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2802 - acc: 0.9042 - val_loss: 0.2848 - val_acc: 0.9017\n",
      "Epoch 251/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2801 - acc: 0.9044 - val_loss: 0.2854 - val_acc: 0.9027\n",
      "Epoch 252/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2803 - acc: 0.9043 - val_loss: 0.2858 - val_acc: 0.9019\n",
      "Epoch 253/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9045 - val_loss: 0.2849 - val_acc: 0.9018\n",
      "Epoch 254/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9045 - val_loss: 0.2900 - val_acc: 0.9018\n",
      "Epoch 255/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9044 - val_loss: 0.2852 - val_acc: 0.9019\n",
      "Epoch 256/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9044 - val_loss: 0.2851 - val_acc: 0.9015\n",
      "Epoch 257/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9042 - val_loss: 0.2844 - val_acc: 0.9023\n",
      "Epoch 258/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2810 - acc: 0.9043 - val_loss: 0.2849 - val_acc: 0.9023\n",
      "Epoch 259/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9045 - val_loss: 0.2849 - val_acc: 0.9018\n",
      "Epoch 260/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2844 - val_acc: 0.9022\n",
      "Epoch 261/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9042 - val_loss: 0.2849 - val_acc: 0.9019\n",
      "Epoch 262/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2857 - val_acc: 0.9014\n",
      "Epoch 263/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9044 - val_loss: 0.2870 - val_acc: 0.9010\n",
      "Epoch 264/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2862 - val_acc: 0.9027\n",
      "Epoch 265/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2809 - acc: 0.9044 - val_loss: 0.2867 - val_acc: 0.9020\n",
      "Epoch 266/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9043 - val_loss: 0.2843 - val_acc: 0.9024\n",
      "Epoch 267/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2801 - acc: 0.9046 - val_loss: 0.2846 - val_acc: 0.9022\n",
      "Epoch 268/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2803 - acc: 0.9044 - val_loss: 0.2847 - val_acc: 0.9020\n",
      "Epoch 269/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2811 - acc: 0.9044 - val_loss: 0.2848 - val_acc: 0.9017\n",
      "Epoch 270/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2801 - acc: 0.9043 - val_loss: 0.2851 - val_acc: 0.9017\n",
      "Epoch 271/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2852 - val_acc: 0.9016\n",
      "Epoch 272/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2801 - acc: 0.9045 - val_loss: 0.2851 - val_acc: 0.9020\n",
      "Epoch 273/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2805 - acc: 0.9045 - val_loss: 0.2858 - val_acc: 0.9015\n",
      "Epoch 274/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2805 - acc: 0.9042 - val_loss: 0.2859 - val_acc: 0.9014\n",
      "Epoch 275/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2803 - acc: 0.9042 - val_loss: 0.2861 - val_acc: 0.9016\n",
      "Epoch 276/500\n",
      "91704/91704 [==============================] - 2s 23us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2843 - val_acc: 0.9020\n",
      "Epoch 277/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2800 - acc: 0.9045 - val_loss: 0.2850 - val_acc: 0.9017\n",
      "Epoch 278/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2801 - acc: 0.9045 - val_loss: 0.2851 - val_acc: 0.9019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2804 - acc: 0.9043 - val_loss: 0.2841 - val_acc: 0.9023\n",
      "Epoch 280/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2807 - acc: 0.9046 - val_loss: 0.2855 - val_acc: 0.9021\n",
      "Epoch 281/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2805 - acc: 0.9043 - val_loss: 0.2844 - val_acc: 0.9025\n",
      "Epoch 282/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2801 - acc: 0.9043 - val_loss: 0.2843 - val_acc: 0.9020\n",
      "Epoch 283/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2848 - val_acc: 0.9016\n",
      "Epoch 284/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2804 - acc: 0.9046 - val_loss: 0.2847 - val_acc: 0.9023\n",
      "Epoch 285/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9048 - val_loss: 0.2834 - val_acc: 0.9026\n",
      "Epoch 286/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9043 - val_loss: 0.2846 - val_acc: 0.9019\n",
      "Epoch 287/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2804 - acc: 0.9043 - val_loss: 0.2846 - val_acc: 0.9018\n",
      "Epoch 288/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2808 - acc: 0.9043 - val_loss: 0.2848 - val_acc: 0.9019\n",
      "Epoch 289/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9044 - val_loss: 0.2866 - val_acc: 0.9015\n",
      "Epoch 290/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2811 - acc: 0.9043 - val_loss: 0.2848 - val_acc: 0.9019\n",
      "Epoch 291/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2800 - acc: 0.9046 - val_loss: 0.2845 - val_acc: 0.9021\n",
      "Epoch 292/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9044 - val_loss: 0.2842 - val_acc: 0.9021\n",
      "Epoch 293/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9043 - val_loss: 0.2849 - val_acc: 0.9017\n",
      "Epoch 294/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2818 - acc: 0.9044 - val_loss: 0.2851 - val_acc: 0.9022\n",
      "Epoch 295/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2807 - acc: 0.9044 - val_loss: 0.2848 - val_acc: 0.9023\n",
      "Epoch 296/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2804 - acc: 0.9046 - val_loss: 0.2861 - val_acc: 0.9013\n",
      "Epoch 297/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2804 - acc: 0.9041 - val_loss: 0.2853 - val_acc: 0.9021\n",
      "Epoch 298/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9046 - val_loss: 0.2857 - val_acc: 0.9015\n",
      "Epoch 299/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2803 - acc: 0.9042 - val_loss: 0.2850 - val_acc: 0.9018\n",
      "Epoch 300/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9043 - val_loss: 0.2851 - val_acc: 0.9025\n",
      "Epoch 301/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2804 - acc: 0.9047 - val_loss: 0.2849 - val_acc: 0.9022\n",
      "Epoch 302/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2801 - acc: 0.9045 - val_loss: 0.2846 - val_acc: 0.9022\n",
      "Epoch 303/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2803 - acc: 0.9045 - val_loss: 0.2850 - val_acc: 0.9024\n",
      "Epoch 304/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2802 - acc: 0.9046 - val_loss: 0.2850 - val_acc: 0.9028\n",
      "Epoch 305/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9046 - val_loss: 0.2845 - val_acc: 0.9022\n",
      "Epoch 306/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9045 - val_loss: 0.2849 - val_acc: 0.9019\n",
      "Epoch 307/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2808 - acc: 0.9043 - val_loss: 0.2856 - val_acc: 0.9022\n",
      "Epoch 308/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9045 - val_loss: 0.2853 - val_acc: 0.9021\n",
      "Epoch 309/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9043 - val_loss: 0.2850 - val_acc: 0.9017\n",
      "Epoch 310/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2852 - val_acc: 0.9021\n",
      "Epoch 311/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9046 - val_loss: 0.2844 - val_acc: 0.9017\n",
      "Epoch 312/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9043 - val_loss: 0.2848 - val_acc: 0.9018\n",
      "Epoch 313/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2845 - val_acc: 0.9018\n",
      "Epoch 314/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9041 - val_loss: 0.2852 - val_acc: 0.9018\n",
      "Epoch 315/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2801 - acc: 0.9044 - val_loss: 0.2850 - val_acc: 0.9017\n",
      "Epoch 316/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2802 - acc: 0.9045 - val_loss: 0.2847 - val_acc: 0.9019\n",
      "Epoch 317/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9041 - val_loss: 0.2847 - val_acc: 0.9022\n",
      "Epoch 318/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2798 - acc: 0.9044 - val_loss: 0.2848 - val_acc: 0.9024\n",
      "Epoch 319/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9046 - val_loss: 0.2848 - val_acc: 0.9017\n",
      "Epoch 320/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9047 - val_loss: 0.2851 - val_acc: 0.9024\n",
      "Epoch 321/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9045 - val_loss: 0.2858 - val_acc: 0.9022\n",
      "Epoch 322/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9044 - val_loss: 0.2848 - val_acc: 0.9018\n",
      "Epoch 323/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2804 - acc: 0.9044 - val_loss: 0.2851 - val_acc: 0.9017\n",
      "Epoch 324/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9046 - val_loss: 0.2848 - val_acc: 0.9016\n",
      "Epoch 325/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9042 - val_loss: 0.2856 - val_acc: 0.9017\n",
      "Epoch 326/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9044 - val_loss: 0.2848 - val_acc: 0.9016\n",
      "Epoch 327/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2799 - acc: 0.9045 - val_loss: 0.2851 - val_acc: 0.9014\n",
      "Epoch 328/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2804 - acc: 0.9042 - val_loss: 0.2853 - val_acc: 0.9018\n",
      "Epoch 329/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2798 - acc: 0.9045 - val_loss: 0.2852 - val_acc: 0.9018\n",
      "Epoch 330/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2801 - acc: 0.9044 - val_loss: 0.2845 - val_acc: 0.9023\n",
      "Epoch 331/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2805 - acc: 0.9044 - val_loss: 0.2869 - val_acc: 0.9023\n",
      "Epoch 332/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9043 - val_loss: 0.2857 - val_acc: 0.9014\n",
      "Epoch 333/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9044 - val_loss: 0.2861 - val_acc: 0.9025\n",
      "Epoch 334/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2851 - val_acc: 0.9015\n",
      "Epoch 335/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9043 - val_loss: 0.2854 - val_acc: 0.9018\n",
      "Epoch 336/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9045 - val_loss: 0.2957 - val_acc: 0.9021\n",
      "Epoch 337/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9045 - val_loss: 0.2856 - val_acc: 0.9019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9044 - val_loss: 0.2853 - val_acc: 0.9015\n",
      "Epoch 339/500\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 0.2802 - acc: 0.904 - 1s 9us/step - loss: 0.2801 - acc: 0.9043 - val_loss: 0.2841 - val_acc: 0.9024\n",
      "Epoch 340/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9042 - val_loss: 0.2846 - val_acc: 0.9021\n",
      "Epoch 341/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9044 - val_loss: 0.2844 - val_acc: 0.9017\n",
      "Epoch 342/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9045 - val_loss: 0.2855 - val_acc: 0.9016\n",
      "Epoch 343/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9044 - val_loss: 0.2851 - val_acc: 0.9022\n",
      "Epoch 344/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9045 - val_loss: 0.2850 - val_acc: 0.9018\n",
      "Epoch 345/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9041 - val_loss: 0.2856 - val_acc: 0.9021\n",
      "Epoch 346/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2805 - acc: 0.9044 - val_loss: 0.2844 - val_acc: 0.9019\n",
      "Epoch 347/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2804 - acc: 0.9044 - val_loss: 0.2855 - val_acc: 0.9014\n",
      "Epoch 348/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2802 - acc: 0.9043 - val_loss: 0.2849 - val_acc: 0.9023\n",
      "Epoch 349/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9047 - val_loss: 0.2844 - val_acc: 0.9021\n",
      "Epoch 350/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2806 - acc: 0.9045 - val_loss: 0.2851 - val_acc: 0.9018\n",
      "Epoch 351/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2806 - acc: 0.9046 - val_loss: 0.2846 - val_acc: 0.9018\n",
      "Epoch 352/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2804 - acc: 0.9043 - val_loss: 0.2920 - val_acc: 0.9017\n",
      "Epoch 353/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9048 - val_loss: 0.2849 - val_acc: 0.9023\n",
      "Epoch 354/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2801 - acc: 0.9043 - val_loss: 0.2848 - val_acc: 0.9019\n",
      "Epoch 355/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2803 - acc: 0.9043 - val_loss: 0.2847 - val_acc: 0.9021\n",
      "Epoch 356/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2802 - acc: 0.9045 - val_loss: 0.2842 - val_acc: 0.9021\n",
      "Epoch 357/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9044 - val_loss: 0.2846 - val_acc: 0.9020\n",
      "Epoch 358/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2808 - acc: 0.9044 - val_loss: 0.2861 - val_acc: 0.9013\n",
      "Epoch 359/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2797 - acc: 0.9046 - val_loss: 0.2845 - val_acc: 0.9017\n",
      "Epoch 360/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9042 - val_loss: 0.2867 - val_acc: 0.9011\n",
      "Epoch 361/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9048 - val_loss: 0.2857 - val_acc: 0.9014\n",
      "Epoch 362/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9043 - val_loss: 0.2848 - val_acc: 0.9018\n",
      "Epoch 363/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2798 - acc: 0.9045 - val_loss: 0.2851 - val_acc: 0.9016\n",
      "Epoch 364/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2800 - acc: 0.9046 - val_loss: 0.2844 - val_acc: 0.9022\n",
      "Epoch 365/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9044 - val_loss: 0.2842 - val_acc: 0.9023\n",
      "Epoch 366/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2813 - acc: 0.9045 - val_loss: 0.2851 - val_acc: 0.9018\n",
      "Epoch 367/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2800 - acc: 0.9043 - val_loss: 0.2864 - val_acc: 0.9015\n",
      "Epoch 368/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9043 - val_loss: 0.2848 - val_acc: 0.9016\n",
      "Epoch 369/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2804 - acc: 0.9042 - val_loss: 0.2851 - val_acc: 0.9016\n",
      "Epoch 370/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2801 - acc: 0.9043 - val_loss: 0.2854 - val_acc: 0.9022\n",
      "Epoch 371/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9044 - val_loss: 0.2839 - val_acc: 0.9023\n",
      "Epoch 372/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2800 - acc: 0.9044 - val_loss: 0.2847 - val_acc: 0.9019\n",
      "Epoch 373/500\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 0.2798 - acc: 0.9045- ETA: 0s - loss: 0.283 - 1s 9us/step - loss: 0.2800 - acc: 0.9045 - val_loss: 0.2851 - val_acc: 0.9025\n",
      "Epoch 374/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2803 - acc: 0.9045 - val_loss: 0.2853 - val_acc: 0.9020\n",
      "Epoch 375/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9042 - val_loss: 0.2850 - val_acc: 0.9016\n",
      "Epoch 376/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2806 - acc: 0.9045 - val_loss: 0.2861 - val_acc: 0.9019\n",
      "Epoch 377/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2805 - acc: 0.9042 - val_loss: 0.2875 - val_acc: 0.9015\n",
      "Epoch 378/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9046 - val_loss: 0.2854 - val_acc: 0.9019\n",
      "Epoch 379/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9045 - val_loss: 0.2856 - val_acc: 0.9017\n",
      "Epoch 380/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2804 - acc: 0.9042 - val_loss: 0.2849 - val_acc: 0.9018\n",
      "Epoch 381/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9044 - val_loss: 0.2847 - val_acc: 0.9019\n",
      "Epoch 382/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9043 - val_loss: 0.2854 - val_acc: 0.9017\n",
      "Epoch 383/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9046 - val_loss: 0.2843 - val_acc: 0.9022\n",
      "Epoch 384/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9044 - val_loss: 0.2852 - val_acc: 0.9015\n",
      "Epoch 385/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2806 - acc: 0.9044 - val_loss: 0.2852 - val_acc: 0.9016\n",
      "Epoch 386/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9045 - val_loss: 0.2847 - val_acc: 0.9018\n",
      "Epoch 387/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9044 - val_loss: 0.2851 - val_acc: 0.9016\n",
      "Epoch 388/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2798 - acc: 0.9044 - val_loss: 0.2846 - val_acc: 0.9018\n",
      "Epoch 389/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2800 - acc: 0.9043 - val_loss: 0.2846 - val_acc: 0.9024\n",
      "Epoch 390/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9045 - val_loss: 0.2849 - val_acc: 0.9017\n",
      "Epoch 391/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9047 - val_loss: 0.2852 - val_acc: 0.9020\n",
      "Epoch 392/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9044 - val_loss: 0.2846 - val_acc: 0.9017\n",
      "Epoch 393/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2856 - val_acc: 0.9018\n",
      "Epoch 394/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2805 - acc: 0.9042 - val_loss: 0.2854 - val_acc: 0.9017\n",
      "Epoch 395/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9046 - val_loss: 0.2853 - val_acc: 0.9016\n",
      "Epoch 396/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2811 - acc: 0.9045 - val_loss: 0.2857 - val_acc: 0.9019\n",
      "Epoch 397/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2804 - acc: 0.9042 - val_loss: 0.2855 - val_acc: 0.9019\n",
      "Epoch 398/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9043 - val_loss: 0.2854 - val_acc: 0.9018\n",
      "Epoch 399/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9047 - val_loss: 0.2852 - val_acc: 0.9016\n",
      "Epoch 400/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9045 - val_loss: 0.2862 - val_acc: 0.9011\n",
      "Epoch 401/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2800 - acc: 0.9044 - val_loss: 0.2847 - val_acc: 0.9018\n",
      "Epoch 402/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9046 - val_loss: 0.2865 - val_acc: 0.9014\n",
      "Epoch 403/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9043 - val_loss: 0.2851 - val_acc: 0.9018\n",
      "Epoch 404/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9044 - val_loss: 0.2843 - val_acc: 0.9025\n",
      "Epoch 405/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9043 - val_loss: 0.2851 - val_acc: 0.9025\n",
      "Epoch 406/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9045 - val_loss: 0.2853 - val_acc: 0.9017\n",
      "Epoch 407/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9044 - val_loss: 0.2860 - val_acc: 0.9011\n",
      "Epoch 408/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2802 - acc: 0.9042 - val_loss: 0.2852 - val_acc: 0.9018\n",
      "Epoch 409/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9045 - val_loss: 0.2856 - val_acc: 0.9018\n",
      "Epoch 410/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9046 - val_loss: 0.2846 - val_acc: 0.9022\n",
      "Epoch 411/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9044 - val_loss: 0.2840 - val_acc: 0.9023\n",
      "Epoch 412/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2798 - acc: 0.9044 - val_loss: 0.2852 - val_acc: 0.9016\n",
      "Epoch 413/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2802 - acc: 0.9045 - val_loss: 0.2848 - val_acc: 0.9027\n",
      "Epoch 414/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2799 - acc: 0.9044 - val_loss: 0.2848 - val_acc: 0.9012\n",
      "Epoch 415/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2805 - acc: 0.9045 - val_loss: 0.2852 - val_acc: 0.9018\n",
      "Epoch 416/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9045 - val_loss: 0.2851 - val_acc: 0.9015\n",
      "Epoch 417/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9041 - val_loss: 0.2845 - val_acc: 0.9020\n",
      "Epoch 418/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2800 - acc: 0.9044 - val_loss: 0.2849 - val_acc: 0.9017\n",
      "Epoch 419/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9045 - val_loss: 0.2887 - val_acc: 0.9026\n",
      "Epoch 420/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9045 - val_loss: 0.2859 - val_acc: 0.9020\n",
      "Epoch 421/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2798 - acc: 0.9044 - val_loss: 0.2851 - val_acc: 0.9023\n",
      "Epoch 422/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9041 - val_loss: 0.2845 - val_acc: 0.9019\n",
      "Epoch 423/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9043 - val_loss: 0.2846 - val_acc: 0.9018\n",
      "Epoch 424/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9043 - val_loss: 0.2841 - val_acc: 0.9018\n",
      "Epoch 425/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2798 - acc: 0.9045 - val_loss: 0.2854 - val_acc: 0.9020\n",
      "Epoch 426/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9042 - val_loss: 0.2922 - val_acc: 0.9025\n",
      "Epoch 427/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9045 - val_loss: 0.2853 - val_acc: 0.9013\n",
      "Epoch 428/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2798 - acc: 0.9043 - val_loss: 0.2851 - val_acc: 0.9024\n",
      "Epoch 429/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9045 - val_loss: 0.2849 - val_acc: 0.9020\n",
      "Epoch 430/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2796 - acc: 0.9046 - val_loss: 0.2844 - val_acc: 0.9019\n",
      "Epoch 431/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2797 - acc: 0.9044 - val_loss: 0.2846 - val_acc: 0.9014\n",
      "Epoch 432/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2799 - acc: 0.9043 - val_loss: 0.2847 - val_acc: 0.9021\n",
      "Epoch 433/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2798 - acc: 0.9041 - val_loss: 0.2846 - val_acc: 0.9018\n",
      "Epoch 434/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9045 - val_loss: 0.2846 - val_acc: 0.9025\n",
      "Epoch 435/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2798 - acc: 0.9045 - val_loss: 0.2845 - val_acc: 0.9027\n",
      "Epoch 436/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2804 - acc: 0.9046 - val_loss: 0.2846 - val_acc: 0.9019\n",
      "Epoch 437/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2798 - acc: 0.9044 - val_loss: 0.2838 - val_acc: 0.9020\n",
      "Epoch 438/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2797 - acc: 0.9045 - val_loss: 0.2857 - val_acc: 0.9020\n",
      "Epoch 439/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2801 - acc: 0.9045 - val_loss: 0.2842 - val_acc: 0.9022\n",
      "Epoch 440/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9042 - val_loss: 0.2848 - val_acc: 0.9017\n",
      "Epoch 441/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2799 - acc: 0.9043 - val_loss: 0.2864 - val_acc: 0.9018\n",
      "Epoch 442/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2802 - acc: 0.9045 - val_loss: 0.2851 - val_acc: 0.9018\n",
      "Epoch 443/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2808 - acc: 0.9046 - val_loss: 0.2876 - val_acc: 0.9006\n",
      "Epoch 444/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9044 - val_loss: 0.2856 - val_acc: 0.9016\n",
      "Epoch 445/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2857 - val_acc: 0.9024\n",
      "Epoch 446/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9043 - val_loss: 0.2849 - val_acc: 0.9025\n",
      "Epoch 447/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2798 - acc: 0.9045 - val_loss: 0.2851 - val_acc: 0.9018\n",
      "Epoch 448/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9043 - val_loss: 0.2863 - val_acc: 0.9021\n",
      "Epoch 449/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2815 - acc: 0.9046 - val_loss: 0.2856 - val_acc: 0.9017\n",
      "Epoch 450/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2800 - acc: 0.9046 - val_loss: 0.2863 - val_acc: 0.9018\n",
      "Epoch 451/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2798 - acc: 0.9045 - val_loss: 0.2853 - val_acc: 0.9022\n",
      "Epoch 452/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2851 - val_acc: 0.9017\n",
      "Epoch 453/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9043 - val_loss: 0.2850 - val_acc: 0.9014\n",
      "Epoch 454/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2798 - acc: 0.9044 - val_loss: 0.2853 - val_acc: 0.9018\n",
      "Epoch 455/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9043 - val_loss: 0.2844 - val_acc: 0.9023\n",
      "Epoch 456/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9045 - val_loss: 0.2861 - val_acc: 0.9024\n",
      "Epoch 457/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9048 - val_loss: 0.2856 - val_acc: 0.9024\n",
      "Epoch 458/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9046 - val_loss: 0.2850 - val_acc: 0.9019\n",
      "Epoch 459/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2807 - acc: 0.9045 - val_loss: 0.2877 - val_acc: 0.9017\n",
      "Epoch 460/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9043 - val_loss: 0.2846 - val_acc: 0.9019\n",
      "Epoch 461/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2798 - acc: 0.9046 - val_loss: 0.2857 - val_acc: 0.9015\n",
      "Epoch 462/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2797 - acc: 0.9048 - val_loss: 0.2845 - val_acc: 0.9020\n",
      "Epoch 463/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9045 - val_loss: 0.2850 - val_acc: 0.9017\n",
      "Epoch 464/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2848 - val_acc: 0.9017\n",
      "Epoch 465/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2798 - acc: 0.9045 - val_loss: 0.2850 - val_acc: 0.9019\n",
      "Epoch 466/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2800 - acc: 0.9046 - val_loss: 0.2859 - val_acc: 0.9019\n",
      "Epoch 467/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2801 - acc: 0.9046 - val_loss: 0.2854 - val_acc: 0.9014\n",
      "Epoch 468/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9046 - val_loss: 0.2844 - val_acc: 0.9020\n",
      "Epoch 469/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9044 - val_loss: 0.2846 - val_acc: 0.9018\n",
      "Epoch 470/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9045 - val_loss: 0.2862 - val_acc: 0.9021\n",
      "Epoch 471/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2799 - acc: 0.9043 - val_loss: 0.2840 - val_acc: 0.9020\n",
      "Epoch 472/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2800 - acc: 0.9045 - val_loss: 0.2869 - val_acc: 0.9011\n",
      "Epoch 473/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9044 - val_loss: 0.2839 - val_acc: 0.9023\n",
      "Epoch 474/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9045 - val_loss: 0.2879 - val_acc: 0.9015\n",
      "Epoch 475/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2800 - acc: 0.9044 - val_loss: 0.2853 - val_acc: 0.9015\n",
      "Epoch 476/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2804 - acc: 0.9042 - val_loss: 0.2846 - val_acc: 0.9019\n",
      "Epoch 477/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2800 - acc: 0.9044 - val_loss: 0.2848 - val_acc: 0.9018\n",
      "Epoch 478/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2812 - acc: 0.9043 - val_loss: 0.2852 - val_acc: 0.9021\n",
      "Epoch 479/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9048 - val_loss: 0.2852 - val_acc: 0.9021\n",
      "Epoch 480/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2800 - acc: 0.9043 - val_loss: 0.2848 - val_acc: 0.9018\n",
      "Epoch 481/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2802 - acc: 0.9046 - val_loss: 0.2974 - val_acc: 0.9017\n",
      "Epoch 482/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2803 - acc: 0.9043 - val_loss: 0.2876 - val_acc: 0.9017\n",
      "Epoch 483/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2797 - acc: 0.9043 - val_loss: 0.2852 - val_acc: 0.9018\n",
      "Epoch 484/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2800 - acc: 0.9046 - val_loss: 0.2856 - val_acc: 0.9013\n",
      "Epoch 485/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9044 - val_loss: 0.2859 - val_acc: 0.9021\n",
      "Epoch 486/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9045 - val_loss: 0.2845 - val_acc: 0.9019\n",
      "Epoch 487/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2800 - acc: 0.9042 - val_loss: 0.2846 - val_acc: 0.9017\n",
      "Epoch 488/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2801 - acc: 0.9045 - val_loss: 0.2857 - val_acc: 0.9024\n",
      "Epoch 489/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9042 - val_loss: 0.3078 - val_acc: 0.9018\n",
      "Epoch 490/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9047 - val_loss: 0.2843 - val_acc: 0.9023\n",
      "Epoch 491/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2805 - acc: 0.9046 - val_loss: 0.2847 - val_acc: 0.9020\n",
      "Epoch 492/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2799 - acc: 0.9046 - val_loss: 0.2853 - val_acc: 0.9018\n",
      "Epoch 493/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2804 - acc: 0.9045 - val_loss: 0.2859 - val_acc: 0.9013\n",
      "Epoch 494/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2797 - acc: 0.9046 - val_loss: 0.2846 - val_acc: 0.9018\n",
      "Epoch 495/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2800 - acc: 0.9045 - val_loss: 0.2848 - val_acc: 0.9018\n",
      "Epoch 496/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2802 - acc: 0.9046 - val_loss: 0.2856 - val_acc: 0.9015\n",
      "Epoch 497/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2802 - acc: 0.9045 - val_loss: 0.2849 - val_acc: 0.9026\n",
      "Epoch 498/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2798 - acc: 0.9045 - val_loss: 0.2850 - val_acc: 0.9026\n",
      "Epoch 499/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2798 - acc: 0.9049 - val_loss: 0.2852 - val_acc: 0.9016\n",
      "Epoch 500/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2800 - acc: 0.9043 - val_loss: 0.2860 - val_acc: 0.9014\n",
      "39302/39302 [==============================] - 0s 2us/step\n",
      "../linkPrediction/dataframes/obesity\n",
      "cm (131006, 7, 3) --------------------------------------------------------------------\n",
      "(131006, 3) (131006,)\n",
      "[131006, 3, 1]\n",
      "(91704, 3) (91704,)\n",
      "Train on 91704 samples, validate on 39302 samples\n",
      "Epoch 1/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.7827 - acc: 0.8752 - val_loss: 0.4347 - val_acc: 0.8966\n",
      "Epoch 2/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.4316 - acc: 0.8957 - val_loss: 0.3884 - val_acc: 0.8963\n",
      "Epoch 3/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.4207 - acc: 0.8943 - val_loss: 0.4301 - val_acc: 0.8942\n",
      "Epoch 4/500\n",
      "91704/91704 [==============================] - 2s 20us/step - loss: 0.3822 - acc: 0.8970 - val_loss: 0.3697 - val_acc: 0.8949\n",
      "Epoch 5/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.3733 - acc: 0.8974 - val_loss: 0.3558 - val_acc: 0.8989\n",
      "Epoch 6/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3641 - acc: 0.8971 - val_loss: 0.3336 - val_acc: 0.8992\n",
      "Epoch 7/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3614 - acc: 0.8977 - val_loss: 0.3297 - val_acc: 0.8957\n",
      "Epoch 8/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3418 - acc: 0.8986 - val_loss: 0.3691 - val_acc: 0.9000\n",
      "Epoch 9/500\n",
      "91704/91704 [==============================] - 1s 15us/step - loss: 0.3321 - acc: 0.9000 - val_loss: 0.3271 - val_acc: 0.9008\n",
      "Epoch 10/500\n",
      "91704/91704 [==============================] - 2s 23us/step - loss: 0.3224 - acc: 0.9004 - val_loss: 0.3330 - val_acc: 0.9013\n",
      "Epoch 11/500\n",
      "91704/91704 [==============================] - 2s 17us/step - loss: 0.3157 - acc: 0.9014 - val_loss: 0.3217 - val_acc: 0.9007\n",
      "Epoch 12/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.3104 - acc: 0.9020 - val_loss: 0.3137 - val_acc: 0.8994\n",
      "Epoch 13/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.3064 - acc: 0.9025 - val_loss: 0.3114 - val_acc: 0.8998\n",
      "Epoch 14/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.3000 - acc: 0.9033 - val_loss: 0.3063 - val_acc: 0.9006\n",
      "Epoch 15/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2993 - acc: 0.9034 - val_loss: 0.3055 - val_acc: 0.9004\n",
      "Epoch 16/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2987 - acc: 0.9034 - val_loss: 0.3059 - val_acc: 0.9010\n",
      "Epoch 17/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2989 - acc: 0.9032 - val_loss: 0.3033 - val_acc: 0.9010\n",
      "Epoch 18/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2982 - acc: 0.9034 - val_loss: 0.3045 - val_acc: 0.9006\n",
      "Epoch 19/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2981 - acc: 0.9035 - val_loss: 0.3049 - val_acc: 0.9010\n",
      "Epoch 20/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2978 - acc: 0.9035 - val_loss: 0.3058 - val_acc: 0.9010\n",
      "Epoch 21/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2979 - acc: 0.9034 - val_loss: 0.3035 - val_acc: 0.9006\n",
      "Epoch 22/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2971 - acc: 0.9034 - val_loss: 0.3108 - val_acc: 0.9016\n",
      "Epoch 23/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2967 - acc: 0.9038 - val_loss: 0.3019 - val_acc: 0.9004\n",
      "Epoch 24/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2966 - acc: 0.9034 - val_loss: 0.3014 - val_acc: 0.9009\n",
      "Epoch 25/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2958 - acc: 0.9037 - val_loss: 0.3039 - val_acc: 0.9016\n",
      "Epoch 26/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2960 - acc: 0.9039 - val_loss: 0.3030 - val_acc: 0.9011\n",
      "Epoch 27/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2965 - acc: 0.9034 - val_loss: 0.3066 - val_acc: 0.9006\n",
      "Epoch 28/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2953 - acc: 0.9042 - val_loss: 0.3023 - val_acc: 0.9019\n",
      "Epoch 29/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2961 - acc: 0.9036 - val_loss: 0.3021 - val_acc: 0.9008\n",
      "Epoch 30/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2957 - acc: 0.9039 - val_loss: 0.3024 - val_acc: 0.9000\n",
      "Epoch 31/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2950 - acc: 0.9038 - val_loss: 0.3033 - val_acc: 0.9013\n",
      "Epoch 32/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2960 - acc: 0.9036 - val_loss: 0.3030 - val_acc: 0.9011\n",
      "Epoch 33/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2947 - acc: 0.9039 - val_loss: 0.3024 - val_acc: 0.9011\n",
      "Epoch 34/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2948 - acc: 0.9038 - val_loss: 0.3014 - val_acc: 0.9006\n",
      "Epoch 35/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2948 - acc: 0.9037 - val_loss: 0.3015 - val_acc: 0.9010\n",
      "Epoch 36/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2942 - acc: 0.9037 - val_loss: 0.3046 - val_acc: 0.9008\n",
      "Epoch 37/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2947 - acc: 0.9038 - val_loss: 0.3035 - val_acc: 0.9013\n",
      "Epoch 38/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2942 - acc: 0.9039 - val_loss: 0.3010 - val_acc: 0.9022\n",
      "Epoch 39/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2943 - acc: 0.9040 - val_loss: 0.3013 - val_acc: 0.9008\n",
      "Epoch 40/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2941 - acc: 0.9041 - val_loss: 0.3012 - val_acc: 0.9012\n",
      "Epoch 41/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2940 - acc: 0.9036 - val_loss: 0.3025 - val_acc: 0.9009\n",
      "Epoch 42/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2941 - acc: 0.9040 - val_loss: 0.2999 - val_acc: 0.9012\n",
      "Epoch 43/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2937 - acc: 0.9041 - val_loss: 0.3031 - val_acc: 0.9013\n",
      "Epoch 44/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2952 - acc: 0.9036 - val_loss: 0.3043 - val_acc: 0.9010\n",
      "Epoch 45/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2946 - acc: 0.9038 - val_loss: 0.3024 - val_acc: 0.9008\n",
      "Epoch 46/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2941 - acc: 0.9041 - val_loss: 0.2995 - val_acc: 0.9004\n",
      "Epoch 47/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2940 - acc: 0.9037 - val_loss: 0.3008 - val_acc: 0.9014\n",
      "Epoch 48/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2938 - acc: 0.9037 - val_loss: 0.3007 - val_acc: 0.9008\n",
      "Epoch 49/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2944 - acc: 0.9040 - val_loss: 0.3003 - val_acc: 0.9016\n",
      "Epoch 50/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2936 - acc: 0.9037 - val_loss: 0.2995 - val_acc: 0.9019\n",
      "Epoch 51/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2935 - acc: 0.9038 - val_loss: 0.3004 - val_acc: 0.9009\n",
      "Epoch 52/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2941 - acc: 0.9040 - val_loss: 0.3000 - val_acc: 0.9014\n",
      "Epoch 53/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2936 - acc: 0.9041 - val_loss: 0.3015 - val_acc: 0.9010\n",
      "Epoch 54/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2938 - acc: 0.9037 - val_loss: 0.3001 - val_acc: 0.9010\n",
      "Epoch 55/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2939 - acc: 0.9040 - val_loss: 0.3010 - val_acc: 0.9015\n",
      "Epoch 56/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2939 - acc: 0.9040 - val_loss: 0.2995 - val_acc: 0.9009\n",
      "Epoch 57/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2937 - acc: 0.9037 - val_loss: 0.3045 - val_acc: 0.9004\n",
      "Epoch 58/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2935 - acc: 0.9037 - val_loss: 0.3002 - val_acc: 0.9021\n",
      "Epoch 59/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2933 - acc: 0.9040 - val_loss: 0.3023 - val_acc: 0.9003\n",
      "Epoch 60/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2933 - acc: 0.9041 - val_loss: 0.3021 - val_acc: 0.9010\n",
      "Epoch 61/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2934 - acc: 0.9041 - val_loss: 0.3002 - val_acc: 0.9009\n",
      "Epoch 62/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2932 - acc: 0.9039 - val_loss: 0.3021 - val_acc: 0.9015\n",
      "Epoch 63/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2933 - acc: 0.9043 - val_loss: 0.2991 - val_acc: 0.9011\n",
      "Epoch 64/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2930 - acc: 0.9040 - val_loss: 0.3007 - val_acc: 0.9018\n",
      "Epoch 65/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2936 - acc: 0.9038 - val_loss: 0.3007 - val_acc: 0.9015\n",
      "Epoch 66/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2933 - acc: 0.9038 - val_loss: 0.2991 - val_acc: 0.9020\n",
      "Epoch 67/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2934 - acc: 0.9040 - val_loss: 0.3020 - val_acc: 0.9010\n",
      "Epoch 68/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2933 - acc: 0.9039 - val_loss: 0.3037 - val_acc: 0.9013\n",
      "Epoch 69/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2931 - acc: 0.9041 - val_loss: 0.2993 - val_acc: 0.9018\n",
      "Epoch 70/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2933 - acc: 0.9039 - val_loss: 0.3031 - val_acc: 0.9017\n",
      "Epoch 71/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2933 - acc: 0.9043 - val_loss: 0.3003 - val_acc: 0.9009\n",
      "Epoch 72/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2932 - acc: 0.9039 - val_loss: 0.2994 - val_acc: 0.9015\n",
      "Epoch 73/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2933 - acc: 0.9042 - val_loss: 0.3005 - val_acc: 0.9011\n",
      "Epoch 74/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2934 - acc: 0.9038 - val_loss: 0.3002 - val_acc: 0.9012\n",
      "Epoch 75/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2929 - acc: 0.9044 - val_loss: 0.3002 - val_acc: 0.9024\n",
      "Epoch 76/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2934 - acc: 0.9042 - val_loss: 0.3050 - val_acc: 0.9011\n",
      "Epoch 77/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2933 - acc: 0.9043 - val_loss: 0.3021 - val_acc: 0.9007\n",
      "Epoch 78/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2931 - acc: 0.9038 - val_loss: 0.3007 - val_acc: 0.9008\n",
      "Epoch 79/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2934 - acc: 0.9044 - val_loss: 0.3014 - val_acc: 0.9008\n",
      "Epoch 80/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2928 - acc: 0.9039 - val_loss: 0.3000 - val_acc: 0.9014\n",
      "Epoch 81/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2930 - acc: 0.9043 - val_loss: 0.3002 - val_acc: 0.9016\n",
      "Epoch 82/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2926 - acc: 0.9041 - val_loss: 0.3002 - val_acc: 0.9005\n",
      "Epoch 83/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2933 - acc: 0.9040 - val_loss: 0.2994 - val_acc: 0.9022\n",
      "Epoch 84/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2931 - acc: 0.9043 - val_loss: 0.2997 - val_acc: 0.9008\n",
      "Epoch 85/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2930 - acc: 0.9041 - val_loss: 0.3002 - val_acc: 0.9009\n",
      "Epoch 86/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2935 - acc: 0.9040 - val_loss: 0.3024 - val_acc: 0.9015\n",
      "Epoch 87/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2932 - acc: 0.9041 - val_loss: 0.2990 - val_acc: 0.9007\n",
      "Epoch 88/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2929 - acc: 0.9041 - val_loss: 0.3015 - val_acc: 0.9008\n",
      "Epoch 89/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2930 - acc: 0.9040 - val_loss: 0.2996 - val_acc: 0.9014\n",
      "Epoch 90/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2930 - acc: 0.9041 - val_loss: 0.2995 - val_acc: 0.9012\n",
      "Epoch 91/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2933 - acc: 0.9041 - val_loss: 0.3000 - val_acc: 0.9009\n",
      "Epoch 92/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2927 - acc: 0.9041 - val_loss: 0.3025 - val_acc: 0.9020\n",
      "Epoch 93/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2926 - acc: 0.9043 - val_loss: 0.2998 - val_acc: 0.9014\n",
      "Epoch 94/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2927 - acc: 0.9043 - val_loss: 0.2987 - val_acc: 0.9022\n",
      "Epoch 95/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2927 - acc: 0.9040 - val_loss: 0.2992 - val_acc: 0.9018\n",
      "Epoch 96/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2927 - acc: 0.9043 - val_loss: 0.2994 - val_acc: 0.9010\n",
      "Epoch 97/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2927 - acc: 0.9042 - val_loss: 0.3031 - val_acc: 0.9011\n",
      "Epoch 98/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2933 - acc: 0.9038 - val_loss: 0.2992 - val_acc: 0.9009\n",
      "Epoch 99/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2928 - acc: 0.9043 - val_loss: 0.2985 - val_acc: 0.9016\n",
      "Epoch 100/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2928 - acc: 0.9039 - val_loss: 0.2988 - val_acc: 0.9017\n",
      "Epoch 101/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2924 - acc: 0.9040 - val_loss: 0.2996 - val_acc: 0.9015\n",
      "Epoch 102/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2939 - acc: 0.9042 - val_loss: 0.2996 - val_acc: 0.9016\n",
      "Epoch 103/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2928 - acc: 0.9044 - val_loss: 0.2996 - val_acc: 0.9007\n",
      "Epoch 104/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2923 - acc: 0.9043 - val_loss: 0.3003 - val_acc: 0.9009\n",
      "Epoch 105/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2933 - acc: 0.9040 - val_loss: 0.3004 - val_acc: 0.9019\n",
      "Epoch 106/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2925 - acc: 0.9043 - val_loss: 0.3002 - val_acc: 0.9015\n",
      "Epoch 107/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2926 - acc: 0.9042 - val_loss: 0.3110 - val_acc: 0.9022\n",
      "Epoch 108/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2932 - acc: 0.9043 - val_loss: 0.3004 - val_acc: 0.9014\n",
      "Epoch 109/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2924 - acc: 0.9042 - val_loss: 0.2992 - val_acc: 0.9018\n",
      "Epoch 110/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2927 - acc: 0.9043 - val_loss: 0.2993 - val_acc: 0.9011\n",
      "Epoch 111/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2929 - acc: 0.9040 - val_loss: 0.2993 - val_acc: 0.9014\n",
      "Epoch 112/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2928 - acc: 0.9038 - val_loss: 0.3019 - val_acc: 0.9009\n",
      "Epoch 113/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2924 - acc: 0.9042 - val_loss: 0.2992 - val_acc: 0.9019\n",
      "Epoch 114/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2926 - acc: 0.9044 - val_loss: 0.2989 - val_acc: 0.9019\n",
      "Epoch 115/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2926 - acc: 0.9040 - val_loss: 0.2985 - val_acc: 0.9005\n",
      "Epoch 116/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2926 - acc: 0.9042 - val_loss: 0.3006 - val_acc: 0.9020\n",
      "Epoch 117/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2927 - acc: 0.9042 - val_loss: 0.3003 - val_acc: 0.9008\n",
      "Epoch 118/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2932 - acc: 0.9041 - val_loss: 0.2995 - val_acc: 0.9023\n",
      "Epoch 119/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2930 - acc: 0.9041 - val_loss: 0.2996 - val_acc: 0.9009\n",
      "Epoch 120/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2925 - acc: 0.9041 - val_loss: 0.2993 - val_acc: 0.9015\n",
      "Epoch 121/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2924 - acc: 0.9042 - val_loss: 0.2999 - val_acc: 0.9016\n",
      "Epoch 122/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2925 - acc: 0.9041 - val_loss: 0.2988 - val_acc: 0.9012\n",
      "Epoch 123/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2928 - acc: 0.9040 - val_loss: 0.3008 - val_acc: 0.9010\n",
      "Epoch 124/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2928 - acc: 0.9039 - val_loss: 0.2983 - val_acc: 0.9020\n",
      "Epoch 125/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2924 - acc: 0.9042 - val_loss: 0.2999 - val_acc: 0.9009\n",
      "Epoch 126/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2921 - acc: 0.9043 - val_loss: 0.3050 - val_acc: 0.9014\n",
      "Epoch 127/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2924 - acc: 0.9041 - val_loss: 0.3004 - val_acc: 0.9009\n",
      "Epoch 128/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2922 - acc: 0.9044 - val_loss: 0.3003 - val_acc: 0.9008\n",
      "Epoch 129/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2923 - acc: 0.9043 - val_loss: 0.2997 - val_acc: 0.9011\n",
      "Epoch 130/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2923 - acc: 0.9042 - val_loss: 0.2989 - val_acc: 0.9016\n",
      "Epoch 131/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2927 - acc: 0.9044 - val_loss: 0.3013 - val_acc: 0.9019\n",
      "Epoch 132/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2922 - acc: 0.9042 - val_loss: 0.3000 - val_acc: 0.9021\n",
      "Epoch 133/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2922 - acc: 0.9043 - val_loss: 0.2987 - val_acc: 0.9008\n",
      "Epoch 134/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2921 - acc: 0.9043 - val_loss: 0.2999 - val_acc: 0.9016\n",
      "Epoch 135/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2919 - acc: 0.9044 - val_loss: 0.3001 - val_acc: 0.9015\n",
      "Epoch 136/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2924 - acc: 0.9044 - val_loss: 0.2989 - val_acc: 0.9008\n",
      "Epoch 137/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2921 - acc: 0.9042 - val_loss: 0.2997 - val_acc: 0.9012\n",
      "Epoch 138/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2921 - acc: 0.9041 - val_loss: 0.3011 - val_acc: 0.9017\n",
      "Epoch 139/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2927 - acc: 0.9043 - val_loss: 0.2999 - val_acc: 0.9013\n",
      "Epoch 140/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2921 - acc: 0.9040 - val_loss: 0.2987 - val_acc: 0.9015\n",
      "Epoch 141/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2923 - acc: 0.9043 - val_loss: 0.2985 - val_acc: 0.9014\n",
      "Epoch 142/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2932 - acc: 0.9040 - val_loss: 0.2996 - val_acc: 0.9024\n",
      "Epoch 143/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2923 - acc: 0.9040 - val_loss: 0.3001 - val_acc: 0.9013\n",
      "Epoch 144/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2920 - acc: 0.9045 - val_loss: 0.2984 - val_acc: 0.9013\n",
      "Epoch 145/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2923 - acc: 0.9042 - val_loss: 0.2982 - val_acc: 0.9017\n",
      "Epoch 146/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2923 - acc: 0.9043 - val_loss: 0.2988 - val_acc: 0.9016\n",
      "Epoch 147/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2930 - acc: 0.9043 - val_loss: 0.3013 - val_acc: 0.9011\n",
      "Epoch 148/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2919 - acc: 0.9044 - val_loss: 0.2993 - val_acc: 0.9021\n",
      "Epoch 149/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2921 - acc: 0.9043 - val_loss: 0.2988 - val_acc: 0.9014\n",
      "Epoch 150/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2922 - acc: 0.9044 - val_loss: 0.3001 - val_acc: 0.9010\n",
      "Epoch 151/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2921 - acc: 0.9043 - val_loss: 0.2992 - val_acc: 0.9021\n",
      "Epoch 152/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2918 - acc: 0.9039 - val_loss: 0.3000 - val_acc: 0.9015\n",
      "Epoch 153/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2920 - acc: 0.9040 - val_loss: 0.2977 - val_acc: 0.9018\n",
      "Epoch 154/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2922 - acc: 0.9041 - val_loss: 0.3002 - val_acc: 0.9023\n",
      "Epoch 155/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2922 - acc: 0.9041 - val_loss: 0.2988 - val_acc: 0.9009\n",
      "Epoch 156/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2925 - acc: 0.9041 - val_loss: 0.2990 - val_acc: 0.9008\n",
      "Epoch 157/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2922 - acc: 0.9045 - val_loss: 0.2990 - val_acc: 0.9011\n",
      "Epoch 158/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2918 - acc: 0.9044 - val_loss: 0.2986 - val_acc: 0.9011\n",
      "Epoch 159/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2922 - acc: 0.9040 - val_loss: 0.2994 - val_acc: 0.9017\n",
      "Epoch 160/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2920 - acc: 0.9043 - val_loss: 0.2987 - val_acc: 0.9011\n",
      "Epoch 161/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2920 - acc: 0.9043 - val_loss: 0.2989 - val_acc: 0.9016\n",
      "Epoch 162/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2918 - acc: 0.9045 - val_loss: 0.2984 - val_acc: 0.9018\n",
      "Epoch 163/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2916 - acc: 0.9044 - val_loss: 0.2991 - val_acc: 0.9020\n",
      "Epoch 164/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2918 - acc: 0.9043 - val_loss: 0.3005 - val_acc: 0.9015\n",
      "Epoch 165/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2923 - acc: 0.9045 - val_loss: 0.2990 - val_acc: 0.9022\n",
      "Epoch 166/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2918 - acc: 0.9042 - val_loss: 0.3001 - val_acc: 0.9013\n",
      "Epoch 167/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2919 - acc: 0.9046 - val_loss: 0.3007 - val_acc: 0.9023\n",
      "Epoch 168/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2925 - acc: 0.9043 - val_loss: 0.2985 - val_acc: 0.9010\n",
      "Epoch 169/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2921 - acc: 0.9043 - val_loss: 0.2987 - val_acc: 0.9023\n",
      "Epoch 170/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2916 - acc: 0.9042 - val_loss: 0.2981 - val_acc: 0.9015\n",
      "Epoch 171/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2922 - acc: 0.9042 - val_loss: 0.2994 - val_acc: 0.9015\n",
      "Epoch 172/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2914 - acc: 0.9044 - val_loss: 0.2986 - val_acc: 0.9016\n",
      "Epoch 173/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2917 - acc: 0.9040 - val_loss: 0.2990 - val_acc: 0.9018\n",
      "Epoch 174/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2923 - acc: 0.9042 - val_loss: 0.2992 - val_acc: 0.9009\n",
      "Epoch 175/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2919 - acc: 0.9044 - val_loss: 0.3004 - val_acc: 0.9012\n",
      "Epoch 176/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2922 - acc: 0.9043 - val_loss: 0.2969 - val_acc: 0.9019\n",
      "Epoch 177/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2920 - acc: 0.9044 - val_loss: 0.3000 - val_acc: 0.9012\n",
      "Epoch 178/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2918 - acc: 0.9040 - val_loss: 0.2986 - val_acc: 0.9015\n",
      "Epoch 179/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2920 - acc: 0.9043 - val_loss: 0.2982 - val_acc: 0.9014\n",
      "Epoch 180/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2914 - acc: 0.9047 - val_loss: 0.2979 - val_acc: 0.9010\n",
      "Epoch 181/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2917 - acc: 0.9039 - val_loss: 0.2993 - val_acc: 0.9009\n",
      "Epoch 182/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2916 - acc: 0.9042 - val_loss: 0.2981 - val_acc: 0.9021\n",
      "Epoch 183/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2916 - acc: 0.9042 - val_loss: 0.2978 - val_acc: 0.9024\n",
      "Epoch 184/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2915 - acc: 0.9039 - val_loss: 0.2991 - val_acc: 0.9010\n",
      "Epoch 185/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2916 - acc: 0.9044 - val_loss: 0.2988 - val_acc: 0.9011\n",
      "Epoch 186/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2915 - acc: 0.9043 - val_loss: 0.2984 - val_acc: 0.9011\n",
      "Epoch 187/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2913 - acc: 0.9044 - val_loss: 0.2983 - val_acc: 0.9021\n",
      "Epoch 188/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2915 - acc: 0.9044 - val_loss: 0.2986 - val_acc: 0.9020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2920 - acc: 0.9040 - val_loss: 0.2995 - val_acc: 0.9009\n",
      "Epoch 190/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2917 - acc: 0.9042 - val_loss: 0.2980 - val_acc: 0.9016\n",
      "Epoch 191/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2916 - acc: 0.9042 - val_loss: 0.2981 - val_acc: 0.9019\n",
      "Epoch 192/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2918 - acc: 0.9042 - val_loss: 0.2996 - val_acc: 0.9012\n",
      "Epoch 193/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2915 - acc: 0.9041 - val_loss: 0.2981 - val_acc: 0.9021\n",
      "Epoch 194/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2911 - acc: 0.9042 - val_loss: 0.2990 - val_acc: 0.9011\n",
      "Epoch 195/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2917 - acc: 0.9045 - val_loss: 0.2999 - val_acc: 0.9009\n",
      "Epoch 196/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2920 - acc: 0.9043 - val_loss: 0.2990 - val_acc: 0.9028\n",
      "Epoch 197/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2913 - acc: 0.9041 - val_loss: 0.2976 - val_acc: 0.9012\n",
      "Epoch 198/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2920 - acc: 0.9043 - val_loss: 0.2979 - val_acc: 0.9027\n",
      "Epoch 199/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2917 - acc: 0.9044 - val_loss: 0.3017 - val_acc: 0.9010\n",
      "Epoch 200/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2922 - acc: 0.9043 - val_loss: 0.2982 - val_acc: 0.9017\n",
      "Epoch 201/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2914 - acc: 0.9046 - val_loss: 0.2991 - val_acc: 0.9016\n",
      "Epoch 202/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2912 - acc: 0.9042 - val_loss: 0.2972 - val_acc: 0.9017\n",
      "Epoch 203/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2915 - acc: 0.9041 - val_loss: 0.2978 - val_acc: 0.9016\n",
      "Epoch 204/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2915 - acc: 0.9041 - val_loss: 0.2979 - val_acc: 0.9008\n",
      "Epoch 205/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2911 - acc: 0.9042 - val_loss: 0.2987 - val_acc: 0.9024\n",
      "Epoch 206/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2912 - acc: 0.9045 - val_loss: 0.2985 - val_acc: 0.9018\n",
      "Epoch 207/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2914 - acc: 0.9047 - val_loss: 0.2990 - val_acc: 0.9025\n",
      "Epoch 208/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2908 - acc: 0.9049 - val_loss: 0.2985 - val_acc: 0.9009\n",
      "Epoch 209/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2912 - acc: 0.9045 - val_loss: 0.2965 - val_acc: 0.9025\n",
      "Epoch 210/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2914 - acc: 0.9045 - val_loss: 0.2980 - val_acc: 0.9022\n",
      "Epoch 211/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2910 - acc: 0.9045 - val_loss: 0.2971 - val_acc: 0.9021\n",
      "Epoch 212/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2906 - acc: 0.9050 - val_loss: 0.2978 - val_acc: 0.9019\n",
      "Epoch 213/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2912 - acc: 0.9046 - val_loss: 0.3007 - val_acc: 0.9009\n",
      "Epoch 214/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2914 - acc: 0.9043 - val_loss: 0.2968 - val_acc: 0.9019\n",
      "Epoch 215/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2912 - acc: 0.9047 - val_loss: 0.2994 - val_acc: 0.9016\n",
      "Epoch 216/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2908 - acc: 0.9047 - val_loss: 0.2986 - val_acc: 0.9019\n",
      "Epoch 217/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2911 - acc: 0.9049 - val_loss: 0.2982 - val_acc: 0.9023\n",
      "Epoch 218/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2914 - acc: 0.9048 - val_loss: 0.2972 - val_acc: 0.9017\n",
      "Epoch 219/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2910 - acc: 0.9045 - val_loss: 0.2968 - val_acc: 0.9018\n",
      "Epoch 220/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2908 - acc: 0.9048 - val_loss: 0.2978 - val_acc: 0.9018\n",
      "Epoch 221/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2912 - acc: 0.9047 - val_loss: 0.2984 - val_acc: 0.9023\n",
      "Epoch 222/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2915 - acc: 0.9046 - val_loss: 0.2974 - val_acc: 0.9023\n",
      "Epoch 223/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2908 - acc: 0.9047 - val_loss: 0.2971 - val_acc: 0.9017\n",
      "Epoch 224/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2911 - acc: 0.9047 - val_loss: 0.2975 - val_acc: 0.9018\n",
      "Epoch 225/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2908 - acc: 0.9049 - val_loss: 0.2988 - val_acc: 0.9021\n",
      "Epoch 226/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2910 - acc: 0.9047 - val_loss: 0.2967 - val_acc: 0.9022\n",
      "Epoch 227/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2912 - acc: 0.9045 - val_loss: 0.2977 - val_acc: 0.9022\n",
      "Epoch 228/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2909 - acc: 0.9046 - val_loss: 0.2973 - val_acc: 0.9021\n",
      "Epoch 229/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2911 - acc: 0.9050 - val_loss: 0.2982 - val_acc: 0.9018\n",
      "Epoch 230/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2912 - acc: 0.9047 - val_loss: 0.2974 - val_acc: 0.9017\n",
      "Epoch 231/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2910 - acc: 0.9047 - val_loss: 0.2972 - val_acc: 0.9026\n",
      "Epoch 232/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2907 - acc: 0.9046 - val_loss: 0.2989 - val_acc: 0.9013\n",
      "Epoch 233/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2910 - acc: 0.9048 - val_loss: 0.2969 - val_acc: 0.9022\n",
      "Epoch 234/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2904 - acc: 0.9048 - val_loss: 0.2994 - val_acc: 0.9010\n",
      "Epoch 235/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2906 - acc: 0.9049 - val_loss: 0.2989 - val_acc: 0.9016\n",
      "Epoch 236/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2910 - acc: 0.9049 - val_loss: 0.3000 - val_acc: 0.9016\n",
      "Epoch 237/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2907 - acc: 0.9048 - val_loss: 0.3024 - val_acc: 0.9025\n",
      "Epoch 238/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2907 - acc: 0.9047 - val_loss: 0.2974 - val_acc: 0.9019\n",
      "Epoch 239/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2909 - acc: 0.9047 - val_loss: 0.2999 - val_acc: 0.9017\n",
      "Epoch 240/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2909 - acc: 0.9046 - val_loss: 0.3000 - val_acc: 0.9015\n",
      "Epoch 241/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2906 - acc: 0.9047 - val_loss: 0.2996 - val_acc: 0.9017\n",
      "Epoch 242/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2906 - acc: 0.9048 - val_loss: 0.2973 - val_acc: 0.9013\n",
      "Epoch 243/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2907 - acc: 0.9048 - val_loss: 0.2966 - val_acc: 0.9024\n",
      "Epoch 244/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2905 - acc: 0.9045 - val_loss: 0.2991 - val_acc: 0.9014\n",
      "Epoch 245/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2905 - acc: 0.9046 - val_loss: 0.3052 - val_acc: 0.9021\n",
      "Epoch 246/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2904 - acc: 0.9048 - val_loss: 0.2975 - val_acc: 0.9016\n",
      "Epoch 247/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2903 - acc: 0.9048 - val_loss: 0.2972 - val_acc: 0.9025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2908 - acc: 0.9048 - val_loss: 0.2974 - val_acc: 0.9027\n",
      "Epoch 249/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2907 - acc: 0.9046 - val_loss: 0.2978 - val_acc: 0.9023\n",
      "Epoch 250/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2902 - acc: 0.9048 - val_loss: 0.2970 - val_acc: 0.9015\n",
      "Epoch 251/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2902 - acc: 0.9048 - val_loss: 0.2971 - val_acc: 0.9023\n",
      "Epoch 252/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2897 - acc: 0.9050 - val_loss: 0.2988 - val_acc: 0.9015\n",
      "Epoch 253/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2898 - acc: 0.9047 - val_loss: 0.2965 - val_acc: 0.9016\n",
      "Epoch 254/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2901 - acc: 0.9048 - val_loss: 0.2967 - val_acc: 0.9015\n",
      "Epoch 255/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2903 - acc: 0.9046 - val_loss: 0.2990 - val_acc: 0.9017\n",
      "Epoch 256/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2903 - acc: 0.9049 - val_loss: 0.2970 - val_acc: 0.9019\n",
      "Epoch 257/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2902 - acc: 0.9048 - val_loss: 0.2968 - val_acc: 0.9016\n",
      "Epoch 258/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2899 - acc: 0.9050 - val_loss: 0.2966 - val_acc: 0.9025\n",
      "Epoch 259/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2903 - acc: 0.9049 - val_loss: 0.2967 - val_acc: 0.9020\n",
      "Epoch 260/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2902 - acc: 0.9047 - val_loss: 0.2967 - val_acc: 0.9020\n",
      "Epoch 261/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2904 - acc: 0.9048 - val_loss: 0.2981 - val_acc: 0.9024\n",
      "Epoch 262/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2897 - acc: 0.9047 - val_loss: 0.2977 - val_acc: 0.9024\n",
      "Epoch 263/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2902 - acc: 0.9045 - val_loss: 0.2986 - val_acc: 0.9019\n",
      "Epoch 264/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2900 - acc: 0.9049 - val_loss: 0.2978 - val_acc: 0.9020\n",
      "Epoch 265/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2899 - acc: 0.9050 - val_loss: 0.2958 - val_acc: 0.9022\n",
      "Epoch 266/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2911 - acc: 0.9046 - val_loss: 0.2967 - val_acc: 0.9019\n",
      "Epoch 267/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2902 - acc: 0.9049 - val_loss: 0.2968 - val_acc: 0.9029\n",
      "Epoch 268/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2901 - acc: 0.9048 - val_loss: 0.2961 - val_acc: 0.9022\n",
      "Epoch 269/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2898 - acc: 0.9045 - val_loss: 0.2975 - val_acc: 0.9012\n",
      "Epoch 270/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2895 - acc: 0.9052 - val_loss: 0.3001 - val_acc: 0.9021\n",
      "Epoch 271/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2897 - acc: 0.9051 - val_loss: 0.2975 - val_acc: 0.9023\n",
      "Epoch 272/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2900 - acc: 0.9047 - val_loss: 0.2961 - val_acc: 0.9019\n",
      "Epoch 273/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2898 - acc: 0.9047 - val_loss: 0.2980 - val_acc: 0.9017\n",
      "Epoch 274/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2899 - acc: 0.9050 - val_loss: 0.2967 - val_acc: 0.9021\n",
      "Epoch 275/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2899 - acc: 0.9048 - val_loss: 0.2961 - val_acc: 0.9024\n",
      "Epoch 276/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2900 - acc: 0.9049 - val_loss: 0.2970 - val_acc: 0.9022\n",
      "Epoch 277/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2895 - acc: 0.9047 - val_loss: 0.2971 - val_acc: 0.9029\n",
      "Epoch 278/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2897 - acc: 0.9049 - val_loss: 0.2966 - val_acc: 0.9022\n",
      "Epoch 279/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2897 - acc: 0.9050 - val_loss: 0.2970 - val_acc: 0.9018\n",
      "Epoch 280/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2900 - acc: 0.9049 - val_loss: 0.2964 - val_acc: 0.9028\n",
      "Epoch 281/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2898 - acc: 0.9049 - val_loss: 0.2967 - val_acc: 0.9021\n",
      "Epoch 282/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2900 - acc: 0.9049 - val_loss: 0.2963 - val_acc: 0.9020\n",
      "Epoch 283/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2898 - acc: 0.9049 - val_loss: 0.2961 - val_acc: 0.9025\n",
      "Epoch 284/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2896 - acc: 0.9050 - val_loss: 0.2967 - val_acc: 0.9022\n",
      "Epoch 285/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2900 - acc: 0.9047 - val_loss: 0.2972 - val_acc: 0.9017\n",
      "Epoch 286/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2898 - acc: 0.9047 - val_loss: 0.2972 - val_acc: 0.9021\n",
      "Epoch 287/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2899 - acc: 0.9050 - val_loss: 0.2963 - val_acc: 0.9018\n",
      "Epoch 288/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2896 - acc: 0.9048 - val_loss: 0.2959 - val_acc: 0.9022\n",
      "Epoch 289/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2895 - acc: 0.9049 - val_loss: 0.2965 - val_acc: 0.9020\n",
      "Epoch 290/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9047 - val_loss: 0.2975 - val_acc: 0.9022\n",
      "Epoch 291/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9048 - val_loss: 0.2971 - val_acc: 0.9026\n",
      "Epoch 292/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2898 - acc: 0.9048 - val_loss: 0.2961 - val_acc: 0.9021\n",
      "Epoch 293/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2898 - acc: 0.9048 - val_loss: 0.2961 - val_acc: 0.9028\n",
      "Epoch 294/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2894 - acc: 0.9047 - val_loss: 0.2976 - val_acc: 0.9024\n",
      "Epoch 295/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2894 - acc: 0.9049 - val_loss: 0.2963 - val_acc: 0.9022\n",
      "Epoch 296/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2896 - acc: 0.9048 - val_loss: 0.2969 - val_acc: 0.9031\n",
      "Epoch 297/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2896 - acc: 0.9047 - val_loss: 0.2965 - val_acc: 0.9022\n",
      "Epoch 298/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9049 - val_loss: 0.2965 - val_acc: 0.9025\n",
      "Epoch 299/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9050 - val_loss: 0.2964 - val_acc: 0.9023\n",
      "Epoch 300/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9049 - val_loss: 0.2970 - val_acc: 0.9026\n",
      "Epoch 301/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2895 - acc: 0.9049 - val_loss: 0.2969 - val_acc: 0.9025\n",
      "Epoch 302/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2895 - acc: 0.9049 - val_loss: 0.2972 - val_acc: 0.9023\n",
      "Epoch 303/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2895 - acc: 0.9049 - val_loss: 0.2959 - val_acc: 0.9024\n",
      "Epoch 304/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2892 - acc: 0.9051 - val_loss: 0.2968 - val_acc: 0.9018\n",
      "Epoch 305/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2896 - acc: 0.9048 - val_loss: 0.2972 - val_acc: 0.9024\n",
      "Epoch 306/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9049 - val_loss: 0.2989 - val_acc: 0.9031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2901 - acc: 0.9047 - val_loss: 0.2958 - val_acc: 0.9018\n",
      "Epoch 308/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9050 - val_loss: 0.2959 - val_acc: 0.9026\n",
      "Epoch 309/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9050 - val_loss: 0.2962 - val_acc: 0.9029\n",
      "Epoch 310/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2895 - acc: 0.9051 - val_loss: 0.2960 - val_acc: 0.9023\n",
      "Epoch 311/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9051 - val_loss: 0.2963 - val_acc: 0.9030\n",
      "Epoch 312/500\n",
      "91704/91704 [==============================] - ETA: 0s - loss: 0.2903 - acc: 0.904 - 1s 8us/step - loss: 0.2899 - acc: 0.9049 - val_loss: 0.2987 - val_acc: 0.9015\n",
      "Epoch 313/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2895 - acc: 0.9050 - val_loss: 0.2963 - val_acc: 0.9027\n",
      "Epoch 314/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2898 - acc: 0.9048 - val_loss: 0.2951 - val_acc: 0.9024\n",
      "Epoch 315/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2899 - acc: 0.9052 - val_loss: 0.2966 - val_acc: 0.9023\n",
      "Epoch 316/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2897 - acc: 0.9050 - val_loss: 0.2973 - val_acc: 0.9031\n",
      "Epoch 317/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2897 - acc: 0.9050 - val_loss: 0.2973 - val_acc: 0.9020\n",
      "Epoch 318/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2896 - acc: 0.9050 - val_loss: 0.2975 - val_acc: 0.9024\n",
      "Epoch 319/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2898 - acc: 0.9048 - val_loss: 0.2972 - val_acc: 0.9014\n",
      "Epoch 320/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9048 - val_loss: 0.2959 - val_acc: 0.9022\n",
      "Epoch 321/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9048 - val_loss: 0.2959 - val_acc: 0.9027\n",
      "Epoch 322/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2895 - acc: 0.9049 - val_loss: 0.2968 - val_acc: 0.9028\n",
      "Epoch 323/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2896 - acc: 0.9050 - val_loss: 0.2971 - val_acc: 0.9018\n",
      "Epoch 324/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9050 - val_loss: 0.2971 - val_acc: 0.9021\n",
      "Epoch 325/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2898 - acc: 0.9049 - val_loss: 0.2970 - val_acc: 0.9025\n",
      "Epoch 326/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9049 - val_loss: 0.2972 - val_acc: 0.9021\n",
      "Epoch 327/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9049 - val_loss: 0.2967 - val_acc: 0.9022\n",
      "Epoch 328/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9048 - val_loss: 0.2971 - val_acc: 0.9026\n",
      "Epoch 329/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9050 - val_loss: 0.2988 - val_acc: 0.9020\n",
      "Epoch 330/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9050 - val_loss: 0.2995 - val_acc: 0.9025\n",
      "Epoch 331/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2895 - acc: 0.9050 - val_loss: 0.2964 - val_acc: 0.9026\n",
      "Epoch 332/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2895 - acc: 0.9053 - val_loss: 0.2972 - val_acc: 0.9026\n",
      "Epoch 333/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2898 - acc: 0.9051 - val_loss: 0.2968 - val_acc: 0.9025\n",
      "Epoch 334/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2891 - acc: 0.9052 - val_loss: 0.2953 - val_acc: 0.9032\n",
      "Epoch 335/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2897 - acc: 0.9047 - val_loss: 0.2996 - val_acc: 0.9026\n",
      "Epoch 336/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2892 - acc: 0.9049 - val_loss: 0.2960 - val_acc: 0.9025\n",
      "Epoch 337/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2894 - acc: 0.9048 - val_loss: 0.2993 - val_acc: 0.9014\n",
      "Epoch 338/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2893 - acc: 0.9048 - val_loss: 0.2964 - val_acc: 0.9022\n",
      "Epoch 339/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9047 - val_loss: 0.2979 - val_acc: 0.9024\n",
      "Epoch 340/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9050 - val_loss: 0.2961 - val_acc: 0.9026\n",
      "Epoch 341/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9051 - val_loss: 0.2964 - val_acc: 0.9023\n",
      "Epoch 342/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2897 - acc: 0.9049 - val_loss: 0.2963 - val_acc: 0.9023\n",
      "Epoch 343/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9050 - val_loss: 0.2972 - val_acc: 0.9024\n",
      "Epoch 344/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2892 - acc: 0.9050 - val_loss: 0.2964 - val_acc: 0.9024\n",
      "Epoch 345/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9049 - val_loss: 0.2967 - val_acc: 0.9025\n",
      "Epoch 346/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2897 - acc: 0.9049 - val_loss: 0.2961 - val_acc: 0.9026\n",
      "Epoch 347/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2892 - acc: 0.9049 - val_loss: 0.2978 - val_acc: 0.9018\n",
      "Epoch 348/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2896 - acc: 0.9049 - val_loss: 0.2963 - val_acc: 0.9019\n",
      "Epoch 349/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2891 - acc: 0.9050 - val_loss: 0.2962 - val_acc: 0.9029\n",
      "Epoch 350/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2893 - acc: 0.9051 - val_loss: 0.2962 - val_acc: 0.9029\n",
      "Epoch 351/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2891 - acc: 0.9049 - val_loss: 0.2972 - val_acc: 0.9018\n",
      "Epoch 352/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9049 - val_loss: 0.2956 - val_acc: 0.9029\n",
      "Epoch 353/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2893 - acc: 0.9053 - val_loss: 0.2985 - val_acc: 0.9023\n",
      "Epoch 354/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2892 - acc: 0.9052 - val_loss: 0.2957 - val_acc: 0.9022\n",
      "Epoch 355/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2897 - acc: 0.9047 - val_loss: 0.2960 - val_acc: 0.9025\n",
      "Epoch 356/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9049 - val_loss: 0.2955 - val_acc: 0.9022\n",
      "Epoch 357/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2893 - acc: 0.9051 - val_loss: 0.2971 - val_acc: 0.9022\n",
      "Epoch 358/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9049 - val_loss: 0.2966 - val_acc: 0.9019\n",
      "Epoch 359/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2896 - acc: 0.9049 - val_loss: 0.2975 - val_acc: 0.9016\n",
      "Epoch 360/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9051 - val_loss: 0.2956 - val_acc: 0.9026\n",
      "Epoch 361/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2892 - acc: 0.9048 - val_loss: 0.2968 - val_acc: 0.9032\n",
      "Epoch 362/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9049 - val_loss: 0.2963 - val_acc: 0.9025\n",
      "Epoch 363/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9050 - val_loss: 0.2959 - val_acc: 0.9024\n",
      "Epoch 364/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9050 - val_loss: 0.2981 - val_acc: 0.9020\n",
      "Epoch 365/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9051 - val_loss: 0.2979 - val_acc: 0.9021\n",
      "Epoch 366/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9052 - val_loss: 0.2977 - val_acc: 0.9030\n",
      "Epoch 367/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2892 - acc: 0.9049 - val_loss: 0.2969 - val_acc: 0.9027\n",
      "Epoch 368/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2895 - acc: 0.9049 - val_loss: 0.2963 - val_acc: 0.9022\n",
      "Epoch 369/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2889 - acc: 0.9051 - val_loss: 0.2963 - val_acc: 0.9026\n",
      "Epoch 370/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9052 - val_loss: 0.2969 - val_acc: 0.9028\n",
      "Epoch 371/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2892 - acc: 0.9052 - val_loss: 0.2965 - val_acc: 0.9023\n",
      "Epoch 372/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9051 - val_loss: 0.2963 - val_acc: 0.9026\n",
      "Epoch 373/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2897 - acc: 0.9051 - val_loss: 0.2961 - val_acc: 0.9030\n",
      "Epoch 374/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9048 - val_loss: 0.2968 - val_acc: 0.9026\n",
      "Epoch 375/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2896 - acc: 0.9049 - val_loss: 0.2961 - val_acc: 0.9026\n",
      "Epoch 376/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2897 - acc: 0.9048 - val_loss: 0.2958 - val_acc: 0.9024\n",
      "Epoch 377/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2889 - acc: 0.9052 - val_loss: 0.2965 - val_acc: 0.9020\n",
      "Epoch 378/500\n",
      "91704/91704 [==============================] - 1s 13us/step - loss: 0.2889 - acc: 0.9051 - val_loss: 0.2967 - val_acc: 0.9022\n",
      "Epoch 379/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2891 - acc: 0.9048 - val_loss: 0.2967 - val_acc: 0.9016\n",
      "Epoch 380/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2890 - acc: 0.9050 - val_loss: 0.2960 - val_acc: 0.9024\n",
      "Epoch 381/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2896 - acc: 0.9052 - val_loss: 0.2966 - val_acc: 0.9023\n",
      "Epoch 382/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2900 - acc: 0.9047 - val_loss: 0.2959 - val_acc: 0.9021\n",
      "Epoch 383/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2891 - acc: 0.9051 - val_loss: 0.2995 - val_acc: 0.9018\n",
      "Epoch 384/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2896 - acc: 0.9050 - val_loss: 0.2967 - val_acc: 0.9026\n",
      "Epoch 385/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2894 - acc: 0.9047 - val_loss: 0.2965 - val_acc: 0.9025\n",
      "Epoch 386/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2888 - acc: 0.9051 - val_loss: 0.2969 - val_acc: 0.9023\n",
      "Epoch 387/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2890 - acc: 0.9050 - val_loss: 0.2972 - val_acc: 0.9016\n",
      "Epoch 388/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2891 - acc: 0.9049 - val_loss: 0.2984 - val_acc: 0.9016\n",
      "Epoch 389/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2893 - acc: 0.9051 - val_loss: 0.2973 - val_acc: 0.9024\n",
      "Epoch 390/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2886 - acc: 0.9052 - val_loss: 0.2959 - val_acc: 0.9023\n",
      "Epoch 391/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2891 - acc: 0.9048 - val_loss: 0.2963 - val_acc: 0.9030\n",
      "Epoch 392/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9051 - val_loss: 0.2985 - val_acc: 0.9027\n",
      "Epoch 393/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2892 - acc: 0.9050 - val_loss: 0.2976 - val_acc: 0.9018\n",
      "Epoch 394/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2904 - acc: 0.9050 - val_loss: 0.2959 - val_acc: 0.9035\n",
      "Epoch 395/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2891 - acc: 0.9048 - val_loss: 0.2962 - val_acc: 0.9023\n",
      "Epoch 396/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2895 - acc: 0.9051 - val_loss: 0.2967 - val_acc: 0.9025\n",
      "Epoch 397/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2890 - acc: 0.9051 - val_loss: 0.2965 - val_acc: 0.9021\n",
      "Epoch 398/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2891 - acc: 0.9050 - val_loss: 0.2976 - val_acc: 0.9023\n",
      "Epoch 399/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2895 - acc: 0.9050 - val_loss: 0.2966 - val_acc: 0.9021\n",
      "Epoch 400/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2894 - acc: 0.9053 - val_loss: 0.2964 - val_acc: 0.9030\n",
      "Epoch 401/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2889 - acc: 0.9052 - val_loss: 0.2961 - val_acc: 0.9020\n",
      "Epoch 402/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9051 - val_loss: 0.2968 - val_acc: 0.9021\n",
      "Epoch 403/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9049 - val_loss: 0.2972 - val_acc: 0.9026\n",
      "Epoch 404/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9049 - val_loss: 0.2961 - val_acc: 0.9023\n",
      "Epoch 405/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2888 - acc: 0.9052 - val_loss: 0.2987 - val_acc: 0.9022\n",
      "Epoch 406/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9050 - val_loss: 0.2967 - val_acc: 0.9016\n",
      "Epoch 407/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2889 - acc: 0.9049 - val_loss: 0.2962 - val_acc: 0.9021\n",
      "Epoch 408/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9049 - val_loss: 0.2974 - val_acc: 0.9028\n",
      "Epoch 409/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9051 - val_loss: 0.2968 - val_acc: 0.9018\n",
      "Epoch 410/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9048 - val_loss: 0.2959 - val_acc: 0.9024\n",
      "Epoch 411/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2889 - acc: 0.9045 - val_loss: 0.2992 - val_acc: 0.9025\n",
      "Epoch 412/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2892 - acc: 0.9050 - val_loss: 0.2961 - val_acc: 0.9022\n",
      "Epoch 413/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2891 - acc: 0.9052 - val_loss: 0.2973 - val_acc: 0.9019\n",
      "Epoch 414/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2890 - acc: 0.9048 - val_loss: 0.2965 - val_acc: 0.9020\n",
      "Epoch 415/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2889 - acc: 0.9050 - val_loss: 0.2972 - val_acc: 0.9028\n",
      "Epoch 416/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9049 - val_loss: 0.2955 - val_acc: 0.9026\n",
      "Epoch 417/500\n",
      "91704/91704 [==============================] - 1s 14us/step - loss: 0.2890 - acc: 0.9052 - val_loss: 0.2953 - val_acc: 0.9022\n",
      "Epoch 418/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2890 - acc: 0.9051 - val_loss: 0.2958 - val_acc: 0.9028\n",
      "Epoch 419/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2890 - acc: 0.9046 - val_loss: 0.2963 - val_acc: 0.9025\n",
      "Epoch 420/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2892 - acc: 0.9049 - val_loss: 0.2961 - val_acc: 0.9024\n",
      "Epoch 421/500\n",
      "91704/91704 [==============================] - 1s 10us/step - loss: 0.2893 - acc: 0.9049 - val_loss: 0.2977 - val_acc: 0.9027\n",
      "Epoch 422/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9052 - val_loss: 0.2953 - val_acc: 0.9022\n",
      "Epoch 423/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9048 - val_loss: 0.2967 - val_acc: 0.9030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9048 - val_loss: 0.2964 - val_acc: 0.9033\n",
      "Epoch 425/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9049 - val_loss: 0.2978 - val_acc: 0.9024\n",
      "Epoch 426/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2885 - acc: 0.9051 - val_loss: 0.2957 - val_acc: 0.9026\n",
      "Epoch 427/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9051 - val_loss: 0.2967 - val_acc: 0.9023\n",
      "Epoch 428/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2892 - acc: 0.9052 - val_loss: 0.2962 - val_acc: 0.9028\n",
      "Epoch 429/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9049 - val_loss: 0.2977 - val_acc: 0.9015\n",
      "Epoch 430/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2896 - acc: 0.9050 - val_loss: 0.2984 - val_acc: 0.9024\n",
      "Epoch 431/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2895 - acc: 0.9050 - val_loss: 0.2985 - val_acc: 0.9012\n",
      "Epoch 432/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2897 - acc: 0.9052 - val_loss: 0.2955 - val_acc: 0.9027\n",
      "Epoch 433/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9047 - val_loss: 0.2968 - val_acc: 0.9022\n",
      "Epoch 434/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2892 - acc: 0.9050 - val_loss: 0.2967 - val_acc: 0.9028\n",
      "Epoch 435/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9048 - val_loss: 0.2969 - val_acc: 0.9029\n",
      "Epoch 436/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9050 - val_loss: 0.2972 - val_acc: 0.9030\n",
      "Epoch 437/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2888 - acc: 0.9050 - val_loss: 0.2963 - val_acc: 0.9023\n",
      "Epoch 438/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2890 - acc: 0.9050 - val_loss: 0.2967 - val_acc: 0.9026\n",
      "Epoch 439/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2890 - acc: 0.9049 - val_loss: 0.2959 - val_acc: 0.9026\n",
      "Epoch 440/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2886 - acc: 0.9051 - val_loss: 0.2963 - val_acc: 0.9024\n",
      "Epoch 441/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9047 - val_loss: 0.2958 - val_acc: 0.9027\n",
      "Epoch 442/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2889 - acc: 0.9051 - val_loss: 0.2956 - val_acc: 0.9025\n",
      "Epoch 443/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2890 - acc: 0.9052 - val_loss: 0.2973 - val_acc: 0.9024\n",
      "Epoch 444/500\n",
      "91704/91704 [==============================] - 1s 11us/step - loss: 0.2891 - acc: 0.9052 - val_loss: 0.2966 - val_acc: 0.9029\n",
      "Epoch 445/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9049 - val_loss: 0.2958 - val_acc: 0.9022\n",
      "Epoch 446/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2893 - acc: 0.9047 - val_loss: 0.2967 - val_acc: 0.9018\n",
      "Epoch 447/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2892 - acc: 0.9049 - val_loss: 0.2968 - val_acc: 0.9021\n",
      "Epoch 448/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9051 - val_loss: 0.2961 - val_acc: 0.9024\n",
      "Epoch 449/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2888 - acc: 0.9051 - val_loss: 0.2964 - val_acc: 0.9021\n",
      "Epoch 450/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2890 - acc: 0.9049 - val_loss: 0.2963 - val_acc: 0.9029\n",
      "Epoch 451/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2890 - acc: 0.9050 - val_loss: 0.2974 - val_acc: 0.9021\n",
      "Epoch 452/500\n",
      "91704/91704 [==============================] - 1s 12us/step - loss: 0.2889 - acc: 0.9050 - val_loss: 0.3002 - val_acc: 0.9024\n",
      "Epoch 453/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2892 - acc: 0.9052 - val_loss: 0.2971 - val_acc: 0.9028\n",
      "Epoch 454/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2892 - acc: 0.9053 - val_loss: 0.2984 - val_acc: 0.9017\n",
      "Epoch 455/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2890 - acc: 0.9051 - val_loss: 0.2960 - val_acc: 0.9024\n",
      "Epoch 456/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2888 - acc: 0.9049 - val_loss: 0.2965 - val_acc: 0.9025\n",
      "Epoch 457/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2894 - acc: 0.9049 - val_loss: 0.2961 - val_acc: 0.9024\n",
      "Epoch 458/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2887 - acc: 0.9050 - val_loss: 0.2971 - val_acc: 0.9014\n",
      "Epoch 459/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9050 - val_loss: 0.2974 - val_acc: 0.9022\n",
      "Epoch 460/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2889 - acc: 0.9053 - val_loss: 0.2951 - val_acc: 0.9026\n",
      "Epoch 461/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2889 - acc: 0.9051 - val_loss: 0.2963 - val_acc: 0.9024\n",
      "Epoch 462/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9050 - val_loss: 0.2960 - val_acc: 0.9030\n",
      "Epoch 463/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2888 - acc: 0.9049 - val_loss: 0.2997 - val_acc: 0.9018\n",
      "Epoch 464/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2887 - acc: 0.9050 - val_loss: 0.2966 - val_acc: 0.9018\n",
      "Epoch 465/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9049 - val_loss: 0.2972 - val_acc: 0.9025\n",
      "Epoch 466/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9049 - val_loss: 0.2962 - val_acc: 0.9023\n",
      "Epoch 467/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2889 - acc: 0.9052 - val_loss: 0.2968 - val_acc: 0.9023\n",
      "Epoch 468/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2889 - acc: 0.9049 - val_loss: 0.2969 - val_acc: 0.9025\n",
      "Epoch 469/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9053 - val_loss: 0.2958 - val_acc: 0.9027\n",
      "Epoch 470/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2889 - acc: 0.9049 - val_loss: 0.3052 - val_acc: 0.9012\n",
      "Epoch 471/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2892 - acc: 0.9050 - val_loss: 0.2955 - val_acc: 0.9025\n",
      "Epoch 472/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2892 - acc: 0.9051 - val_loss: 0.2970 - val_acc: 0.9019\n",
      "Epoch 473/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2888 - acc: 0.9053 - val_loss: 0.2968 - val_acc: 0.9019\n",
      "Epoch 474/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9048 - val_loss: 0.2960 - val_acc: 0.9023\n",
      "Epoch 475/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9051 - val_loss: 0.2961 - val_acc: 0.9018\n",
      "Epoch 476/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2893 - acc: 0.9051 - val_loss: 0.2961 - val_acc: 0.9021\n",
      "Epoch 477/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2887 - acc: 0.9051 - val_loss: 0.2975 - val_acc: 0.9024\n",
      "Epoch 478/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2895 - acc: 0.9049 - val_loss: 0.2973 - val_acc: 0.9029\n",
      "Epoch 479/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2893 - acc: 0.9051 - val_loss: 0.2967 - val_acc: 0.9025\n",
      "Epoch 480/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2891 - acc: 0.9051 - val_loss: 0.2967 - val_acc: 0.9024\n",
      "Epoch 481/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2889 - acc: 0.9050 - val_loss: 0.2991 - val_acc: 0.9017\n",
      "Epoch 482/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9049 - val_loss: 0.2965 - val_acc: 0.9024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2887 - acc: 0.9052 - val_loss: 0.2964 - val_acc: 0.9022\n",
      "Epoch 484/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2888 - acc: 0.9051 - val_loss: 0.2993 - val_acc: 0.9014\n",
      "Epoch 485/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9052 - val_loss: 0.2975 - val_acc: 0.9025\n",
      "Epoch 486/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9051 - val_loss: 0.2975 - val_acc: 0.9024\n",
      "Epoch 487/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9051 - val_loss: 0.2990 - val_acc: 0.9006\n",
      "Epoch 488/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2887 - acc: 0.9053 - val_loss: 0.2956 - val_acc: 0.9025\n",
      "Epoch 489/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9049 - val_loss: 0.2957 - val_acc: 0.9024\n",
      "Epoch 490/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2889 - acc: 0.9051 - val_loss: 0.2961 - val_acc: 0.9021\n",
      "Epoch 491/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2888 - acc: 0.9049 - val_loss: 0.2970 - val_acc: 0.9025\n",
      "Epoch 492/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2886 - acc: 0.9052 - val_loss: 0.2970 - val_acc: 0.9023\n",
      "Epoch 493/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2890 - acc: 0.9050 - val_loss: 0.2965 - val_acc: 0.9020\n",
      "Epoch 494/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2887 - acc: 0.9053 - val_loss: 0.2961 - val_acc: 0.9025\n",
      "Epoch 495/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2892 - acc: 0.9048 - val_loss: 0.2966 - val_acc: 0.9022\n",
      "Epoch 496/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2897 - acc: 0.9049 - val_loss: 0.2964 - val_acc: 0.9016\n",
      "Epoch 497/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2890 - acc: 0.9048 - val_loss: 0.2968 - val_acc: 0.9029\n",
      "Epoch 498/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2890 - acc: 0.9051 - val_loss: 0.2981 - val_acc: 0.9031\n",
      "Epoch 499/500\n",
      "91704/91704 [==============================] - 1s 8us/step - loss: 0.2891 - acc: 0.9051 - val_loss: 0.2962 - val_acc: 0.9023\n",
      "Epoch 500/500\n",
      "91704/91704 [==============================] - 1s 9us/step - loss: 0.2891 - acc: 0.9049 - val_loss: 0.2961 - val_acc: 0.9023\n",
      "39302/39302 [==============================] - 0s 2us/step\n",
      "../linkPrediction/dataframes/obesity\\obesity-results_2008-2015.pkl\n"
     ]
    }
   ],
   "source": [
    "feature_names = {\n",
    "'author':[0,6,22,9,10,11,12,25,26,27,28],\n",
    "'article': [1,7,23,13,14,15,16,29,30,31,32],\n",
    "'degree': [2,8,24,17,18,19,20,33,34,35,36],\n",
    "'citation': [3,21,37],\n",
    "'pref': [4,8,24],\n",
    "'cm': [5,8,24]\n",
    "}\n",
    "\n",
    "results = []\n",
    "names1 = set(['author','article','degree'])\n",
    "names2 = set(['citation','pref','cm'])\n",
    "X = ut.load_data(datapath, domain[select_domain], \"X-features\", times)\n",
    "y = ut.load_data(datapath, domain[select_domain], \"y-features\", times)\n",
    "for name,feature in feature_names.items():\n",
    "    param = [0.3,64,500,name,times]\n",
    "    m=ut.load_data(datapath, domain[select_domain], \"model-\"+name+\"-\"+str(1000), times)\n",
    "    X1=X[:,:,feature]\n",
    "    X1=X1[:,0:7]\n",
    "    print(name, X1.shape, \"--------------------------------------------------------------------\")\n",
    "    if name in names1:\n",
    "        y_pr = m.predict([X1[:,:,0:3],X1[:,:,3:7],X1[:,:,7:11]])\n",
    "#         row_maxes = y_pr[1].max(axis=1).reshape(-1, 1)\n",
    "#         y_pr[1][:] = np.where(y_pr[1] == row_maxes, 1, 0)\n",
    "#         row_maxes = y_pr[2].max(axis=1).reshape(-1, 1)\n",
    "#         y_pr[2][:] = np.where(y_pr[2] == row_maxes, 1, 0)\n",
    "        y_pr1 = np.concatenate((y_pr[0],y_pr[1],y_pr[2]),axis=1)\n",
    "    if name in names2:\n",
    "        y_pr1 = m.predict(X1)\n",
    "    X_test, y_test, model = lstm_classification(y_pr1,y,param)\n",
    "    results.append(cl.model_evaluate(model, X_test, y_test, param[1], name))\n",
    "ut.save_data(results, datapath, domain[select_domain], \"results\", times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/obesity\n",
      "author 0.7737720261046951 0.9080199480942446\n",
      "article 0.7762888488546066 0.9091903719912473\n",
      "degree 0.7683216576825863 0.9028293725510153\n",
      "citation 0.7520289792412126 0.9019388326293827\n",
      "pref 0.7435201646236598 0.9013536206808814\n",
      "cm 0.6969188507475792 0.9023204925957966\n"
     ]
    }
   ],
   "source": [
    "#obesity\n",
    "results = ut.load_data(datapath, domain[select_domain], \"results\", times)\n",
    "for result in results:\n",
    "    print(result['model name'], result['auc'], result['test accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../linkPrediction/dataframes/apnea\n",
      "author 0.7526146426250557 0.901040277296017\n",
      "article 0.7341798266561229 0.901040277455005\n",
      "degree 0.7834849635539409 0.9074419844179161\n",
      "citation 0.6870195657790688 0.9007735394992711\n",
      "pref 0.671423314516571 0.8978394238940555\n",
      "cm 0.6365607603955434 0.8970392105038181\n"
     ]
    }
   ],
   "source": [
    "#apnea\n",
    "results = ut.load_data(datapath, domain[select_domain], \"results\", times)\n",
    "for result in results:\n",
    "    print(result['model name'], result['auc'], result['test accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author 0.7976199802178843 0.9106894841269841\n",
      "article 0.7834611478880477 0.9105406746031746\n",
      "degree 0.7943377968137546 0.9105654761904762\n",
      "citation 0.7768129470077616 0.9076884920634921\n",
      "pref 0.7537172907977944 0.9024553571428572\n",
      "cm 0.6891570370334035 0.9040426587301588\n"
     ]
    }
   ],
   "source": [
    "#test obesity\n",
    "# a=np.argmax(y_pr[2], axis=1) \n",
    "for i, result in enumerate(results):\n",
    "    print(result['model name'], result['auc'], result['test accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author 0.759648860252997 0.8872040437237637\n",
      "article 0.7494976864217086 0.8933226923005129\n",
      "degree 0.7659086254724182 0.8951848896934366\n",
      "citation 0.6717593792650112 0.8893322693473895\n",
      "pref 0.6760764834182814 0.8885341847187092\n",
      "cm 0.7216259063484131 0.8901303539126437\n"
     ]
    }
   ],
   "source": [
    "#test apnea\n",
    "# a=np.argmax(y_pr[2], axis=1) \n",
    "for i, result in enumerate(results):\n",
    "    print(result['model name'], result['auc'], result['test accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pr[2][:] = np.where(y_pr[2] == row_maxes, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "article\n",
      "degree\n",
      "citation\n",
      "pref\n",
      "cm\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(results):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(y_f):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     y_f = y_f.reshape((len(y_f), 1))\n",
    "    scaler = scaler.fit(y_f)\n",
    "#     print('Min: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))\n",
    "    #normalize the dataset and print\n",
    "#     normalized = scaler.transform(y_f)\n",
    "#     print(normalized)\n",
    "    # # inverse transform and print\n",
    "#     inversed = scaler.inverse_transform(normalized)\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.120226892549391"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test[:,2],y_pr[0][:,2])\n",
    "rmse = sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1533.4943757214987"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xl = X[:,:,feature_names['author']]\n",
    "x_r = xl[:,:,0:3].reshape(-1,3)\n",
    "scaler = transform(x_r)\n",
    "# in_yp[:,0][in_yp[:,0]<0] = 0\n",
    "in_yt = scaler.inverse_transform(y_test)\n",
    "in_yp = scaler.inverse_transform(y_pr)\n",
    "mse = mean_squared_error(y_test[:,0],y_pr[:,0])\n",
    "mse = mean_squared_error(in_yt[:,0],in_yp[:,0])\n",
    "rmse = sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_r = X[:,:,0:3].reshape(-1,3)\n",
    "scaler = transform(x_r)\n",
    "# mima = MinMaxScaler()\n",
    "# n_y_f = mima.fit_transform(x_r)\n",
    "# i_y_f = mima.inverse_transform(n_y_f)\n",
    "# n_y_f = scaler.transform(y_f)\n",
    "# y_test, y_pr, model = lstm_forecast(X,0.3)\n",
    "# in_yt = scaler.inverse_transform(y_test)\n",
    "# in_yp = scaler.inverse_transform(y_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test[:,3][y_test[:,3]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3IAAAKvCAYAAAAvAP2kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzsvXmAXEW59/+t7kkIS1gTVBZNRBRBFhEQBPUiguCC11fcEJcXkSteufJ6/V2DCyrXfWGTfUcJSwiEBBLCZJnsy2QmyWQmk1kz+75vPT291e+P3s5+6mzdp3uezx9JT3edqufUqVNVz1NPPcU45yAIgiAIgiAIgiAKh0C+BSAIgiAIgiAIgiCsQYocQRAEQRAEQRBEgUGKHEEQBEEQBEEQRIFBihxBEARBEARBEESBQYocQRAEQRAEQRBEgUGKHEEQBEEQBEEQRIFBihxBEARBEARBEESBQYocQRAEQRAEQRBEgUGKHEEQBEEQBEEQRIFRkq+CFyxYwBctWpSv4gmCIAiCIAiCIPJKZWXlIOd8oZ1r86bILVq0CBUVFfkqniAIgiAIgiAIIq8wxtrsXkuulQRBEARBEARBEAUGKXIEQRAEQRAEQRAFBilyBEEQBEEQBEEQBUbe9sgRBEEQBEEQBOFfotEoOjs7EQ6H8y1KwTNv3jycdtppmDNnjmt5kiJHEARBEERRs+vwEB7fchhPfvsiBAIs3+IQRMHQ2dmJ+fPnY9GiRWCM3h27cM4xNDSEzs5OLF682LV8ybWSIAiCIIii5gfPV2JjXT/GpqP5FoUgCopwOIyTTjqJlDiHMMZw0kknub6ySYocQRAEQRAEQRCakBLnDl7UIylyBEEQBEEQBEEQBQYpcgRBEETxwzkQi+RbCoIgCMIio6OjePjhh21de9999yEUCrkskX8gRY4gCIIoflq3Alv/DkSnxa8ZbQdCw97JRBAEQZhCipw+FLWSIAiCKH76apP/R6eBOUeKXbNvafL/K+/0RqY0iXjy/0DQ23IIgiAKkCVLlqC5uRkXXHABrr76apx88slYtmwZZmZm8KUvfQm//e1vMTU1ha9+9avo7OxEPB7Hr371K/T19aG7uxtXXnklFixYgLKysnzfiuuQIifKZD9QuxL48LeAOfPyLQ1BELOJqpeB4cPeKxREfth2L8ACwMd/km9JCIIgdPntGwdR2z3uap5nn3Isfv2FcwzT/OlPf0JNTQ3279+P0tJSLF++HOXl5eCc4/rrr8eWLVswMDCAU045BatXrwYAjI2N4bjjjsM999yDsrIyLFiwwFW5/QK5VorSsgWYGgRG2/ItCUEQs43hw/mWgPCSeBSIzeRbCoIgCN9TWlqK0tJSfPjDH8aFF16Iuro6NDY24txzz8X69evxs5/9DFu3bsVxxx2Xb1FzAq3IEQRBEEn6DwFHnQQcc3K+JSEIgiB8htnKWS7gnOPOO+/Ef/zHf6h+q6ysxJo1a3DnnXfimmuuwV133ZUHCXMLrcgJ0jMWxgvl7ZiaieVbFIIgCCE45/jFimrUdI2JXXDwdWDPU94KRRB54L28AzcH3wJ4It+iEISnROMJ/O+btRieKp4ovfPnz8fExAQA4DOf+QyefvppTE5OAgC6urrQ39+P7u5uHHXUUbjpppvw05/+FHv37lVdW4yQIifImwe60T8Rxt720XyLIsz62j7saB7MtxhEkVHZNoJ97SP5FoMQYHAygqW72/HdZ8pN0+5oGsR9GxqwpronB5LlnlgigaEpf7ovNvRNoLHf+kQjFIlhbU2vKzL0j4fRPx52JS8/8glU4lg2BcT8cY+xnhpMrL2bjsRIsa1xEPEEdz3f5ZWdru/p8jtvH+zFU9ta8L9v1uZbFNc46aSTcPnll+NDH/oQ1q1bhxtvvBGXXXYZzj33XNxwww2YmJhAdXU1LrnkElxwwQX4/e9/j1/+8pcAgFtvvRXXXXcdrrzyyjzfhTcIuVYyxq4FcD+AIIAnOed/Uvz+bgDPATg+lWYJ53yNy7LmFfe7F++55Z8VAIDWP30uz5IQxcSXH9kBgNpVLnl9fxdah6Zwh9VxiCfwneDbqOEXmia98cnduKMEaOifwGftielr3jzQg9bOTtx0yQwWHCV2zcObm3DGgmPwGY/H/zU1SeX5jq9lv1u0ZDWuPvsdeOLbF+le98sVNXhtXxdW/9cVOOcUZ/tBLvnDBgD0XueKdWteRX1LK7594SBOPPmUfIuTVzYc6sP3nqvAndedhf/45Bmu5v3TV6oAzK52nVaIYx4oxvnkhRdekP394x//WPb3GWecgc985jOq626//XbcfvvtnsqWT0xX5BhjQQAPAbgOwNkAvsEYO1uR7JcAlnHOPwzg6wDsHfZAEARBqGgdmrJ3YTSEE9gEPsEr3BWoAGkfTp4jZMU9PhJL4FBv/qz562r7DH/vGEnfUzwX4hAu0tSXXIEdC9N2jb7RSXwyUIXOAfL0IAiriLhWXgKgiXN+mHMeAfASgC8q0nAAx6Y+Hweg2z0R/QHLtwAEQRAEQRBFxvETDfhwoBFnTFbmWxSCKDhEXCtPBdAh+bsTwEcVaX4DoJQxdjuAowF82hXpCIIgCIIgiKKFpTavMFAgGoKwisiKnNZilNLx9hsAnuWcnwbgswD+xRhT5c0Yu5UxVsEYqxgYGLAuLUEQeefbwbfxzeD6fItBEARR8PDi2sZEEESOEVHkOgGcLvn7NKhdJ78HYBkAcM53ApgHQHWEOuf8cc75RZzzixYuXGhPYoIg8sqJbAILWeFEbyUIgiAIgihGRBS5PQDOZIwtZozNRTKYySpFmnYAVwEAY+yDSCpytORGEARBEAVACWIoAQXeyDWMNuDTqiRBOMBUkeOcxwD8CMDbAA4hGZ3yIGPsbsbY9alk/w3g+4yxKgAvAvgu5/RqEgRBEEQh8J/BlfhhUGmjJQiCKD6OOeYYAEB3dzduuOEGw7T33XcfQqGQpfw3bdqEz3/+87bls4LQOXKpM+HWKL67S/K5FsDl7opGEARBEIQebppLGeOZoBMEQRQ2J2Ac4O/Ktxg5JR6PIxgMWrrmlFNOwfLlyw3T3Hfffbjppptw1FGCB5DmGBHXSgKFeSD4PMzgCETyLQZBEIR/KBBftjNYF07CWL7FIAiiwJg33YfvlJRiUbg236K4RmtrK8466yx85zvfwXnnnYcbbrgBoVAIixYtwt13340rrrgCr7zyCpqbm3HttdfiIx/5CD7+8Y+jrq4OANDS0oLLLrsMF198MX71q1/J8v3Qhz4EIKkI/vSnP8W5556L8847D//4xz/wwAMPoLu7G1deeSWuvPJKAEBpaSkuu+wyXHjhhfjKV76CyclJAMDatWtx1lln4YorrsBrr72Ws7oRWpEjCpMflLwBzhmAL+VbFIIgfM6sURoKxOv/C8GdqU836qYpEJ2UIAyhduwucyLJvvz4mAehKhrXA5N97uZ5zDuAM81PLauvr8dTTz2Fyy+/HDfffDMefvhhAMC8efOwbds2AMBVV12FRx99FGeeeSZ2796NH/7wh9i4cSN+/OMf47bbbsO3v/1tPPTQQ5r5P/7442hpacG+fftQUlKC4eFhnHjiibjnnntQVlaGBQsWYHBwEL/73e+wfv16HH300fjzn/+Me+65B//zP/+D73//+9i4cSPe97734Wtf+5p79WMCKXJFDmOFMWkhCCK/fKtkXb5FIAiCIAhNTj/9dFx+eXIX10033YQHHngAADJK0+TkJHbs2IGvfOUrmWtmZmYAANu3b8err74KAPjWt76Fn/3sZ6r8169fjx/84AcoKUmqRieeeKIqza5du1BbW5uRIxKJ4LLLLkNdXR0WL16MM888MyPf448/7sp9m0GKHEEQBEEQBFF0nM1aMcCPz7cYxYPAyplXMMXSbfrvo48+GgCQSCRw/PHHY//+/ULXK+GcC6W5+uqr8eKLL8q+379/v+m1XkF75AiCIAiCmBX4zUelQDx9C5ZrghX4Zsn6fItBuEB7ezt27ky6nL/44ou44oorZL8fe+yxWLx4MV555RUASaWrqqoKAHD55ZfjpZdeAgAsXbpUM/9rrrkGjz76KGKx5DEsw8PDAID58+djYmICAHDppZdi+/btaGpqAgCEQiE0NDTgrLPOQktLC5qbmzPy5QpS5AiCIAiCIAiiiCg2I8EHP/hBPPfcczjvvPMwPDyM2267TZVm6dKleOqpp3D++efjnHPOwcqVKwEA999/Px566CFcfPHFGBvT3g9+yy234N3vfjfOO+88nH/++XjhhRcAALfeeiuuu+46XHnllVi4cCGeffZZfOMb38B5552HSy+9FHV1dZg3bx4ef/xxfO5zn8MVV1yB97znPd5VhAJyrSQIgiAIYlbgtyNuKdAHQYgRCATw6KOPyr5rbW2V/b148WKsXbtWde3ixYszq3kAsGTJEgDAokWLUFNTAwAoKSnBPffcg3vuuUd27e23347bb7898/enPvUp7NmzR1XGtddem4mSmUtoRc4i1OkSBEEUMNSJEwQxC6CubnZAihxBEARBFCA+W1wiCFtQOybMkK6cEXJIkSMIgiAIYlZAOgNBWMdvLsmFihf1SIocQRAEQRAEQRAq5s2bh6GhIVLmHMI5x9DQEObNm+dqvhTshCAIgiAKkOPjw/hacBNY4qJ8i1Iw+G0u6jd5CELJaaedhs7OTgwMDORblIJn3rx5OO2001zNkxQ5giAIYvZQRDPnCyN7EGFDmBPqA/COfItDEEQRMmfOHCxevDjfYhA6kGslQRAEQRAEQRBEgUGKHEEQBDF7oJjcsxqORL5FIBTQK+kNReR8QBhAihxBEARBEEQeICWGIAgnkCInCFk2CIIgCKLAERjL+8bD6B6d9l4WYnYSHgMS3q8Mk5FgdkCKHEEQBEEQRIqP/mEDPvanjfkWY9YwqwzlkSlg58NA84Z8S0IUCaTIEQRBEAQxK2CzSWkg/Ec0nPx/+HB+5SCKBiFFjjF2LWOsnjHWxBhbopPmq4yxWsbYQcbYC+6KSbgK50DzRiA8nm9JCILwEpq0Em7TtAHorMy3FLahV4IgiGLCVJFjjAUBPATgOgBnA/gGY+xsRZozAdwJ4HLO+TkA7vBA1lkB5xw7m4fAvfQ1GO8C2ncDh97wrgyCIHwATVsJl+koBxpL8y1F0TCr3AoJgnAdkRW5SwA0cc4Pc84jAF4C8EVFmu8DeIhzPgIAnPN+d8WcPayt6cU3ntiF53e3e1dIeuTgce/KKBTadpKLA1G00BxRSg5qY/v9wOFN3pdD2IYUpyIkPJ7ce0YQsxARRe5UAB2SvztT30l5P4D3M8a2M8Z2McaudUvA2UbnSDJSVusgdUo54fAmoOrlfEtB5IKBenInJrwlEkoahwiCyB07HwK2P5BvKQgiL4gocloBTJU2rRIAZwL4NwDfAPAkY+x4VUaM3coYq2CMVQwMDFiVlSAKl+rlwGBjfmUYaZu9VkvOgZrXgH3P51uSvECrEID2UEbMPuhlIGYH1O/PDkQUuU4Ap0v+Pg1At0aalZzzKOe8BUA9koqdDM7545zzizjnFy1cuNCuzHkh1+dx0JSjyBhsTCpz+WT/C8C+pcnPsRlgaii/8nhI50gI0bjGOT3hsdwLk0fSA7lmXRD6DDUDfbX5lqL4GO9OroznEe4zRY7O+nLO4ORM7vu4aBgYbsltmQShgYgitwfAmYyxxYyxuQC+DmCVIs3rAK4EAMbYAiRdLYtq4xFZNohCIJHgiCcMGmsopbztex4ofxxAMsDOAxsa0TsWtlTWL1ZU52TwnInFMTkTE04/Gorgij+X4derDnoolTGmzyFXpDouq89pYGIGUxbqvOg4sAyoXZnzYitah3NeZk6pfC65Mu5zGBJgIONHIRBPcDy/uw2rqpTrCx5zcAVQ9VLSnVrB1EwMoUj++0+rRoLhqQgOD0zivvUN+ORfy7wRyibTkbgv6tSPmCpynPMYgB8BeBvAIQDLOOcHGWN3M8auTyV7G8AQY6wWQBmA/49zXrzmfp8SiSWwaMlqPLKp2btCbGq0D2xoxEf/sN5lYQglX3xoO874+RrzhJPZeES1PeO4Z10Dbn9xr6Wylu5uR1md93GN/s/DO/ChX78tnH4inOzsN9dL3LdzbIkRfg4eI7r6sOuwvLu++Pfr8dkHtnohEgBgU30/Fi1ZjbHpqPA18QTHoiWr8a+drc4K97FV7oZHaX+d14g8/puDb+G2IEV1zjVzEjOWr/n207sBAB0jaoXKU6ZS44tG0Lhzfv02zvtNbiK71naPY9GS1ahsG9FNc829m/HoZvN54af+vgmf+vtm3Le+EW1DOa5PE86/uxRn3yU+D5hNCJ0jxzlfwzl/P+f8DM7571Pf3cU5X5X6zDnnP+Gcn805P5dz/pKXQs8G7Ew10hb0x7Z4pMhNjwKb/gT0Vlu+9J51Degbt95JE9ao7rLuOphIGZ6no+5EMY3FExiadO9ZH+wuvAAldp5DPlmqESXXy4H8HxubAACNfRPqH2MRoHV7tmGmmIkl2+cf1tR5JhcxCxDQ5Oazacxl4kYGJ/jYrpBzTg63Wr5me5M/1wxiOfLI2NyQVChLa3t10zT0TeJPb5n3m6Oh3LR5O0RitEKuh5AiRxAAgKnB5P/9h/IrR6Exy0bqX686iI/8bn3e3SBc2XsyM1nQewkLsum1bgVatgB91g1GxhRiZRjTM27NHTrD9GgyYm9BNhBnzL47JojcUtM1hq88ugNhl4zDhDGkyPkU2v9MFCpv1SQtg9OR/Hbi8jmqzenbzgczewkLkwKctsZTVuFEce2HCEViGA1FXMuvvGUY4ahNK3Xt68ljEqYoejRBEEAsFkMQ7ozZj75Wiss7n8DBNjpSOheQIkcQs4FZaHl3BZ/X24vl7TjUo+966m/pZxfX3LsFF9y9zrX8WoccHCWSVpJ93r6tsq99xB9BhghbtND5ua5i5fV+9IHf4faSFa6Ue3a0BgAwJzzoSn6EMaTIEYTXFNlkyYxFvAvfCb4N8Pz6tM+GsN53vlaN6+53PyjJHSXLsQCFtc9PnPy8j50j03kpd7awv2MUX3p4B+7fYHxeJ59l/XEhMUVRCfNGbLgt3yIQNiFFziKyuWHZH5Nhqj2AhhqiUPkk34MT2AQQze/EVTZfK9LJ27GYwhx4M/k5jXnvdmfnqTg9ByxfTeEM1oWLmYuBWjjHqYws3mn6RsbxpcBWdHR2mKQszr6AmJ347VxEIveU5FuAgmfIw1D/HjEdjePlHa34t4uPx6J8C0MQhG1uLnkLvfxEAF/U/J3neVWUyPKFoLtHC8yfys9hxAnOweC/fdxHTXbgPYE+HD1dCeAq3XR+s+nMBs+BfEGrr8RsgFbkfIqXfXtj3wRGpyNYU6MfrpYoMmbhgDZbJkjvZIV7iLSdR8R8p0Lkh2A8P8e5PLCxES+Uq4+rIAgi9xj1h7NlDJztkCLnU5xMu2fhnN3n0APJB65ErSxwqC9QQ1XinAEXz4kkCK+YDf0fuVYSpMgRwnBwVLQNIzRDG5ILnVgioToAvJgHPc45VlV1UVS0Asa99mmeUcvgFOp6rR9EPzYdRSTuf3dWzpN9QK6Jc+5huaINxF8dXTH3u8VMNJ7AwIR1g8bkTBT3bWjA7pbcnU8aQAJ+a/eEe5Ai54ADnaPoHAnlWwwVXi2nV7aNYlvTIF7Z2+lNAXmgrL4f9X0TnpezuWEA3aP5DP7BsevwEPpSBwi/UdWDx7YU3v5OJxwenMLKqi5L16w/1IdnduRnL9JsZSwcxZrqHtU5hG5NQ0QmziururD2oHXX82d2tODlPbl3O7Ta529tHMSDZU0YDuV2Ze3F8nY8WNaU0zL9D02wvcLLml1V1Y2l5W0Ym45aum5gMnmWZPlhd1ziRVzN/6vkNXw+sEsov3MYjXeFBilyDthY34/lPlRqvLLwRePJiVU4zwc9u0lV5yjequnxthDOsa9jBMsqzaKpecuuliG8mJpktg2rV6aK2Z/e7jtR0z1meaD2FQVo7l+5vwsN/RMoayjMw6qHptw79FsUq4+5qnMUADAwkVtZBz11yRTrwPz3SvhOIEKA9HEikZj/V+AB4H0BMSPm1cFKjyUh3IaiVvqUIp5TEz7FzgSnUKYgud5H8BFWjxPYJIDP5bRcJaLPtBD6G/ci0BVKqyWsQc+VyB2F0Nr8Z7QgvIAUOZ/i5P0r5pUVwiYF3KOfxdrxDjYCJ0pRrsNQfzxYndPynFJIrYM29xNFBTVnz6DjB4jZAClyBOE5hTGY2DEA5MJmcG2wPAelEH5B721x7S1KFMb7SHgEna04e/BQkWMolJGdKHZoj1wRQZ2KPylWq+D1ge1AojD2jxXrMzBHbNLqx0V8rpAq/QjpHDk3ma3vhY+YtX2TW+jXH9UsMRsgRc5nMAacgkFbnfvsnaz6Gz88Fq5nhXYg3HsDPThqsjAOBvbDM/AzrlVPNAxEnEXyZZn/taVy6lpJTWF247e+wGfiFBx6/YTX+OW5GfWHtM1mdkCKnM84bvIwvlqyCe8K1eVbFBVkCbeHH/b0mE1eGBLgRexy5odnkA9EJ63HR/vdKXDbvcD2+93JS8nsfIQeQ306UdgYteCcKO1F+AotYj34WKAm32IQgpAi5wJfe2wndh1253DHubHkIbRHxsbEL2pcD/QcoHkOYQsWDeHHJa/hA/F6V/P1V3v0lzR+Y3G4Nt8iZOCZ/xWuleA4jfVjHpy68+q3hd+9WYtFS1Y7zJ/wN/7qC/wljUcc3gSU/dH7ckLKs9lyULt5foBeGNj/PbgdlwT8t5hAaEOKnAvsbhnGT1+pyp8AnXuAuuzkwysrlJNVjbNZK64P7HBRmsLBDy6vuhJwjmAkaTx4b9zdg0Dzf9dZfPAI8kL6to9i1s/vOivgvdus0WNRuUwlYrghuAVfYFuclWlQ6JPbCukw3CJcCsgBvusKZkPn1LYz+b/X97r3Odmfs8ETw+geZ0PTIkiRKyr8/NJeE6zAewPdOS93eCqCq/6+Cc0DkzkvO40fHovuHjlZmhwIQuQWBw/1nUxp3c4NeuoJTyTb8IkYz50wvqY4Xtim/kmUHux1L8MC2RiUXnGeDcqGl8gMPtFwHiSg50fkFyFFjjF2LWOsnjHWxBhbYpDuBsYYZ4xd5J6IswutIejwwCRuea4C4Wjc8FoOjmMxiRJop2sfCjlaHSrEPXLranvRPDCFxzY3500G0b1nB7vHTJ+xGUHEMVfhehZPcHSMTDvK1w6iE5REgnu+alks+/+GpyIYmy6MSKFGzOERfIgdNt7f4lZ/01AKVD4ryddeW+Dc+3ZqlwLRXTT59D2bceu/Kt3L0OQZ+eUZ5itIR17Jcd17UdwvVlTjm0/uMisZZgqeW6IxDpzBugDOMR6OYlWV3GCez/Y+Nh3DWKjwxyu/Y6rIMcaCAB4CcB2AswF8gzF2tka6+QD+C8But4UsVg50jmLRktVoGZzKfKf1yt218iDWH+rDnlYTC3k8gptL1uKTfI/qp0M94/jEX8vw+JbDDqX2B09sOYz71zfmWwzX6BsP43MPbMMvX3e2wfjbwVL8sGSlrPP+y9o6XHOvnjtaNp3bk0EmeFzTe3++Bj9cutfdwouUC/93HS64u1Q4fa6t/QOTM+gZMzcaXDyzE58O7sWcUJ/qt7TEyomu7TvpqgTGe+xeneHGJ3Zj8Z1r7F0cFltFPKHIVhv/Z3kVbnzCbNIrZ3PDADqGnUU+LSSk8+zGvgnc+MQuTEfEDXpj01F89bGd6BwRr7N97SO47flKxIvAwCXtJ1RGLg+UmKW727G9yTgmwm3BN/C94Fuul63FiVMN+EJwJ06ZOoj/XlaF/3pxHzol708+jZg/e/UAzpeMV5/62ybcu67BUh6NfRNFYbz0EpEVuUsANHHOD3POIwBeAvBFjXT/C+AvAPKxtp0z3JzsrqjswPtZB8oOqSczVmgfDmFoagaIxwAA74baTSU9MO5pHXFUll/4/ZpDuHe9tQ5BhPahECIx8QNjV+7vwkTYuJPRm0wv3d2Gqo5RAMjksa/d2fM5jiWNAtLxa2vjoJD1N5+G6rdqsm12f8coNtY5eyeUuK3QVHeO4V+72lzNU5T0c5Iq609va8FoKJIXeaQs3d2Glys6TNMdyZPDBEvEdNMou9r0/VrtgoemZmSTXLsW6p0OAlq1bXpWKN13Skrx7w9tF8zV/8twyyo6saPZWr195+lyfPKvZfYLNR2k/au83P1mLXY0D2F3i3idvXmgG+Utw3ioTNzr5IdL9+Ktml70jedmuhZLJHIyGRfpe+zw+r4uTM7o9VXq9nQEi2A+M1as3Xp758SSY/7c+FTGiBaOZQ0BTlr7WChqaT5kxuHBKdy/wZoB/ukHfo1fPvTPzN9ldS5FWC4iRBS5UwFI347O1HcZGGMfBnA65/xNF2XLG49tbsZNT3q/sHj6VDU+G9yNE6aaMt/Zeblf29eJf+1qy76wgpm0Dk2ZJ9LAv8OgNZSD2Nh0FJ/4axl+saJa6PpDPeP48Uv78T/LDxim05s43rNiO7720EbDa5/b0YrWQevPKSEpM2Fj4toxHMIFd5faKjuN3Xbyj0cewIHnlwBT7kSCBdx3L/nCg9vwK4erp06RWlrvfrMWd76mbrc+8SKzRUKnIxO9peWVnahsG8a/drVh+d5O9wSzwevl4pOX/R2jgu01myYfz3l706BneSsXEXY0DeKF3e3472VVuoazTB2YuVa6IJ+bSJ81K2QfWQNWH+jBMzta4HXthyL6hiG7VHeO4Y6X9+PnGv2rHzDb8iKyP16P8+8uxW3Pu+j2bIN3sBGcMbot8/f/fVbtcaZkeWUnFi1ZjeGp/Bs3c4GIIqfVSrI6A2MBAPcC+G/TjBi7lTFWwRirGBgYEJcyx/zxrTpsszBI3VGyHO+PW9+DNTeetNiUxF3ev+S3kcoCiQTHmuoeJHLgDvCXtfJw+1Mpi5vosw+l3F96bVo1v1WyDt8Mrtf9PRyN49erDuIrj+20nLe0+owUOWknL51DrNzfhdFQFK9UWrdwco1PVjg3kIoceOBlW9fzWAR3lCzHOYns83W7NZ2KAVzCDrkB2CjXAAAgAElEQVScqzOcWLxd24/mIVaf4U9fqcKXH1G/O4Ws3PqJW56ryFlZNz65Gz9fUY1X93bime2tOSvXU/z/yrlGy1DaU8T9l8/rapxKKYd2x3mvMTsQ3GmdbyiAFTClK3LaW6bN5mJFoSGiyHUCOF3y92kApLsp5wP4EIBNjLFWAJcCWKUV8IRz/jjn/CLO+UULFy60L3Ue0Xsnzk/k/xymXE1QnHScZp3K8spO/HDp3ry5rVllPkJgDixe85m5Ej9uY4Iu7dwTXGxjvdvtx3l+9jJg0WTnfU7CfdfbNF8p2YyPBQ96lr8IQms2glXox8ALatdK7e99g4svkFhW+a2JfEVb1Ltr0cUs3yjyGnL4JRCLV+T6/twqL4i4fsOxXERxP+Ncs6N5EB+8ay12NA+isW8Cmxv8u0jkFSKK3B4AZzLGFjPG5gL4OoBV6R8552Oc8wWc80Wc80UAdgG4nnOeO3OdH5AMIj1j0zjzF2tQ221947qTVzwzsGoMaG52HdK8vvTwdleDjvRPhGX/+5ngzBi+V7IGH4qauFbaXF10MgYlJLplSTyMs5m2Ysw5NGdATspO5+ansNrFOEGSrqb+MLgSC2IuhnD3I6ln6PxJFktbKJb7cBkzjc4n1cYlPaWSYnWx9KLqvTZCBSMTuL1kBc6IJg2DCzCGUzGAzN34fGwpprHvKIRxNOTG712Hk0EAy1uGcfW9W/Cdp8vzIVpeMVXkOOcxAD8C8DaAQwCWcc4PMsbuZoxd77WAhcj62j5E4xxLd+dpVcngvXU0Pmhcu6991FLQkVz3KVbLO40NYA4XWwELpFZ+3hE3nkBbUWi0Utp5ZtIyr4jtxCeD2gfWm0lm58iJTJ55GkC0ii2mwUyLuSyKD85o7eEo3PtWSm7VMHAsJjEPWgeh+79O/C+h/xDdI+e/2vWbPN7BE+4FzhAqz4W6LYmMAQBOjyXnczeVrMNXSjZLyvAL2gZZJ3vk/MQCjOHWkjfx/ZLV+RbFd5SIJOKcrwGwRvHdXTpp/825WIVNJny2jQm4IzucX3qU8R7gqBOBkiNUP/lFRC1YNIQbgpsxkjgdwLWu5ZsPNylpmfMS+qubPJHwzKLpJ93JT7K4hdgt+fPGbUllMWrlzSVrEeZz9bJxH5cy/ligBuDXCaRkOp/9wxzEEIC1ieRpbACj/GiPJPIfxdg36VGIK3JGJQPWnx9z+YEzqQ9M2ilLMvksFiPmTSXrxBMXyT2LInQgOJFFRDnL7uXI7eBqNWql/QIMiEWSh+8efN0jIaxhSZlOhUI/kY+5LIW1CHTZb+x3Rlz22SSKm8HPdmTIt2vlbOnCC/mQc32nMnUaJVbueh4rvKhllwTqLE++GPNnW7gluAa3lawyTyjhhuBmfDtoYdKWItPXF4hboh/3pXpNzvfIedpHcsX/+UE6zh6dmMTHA8ZbPXxFPAZs/gvQl9/95oUOKXIekDnvyKXxxPKEOJ/9Ck9FDxrv0v5ZsCMvJoOKlVuRNhkndSCrZ6OolfaLyGmelsrX9q3MvSB+QPC2izFqZfGTrRG/Nu8jbCrSc5mNAE+ibd2ndTUb8NO+abfw0z1dHtmOjwQacEw0e3SPrw1+0SkgEQeay9zNt0CMOW5BipxbcPVHt5uS+XkhHr+wOXg3crnJW9kBe+dxZTPYiZMyBfPRk82Nx5A3lw6t4C0+GmzdohjuyaiZqe7OrfbknW+lwS/WXqjCf7L5xLiui20lrJAU00KSVRS79+RWVUjnhVpuzNyiazNReJAi5wFafsqGCKYrholbIdyB26qk3Xt2oghJLxU9k88tHTrjNpevYCda3xVCw7OISP2KPoN8TW6tlFqEj1AXsecm3QfjnSyFh4kreY6kEMWtFRN7QbFyTK5dK3OQmfV5mbt1YFq+zzuHkVAEsRwHwSk2SJFzC0knyjnHmaxT+Hwxtza/+vx9BVAgMrqtyuVhRU5rhVg7Gc/MAFxb8HAnG/vl51sATynqm5OhPkfO2WAfTFmmj+7a5iifXJAo7kYs4whEcBwm8y1G7tEYZhiP43TWZys7K00mX45nVpv1d58px1cf22mY5lx22KhEawXmkJw8Aw78eW19LkrS5KOBQ7iY1en+PjYdw3M7W7H6QI+jco5ByNH1hY5Q1ErCGsdNNuNzwV04bupoAOeapucAGvsmcPqJR2n+bjloyuxyDzbEcODI0WTJtuuFkz1ysv0zBi5ffvafd5HZcZdq/H7fRl3VO4d2A/isa2UFUorg3PF21/L0C/l4zqejN9lJOVzKvzG4AcexKQBfc0ewQhkANR7aueFKXBjci7mhSwAsFMqmIFbiMuVaM8Zsqjc/3PmKYI1+eTkY4/0cFfJQ7zhWt7bjB3ma6b8n0If3QN8wEYokA8y1DmkrYiLHVRw/3YZbStbg+Onj7QlZBNCKnAfMiScPLDw1VA80bTBNPzkTw9X3bsHPXnUYbSjdoQjGejiFDam/NEJjxAggAWahc/aTe+hpYfHz7xxh27fSQZGya/PkWimoJP4ouAL/FtjvTuHJktXf+HiwtUshK+GG8d5SX5bEw8moZpnv/X2/bp7XVAgrcl9kW4E9TzrOJ6nE5Q6/9AVpzw+pNPMT4wCAQGxa4wr3cdTlj7YDPdbmLEJV75PnI4zVfjh1f+7fZXY6n27jCQ4sZKOul5QrRJrC/Jl+AMAxM4MeS+NfSJHzgHTbOyI+BXQkT5lfursNh3rGNdOHo8lIj7tTJ9TbLleg0Ts7p05dwH+VvIb/ExB3Vcp1H22knJwQtefCYhW7m43dOn7AdJxJDyx5cq0sYXFcEGhSfb+tycWOudAmBy4h3ob8v4qRiye4ECO4yMAVyAijJmbVSGJVSc9b856avZMn95A8PP+/hln2LQXqrB3OnPPjB3JamhjeyaTOeQEfwZeDWz0r0SmmUxMLtVXd5faxUYUDKXJuId2TlLLMSvvkX6yowXX3e/tCZRq9x4OB8tU6PdCPqZkYfr2yJrNUbpcjI8O4o2Q5jo74Z4Lwqb9vwo1P7PK8nLNZK+bx7OHdTsa8LfX9eH5Xm2k+bg6shwcm8eTWw5iOxNO5O8pvb9uIreuKWWeTBiVRGgg0lQXR4z6cCOUAza5K+mVXpetlGt3rN0s2GLpq2c3XKgmrq3uFpAB4wGfu3YLfvlkrlNZPXiFAcfdXSqyON+/EEN4Fi55D8gLtX6vEtXeMu5udJF/lGHA0crOy6xVW2kt934SHkvgbUuREEWhPkVhCntbq1jbHb7a+ayUAzIEzJcsoCudjWw7juZ1teH5Xq6Myjg8lrz9pusUwXQAJzVC7ltCpp/FwFHGJRfzwwBR2NKsHk+moWH1K+6KO4RA21fer0gTCo7gmWIFPxLabiZfhUM84Lv3DBgxPqc9q+n/L9uGXr9ekyjfYI+fipObLj+zA71YfyuZNUSs9pRjvCVAEf2reCMSS7dstV1LP3BZdzDdXj7YQQ/FrDUN9fd04DmoXzb+X1mPREmurRrkin3WfHt9yLYHeeCP9Vuqi/PWSMnytpMx+eZKMK9tGMBOL6ye2XYY/Vs8ZmPWI6TbpGZtGy6Bzl2gzKfWqKhyN+8ZF2g+QIucSY9NRvP+Xb2FH82Cms3Lmxij9KGhVN0g2Z2YE/1nyOk6baXQgk34B8dSmVNO9qS69fN8LrsGPgq8LpQ1Cu/NWSiLtGNKrWUAyItIdJctRVp7dx7ViXyfueKlKqHxpOVfdsxnffWaPRqJkxR0pW5EzrqtHNzejdzyMLQ3qDeEBC22Gu9TnT824P0i6xWw4S8fJOei5XtCxdH6cS9PNdB+1rtYbl2o3JxaWlVajssufABrXOxMoR9itw++WvI1PBNX7tTaVleK24Cqa9EkobxlG/8QMgDy4OgoU55VIX35kB36z6qDr+Vo2hnp0g7lcab7sjxtx5d82eV6OXj941q/W4omt+tFKj05M4N8C+zLzqmKHFDmX2dk8ZNnSxgTDv5seCG7gWnlEJLn/7l3RDkuyyfN3nsqtPuxoFkaAmb+kR8wM4vaSFTg53GqaVirbkGSV690suYLWWrUl893GOvNoWlpkVm0FcFJV0jZo2B4592zgzNfUSfN+inAe5+4kzE8VpN3POb3f9ErcSEi9gi3CmawTlwb03fdcrUE3n+3UINCpYTzyIW73RVcF9+IIFpFNCHMVJGhwcgaLlqzG8spO7QR5coeV7j3OuX6rU/eeVYWiuIPd2nEK3Mjb48sICXMQwxv7u1XffzGwDXeULMfHZrbjgkAz5oRyEwch35AiZxGRM8akneN9Gxrwvya++2b7RObwCM5jzeK9rtG8XSwHbVxYrs/1ysiR00klbEHEigJrXktzEyF8Oii2f8fuBFTrslg8gd+9WYvByRnDa0WflNNBJRibAsLam4zdjOJnhVy2sbxZ+ps3Ys6Oe02TFeJKhGcuZw7r4nPBXcaKnIt1nbB6QK7dSaXPLNZGt3EspvC94GrMjVnfC5OPt6A15Xr2YrnxcRfyZ2B9jOUJjsWsR/jc2nz6ZOutGsn2/haYgUpE3A2H+jJnpXnpWqkkEs/t+z0ejuK7z5RjLBR1JT+9sfw/S17H2fFDqu8XB3pdKbfQIEXOInqTjGPZFO4oWY5jZvqyKVLv1cbtO3BHyXIchbDmtWbv9Yend+NTwX04YkptgZDlY3XwByxFHRM5uLyQ9lxYllXST549VY6TmKB1TyzmssY36u/K6gfw5LYW/HqluIuIUemcO3PIWNizGdj5sIMccoOrk4OxrIU910cAZJpg+26vcvYvymcYjwr4cmfxeNuIq1h/K3Pf7+a6xHMCrZjPprFg0vqxMdLgMX6xbYgYhUU4dqoVXwxux6JQNRAeB8r+CAxruJ1Nq8PQ57ouxFwrvRFqEetBCXdHwZAiIu33nqvAf76wV3aF7nVlfwQa11mW46ios6jn2lh7Fiv3d2NT/QBGpsW8HsxyN2oKF0T2KdIWUAfvMqTIucwJ4fZM60tbSM5nzQCAk5lxFD7GoDnbmJvaN8W4s2AlmpQ/4X6eBuR84mvwbisHDNMBRPKzlS5De++SyIim/iq9ST2asrQdAe0O04qSmk/XSi8Gba02dkSjQMCDA8uAzgrzdHv/lS3LimB5wZ8ScsX/8t90XCuVX2z5G1C/xkWpnOHmHhWrRjm7JTt5/eIJjrDLwSPE+gN7q1aGdFYCPWJ7nl1DUyTrD6QknjxM+Yj4BDCeMvZ2yye56K0Gdj0CjLTJBsXcR/DM8Z48SXn/HtyOSyLlNvLQaW+pr62PYQLpRcYhBSeE7W+b8S0GdVtIhjmvIUXOE5KNbzxszfrDObINV2vyL3DqhmHeSHdKNjtTgTeHJzj6xsO6S/r+nFamyFht5fdpZjldEB+0PCNSTSw0nzdwWeAgToL2gZ6nhJtwW8kqzA2ro2CKKnJeDuQinj5eKJFaeQYmdPaphMezrqFDzZYtofl0TbNddftfBAbq3RTFZZJ31jwwhcMDk5kHqtlWe6sVl3KgdRswo+F+56StjRq7xwHuGql8cdZ7PJZUCAxe0se26AccsIPwpJhz4PBmYEJsD4y87WiU0VgK1OXHKOD0UQtNaNMKnsIDx0n/2zY0hapOa4dNi/mmeNf453MHe+SUYtl2Z07+fxzX6qPcvndn2k6uPKz0pBSrDtLoSJHzgPRg1ODSuRZmQU6y5Rr+msrLAQJv1XQsjhf3tOP1fcZuoP5AuSKnncqsM+MA0G8UBEHLbVJOQuPJ8FgUHw0cwg1sk2a+CyNdAIAjZuy7VHCusyqSo4mkaTEt1s9eFGrj06PJm9z5kCPXUD/Mt41RGgw4MNIK1LzmfdFdlcDMZPbv3uqk21BMbH9n2/AUVh3oRih9zIdIo5zoSbaZQ29q/OjgaQkocm5idZ+nJ+9r23agfi3Qr96Lki3XxVVIk8BLsn44EQPadgD7/qV/gSJvyV/2BPQKmWy5nZQ6qYkV+7tQpnGUjmF5Og9Yaix1sy3nxAPI8vEDkvRR7e029vGvUsM5x0dYPU5jA9Ivk//pXWPQDyrvlDEfv+MeQ4qcXQxPWXYhf/++j4ZEU1EZu8e0D6IUXcHIxz4GR5bAuIFPuMbNqOpBI006yp7WeXnyod+4sRj+yr2sa/OMTSeCrdtslKqzvJlmoi/pZuTCYdO5dhWWFy6QJF/iTY8ADaVAzavZ79p2Jv+XrJZpuh0rWmwifeaVkDk/9a5ovo+FM7h74q6lWY7Bj9Gkyx5ibk829WWxHKhI4wa0+jvb72nc/T1VSnL9jh4Rm8D3gmtwrMa5e37Abwe2m551Zndlzs3MkJ4HuLRsmMnTPTgHPh6sxg3BzdJvTa/RhXwrM5Aip8E8zOB4GK+mGQ+0Diw09rJIXWM+CHIw7bxjAptTXYlaaVqI9UxbtuhY4I1ReTeaWAuF7abTI0AkO0hKr/sAa8fnAzs1ulvzVTsryKKAGeXEueGKo+hqsF7ebiI+uU1P/LnimxTTqRVMF1ZZcj3pcOzqkrOl1lQ5aWXA2sWaf8vu3c59eHzvrmZvOWil3cL9E7WSw5061PQwkPaHVsrY8jdgUrLqFIskDRQi46UJRu+yly315Ml6zGchnB1oc3ePcvsuoPI5wyR6CrXsWzdXeV3LyT0E/Hts5uufu9XajqLt+WOmyBnNTZRpZ69iJ6TIMcauZYzVM8aaGGNLNH7/CWOsljF2gDG2gTH2HvdFzR3fCZbiuyVva/6W7ocMF+RcNqYKHwhu8BvTm9QCyb1BW/8OjJpsluXmN28a2dLkd/nyuCCt29V7ZYSK44q/xMs23De361Fgxz80f7ouWI73BbpUA5pWJ2S0emnWZVnbI5e/AcBKyVa2z+QKVydCAw1Ab4142bYKyVHlpI0+DgZqVVr5hdZl0iMaBjrKHeepWk2qXQlUPgvAunkqkaNG7JcIjkCqLegIdAbrwvksuR+PM2ZZcEf1OSEJad5ZnlzJbzI/YN1Oy2Ya37mPwVzACc1l2b14uiWLeGm4JVCusOcGXcxqh9b8Q9XXc44jOrYb5mNFkbPya7FhqsgxxoIAHgJwHYCzAXyDMXa2Itk+ABdxzs8DsBzAX9wWNJccyYz3cCQxsqZZXJGT/mGw6mW6OiLYA6pSjbYl/x/TCQiRLt+NFbk8ddIiK0tp2eazkNDqplBm0LZCqtuIVsdnv3jhc+TcMoOXP4FLmVwJEcnVk/aQjhpbaK4XNa8Ch94wTPKxwEFcyKyHX8+QsxcwXfd27M+KYEOpCI62jlcRKA2NpUDThuTeQSe5K7PvqwXGe+zl5Qvreu73a+k1zy8Ed+IIJrYKpu1aKW07Duo2PS64EeHSB91TzsfjHBeYi2BU1g33bq4CSC6V3KpbBkY3g52ocgqPYs6g/v7b5DUG5fvg/fELIitylwBo4pwf5pxHALwE4IvSBJzzMs552odmF4DT3BXTfxgv9FhU5LjeH9YQu1Le+sNR8fDRKtVDU1YzKcx+9+btNN03Bcjq/l2T6nPaTo50WIpq+PMV1bjk9+u13SYVdaddlekvndWJ2apk1kLooNOeGsTFTNEpC7Rla6ugGkwOAF17tX6RK9MezR9yvUfuI4EGfCJ4QDi9VL5km8vVilwgXWjmq6lIDAe7tQ+Pl6NcKTdPI4JuG0jvAUu4G0rfCQmrB/nabOBubhFwirU9cg6MpTlCuNd2uhIscHlj/yTu29CArtEQ0pJdGqhNBo3JIc59i/yHXWlHpiOIq4xTHCOhiK2DvPd2SI63cqkKfxhciUuU4zqAOYjpHn2ULF7Lw0j9RXr8txO1UmT1+oTDq/QzKCJEFLlTAUh97jpT3+nxPQBvORGqEDC2DlsdZLjsfwC25u7CboQS2R/d0my9gNRKB5eJm/wuPW/UFT/HfbTxooy+MlUSV6/KlvBI5nwXkdWeF3a3o39iRmig1XLvNppkmavDXPOzVj5OHslb1T1Ysa9LN28zrMxhNOuj4img4W1FOvE8N9b1obS21zyhhJ2Hh7Jl5WvSwZhlq2tSj8vxnihJecsqOrDuUB86RrL75sTaSLp/lH1pQxZvn5VXBxl7id9kFhGHwbprpdl9xhIJxARXfDfU9eFfu1r1E4x1Alv+hkBs2rBs42NtrE8AjK7Y1Zzss/Z3yI8LYJHcBjwRMXx52yTdMxRzjU/Wrksat5Q8t7MVq/Zrj6l2ynBCkCXwsaDaqH1z8C3cVqKvJGm6VooY0y1h/iwDtvZoFx4lAmk0PRU0EzJ2E4CLAHxS5/dbAdwKAO9+97sFRfQXmW1ihoncKMiFPLzKWmNilVFGTSaKTs7Ccxv1gOFV2ep8lXs2tAcv+5Nu4T1yDldp4pyjbXgKkXgCceU9ieRrTZMT+i5t1RfxrDzQlVwhukZcCuxukShyPpsIK5kzoQjoojDGeAdX/A9MhJOTlqhFazPPRK2U9zh+w822kLCocNst2fi6XLtWcssBjYTzlihpWkU8WNaEI0qCuO0q43wGJmdQ3WWyqty+C4hHMXfS5AgezycR5nnn6i3inIExrjsmCAfnslquazmpyTiPWy2ES9ui4uLU352j2lG//YLY9iM5tmL6GSj+yiHMVnyFIkFkRa4TwOmSv08DoOqhGGOfBvALANdzzjWfMuf8cc75RZzzixYuXGhH3pxiZ2BOBoC1dt3ulhHzRDrIZDQc/J03csbkzUVa9rzoGH4QXIUj4yZn53kw8Y0lErZcEYxW5LSTW5P9usBu/Dj4qmbNJ9QhM9XFOXDbCyKBORBzm3HjkTy8qclWxla2C1geL2dZv67SzSJTYIc3Zf5Mm1+6R6cxHfHYjTBj8TIz7AhkZbHo6WjcNXfM/GFRVtuN3Wi1PunmlSuE+zsGGytyen9kmYmp34nannHZeL6pbkCVxgwz7418tspc9ZHpSbZeebIaclMoF/IyNz07KENl0HXHYyJnbcrWarOF7IXuROIqPEsRUeT2ADiTMbaYMTYXwNcByNZUGWMfBvAYkkqctRMifYxMR1L9ZjBVsNh5jEwk3RvshHqXyZj+bOKxoZQ9GufY1zEi7FqSKU/y+eRQA+axCBaGNCb0OvLqCmiRZ7a3aisSpihXkOT3/2J5O376ShXOYslVjbq+Cayq6jaVcnV1D8pbhvCBQEfSCqlx03FV1Eoz6fTR6uy+GdyA/yx5XTCDVDAJlzrftLVOyKXUZNVx/aG+bFqN/Gp7xvHSHp1VJ1k52e+i8QTWH+rDWNj5GVFursJ0j02jfVjMFWQqEpO5eGoxMTWJNw5kbW48kQA4x7LKDizfaxzYyCnhWAL/2NiI+t5x44QibSTTL2l1dnL6JsJ4bEuz5kHFeo9qciZZl0aRDXeZ1HVSOvn1uw4PYV1tn05qEywacey2Q6PLtjYO4rmdrZlVa0NG2mQu+3YRn8harB9J+iMHq5IH0wucEVda24tdh4ctldU+HMJT2w5jYka0f3GnDxHPRbq7yL3+a0fzIJ7Z3iL7LpHgshX4XEetdFWh0RseLb+rkiwVq0hubbnOmcv/pj8BY13YfbAZr28uN5ZJQ6SqlKuvnrSGUSsFpiuHB/15VqLbmCpynPMYgB8BeBvAIQDLOOcHGWN3M8auTyX7K4BjALzCGNvPGCuKHYZGVl2jF8XqS3RFsAYBJJLXGbROkaAZEhF1v1Tms6a6B5sbBrC+zlgHV16n7elmfO9edDBafuaZ8gyKUy2KKb6487VqLK/sxHsC2cnY4cFJU3ka+yewQzrx01IsFBMWLYVGqy4DsWncFlyFE2LGluG5TGwS4bZF9mhkXUKEFDmDNIwBNbLgGOrEpbW96B0PyzLK2DOkr5Lk0p2Hh1DTPYblFRaUGT3DjYsVuKyiA6/tE5Op9GCfqYtX/KD6bMVEarI9OGHdNcYKPaMhxDnHlgaNdiqdyNgOiKOjyI0lA5fUdqsVSD134+UVHdjdMoQ9rfoT9q4Rc1cn5a3sahnCwR6R4C5qrLpW2ke//ltSk6BOs3sfaQP2vwC0GYcSN5WEezf9TEiUzCMHU3t+BPeHTc5YCwiytqYXEzMxHOg0MWKkcNqFWPeSlvSVLlZ4eeuwyjh252vVOPMX2ZAJIv2llyqIW8ZKZzJIPivmHK6997l0Rxltx84Xf4fWdY8YJlO+3V1j09jfOaqTOn2NCPqpjPr0YkJkjxw452sArFF8d5fk86ddlssXJDud5IuvjJBj6CLAld+ZN8cSxNOF2pBR/dkKoWhyoAqZDViK/Ot7tdwo/em+pLnaqVTkFH9fFajE+5jJPgfY20misrwJKsVHhrpxBIvgfeFqoGRuqnz7J6pIdy2YttNYJBvhT4dMO07lboa1c8QM0nKJEYSr31GuSComnUOZHBKLJ5DgwNwStb1tWiDabHBCvmGeA4i7vPqqx+v7O8GgCLpj/gpqkl4pcx4hVPv6mViyTpR7PF3K3mZWVlec7BZkfqVpvxBJGbdC5quWsnIVDYLzhOwZtw+F8O6TjtK8vKFvAmeCCysx+RmVOK4IVAOJj2j+6tWengTniMUTmCuQ1ut6eblCcTat0DvmnlS5WJmyWgLn+vs1Ey6sakuZy9yLSlrROoxTTzgS7zruSP1EnOMs1o6gpmFa/rdqe4lWdgb1YTzv8ec81CuEDgQnJKTbh1FEQRuKnFNxxNNbj/ilWVZvNb78YJkqjdm7ma/gEGJWfXmncW6gRX9Tr8N5cDyuXJETXG3VwNFglRAPMFDz5j+w8Zm7DNPMhdQiK6LIWRi4DOV0btCwg5dFfeHB7Xj/L7UDAMdsKDWcc9cnCnqkVzvN+j6hZ5UOdiK/0LJMZlfkylYvch6e1dvL/zqDc5Jxl7I3/om/qscXAKhoHcGXHtqGut4J8QFQY8VeC9uusBocG+nHRYF6XDqzwzCd233Imuoe/ORlsXPu/HFeoRw3+29XdWWdvJzUoTromUsCezAw3fDoTlz1982GaY6bbMa1wXK8kx7lJwQAACAASURBVKlXwowk0j1+wOgag05vtu2PJ0XOALttQfwsnCxHIQxmMqnVskBIl+INyxW4GfMDx5P/HR8fBg69iasDlZJr02lMNTlzQVzEituJXdHMLtM8EFzpWqk5uctxqHgT1lfUmO6X+WbJhsxnp240OgG9NPFaQdFVOD08R+5Qj75rlnKPJSDWfkWsoCYZAGExlzHAHSOW9t41vXwNDiL3uO8RNUoIuRx70a5GO1SFG5aSXuDOkZrIZf4B+nSMToOBY3BS3D1YdIKc3gMtv1a4mPQVsv8DOv24V/XaNGDm/p97tZ+nztfRa9dc57PzguV/Buzk7sKc5gzWhQ+k9trLvUMU8wC3bt6jvi5kEiSrJKHvsSNiwFJd40EQp2KEFDkDjLaf6bcvpmpDIt3md0vexmV8n7E8mqs22p8N87HvhwMACKaiIR7NphW/SF48nZsWLzoHL6KqIuyV2TseRtRg4qX13JSKRzqFbOJrMpnjLO32axYVzUg25NV85daEVVqfWjmK7HHqGw/r7ofRq6J8WbRjcTsrcomMAhhgCaFgDypatwA7HzJV5tLt2HRFTmTVNp1G0dltrOuXnUknu8ag71aSjiro9Em6G2zPYmYGybvHpjE2HQX2PQ/0yyO7iRTjiUeJ5r5hruoP9OqBARiaFD842d8WemfCSe+te0wkbL1kddJDQ5R2ySJWDH89LD2ZzeeCWb4Q3InrguWqC5TzALcMkqdO+S+Co9tPtXVIf4+rz5qQ55AiZ4CRO57xqpv8undoLDNr8R5ufAiktmHaqibnxBonz187J5OJW57esHfMtAEJY2uSsGgaCTeZBIpRZyHgXpVpa9o17YZdNe/noFmKSqWfNqHxHsxFFBhpBQCsrzN3mXpxTzue3dGiLabONfmqP6MIi3pwrthMP2nDjWyoOfm/yUGrhm3TYp+V2SOneAoHukbxqm70TXefC5c0Rl6rHctLuPsQUl7dW2FeVtGBZ9Ltelp+1I2vXN01gp3o70XnaB2aEj44WXS11NW1KveGWmGa+5OrcfK9yjnGwEAk5KXhpkFE9beNh2JgTLCHRJFW5O002Ak38EhIr4rmC70z80wuEslZ4JvihhQ5AzStuhrGYXUa+Y+WNpwaRq3Ul8c0W2nnYXOSoCzrGEmEwrTU7hn43O106rsGEWmS+3ero3DaF94oUILWT3rnyEkHGi15pM0jYxE067bMbsujyZyItdfKipZV18q5iAD7X1RFp9ObRAIGe890Cs/XgJEQeD+0hjc77i1SIvGE0BEJp0LfsHHcwecwl4ufT5Z9D6QTIJP7MHkwTlxMexsqLBdq9l4rsfqYRPr09Yf6EBIIkpPGwElVjo5ia5XkgeDy+zALQGMaUTOddz4UVtN+1+gn6/JKe4RFgV6gx3yfnCf1clh/H5VQaa6KZCOz/kPAYKNwDk6qUKm45XiBNMuUhUBFdhGJ8GY5hQCcA52VwESvG7n5ElLkvMBu6+Mw7BW0Ol3ZAC4aHMOmfMry57PshI5nExnnIaxEutOjScVZtbvOsAQnK3KGir3WlFo1U0umkSvc1sqxg+6uFM7xbtbnuY+CFdcezhOobBvWnITLBsTU5+loHA19E0DCeeQu3XMj872iaRFlkB2rvL6vC6/t60SHiTL3MagnkWllZmBiBkfxqdR3AvWXDnbCpV85mCUD+PWqg+bl6qCKxJcu0Wh12WJ/5tbBwFJqusfw1oEeZUGu5N09Ng0r3r7a+4bVT03/ORt7KyiR5qNlGEizMOLt+YpayG+RaXxnAUl1xPrq9NNpFT7U7MpZgJkopprF6RnEpHHB87w3/ODrQPXyzJ8i+/qswA2mbE5dXVnmvdAoV+9dGWwCyh93VK4Itp6rzRdBdVljKVDxjK28CgFS5AyQeQCpfjOyvmrz6cBeZ/JofSfYzjMriR5vdDad2Aq/l+5PkMfDigm9qgjJYG+0MsoTjoOoKC1xmhMbk06dZf534OShU8ZJoSb8n+BWvGNKYDKgl7fDNMp629E8hC8/shNPbD2sSitVUNLXxRIca2p6MKAIipCuL1n2pgYIPRnzpcgJWDM1Jgl2XDKl9KfOnzM6uxHIng8nPScu3UrXHuzFxHQ0JaPIfaQmJ5K2anYfZrm+WN5uksICnAOJhLhrpWsuRdaT2zZeGdA1Oo1lFR0oPdhjnlhHDgCaEXS19Apuo8fTPm9V/d17p6uT5+I5IildMCG46iyTQ220EC1PyZsHzI/OydTLUDNwYBnQsctKwXq5Wv5FZeioW508tD1N9z5gTMyNNkNoGMHBenk5toZKbamzK9YW31XpZ+UeOZfGE0vZTFnbFmIX1f5XEY8dF6ojV5Ga84nQOXKzFc0VkUxHazgF1fz2GGbiBmLWyWiNRbLP5jJpnXMnitFlwm44wmXlI7KWZNJp8Hy1OlujASI4PajOQxXsRMPCLDw5Mxg4BSa8WmnmxpJnBB4R1zorUFAuoUm6eCfbPZp8fxr61BbfhMZkKE1UZ6lAcYqVSenuWmWdIrLfQTPITo4OmubKT7EZHJcYQ3q38HQ05RxqYY+cFNOVxVwp2H21QP2a5L6g824VukRMj7Mqv0560/ffuVI5kToEumfM+IxJeZbaY6tSHr2JbWbiLzpMCNbnidHe5OHmjkiW9c6pOpirUtYVAb3yJCM8AKBP4Hlkyk6voin2UNohwbMrBEdjGiexbGAkYRtGzwH5l/Vrk/9feae4IHuexBHTciOenW7B3Dht//mp940Vs9LBDf7Su8Ju3WbrMZFIFP2KFSlyBmhZDNITfMPmZfNltKO6SC06Ts8dM99rJTAxd5ggu8qUi4mYsmMRK1PLwmNUNUc3vWGaB8/MS6SrDs479QR3Fjkwnyu4TBkAlnOcjBGAn6pKm5CuyNkTxN7PHioMp7M+HAPtyZjQIKicIyCRqSfPzSTKwru1I/KKDebp/0XeDbHnsVhjim0rGEDtSuvXCOBa1EpRF9Rx9WqaZm1oKmB20MiHc9W5X1p75BZiFN8t0Y/wrHnwvOCKnCGhYbxr4gCE14XMsjc8B8t5v2J0lHI2UUL+nd1yD7yS+Sidk3w9WIb5LJR5t8yOWEqK4FKfmoi7oCQbvFpI1poTk4vSUGHHs1KrGWk2d+tZS/LjeC/rxjCfbz8PVZ7etQXGs+XFeaLoFZ1iV1Qdob0il/rfhmulaXkcltf+xctKKaBm+TeuA/Y8ab8sbjxRtPxe9lYDh960eFEWw9tVCCPqn25ZwdKcQwhY4gRX/owcjZLlGK3YJQxXH73GStHHTHfjxpINeM+0en+T9JkoFVdpXcv3YliQU3fFw0ImFvlycCs+E9xj+3r1wCmZONjzMZJgw31AenX66AwRC30i3afwTNZx3VXW1LqEScP6XGCn7rV2EZ00iuwVyZnLbrqYGfGzAfXysNKitO6OK344nfVpdounwzjaqrbOpluiOFUvIcjF99vanIKmrlVcHQ0DY9r793RfZa17ZnLVw5XjUzgHhpoyf0r7Yuk+ej2RgNydbGer2zPZp2mZhHS1SDkHsW68PW2kXONbd/uPBAeuD+7Ad0vetp2H8t7EInfbLi3zKeFwX3ghQIqcAXYjvIlMTuygORTJNnEbXJvpMJjuJIGBAZ0VwOSAgCw6q3rZuZbulUKkkx16M6nMuYCdOH+aqRJW16k0DAI658jJvhMNqsJjwPSoZslJNxcjRU677MweJwcjrJjbpLFsUubGkpPNY2Lq4zxk+1lVGoy+kiciRzILnfZudl0+g6GojAXc+YHg4oW7lxOX/w8YrTakSzdTJJ3JpElcLCKkN66Vujk5+NVaCcxCpWoqW4mE7Ll9ObjVdM+QuGelVHkxEMKImLjrqGOUslUvA/b+yzQYidyjw3z8cKWdKQ2iWnKlJkVmZ7K5JpORMDazWBjv0/QssDpPNLpXp3vkuOJ/t4i7MG6o3KaF9sjZjLAuLSfuPNiZ3yFFzgBDG56R0iTwGo2GImjq14/upJmvVsMXfr949l+Ra4Zb1DmIKI1u7MmAfOXEiKgFa4tqEq8x0c18NJiUJHjCksuh1h3HVdYpzZmNUP7v6i0Ddj2iWffJ+rbWCTf1T6Kuz/7eOCu4daC27EBw5cCqmmholFn+hK1yPdw+YZyvjTQcQCJ1lqJzPcZYAtEJidjqVDpNdumH6733guVaNdKK1Be3sFpjmpfF90J38uuogQZSskiTG1ScpQBQWvlwlTjKflIEra5bMxSNYP963/oG3PJcBfa0jWJ3i3iYduGtDiKrhWnXV02Zszf8zs611sp3oYOyMkEXEsmpQG4jFbo+W7+aQbMsZ614ntNiZw7bKstBr+84CMueJ4Gocr+iSN9vszzJhXGT84OLAVLkDJBb8eRLTYaNUKD1ffvpctXJ9EmvB/m1k3UbcHwsHSxDna9sr5WBTGl5OQIGVjHJ91UvAeExVQr1J/nf6TxsdxmpC4+JqgOEaHHzs3LXs3/ubMWiJasRTp2XZPQotA8ASIlhFOzEonVKKyvVPjvBvSfarpXpC3T27pnu/5L//ul7NuNAh/LZW0eolhwMEI0SZdPI3TUmsFLCw9ormuYXSuSfHgF6qlDdOab9u5toZKtsG2o7RUI+MR7vBjpsum7auK/R6exBwVbcGDUNITrPOz3hEMm/b9z5CkuCZyMtMlHLr8he47wdKKXmpLHaZATBRMLQbdFJ9Fwg+ZyV42pCYxJmp2a0m4s6J707WH+oD9uazD1V9PK1iv4WUK0+Plsek32vvlw1fqjdF0TEU4ikMJQZbjuRy//C7nZ0jSqDwFnoG0wNx+6hrinFN5GQ7l5g2XUyg7g8jyMPLVcmt4WV7nlwcgZPb1cb7qWIG+Z03qDJAby1NRsRdTQUwTef2C2QoW1NLvMpIegpUciQImeERrjrkVAEP1t+AOGYgdIkkPWBTvVEWd2ncjz5/PPoGxlP/anOOSoa5IGnV+TUL5ruAByPan/P9TtQ045VcIJyQrgTexs7VKHjlWxtlCt8D5UlffVHQuahn2UKWTyKkmkxa2uCixzHnEXb4KqcZWslSU2QpIEsjRZlNQb5aCxu6FoJyURUi6OiNhUcCD5rK/20Qs6r792S+SxVUJRZKt1CtNq72b4a/fOPJN/v/SdQtwZfeHCrrixuIbQip9XEJBPjseq1aNntTbAOJXvbR+STgXR/JHAjaSVd5PiB9GqsSP189A8bBFIZ8+iWZty/sRGltb1IJHT6SwVCcxOLLkWNuivoitUSznHd/VszSuxPXjE/NPrISKpf1Lm/3lReyrcqbHD4uN77pvzevf0tYnuQjZiJCnhRIGsE3N8p1ndq9+l6K6z6daqsf7GhNpXIga+x8l00VOQkP42Fovj5imp85+ly2VisdXltz7grhhc7mK0ccc6THjHb70+u2E0ZG6Er27KRQZVG4emIdaVDrQhbY0vDIMbDxn2XG3all/Zkj3y5b32j3Nim0/xMX9FoGHPixvdvd4tUIUGKnAFS61F6PHlsczNerujAxjrtDdexBEfvmLMXK41eiHopcoXSaMKufwqlsBtPxvKqtswyRRo9y4yV/uDmp7Zj6W5rZ/qchDFcGdgntGomi4hWuxLHdYhN7HicQ6/n0eo0xMLAK9LMTOLIwRqtEgAA74xoHEqsMeBEYnHD1Qlu4nBxYsjYUucU445a2U6TaK2WsvA40H9IM0+Rc2S0xLhvfaPk92SKqort8uukhUWSG/uDkL+Tj2xqxi3PVZjKYAXdauuqBEY7UmmUmlwi42bCAPxzVytW7rd4NlMKq2fztA8pDxBPXS+mySWTysrXvu6k5tfE802RmcPasP5GUv1vbc84/vCG1vtqD6kktzy3JxPiP81EOIqZWHbS989dbajvlStzXW1N2Lpmqey70to+HOrJBjYx6hu0Vm+0JunVXdqr9z96wejcVHU+mscPJNSrnAkEDfIVLk7zy7q+CTy6uVn23TXBClwWUAdY0jRUhYZxclTxTtloV439ExiSGjHTD8PEtVL2bY4iRKqPjDAsMPMx3X6b+ifx+Bb12aBSSmt78eIe9dmPeuI39U/g1b2diFk5pV4H8xy4fI+6iSvfP3e1Zq9UPCOtezRD6dmVkkiNA2Xd9LiXdBEGbU7a10j7LgDaAkdCmF9lsuVh54N4x6T6rFvpHCFOe+RmH72Ss1d4NPtZ6at/VIn2YLKqqls2UFohGk/IXrZoTGEl0ei1ZqIxo58l16Yt1Uw3nZlrTGYibaD6mY8L4h3rMcy6Be7a+BacH2gGD5s/A9lkcKRVM9S15nU8gWBAu640tzFqfGeqpB98DUcN7M/+3boNmOiV5TUaUrQPjQEkqcjJGZmSr1YqxTsGIZzIHESx081ZK4W8Hoz2PM6LZAdL5QTkqIMvAQdf1wwGEBdxrdR4SC8pBlWeSKDsdXlEV607lK6AbmkYwJ/X1mH9IeNIe5bRq9qGUmDf88kkSj0uHs9u/GaSlUobkznRvUu6OeuUqWWRTu9vkr5buoqkg3mb0/2aVe36lni5m7553Un7pppDh/CTZfKVs3N/U4pHNmUVDgaOn0pW177/zwose/wPqNy9WXbdpInl3RAeN5z4K+eJ6w/pHzSs6faXUL+HP/r7syitkhuTpCkYxFzdpatGyyo6kn29zr2ElZNMAB8NHFKZvDTdufcvNZwv3/zsHpz3G3nkPy1l+qXydlz/4HbV99ZWajXcUpV9gk7VhaNx3RXVRIJjTXWP5G/xaITSdywc1Usn/h7qpbz7zUPoGAmhc0RpQLJBqn11j01nzjIVEkIoa4OLBdw09dB6T504PnMd5VS5B9+wf5B8noklcBIz2Yc/0mJet3peY5ILY8p5dBFCipyCtTXZDqprX7bDTc8vj0UI72OdOGKOtiL3HtaH8wPNmr+l+b/PlONs1ooLAk2y7yOKASQWU1oSNFbkJJ3tJp1VwuSlKUXOYJQJJsLY0jCA+zY04L4NDZiakb8AWxqSewS4gTtefW9SAdCz9B7oHMXZd63FoInLZGX7CG4IJichLYOTmRFnLBTFmFKB0eCRTc3gnMsHVcWtKyejGyQTD+NgJxwlQe3ftSa4tRqKfZ3ku0SC4zGFFRgzExLFGdixfgV6yx7LDLyjoQgaUu5UE+EY6nrHtVfkojHVs/h/v/9r5jNPyCc0UzMx3FKyBh8IJFd1DvU4CHpiYy/Qmb94S3K5/Ld5A8mJKof6kO+G/klUtA0DiRiUblQi+xG3Nxm71fIEx0xE7a77yxUHZJMFDo6ApPybn8vuQVtX24fWwSn86vUalbvnP16XT7jdQHWXiURqNVnubqo3SBvmbfGaf+2Sr6ynJ9/SZ9wzNo0P3rU2089ky+L43RsHceuzuyTXa08C08/CzpEaTlcngrJDaA1WwTnw38uqsGjJaiNpMp++XlKGZo3AWMoeKL0yNjUTw7pa9wwHnANtQ1P47lM7DY1dSnlOhrXDpTnU48onggdQtW6pKmWaSJzjjJ+bH09zy3PlCEuMBNOROHY2D8pXvSzy/efUYd/HJibQplx9lowlffW7cV5EPkHXMiB8JNCIxGjyuIG/vl2Hv5fWY3/HKMAT+PIjO/CBJSvQNx5Gfe+E7OrDA9nVGa3VEXXAL+2+8cN3r8N5vy1VXQ8k3+UfLt2rvCSD0X5laX8/red6K/gaVu4qQ9OhA4Zp7LzRjf0TaBnM1qM0j2WVWU8YFg1ppIDseatWngCUSPoJoy4nXKPfP9z05G48uLFR9/cRrTmSRK7mgUnTOZgUqTE0FteXX08x7RmblrW9aJzj6qBzL5Wm/glNF2apFF94YKvq92KDFDklkgAfW+p6MRGO4voHt2X8kC8P1uDzwV26IU3fycyjDpXVD+DqQKVhmkg8gakZxYum8Y5IrVqb92hbcBYtWY0HNzQAAFhAHewkvRL3rrEq7O3IDr7949kBaWfzEDY3JC3O8URCu6NA0rUUAKYjCSxashqv7ZWfffPsthaEInHsPqyup73tI1i6S+1asLKqOzPgnH93Ka68W3tD8KIlq5Ge379Z1Yn2YbU1bnvTYGbVVTrZGglFZX7i/Qb++DzBUaK3IjeptkJXaXQ095TWZz439E8kFTEF6bOy5rA4yluH8VJ5K2ZSyv1wKJJRGHY0D2LtwV7N6EwzGq6VUgOC9JfpaBzn/FpuLZ5IK/Mu+Zm/UdUtWzmwMtBWtmfb5nQ0jvexbNva0TyIbU2DiMUiqkxlES11jnDdJ2n34d5G9Gx6UjZKcQAzM2pFrqJ1BL9YkXWpiyc45iDbN0hbyff/WYFP/W0j1u3ai4rWYSQSHE39ExicnEG84tnsvUXiaOrPKtBaE36zepuaialWFGOxCGai6nuI2LBYWgpHHRpWtcF0OPLHVm3C7o3JfXodw9OYB/XkgnOgasdafLVkU+oL+YRh0ZLVGJiYwaIlb2J363A6iSEBlkAACZniEIxaiyKspESyAvJZxeRBef+v7tU+EyyN3v7SeIIjHI1jLqIokbSzeYjiJCTHrp+9sA2LmfqAby3SctX3yt0jZ2LxjNLWOzaNFfu7sLdt2NiIlmrs4+EoOOf4eklZ5qfugSE0t2ddDrVWbfQmtUdx+SpIUDIhncNiOJPJXRm1vCUmw/K+cSYWx38v248fvSC+6nEE5Pd+fova7euZnR0qZbdtaApffHAbAODqYCUuCtSjvGU4M5HuHJnG5/+xFbXd2THgXWwIX0vV30NlSSPfpoZ+zESj6G+vw20lq/D7p1/B9fetR1ldLwCgeWAKB3ukgZZEXMqTssbiCcQk/eR0NJ5xG1bSMaw8G47j8ED23QmM9wAd5fjxS8Z1m+it1nRZfaumVyii99Y3/4m3XrxP87ejE8nrrUS1TrO6ugcrq4zbqpT00x4JRbCxrg+Jqpczv/1lbb0s7eDkDK4NZI17Y1NhoPJZYEht/H90i/6CwLamQfyttEHjl2Tb759Qz18YgOGpCBYtWY2r/r4ZV/51EwAgIuCxEpEsKtz5WvY4qD2tw7K5nJ4x7OWKDlkfuCAkd6WdCEc0OwCzfvzN6h7MaLVTSV4BJDA2HcXYdPGuzJEip2Dl+k2ZzzVdo9hUP4ADnWMyKwQAxGfsrVRc8vv1uKNkeWYiI+VoFkbjnvUAgLL6flx37ybZ75xzjE1Hce5v3saOpkH8/+ydd5yU1dX4v3dmdulLb9JBUVERDWJDY40ltkRNNMYYE2PUNJP3ffPDJCYaTTTNFruCYENQEJHeOwsssLTty/be++y0+/tj+swzdWd3ZuF+Px/YmafdO89t59x7zrkmi40fzndH/rlKr73fWjJmLtDZzVOS9TqSjd6rD7ZGe6eVV+Pdedo8ZpOa2o1cqbMLrJVNHX5CohNnY+0jTEwRFTzzhfespQ4bU0U5nRYrjyw6wInyJrB0QlMZ27ICm+JYrVZe3pjDcJr4kcE9U3gGbnOmM0UpyVb7bzBgpa3Tu4PqMFl54P193PmGfVD1FEa/OOBtvrM7SISyFeklfsLCsZ1fIW02bPvnB7zPE89VG8xG7tbbBb/aVrugnVvdyrLDdmHPc1bvX+vdA0OKz2arxk7/jqqt0xzSR845mDe2mxmH9u/euPS/wX5OgGf786vFh/niYCmNxzdS/tUzXoNks9HMGDzqpkm7jTUXHebhBfu4TZ/qd66to9MvZU8beYGkf0th0HyvXfImSzbtZpDZnZcTxw5h0lCCQFLX1snkeavJrmqhsLadRwxrXGe/p9/GZA+h+mrdEe4zbOXn727krjd3c8NLO5j9/CavJ/7ms8Pc8NIOgqE1XiZL9+B9otx/YsBoMtOhUUd+8sG+gLOzj310kINF/pMuEfnI7XvHr646uViXw94tdpNYXWcTjxm+dvVVTiSSOTq3H4RVSj9FMr2k0SeoT2hF89eG5V7P6Ve0NeC1Sw74+6T6CkuDcP/GLB9/tSSPFXwpJWdQy0yRz9HSRk1TfL9VGkdE49fnv8ezz/wfTxi+4lq92/T6Rn0aDxo2MnneakblfcGd+t2aY4xA8qThC0YIu8A/0qH8VTR5/5Zv/nMb27LtfYFzK5IRoknTH8eJXifI27eGd557gh+9sd5rEmPxK7/n63f/5PEOYP2XCynMd/dnTR2dvL1NS3j1rmspwluxu1XvHf3O2e+vPupud30w0Ve42299mwmBpDwCf3adCFDnbTaO7t3Ak3/8g+Zec2NFHdYyb6Xme++4N6R/bVM25WWl3PraTtqDBIgB6DRZuE1n/71Ta7fwY/16l9Lja0YopH2iIquiSXPvTXAL3n/5OoPXt7on+O7Q7eYOnd20s6Wlmbw8dzlZLCYuEe72aDRbWXm03PW9sbmZ/L1f8VW6+5iTptpyCqrt9b0y9XMu1WVyv34z1+nd72f1+nWsOuZ/r5O61k5+/lHw1ZxZHfaxYVdeYHPn93ac5EiJ9yTr1xs2Bn2uJlYrGzIqWbS3kKNlTeSVuOtdUV07lLhloJufX0Yfj3q4d9krlBTmQ9YqbTPQnf+Boj0Bk37iE+8FAYMMrKwIAQW1bQynie/odnKu6RjtJgvLDwafVAK4+V/uCd7lh91K7t6Tdczf6FEWQX3k3Azt9E5zgDC6XAIAqpraWbrzWNRWq40ewe6GiFY+2FPAB3sKXFZMpxqGcC4SQtwMvArogfellC/6nO8DfAh8A6gDvi+lLIxtVnuA1hq+qXevFgjg7e359KWTaTrvjqW9Jbrw7ONbjxHMV1tvtTfmJCz0Nbd4lVD/tmJOlJ1Di9HCq5tzeebWM70VAgd9MHn5S12jS2eQQ5CaZjxBR3am1/UN1XalzDcqlMVqsW8O3lDI8KoihojAs2R6h1P6AOEWCO/U76ZJNwT4ruvYkKq9zNGXMjItk5MF5/K7+g7WX1sGDYVcUtpMm07bN2vH0WzE9pe4UneG13HXLD1wmz4V5zj4oGEjj/63k3kXu99D0AYR1gAAIABJREFUZ/kxnjQco7JtGDSd4zVz6mtGGozKXR8xdpj39cmyk+asLXywM7jTtpMb9G7TFJ3J/ZuHihYwNrHjaJ7WbZzpMfvsu/q7eH+h3/V5+ScxiMDCQXOH2TWYjxSN3GvQMPGTkhPH0/2Ph8Bqk7QZTeh1gr7JSQAMppVhooWFn9mFhB8Z3nFd/8vXlnjN4gejrjRbsx2t37WPPnlrvI5tWfwfr+/9G+xCyBmmQrSMU4odA+ptFvfgtXfVAsY98TfNvJysqOMJ/WrWHvdfpR8j6rlLv5t3LLfRQV/GCPvKX19MmpFrAVLzqrhYuGdbvZRbJzZ/pbK5tpw3t+k4d2wKuv7+AnGnyUSHhnno4cI6BunaOUdjWm9E1ke8ljmKhX97ymvD5462Vkj7AM6+BQaNobC2TXPluanDzIr0MmbqAisAAFg6GFijHRzDV2m0SajyEMBninya22dyv36L69gAazPhDNmWTrfwtDMn8ESS1vr7U6+8zwUe3+fq3SuzQ/Hux5L0OtdaY1VDi6vfuuP1aQA86TMS+85sD5bNUJONLNrL6CDOLklYSBGB3/WlOu++/0pHnpPb3aaYL6zNpLLZyHSdd4W4Q7+Hn743hJ8GkBqSdIJVX39OkoBvVC7xOqf3UYKyS2vIPLidvGNuJezvqzM4XFTPwz7PL280MtLjN7eZggcvMFdlcvyTeeR6+KX69murj1UgxHT6Jem7bG1gLj3MltWLmRykXG7QH0J6COSe4/alukzGiHo+sVxPa10FgzyeU1bbaB/PHXyaWuilCPQTnVzDIcczveuMpbmSpVv2U7H1bUYM7APAgcIGxg3wME3N20H10L7oS/aCgP2F9cyZAVN1dmWkrLKSNUveoa2mkCf+/C5JSQaO7tvK1R51fe0Ob0XDudo8VfgrY/vXfcRByx7efnaeq78YLbxNcC/X21fpTpRr94/v7SygLmN7QDnKYrEGNPEbYbP3pY3tJt5Ys59FooOr58zm79+xt+T8HZ/63RPK+mB4/nK2ekzGrPFwz9mUWQUT3eafPzT4K4rLDpdy+yUDyC3zl30KqxqYYNqGftIVSCnJqGjmvDMGu9M6VsF0j/Yy0NpEIJuwZGHF2t7Ig448TKKKyiYj/UToCN8PG9z75/UR3u1vhs5tNp+3dxUBjJW4xmPiqam1g0E+509knuC8ln/CmdezaOUhksv28GHInIXmFr1bkf7WyzsofPHbMXhqYiFC+QUIIfRADnAjUAocAO6XUmZ4XPMEMFNK+ZgQ4j7gO1LK7wd77uzZs2VaWmwjuXWVhsztLPpkoet7nm0cFXIYs3T5LkUo3rxl+w42m2Tu5EG8OHY7f9kH5+j8V8fKB87kjNbg9uNOBvdL0lx23tP/BpZebn/25wdLgoa5PWvUIHKrtUWnmrHXMbJii9exMSl9qWw20iwH8PhlI6ho6qC5w2L3c9LgG5OGeoXt7SrXnj2KxVmWsExhu5s5F13E/sPuGcmfXz2Nj1OLQgosvlTI4YwV4W9YC3DUNpWzZ1xEn6xlAa/5zbPv8upfHo3ouQBbrBcxV3ecOlLY3v9mfnb5GFq2/Cf0jWHQLvvQX0Tv3wIwYkAfatv8n2FISsaisfr2vdkTWJrmvTKz0HITF+nyQvrFAuTYxjNdZxdy9tvOYY/tPEbRSDt9vFbxDtjO5hJddqDHhMVFV97M4d3rvI4tt15Ffzq5We+9Sp5lm4gFPef7rIR5csmP/8UjC/bwc92XrmOzJw1jSL8k6i/5LS8s3oi5s01zlTQc7nr491Rtn8/ek/71N8s2kWminCQPASI/+VymmdxKyTLrVa5V7UAM7ZdMQ4d3uV4wcSQrC/VM0VVGlN8nfzOPV159MfSFgO2K35B0cIHLisMkDSQ7fss7lttIoZ37Dd79441XzWXjzl2u74P7JTF46CiKy6OLMhqMhx74MZtXL6HU0b+/brmLWSLPSzENB50QYe83lWcbx5m62P+WSNhtPZ+sPudx78wRpBx6I6pn/Oav75P52Z/YkBG6/vzsqqm8F+ZEXyA+s1wb9mQXgG3QeHQtoVdcPKmfchfDCla4vgudAWmzUDnicmafP4Olm1O5Qu82iex/5tW05wW3IPAlwzbJSwEIl7csdzC+v5XbTYH9x779o/9j9Yf/Cnh+4vWPYTjyEScdfnALLLdwxZAGrr3mBipWPe+67tFHf4Pe0sZr8xd69T2+zJ40LKDcUmgbw+/nJPmNG76YpYG3rbfzK8OXfuemjhjI1Lnfo/5kGq8dtvGLhx7k5UWfcZkug1XWy70ms0Nx+8wz+Npj9XTniPu4qvazsO8H+8p7RKb1EfCDORPR6wQfZ9qQTcHfWTBMMolk4S/T/tfyHS6cOJzlT1zZlWx2C0KIg1LK2VHdG4YidznwjJTyJsf3pwCklC94XLPecc1eIYQBqARGyiAPT0RFbsGrf6a5JvrK05MM7ZdM/2Q9ZTHa6kChCER3dtynM7FQRhMBm9QFNjsLk3PHpJCp4SeqUCQy371oPMsPR6YoKRSK+GEcPoN5v/2/eGfDj64ocuH4yI0DPLWbUscxzWuklBagCRgeTYbiyS1XRvUO40JDh0kpcYqIybJNjPgepcR1D6eCEgdBfIciQClxit6IUuIUit7FeRoWbL2dcHzktCxefSW7cK5BCPEo8CjAxImRC5TdzdjZdzDKdC7Va/7ONdNHUttqYm+ZmU6SGHjJAxTWtfKzkVk0p5xFedZ+ytsF46ddwPC2XAa2l9L/vFswW23UW/sxKqUv87ecQNblc/PMcaw/WkodKVzbJ4d2s5WJw/pz8wXjeKbycr43xcSg0u2sajuH++66i5Hlm/l8x1E+Lx3CJbosDP0G09hnLPvFTH4100ZJUR7WolTGDelH3yQ9111+GYtrJjBhRAqr0sv4zpwzGU4z7+6rwlJ8gJRBKUyinKKkqRTWGZmY3ML0kf2wzPgujfXVZB/azpzZcxhsLGdg5X52JM9lXEoSszt20ZI8mn+UX8jo1kyunD6GX9w8iyPbv+KNqhnkV9bz+9l6OmsLKauq4ds33Urm3tWUj7meG2dORCb1o19yMr9YcoyUxkzK5Ahq5GAeuXIiM/s3cN4IHRU5BzHO/BHNRguthz4nLa+cW6boOVDoNlUYO+Es9nSMY8qwvpxtPMLYvhaW10/iqrnXQvIArhpt5rlPNzLz7DNZlZZHss7GN6+Yy7KN27hAV4AYdxFXX3MzC1Zv54yJZ9Jmkgwq3cqw1jyGz7iGD48buXGMkW/oMjn/1sdIHj6Zu1/8nDkjzeQ0SGoMo/nOWcmc25lOWn4VRv1ANpvO494LhzMkczEWm821avWZ5Vq+MVowZ9oY7px1BscOp9KeNJQx1LF1zx5q5BBGikYunDCMmpQZFDaBaKtCJg3g1vNG8LfNZUwZPYwhYyYxwVbOpf1KePvkKCb07cDWbzg/nTWAVjGAzzfuYG/nZM6aMoWhmXYn4YbRc5k0aTJTx43meO5J6kwGHrz+Ioa35FCgm0Tqro1ccuY1fLIljduGlrG/SnKBOMkAYaTQNobCgbO4ZrSRfqU7qZ5wK1fNvpB/LF7PDVOSObMtnYK6NkaMHkdtVRmVfc/kzCFAfSGdk7/JtiIT500czewJg7h0cgpvL9/AwIYsGhlIsRzF3ME19MfEsMED6Xv+Hew42cignOWcNWoQ06++l72NQ5nUfoJVB7KYc83ttO16myS9joPNgxk1eADZAy/hnjFVNJsF+xsGUl1WwHO3n8PYwX34oGAox7OymHdZfxg4ilHjp/L1ll2knqzlIstROsxWMsxj6Dd8Ap3V+WTJidxxxQWs2XeCX10oyaoxMeTsuaTm1zBuSF8GyxaG0EJ1cTZ3fO8nrFvwHK0WHcnCwrgh/Sgachn3DMmh1arn9+mjuGr2RTwydzLvvP8WAztKuelHT1F8Yg/b045y9jA9M8+cyPGME4wZPpQZF8/llYNmBhZvYrBoo8g2mnP71mEWybSboWHANDrGXcYNF0ykT302n27cw9VD6/jG2L7sya+lwDSYh+7/Ibsyi9lTN4hBxZs5b1ALl133XepTzmbzig8Y0Wb3/KsfdQXbK3S0yX5cde44+uZ8xWjRwND+yVz38HOkrv2I/a0jGVK1lwHCyD7buUzs28FYU6Gr7aX0TaLTYqUiaRKNsj9VbXDrwFzGDunLRTfeT1NrOys276SowUQtg6mXg7hmdCf3TGhBZzXySul0Lp51IcW5GSSPmMxFtuOY60u4Ypwe+g7hT1kTySpr4E79LsrkCEzSwBRdJWutc3jghkuZWLoSfWczz5bM4n+mldFUXUyVZSB6Yz2zJo/gP7ljMWFgji6Ls1Is9B82lvTG/mzqPI//u3wgZ5uz+CrPzJSBZsrzjsCFDzDaVsnQMy8hPf0g9RUFjElqZ/LoETSUZNA44iLOtmTTlDwWw9jzyatqYkCROxjNNdNHUaMbztKMDqafcz6jhw8jp6SSi2acy/LMFgoL8vl2Sh6zJw2jSD+JpNZStp1soUYO4fG7v8WQk6tJHjSc2tw0UlJSSMsrw5KUwuhkI+OG9Gel7jrmTuzLgcOHePTWy3lsQzujkzqYPHo4V00fzWvLNjFFVGBBz7hRI5h9xXVkVbSQnZPJOU07KJMjmDr7Fm6bczYvvPkOP7jlOtKrLWQUVVJc28wN4gB1428kq6iCwaKN6aKECjmcjP6X8JfvzeXI8SNU6UYxpO4IM887D4O1k9TSdkY2HqWyOJdGBmKReqYYarh0ynAMeh0Lqqdz68XTOLN+Gx9UT+dESQ039znK9LPOYVdNXwZb6njozltIy8xj2740Lpk+AXN1Hq+3XMVUSz6Vchj/uH0qdZ16cotKuPri8zlS2kTm7pUMEa0UjL+T0XUHGH7WpbxyyMw4Uct7j99Chak/Xx4qZm7/EizZG7CcdzdbCzsZVn8Ic5s9+E22bQJ9J36DSaZsZowwUNXQypThfTClTKb96EqMHa1YbZKZNz9CfWkupce3s9E6mwo5jJ/22YRtwhU09J/C5UObSSraznnjBvP1kXKGD0hmV20/xolabMkpXH/tDZSXl5JxNI1COQbZN4Xijn600ZcrhzRw0YQUkmsz2d0wmNlTRrAuq8FlWtjHoGOB8Tp+OKGGKbKEM2ZcwbSO4xwsamDD4HsZN2wguTs/x4qOb144nS0lkvZBU5jWp4Er2rcxpK/gxdzxFMrRpIh2fjpoP3c/9gzzN6RRdHQXFw83MXH4IBabrmRw/TFamxuYpivnK/1NXDIGLu5TwZVD6qlPGsPf9lkpkiOZKXOwoKcfnQigRjeSb/c/gdUmGXvuZdx48XTWbdpEXpH9N1w640wa9CNo7X8GyXnrKWowcsYF11CQn80ISxU72ydyRd8i7vnGeHbmN7ChciA1cggmDAwcNJjv9k9HCh3H24fR2NLKI7ddRXHOUVKt51BenI8wt5Fum8YTc8eRX5DPLddeR0ZFE1azkblThzJo4ACGjhjLL//6T2aIIhpHXMSqqmF8/vhcavMP0Xh8A/OrzuK2lHyaW5ppGDaLs0yZJI89j6TkPgwcMIAPU4uZLkooHXA+nf3HcPXUwdgyVlLWYsU2YBTn9q1HZzUxdsRQcsbeTh/ZyeEagS1/K7eNaUBKeLbuOob01fG3u85nQEsBBzYtJaMpif195/LAlFYmTTuXF1ceIkeO57KxghtmTqWixUSf1nIa8/eRct6NHMktprqpjZE0YBw0mZsm62g7sZYaOYRBtDNAZ2aJ5Wr0A4bzy2unIevzuXbGON76ajtmq0Svgz6jpvOtaf2YMX4YO4/mUNbZn90NKVwxpIFxtnK2tUxkf145t+v3Mnjc2eyqNDDYXEMbfWlmAONFDd8/CyotA1lWN4Vr5sxi2uih7NmxgcuvvJrqVgtn96mjj7BiE0m8sTWXO785h4bqMi6YMJy2nO28kD+F5757IaMyFvJ+ho5cOR6DwUCfASk01FRwxzkDefmQlQY5kBGD+vKbcdksyE7mUl0mRvpw4Zg+NPWfzFd5Zvtv76Pjj3P0FJeXY6jLoaa1kx3WmeixMTOlhTH9JVMumMuOog7WZzdxx8hKRJ9BHCgz8p3hxdQ32l1zLvrBs92oRcQHZVoZC6QEqwkMfaK/Vkr/HVWDYekEoQN9UmR57Q10NIK5HQaOsb+TSN5LvLCYQKe3/+tNOB39dWEszkdaR08VGothwChI6us+ZmyCpP7htz9jEyQPdNcPUztUHoXxc8J797HC0gm6pMjS9C335grQGWDgyOD3tNUGvyZSnMNJvOqg1QIdDbH9Tb2ZrvQH4d6bSH2Oqc2+T2VLJQyeAMn9o3+WzQYV6TD2wt4zZlgtdpkj2v6qvR6S+tn/KaLDuZF9T4wZzs22uypjWs2JIadazSD0PTveRkB3+8gZsAc7uR4owx7s5AdSyhMe1/wCuMAj2Ml3pZTfC/bcU0qRUygUCoVCoVAoFIoI6YoiF9K0UkppEUL8EliPPeDrAinlCSHEX4E0KeVKYD7wkRAiD6gH7osmMwqFQqFQKBQKhUKhCE1Y+8hJKdcAa3yO/dnjsxG4N7ZZUygUCoVCoVAoFAqFFolpLKpQKBQKhUKhUCgUioAoRU6hUCgUCoVCoVAoehkhg510W8JC1ABFcUk8OCOA2nhnQuGFKpPERJVL4qHKJPFQZZJ4qDJJTFS5JB6qTHqGSVLKqEIix02RS1SEEGnRRo5RdA+qTBITVS6JhyqTxEOVSeKhyiQxUeWSeKgySXyUaaVCoVAoFAqFQqFQ9DKUIqdQKBQKhUKhUCgUvQylyPnzbrwzoPBDlUliosol8VBlknioMkk8VJkkJqpcEg9VJgmO8pFTKBQKhUKhUCgUil6GWpFTKBQKhUKhUCgUil6GUuQUCoVCoVAoFAqFopehFDkPhBA3CyGyhRB5Qoh58c7P6YQQolAIcUwIkS6ESHMcGyaE2CiEyHX8Heo4LoQQrznK6agQ4uL45v7UQAixQAhRLYQ47nEs4jIQQjzkuD5XCPFQPH7LqUKAMnlGCFHmaCvpQohbPc495SiTbCHETR7HVd8WI4QQE4QQW4UQmUKIE0KI3ziOq7YSJ4KUiWorcUQI0VcIsV8IccRRLs86jk8RQuxz1PslQohkx/E+ju95jvOTPZ6lWV6KyAhSJguFEAUebWWW47jqvxIdKaX6Z/cT1AP5wFQgGTgCzIh3vk6Xf0AhMMLn2D+BeY7P84B/OD7fCqwFBHAZsC/e+T8V/gFXAxcDx6MtA2AYcNLxd6jj89B4/7be+i9AmTwD/K/GtTMc/VYfYIqjP9Orvi3mZTIWuNjxeRCQ43j3qq0kXpmothLfchHAQMfnJGCfow0sBe5zHH8beNzx+Qngbcfn+4Alwcor3r+vN/4LUiYLgXs0rlf9V4L/UytybuYAeVLKk1JKE/AZcGec83S6cyewyPF5EXCXx/EPpZ1UYIgQYmw8MngqIaXcAdT7HI60DG4CNkop66WUDcBG4Obuz/2pSYAyCcSdwGdSyk4pZQGQh71fU31bDJFSVkgpDzk+twCZwDhUW4kbQcokEKqt9ACOOt/q+Jrk+CeB64AvHMd924qzDX0BXC+EEAQuL0WEBCmTQKj+K8FRipybcUCJx/dSgg8EitgigQ1CiINCiEcdx0ZLKSvAPlADoxzHVVn1HJGWgSqbnuGXDjOXBU4TPlSZ9DgO06+LsM9qq7aSAPiUCai2EleEEHohRDpQjV3YzwcapZQWxyWe79j1/h3nm4DhqHKJKb5lIqV0tpW/OdrKy0KIPo5jqq0kOEqRcyM0jqm9GXqOK6WUFwO3AL8QQlwd5FpVVvEnUBmosul+3gKmAbOACuA/juOqTHoQIcRAYBnwpJSyOdilGsdUuXQDGmWi2kqckVJapZSzgPHYV9HO1brM8VeVSw/gWyZCiPOBp4BzgEuwm0v+P8flqkwSHKXIuSkFJnh8Hw+Uxykvpx1SynLH32rgS+wdfpXTZNLxt9pxuSqrniPSMlBl081IKascA7ENeA+3iZEqkx5CCJGEXWH4REq53HFYtZU4olUmqq0kDlLKRmAbdj+rIUIIg+OU5zt2vX/H+cHYTctVuXQDHmVys8M8WUopO4EPUG2l16AUOTcHgLMc0ZSSsTvaroxznk4LhBADhBCDnJ+BbwHHsb9/ZySkh4CvHJ9XAj9yRFO6DGhymjQpYk6kZbAe+JYQYqjDjOlbjmOKGOHjD/od7G0F7GVynyPy2xTgLGA/qm+LKQ6fnflAppTyJY9Tqq3EiUBlotpKfBFCjBRCDHF87gfcgN1/cStwj+My37bibEP3AFuklJLA5aWIkABlkuUxCSWw+yx6thXVfyUwhtCXnB5IKS1CiF9ir4h6YIGU8kScs3W6MBr40t5/YAA+lVKuE0IcAJYKIX4KFAP3Oq5fgz2SUh7QDjzc81k+9RBCLAauAUYIIUqBvwAvEkEZSCnrhRDPYReIAP4qpQw3WIfChwBlco0jNLTEHu315wBSyhNCiKVABmABfiGltDqeo/q22HEl8CBwzOFnAvAHVFuJJ4HK5H7VVuLKWGCREEKPfeFgqZRylRAiA/hMCPE8cBi7Eo7j70dCiDzsK3H3QfDyUkRMoDLZIoQYid1kMh14zHG96r8SHGGf7FAoFAqFQqFQKBQKRW9BmVYqFAqFQqFQKBQKRS9DKXIKhUKhUCgUCoVC0ctQipxCoVAoFAqFQqFQ9DKUIqdQKBQKhUKhUCgUvQylyCkUCoVCoVAoFApFL0MpcgqFQqFQKBQKhULRy1CKnEKhUCgUCoVCoVD0MpQip1AoFAqFQqFQKBS9DKXIKRQKhUKhUCgUCkUvQylyCoVCoVAoFAqFQtHLUIqcQqFQKBQKhUKhUPQylCKnUCgUCoVCoVAoFL0MQ7wSHjFihJw8eXK8klcoFAqFQqFQKBSKuHLw4MFaKeXIaO6NmyI3efJk0tLS4pW8QqFQKBQKhUKhUMQVIURRtPcq00qFQqFQKBQKhUKh6GUoRU6hUCgUCoVCoVAoehkhFTkhxAIhRLUQ4niA80II8ZoQIk8IcVQIcXHss6lQKBQKhUKhUCgUCifhrMgtBG4Ocv4W4CzHv0eBt7qeLYVCoVAoFIpTFGMTFO4GKeOdE4VC0YsJqchJKXcA9UEuuRP4UNpJBYYIIcbGKoOK6LF2tmM1dcQ7GwqFohdgtUmsNiVUJgoWqw1bD5aHKv+eRR5bhvXkduhoiHdWFKcgJost3llQ9BCx8JEbB5R4fC91HFPEmdef+wWL/vXbeGdDoVD0Ah56cRHf/fPb8c6GwsGZf1zLQx/s77H0Zj+/kdnPb+yx9E53dmaX898tuTS3m+KdFcUpRl51K9P/tJaVR8rjnRVFDxALRU5oHNOc1hNCPCqESBNCpNXU1MQgaUUwJNDc0RnvbCgUil7A7PbtXEvPKQ6K0OzMre2xtBrazTS0m3ssvdOdI8WNANQpRU4RY06UNzGWOjadqIh3VhQ9QCwUuVJggsf38YDmNICU8l0p5Wwp5eyRI6Pa906hUCgUilOe88VJxlIX72woFIpeRr/2Mr5v2MrUjmPxzoqiB4iFIrcS+JEjeuVlQJOUUk0DKBQKhUIRJTfoD/F9w9Z4Z0PRTUhNYyaFousYzG0ADLQo/8vTAUOoC4QQi4FrgBFCiFLgL0ASgJTybWANcCuQB7QDD3dXZhUKhUKhUMSe63UHHZ++Hdd8KBSKriGEmiQ4nQipyEkp7w9xXgK/iFmOFAqFQqFQ9CgX6ArinYXTCqEdSkCh6DpKjzutiIVppUKhUCgUCoVCoYg3ao7gtEIpcqcYrZ2WHt17SJFYmCw2OkzWeGcj7qh24CYR64SUkhajipDoSbvJgsWq9n46XVA+crHBaLYm3J5pRrOVTkti9bmRYLbaaDdZ4p0NLzotVozm3vtOuxOlyJ1CGM1Wzv/Lep5bnRHvrCjixK2v7eTcP6+LdzbiSrPRzPl/Wc+/N2THOysJwV1v7A5ZJ5YdLO2h3Nh5f2cBFzyzgYqmjh5NN5GZ8ef1PPbxoXhnQ6HoVZzz9Dquf2lbvLPhxTlPr2P2c5vinY2o+cnCA8z48/p4Z8OL2c9t4pynT2/ZJhBKkTuFcM66Lz9UFuecKOJFXnVrvLMQd5oce2F9lX4abIbaUAjG5qCXZFQEPw+wPadn9/Vcd6ISgLIGpch5simzKt5ZUCh6HSX1idePtHQm1opWJPTk/pXh0pvfZ3ejFLlTCBWoSJEIfPblcl7508MYO+OzGb2zHdjjMJ3avPKfZ1m94PkuP0fn0Xekph/llT89TGZ+YZefG4jToWx8+cF7qUyetzre2VAkGKdjW4g1F4o8Hn/po3hnI3FQsuBphVLkTkHUwKCIJ5VHNwPQ1tYWl/R1Dk3udGkFueVdX03zDFedezQVgPzso11+buh0uz2JhGFPvtrcW6HoDq7Vp3N2/ZZ4Z0OhiAtKkesFrDxSzuR5q6lsMga9TnB6CbDhkFfdyuR5q3vcdCxSmo1mJs9bzYd7C72OlzV29Fqn6XjtZeNM1nYKTmjM+dsmvvPm7pg/V6uourP8emPJPLIojWl/WBP1/f0wMhhl+twVCmqjnxx6c1sek+etTrj+tKvNLK+6hcnzVrMzN/wx7v2dJ5k8b3XCBbRQJBYVTR0xDZQ1ed5qfrc0PWbPU9hRilwvYOmBEgByq1uCX3gazW6Hy8GiegBWHUlsf6nqZrsZ4sLdha5jZquNK1/cwm+XRN7xnc6rsq4VuVPwFVS3dHK4uDHmz9XFbWms93RamzKrsHYhEuoj+jU8bFDO+tGy9lgF1/57GxszovMjfHfHSQDaOxNLkesqqSftY9yaY5Vh3zN/l33PwMZ2FTn2VMTdq3ZtELz8hS38+IP9Xc2OFyqGQ+xRilwXsVht/GThAQ4WNUR8b0VTB/dfsLOxAAAgAElEQVS/tYOGNlPQ62SIxvjs1yf4wjPqXA8KsHe+vouXNub0XIIRIrpRUOy0WPnft5dzojQ6x+Cnlh9lzbEKwO2j5LmKZLHaP2/OrI4ib+5wzMfLmnhw/r4eD9Ec7Zv/ZF8RL6zN7FK6fTAhbd33e9cdr+D3XxzptudHym/fXkF2eeR9kBPPsupK9zF/VwEvJ1h/sCQ1n3+siu8s8MGievQivPr45GeHuzk3PceiPYX8J8Losb9dks4/12X5HT9W1gRAdmXo4D1aJOrETqLmK5bszK3hF590f0TW3ZlFMX+m0Wzlwff2kFlur38fpRZp1s9TlX0F9XFN/w+Ld7HpmH0xow8m/rs+sMn/fzZkc9cbsbdYSXSUItdFKpqMbMmq4tefRt5JfbF+G5eWfcD6veHdG0gp+WB3If/7uV2oHEkjBnrOXOJIaROvbc7tsfQSiaz8AsaXfs3Xn38Q1f2jD73M0sXzAfeKSKy2PvNUCJ/+4gB1eWlkV4ZY0Y0RzqSjXeT545fHeWf7yajTF9ZOHjesZI7sPkXrsY8PsTStZ0P2B2NS6Vd8tUzb2T+FVkYTfDD2HAhEF+rg/jWLKNoauj0MtdTyA/1msHX/ikD21y/TJ/XVbk8nGI+Hsa3ANbrDTBcl7Eg/dYTE11fu4suteyO6pzh9Cyu27fM7bnV0LHpd18SWU80vszf8ngfn72f1sYputxRZ9/FLMX/msfwSvlH0HouWrQBg1Vefk7tjSdB7xlHDWBLBJza6ypFCG+NF5BPI3cGoE/PZ8Jm9/37csBLrzpcDXvvfLXmkl8TeYiXRMcQ7A70dYe3kScMysm0XA9dHdO/QzjJqgQGdXQs5PZY62ukDFhMPGDZRxnjg2116piI0wmI3hxxki26GGGCWLh8AvWNJriumWwDniUKGiBakvMl17HLTXpL1JzEYbwYGd+n5ERGlhDFDFDJYtBFtHdZZ7eUyVZZEdX84jKWOsaKORGpnKbYmzeM/cZnzPRjw3knGDILbBYTHubrwZsQvNh3EIhpI7qgGRsUg5cCkiPgE3fFErwvdFmbp8plFvuPb/d2boR7iAcNmx6cfh33PVfpjjk8PeR232ZyKXNfzdSrRFd2opxYDk4WF/rIDq01i0MdW8zxHFLs+DxfRj8WBMJjs/epEcyEAl+tPhLznXsN2x6cfxTw/PcHD+nUIIXnFck+8swLAGSIRlOLERSlyXURntQcgOduWH+LK6AnVUX/fsNV+nc0uvI8l8fYAiTeJbr2iFTLfaVIbiT50oz7Nca+bfrIDKyBsPbVS60g9SgnjW47fEC3uIB3dV+rONpdIdOXXplhq/XoN2Y1myYneHmPNmISYne/dWB2WqdH6cw6RTczQFYC8IYa56jqxWlGL5Dk9vYh3uz6VCVRitd2DIcaa+M362PpwnVpE19OKrphlKHocNbfVRTwjRaaerPMzHbjp5R0sOVCscWcUaYXofV1JqzboJsIRS0qpWY6+WG2SI6WRL+E3tJnI0vDx0DKt1MpCQ5uJWX/dwOHiBqw2yf4A9uuJEOykO/0Tg+FSQOL/CnqUrrxvrTt7wmSrF1iFxYQbbLvinYVej9NcPFpF7na2c6kuE2EJHv0ZAGMTdETvcwrQ2mlh9vMb2ZOvPbHqGq5j1E+F+xwpJeUhImDHmknCbnVki9Di5OkVx/mfpYnhi9yVYvrLV8f5XRRBy7rKoaIGmjpib75e2WSkUCOCbFWzkZnPrO8WN47+9Gyd7U0oRa6LOMeUVqOZ+95N9Q46AmRXtfD/lh0ju7KFJr8IUeENSJF29HGVX6WE/K3Qmhj21QDjRTVChhdoYEV6Gfe9mxoystKbW/N4c6t9FTYSseLON3Zz8ys7/Y67FTl36WmFz99XUE9ju5m3tuXz9vZ8vvfOXk1BIZ51wGju2aAqvrhXkuKbjx6nC1pRT/vZhLXa19kKNYkVOCVqInzB3Rmop7dic/nIRVdZdc7+IJwBde+bkPp2VOk4yapoprbVxL/XBwj2EoeVOIhh1ECbDazhWXlIh6hps0UWMfSj1CKWHUocX+RoWbS3iOWH4xOtsTt8xi57YTPX/Hub3/ENGVU0Gy1+2yjFgkcNq2L+zFMFpch1ESG8X2FxfbvmdTe9soO7394TXSJSMoSWkP1+QixAWIxQnArpn8Y7JwAMbCvmHv0OJrUfD+v6wlp7+RUFKEcnOdXR7QcVqH64o1a6jwUrT4l9jzxAc39BaZVe1/YUNS2d7i9x8sKXfh9OQaS0C1IxwnvPuO5XIkQ4aRxdAseXgSUW3nvxRUQ41HbVV/ZUxOJ4J7ooFTnpsp7pGSVZhDAMiJX1mpSgJ3wFyT62yfDaYDAOfwg7/hXWpc4Ss6oJCkU3koSFfqfhyp3ykesibvnHo1cuPQi5G+DK33hdm+cn/IfXk59rOsqlhlQMxouAEQGvi4c53d26HRTJUXgGfThU3MCUMYKhPZ4bf5Is9nfe36odCCIQIUUFKRkq7OYDsfIlMmBB2pLcSdiceXE/3+1L57nxtUb2bGYg2euYiFIAigTPDWZDbZvRXUiXi1wYQoNTSTAkB7/Ok5z1EecpVnxfv5VW2Q8yrVDl7XQfc9PKqJ8WQbpBlP2GumoKqhq4OEE08vNEASNFI1EFuInwZVrDtCA4nZBS0pdOou3GIjFlLKxrwyYlU7VOGpvAbIRBo0M8Jbz9LLs639XPWMOvDF8iO+8GLgjrnktFFpfrTyAtVwH9okq3vOQkzR1mzgnnYiFAgs16au3hl6iIAJ/jzXmikBrZfQHXHtBvYohoBe7utjQSEbUi10WcjcSAjSt0x9HZLFDh2AeoMzw74VDjygir3UxRbw6+CuR2kes5wWeCrpq5evdqV1OHmR25NXx2oPsiBnYnEg8TnCBMMma6gnIEFEaby/2E7fNEAXfrdvhfa+7gl4YVzJIZHnmRjKWOZI94gp4pDbVU86ThC3Qm/3qWCD5yMk6rChHNdO96GXb+J7IEyrp/P6RAjBV1nKUr9atXXUYk3lCw+EAxO3JraOvs5iA9UkJrTcjLbtQfdEWZjZzIxCmbNQEUubp82PpCWO+mJxjaUcxjhq9J6YjS1E56/QnKivQyVh4p1z65901IWxD4ZlMb5G12rXgFSi9WvWO/Trt8MLwz/DH3fJ19e5ew/AUDsDSthHUnPDYhNxuhPfg2J2pFzoGxCcpjuF/k9n/BIe3tZwQSytPB0ql5vie5UZ/GD1yRbEMTqRxjV+JOP8IavYUQNwshsoUQeUKIeRrnJwohtgohDgshjgohbo19VhMUx/jcT3QyR5fFGS2BNyv0uzXiqZLgNySA7O4yCTL3pCBis4a01Q/31QwyVvBrw3IGd2oM4mYjtNmjzw21BPEBtFntZm8HF0HGSq9TN+oPMkGnca/FbnJ5lnSHb7dZrXzfsJXbhdYGl5JJHfb9pvq3+ws2Pa7IZayE8nR+tKCHI4h1NEC1z75boWwrbVbI3WQXuE6llY8u+ci5b45JzbGa7WZXvmXjm26Qc53R+lq2VtvLOFyKdsOB96ElyDYwxsBhzf/81XEmz1sdNAkR4d5nCSHw1jr8E5sSY1JusMlePgM6o1MsXZYTkbzbOh/FPRxhOGc9lOynT3NBePnq4a56gKmWQaIj9g9OWwD73tE+J5w+ctHV68nzVrv2yu1pRHcUUPpiyF7nV5/+3xdHQ/Ylvsx8Zj0rDhVBk/YER5/2SsheCznrNM8HYyQN9NHYmOabuiPcofNwFWqvh8bY9xOJINP2BkKOLkIIPfAGcAswA7hfCDHD57I/AUullBcB9wFvxjqjCYv0FkV02KhvM7Mjp8a1gWkMErH/CRW1MgFMkJwO6T0asXD/uwFt9SPNx2Cj3SE5xeivyLXsmU/VptdCPqN29XM07HqP4vp20kvCjXzm778hHcLoSNzP8BS4nZ+1qpmmIteNvWJ13kHajn5NUZ3bBzAWqVXs+ICa9MADW/ve+VTs8fXHDLH9QW0ulB6A3I3kVLVoRhENRlljNwhBkaLTh77GZrP7mIWBlymO473JrqzSmdooqW3GlLMp+mc48xNJE26vp3j9fyNLt9nR1oNYUMiKwELkh3tD750XaT+UCIqc1SYpqGtLgFHFgaM/FOHUfQ3cPnLhU7j1Ay9lTpbsY1t2dfCIxTLMoCpxsnkb1l7YLc9ta6qjqll7hU86x6ou1GvfQHK9mZqGBvbk1yJ9JhKXpEWuDDUbLRTWtVFQq70a5dp2yBTc71+LBwyb+Z5+m9/xi3S5TNV5yEj73oHDH0f8/FBEOyEtpbQrtqVd28qotxCOj9wcIE9KeRJACPEZcCeQ4XGNBFIcnwcDAWwSTj20qtniA8WYmxoYVeUWDFJopYO+0aXh0uNCanKBM9VDuMIL9+Qg1RGbqEyf7itm5eEyLtNpv+vF2w7Tbrby5J3Bn/PxviLALdzN0rjGt4NyRvXyNAvUilrpvh+XhOs7GPjd2wPK9af7izHodMDFHsl2vSIu2WA3Q31ylrZf0hepudS3m3jyLvcxZ6oilFGTtLHmeAVAeH4eDj4/mAgrFMJv4savdE0tEUR9jG3dqGq1suxQKRNHGfnuXP/z4VUNZ18Sft4KK2pYcbiUcXVp3HvOTWHfF4rtOV3bmzNS64tEMK1cf6KSnPQyLh9Tz6Xj4p0b98SWLmpFzvE3gn5pRXoZGw6u47IrruXPt89gW5ZbibswYELO/T+F1/dAGYrVio+Mytkudu1+4d5CzFab9vjoyFuPTlCY2uwmjCln9FyaYfLp/mKk2ch5HWYGJ/n7KJosNpINkU2kfXWknCfv9T/eVR/MiDZZj/FkcTAZKPh9oHeamo6fHcMcJSbh1JRxgKfkUuo45skzwA+FEKXAGuBXMcldL8C3nkmhcykzUsIg2jFg4SeGddyt3xH03kAID9E0rDyF99iAbMqoYuYz6zGaI3dMdu/1E336609UcuGzG6JKvyv8c31wM7D2KPOjNZPoX/bOQd9jRU6jJD23uhYaWxYEvTfCHv3f67P53jt7w77e4hik+wmnuUj3zyjUt9vNPrxmekNtqCj9FYRffBKd31u3mrB2NAYx95NRvd7KJiNn/XENx8u8g/94BsKJxS/qcLSVuhb/vYa80g1SJcOewPKgudOebnVLbCOX1bV2zb8k0raXCMFOahy/2dnGehxfP1DnO4nQTNUXrYmvoNcjWLC7gK/Sy3h358mw7xNRrAAG4ouDpVz6902a+7B5Hnl3Rz53vbzevcocAndXKe2+v2FuJ6CFy51Co090vgtruMFOivfBvncZRjPDiSxQmYuDi+z/YkRBXRtvbM2LybNcgcwCudcbY7f3W6ievaiujTP/sEYjGJ/v/T1PtOPr6Rb1N5weUascfd/S/cBCKeV44FbgI+Eblx8QQjwqhEgTQqTV1CSGA3VX0RKY3SYckp8a1rhsiccItyNwfk0rmzLtvlKxaiiL9hQGPJdd2cJDC/aHVI6OlzXxyIdpNBstlDa4l+JtNskrm3J44P1Uvkq3mx/uyfUXMm2OHkogWLi7gJM1kTufPr86g6YOM1XNRtYcq+DZr4MHdjhZ28qJcndnn3qyjnvf3uPtpxdGu/bsM3w72I9Svc2nIimzPyw/5nfMV/lyW+h6bBsQMtqZvYlVNRlZ7rPXjrRJjGYrUkoqm72F0Ne35PKbz0I7Wr++NS/ghuOB6Is7rVh3pWuPVfDMSu26YPEQELyEEw3MNhvbsqtpNrqFltXHKqLKU7jjTF1rJ7e8upOSENtaeFK/+VXKN72hea65w8S2HO8+1FdZkFKy22ePwa3Z1Zitko9Ti9iYUcWfVjjqpkaF7kq/ZHX4xumltmAYSd2IRPDemlXtuEf7/Msbc1i8v9jrWFOHiW051a6JCC1sYbyNoMJDhGaq0foS+eLsA7R4blUGb20LHbylR83kPcjf/imPLEojs8KxIiAdbVynZ9nBUiwe/ftPFx5g3fHgbThYvyCl5MvDpZrjo3Mi9c9fhQ4wtCmjivm78tmWXY1VwmRRQUZpHes9g4L4Ebqs5y07SlVzp2sLhkD8fU0Ws2u/omhjhN4tNdl2375CjUBckVJ6wPWx/vhmCr/4k+t72IJ5/hZor+NHhg08aNgYXT6MUSqAQfiXx56AC3cX8Mcv/cd2LQbQwSC03A4CjFFdXJF3rs5OFpU8uTTdNSmjxddHyrHY7PVfC+e4krFtKRW52nJDUX0bR0sbkVIyVZR7BYwrrG3jxx/sp8MU+UR4pJMuTmxSUt7YwaHicF1bejfhjC6lwASP7+PxN538KbAUQEq5F+iLRpx8KeW7UsrZUsrZI0eOjC7HCYZWv+QbFn6iRnCLu9/aE7mgG2JWd8HuwM7VN72yg+05NZqbR3vyl9fnc5vOfxVmW041r2zKZXdeHb/5LB2A/Yv84t6Q65jVkUie+TqDu9+KfO+8knq7D5JA8MQnh/hgd6Hr3PGyJo6V2jvolUfKae20sPJIORsz7UplQ5uJ+95N5UBhAxWNxohEkGCDzNMrwtuHThONTPiPx/5mOM6oj57bGwiriR/oNzPI2uA6uvxQKb9b6u3D8/qWXM55eh2NfpvQw7835PBVevdYP08QbuUi1otVT36Syoo92gOn2Wum12lKqp2B1Pw60ksbWZoWnc+F54bE4QomXx8pJ7OimfcimNH/MLWQpQHMOFccLgvupwNUtXRyoNBbEffM7s8+TOPjVLtSE2thfduGFX7pAdBYDAfed+17FU66kdQjp5Km+dSOBpZsTuUpn4mVzw+WkV7S6PeuIiWY8BXpilwsNgSvbzNxztPreHu7dp2bv6uAf6wLboUQT74+Wk5d1i6e/twRQMnxTg6eyKLky6f5fJN7bNmcVc1jHx8KOlHpmmDVqFA7Mko49MW/eHNVYAuEcIrwkQ8PcKy0ifTSRt5cvZe79Lu5XneYn390UOOBjnyFUb/de9IFttJwMlB08GWYm0+7nmZ1rLpG4UflR4tbaV22/DNWpJe5/G0j3RA8IfAo+BEeq4PPfJ3BJ/uKte7w42eG1fzUsMbveECr2xiNncnCwmga+GRfEQ0BVtbDdeXcsGktSz/8r6a1w5eHy9iSXc3gtgLu0O9hYpu7j31+dQbbsmvYmRv54k2078Fqkyw9WMKO3OjS7W2Eo8gdAM4SQkwRQiRjD2ay0ueaYuB6ACHEudgVuV759o6UNLpWnMIhWD0LJuS1Gj3327IrIOWNHRjNVv76dQatYYbc9pzlCDTOSGnf/HMsdSGfd5X+GGfqyhyRitxPNFnCEywedwxYrUZ7vho7wjcRaDdZ/CJTjaSBs4W7s7ztv7u4/fVdnChv4teLD/sJZY9+FKVza9FeHmdpEL8qb3z3jrNEOIP2t9UZPkec5rju9G0as1H924sZJRo4tyOdcsdG4BfqTvKYfqXXvcsdA3lTBO/fSVphPWujXKH6tj7V9Tka1SBYIJHHDSv5sWE9NLhXR50C8vrj5a5w4S5hJ0D7c76naOzvVxwu81p5CecZe/PrWOJQGqMZmObvsk/QeK6Qt2ia3viuyPlf4Xw3QkB/jIxx9AnaUSujV+5aOkxe6VU0ddDQZoLcjdBaQ4otfL+LcIM4fXGwlHN0JY57NEh9m/sMWxmIt7DqLM5Qqx2BGEwrU0W51/1bs6q9xpFI95r0rGPRtGHAFXhihYdQn1/TGr7JuiMLSeZmKPNWRKw2qWnmF2u+qT/CFaZdgHtipl+b4/c05GG22sj18EUPpJjWt5kwWQNvB2CtzWe4aGZIzQGNszjSD81NujQm6+yKTKPDrHhwoJDoHhmpbe3kja15AWUGAzZSaENKaGw3UdHk2U+67xlEOIqY53qQr5l5lGXqGbHQoy9pc+0r6jStjL/JcDBsNhl0Zf2HEa4OBjLJlgH8J6/RpfMb/bKISmGEhumpp699srCXwdIAW0J9uSudJw1fMMCkLR969l1SSu5/N1XzOgCD1V7/+lr966HnGGM0WymotbePvOpWOi3afVLUppUe9z04v4cjaceBkIqclNIC/BJYD2Rij055QgjxVyHEHY7L/gf4mRDiCLAY+LFMhI2souDON3a7VpzCwXfp16vSB7lP5zO9d9kLm7nixS0s3l/Mgt0F/HdLrt89WjOCv1saOq9LDpRwhe4E3zdsJblD2+fGaLZ6zSg/bliJMLsHC9/SDGQi5qsIRVIL5u8s4IuDpZwlSvm1fjnCZuYBw2Zu0fs3xDaHL0ylx4BmttpcK4LgLwBabTJwhMKi3UjAQHhCjueTC+vaOPOPawMKNjpLh99eWIt8It2535Onj1xgKpo6yKy0CzCjRAN9hcn7ZXvUy3CVUyf3vL2Xx6P0GfMkmiiqV764RftZnr+t0q68HypucEUSn/fFEX69+LDzYgBEgA3ltGSWUTRQHkY0yieXeLc3326u3WTxEiwB7n8v1WUeFs07eW5VBpVNRi8/vnC6V80VBCk5VxQhpI0f6jdyn2Gr/VoNMbWrTvKO5AC4/IUtzPm7fyTJYO/DbQkX3jv738+PMEsX2oflEZ+ZcZ1LpopuyPqBfgt36Pdgtdho67RQWNvGwwsPhDWOLD9UyhqNSRNP08obXtoe9BkWq03bJNBnFaet08L1/9nO/0QYxn1Uw2HI2QAW94z+tD+s4dbXdvpda3WYdEdCVbORWofAq7USmWSzK7K+daWgtp0X12Zx48tuc8DqZm3B+RvPb/RYkQucP61VVed9OkLvMXquzt2vh6u8SyQPzt/Pv9Znc7hEe5X9Zt0+fmJYC9LGZS9s5vIX/PtJATykXx9Wmq60Xa80/OXBnKoWXlzrozB7RizU8pELEpgL7Mqpb7/pyS/0K7hGF7t916SUvLA2088v7OcfH2TaH/xXzgDGEGLFvrnc/h48/Az/EsAVIBCzdHkIIbFZwvdVDFu51KiONS2djDDa6+yIDu2Ve9967BmZOhySbUau1B3zkkl++ekhrv33NmpbO7nhpe08tUzb0ibaSOw9McmUSIRluC+lXCOlnC6lnCal/Jvj2J+llCsdnzOklFdKKS+UUs6SUm7ozkwnMsJr9iLwdXqfaCCdjhUv1z5sFk+h3P2xw2Tlrjd2c7ysicomI2uPu80YnAK7b7orj5S7Zm30ZncjXLy/mINF9s7pnKfX+ZlBCkvgUPJX/XOr5u+KVGnwxDmIztUdQyds6IJsgK61zcG3X9vpZ0roKYy+ujmXm1/ZSZqGCVVaUUPYq46h8uTLd/W7+NmHIVYKnfd66WL+HtHOT40dZr8OViNQpXdpRCiYD6GFcV1ZWNd4H00dZgprgwfA0KJQY/D47pt7XO/As96FayriWdo/MNgnUsC+aqHl1K4l6PsKJj//6CA3vryD4gCDXdSmIlK6+gjHk/yuCUfxSmk9yU36A0xpS6e/cAu9nvdGtKF6QKTH/3bMVumnRR8tbXIJ8f6PiO1gvCFD20/JOalms9kDLT2yyHtV5qnlR9kY4F6APsKu4JjNRn78wX6u+fc2/4sCFM7vlh7hCY1JE8/ofjUt3u/nmZUneH/nSZrazRTVtfHYxwc552n7HlGHihuodqzEuYJtOF6jU8HakxdZBM7DxQ28sjnHyw8VIKuyhezKFtfMOsCvPzvsyku4ViWX/n0zs5/f5JVXTwLVghPlza7V6lBI6SGQagYMsR+rKi2AJm2LnDkc4xJdtuY5IGorBilxTfSYA4xBU7A/22azYQyyv6JBRKZEu/W48FfkfvDePt7e7u1b+bGPDzngVS+c7z6QaeXzqzO58eUdAetMkrAwSxfan1MTjUpV2Wzkne0nechn39ONGYH3kgz1btM3LeaVZZtprnfXg1AyxT1v7dbcskFYurjFjZeFhXOM9Mdr9TFAH2WyCa+y9F2E8MLjXbd2Wrjrjd2MrNzOJbps+re668jOXHsf1OywNth7Uns1MFqFzHdVtbrZGHBrjFOBroV/UvgJd9tyaqh0mLxpdSBO/y5fRc6Ja+bKy8BJuj4dKW0kvaSRv67KCNvkJlC7e2r5Me5+y+0TcLS0687BsfS08Q3SsTff3dil+5W4yKnyVvx8X/9Rh0/RPW/7+0HsyvUWbkIJxVqnA/U5w2liT35ws1b3z9HQxrzyZW+yY6nzV+RCDMLB/JHKGjv8AtP82LCeew3u1YBOizWy4Cca2fnOG7vtgq6xGeqDC2FTn3LvH+eZ80c/SnPP4DuO6bwS8074d0vSeWWTRhj+AK/r+++k8q/12X7mi+Hs1+ccoAKZ+EarmvhtV6Ep8HqXr1Z5G2z2vinZ5iMoeFX4ritQgQJLZFe28Nb2fJcp8qubcvnOG7tCPMv+jA6TlYNF3s7rJouNfQGEAF8yKrRX410/3Wpk0SeL2JzprbQt3l9CQ7u/gFnb2klmRTMmmWS/vbOdA4VROtf7vKdAwU7+tOIYC/cU8vzqTC786wa++a9trqBZYJ/ccK6UuVfk7OhcY0toShvaqXL4wjijVnZabFQ1G71WTm56ZQfXeiiuq4+6hdg7/hu8XLUwB/Gh8lwZiwZXlQzyBlJEGxz6UPPcDHw3B3evUBbWtoVtxZBX3WIXKl2LYO6yDrT3bKSr077pXfniFr8JAe/n+a/IPbcqQ9M33DcoUH5NK7VtHs+uOgFbX/CqF4RQ5JyRnT1dTmKG5gSc/W+04e212JFn74c8zV4DyQTOulzR2M5n+/1NHrXcKqIlmCIXzoqXRHiVZbiWGnvyakkvaaShxfE+PK2EAs+pAHZZ40BhffBgJ1mradw9XzPapm87mvP3zVz6983hZbwXohS5MCisbWPd8WBRp9x4dpZancSBwnrWHKvwCs/vuY+MM/JkNP2La0XO94SULjtp57mXN/oLtlNEdDOK3cVPFrpnxg8U1nP/e27bbGcUsGDbHHiJ9lJiCHJxVzZTH4CRqaI84KCgFzYMhBqg7Pd6KiTBBpm++PDsw5QAACAASURBVM8ueZolOeuC5zP+uT6LyfO0N9e+8sUtXPef4CZcz6/K5Hvv7CUniAmMV340jp10zOzZ9r+P5fCn1LV2Mnnean67JN2vQw42WegMn29zdGG6ICapyw+X8comf1PlQHQ6Vi6cz/lkXxG//+KI9jYP0r1K/uKqY6Rg/33tASJ0fRqmc7xWOl7fNa4JZ3x1h/T3uVdzdO7KtIy9PHwH6jXHK+m0WF0zsTfpD3B3i/ZGsr664P99cYS739rjNbP67w3ZfP/dVNcEWTQ4FZwRlbuYo8timggvENCNL23nlld3YnNMrtzzlr+poZvI3mUgRW7bvjTu028JauJX22ryStEprLuEpzBmuef+YytZld7tUQj76tmNL+/gFt0+u7lUEE4GWXmXUvLg/H2uKKNOXtIYl5z597UCnCbKET7vISzBVGtFzuNQIGXKrwRL9rk+aq7CBuCGl3Zw6d83uydegs/deSWuvdVM4LplNFu54aUdlDV2aK5Iu16FS+t3v8/5uwr4KLWI0oZ2Vh11twnfLGzO9F7FsknpHwHWueptdd9sKT2EOWud12WB3n3XsPtz7g5jJXq8qGa2iC4AkLNeeQrVgRTv/jhXzYM/KxZIR0hsrS5eytA9k9VHTfBckXtq+TE+2lvo/1wBA/s4t6n2n3XX+awA+76mZ7/O4N639wbcEgHAWn6EhWt3aZqe9+R2hYmAUuTC4PqXtvPYxweRUrJgVwGNHtF/fBucr/Lgy19XZfDEJ4foL0yMF/5ma8UO3zPPe8NVMn6kd1q0el/fdnI/44SzE7M3oFc3ewu2/TFyp353wGdLCeNFjd/A6YvnilIKra7odF3FtcrpYKFD4Q0Z9c7jdDCTAN+i8r1yMIE7lMGijTv0e4JGmvu2ztdB2HeFRfod14pa6fkxnFrhWY8OF3dt43Snf2FDW7j7SgXO4ZrDBby+Nc/l0/jl4TK/DjmY8utU5DQWZsPGN3cP69cCdlO58aLGJdP88cvjLE0r1fw1NpuN9BL7Knn5nsX8xLCWO3R7ENbg7+iz/cXkVdsV4l25tTyz8kREZiRR+8j5BTdwfA3TtzdsHL/FaLF67VnnDAhicCQ3WIRhZuv4rcccz/FUkp2rQ/6R1ML/Fc75ncwy+4y6jvACeTQ4zLidl7YH2fvJc7Pm3KoWJs9b7R1B2Kc8A+0j9y3dQcaIegYS3PRqxeEyD+sOO84y7ocRuhg98GxdiaaZoQ4bfekM2UeYrDZ25tb6RXPMCzJJJKV3nR0mWrhIhL+vV7ColZ6H3tmhbcLn256OlfpaJwSYyMMWYhwMPXnnLDuteukcc7dl+8sTnuHyteu0/Vh+bRu51S1o/YZ73trLLz89HDBIlNNf3cnqoxW87mOarnXvG++8zhsfL+FgUQMDaedSkYmtO4KhSMkbW/N44P19LmUuUOu+R7+DufroIlS7Vr5D7cnpsS2CQPLyphze2Z7PJi+zzhgqcq60/AcE71S0R1HfnHjOhy/eX8zTHttyeMp/A/saCIRO2JVmq1X7d2Y5rCcag+xh+ZFPnAFPumdCIHFRilwYOO1tDxU38NdVGdz0yg5eWJPpOOuryHk24sCV6Q62M1IEFqydd+bXtLrsrH1nzX0HFt9VNye+M8xOpeg23V5mCvug9ahhVcC8APRpL+ce/XYu12VwqchkvPDfUsEz5wIbPzGs49u6fV5nt+fUeEXfA7uz/udpJUEbX6ABrtgj6MpEUcUMUejOic894ZgEaPn4SSl52LBO42pvFu4JHFp+is57NtQ/Hed7c+P2AwxEYNPKQP6SXUFrg9tXN+UGnOkMlnaew4wzWJFcKNwCle8g9O8NOVynO+Sq854TDL7mGCNpYAhuAdEV3MLnmU6l4tvs5h79dqSPMhYoCqSznk3VVTj+lnO5NbhP5Lzlx7j5FfsKzg/n72PhnkLXFhqB8PKBDHqlvc5mBjAltCMCft2ZG5kPlWb6Hjn0fJ4zOJku2FJ6gGc5f7/nrXrH5tCeAquLiqOw6+WQz3f2q4W17r4kEkEgmOnSg/P3kV7S6HXW6Q/y5SHPqJbe6QUSaJ0Kgecs+RBamC5KvFYqX9+a515k8Zjt0GPlIVZC9tpwfpoXzud49rG+3K7bw2OGr5m3/Gh4zww4oeV5jTeefedQ8f/Z++44KY473291z8zmXZa05JxEFgJEEgIkJJSDebZknXOQHO5Od/cu+HPv7vl8vvM9n+8s66xoK1nRFgqAEgIEIktkEDktOezCwubd6e56f3RXd3V3VYeZ2QUkvn/Azkx3VXV11a9++ecW/E7XttgxgrtO1rqyCTv73d9HxxonAYw3rkmBgcnKDuRRt6C+44R7fz2ous9Q1l8FqcGfJ97y9ck8cVzWwBAFgtDVTLJWD1U34FxDK5LQMIHs5opxcyvV6u/7L24ya2kK2mJKkla74Lf798ZWt8LtQLVf6SkSbdi7XrLrNG5TP8VkdQe0utMhdCsaGls17LITm1FstSz2dR7XzZMXwuOmosb9s1cnOsNdOLOL+2D+/tSKg26XzByalAJdKym1k4JJrYOeX4IU4qv2O27uSVWx2vUrD8eQfZirroBSE+wpE2SZPN8kF/KuJDu5AgDwZRkEnIQkp2tb8NQKk2k/HFTgN2AxdSGOVkaUSZHt/xv+62OcuJBl4CsHQsz4h7nqxxikHMcsVZ4JihccE1bik06oxWR1B+aq4sKhxPN/P+IWYL7x7Ke46dfue3+38hD+dt42vLkpetkHBj5d/b3qStykymKTSKBgwX4bp0R3wfPiV4v2RCYgPlJoHwJ+S2yLZtjCUhD7+wSnBR2tHMTDiXmAnlnq8qj49ZK9eOD3nwh/y8ZdFXAUE/52zVkYrTiCsytGztPtA4mlZtkCQUsidLYULN7D1KAUHeHeq4ZhCLf5AKNS2DYPb7r7oDpkUeQK/nx9Y9Nx/PgVwd4WB/q5Xb1zoQ2WDJg9s48XCLKSWH8wJpdnJJi79O5TboaegAL7FgHpKIyaH2EMtWucNqPkf38r91Xj7+eJhZp3tsld2b10hNG5BHNZ5UY9XdmGW9VP8P/mO7Svur4F0FvwcGIe+umHzPERKysvBVAtT9ohA9vPMhoLOAqrqIlOIvXr8VbgQxFGKYdc1248XIOJ/74UB6vqcctvVgrLEby0rtKXjKigWaaYBGarG3Gtssu3Zr1LtoDIiy4LYSuUeOEm+JY4Lnczf7UcBqWYrOzAVPUzlNX5zzZvayv2Vdmu8wPJcQwmx5CwGHIm4HrviZIkzLDuOnKuAb/31NIkMJOZAMDjH+3DLb9ZiXMNMefSg39ZsBOLdpwy9w2ltit3WUEyq3aDwOlLbIispDiwzL5KFplMqUkD/nvx3hgeMCHjEmSxcisHIyrXeEUadBfd28kpN7xu/HxfnYl1naRuIeM9M41hvNTLXOQaVwQ5CbyuhyJQSl0pwQGPRS4oUJM7FdYcMF00pinbcRU5jCQ0m7gXo9E+vM02Iw0/YMzm/yK3zij3hSEKE+iNH2Iav6DkLZlsaO8dQWdgUOtRu1ZAI9ei8s2T1YniOtSdg1MkLHkJ76NcyYqJisnA8JlHc4FS1AvcBiXPnOVivVZxNJdh1lS3IBfcrxNoHdwoW3P3KCtNoRjA1xPuhLyUApTqvtTYmSQlCHITjiIU8/fvkZXZEApMBnJ9FKgSt1hbkPO6EuqC9PkeS5w31guQJ42KA5F1MBN6IxtJFOujl0H3JoX43gum8OQUUnfQk5hacOaKPJAcB9HTUCwXrlG6uY8otRRa7ENM5DIxBDUoHk7MwwS462kGK9vkFjUvzlrM7yaBO/lbG4/ia8+KlU/BkHtAZALH1dP5TjrH1qL/78WC+K0A4mhQIMX2ou7fk7bLo7X/5204ijmPmIrWO9S1uE1dh5QlyKV16ronFqxbfrZgJ37+7i6fFY89wbbjJt3yumvGxclazopIDTRZcc95ybZneeOQJHm2ZQMf763Co0v34Z/mx3f15JcEe7eydSKymPEoIs1IweHNeEXanyfewlfU5ZHGxD9ekjCFlIouqIFCxbxfpjQn05qglyuuCHIStESohSNaK0OVo7bLZNBS4q1dY5X9mKFswXhlD25W1+NHibdR3mwmRfhu4j10JTXsJud+BFhnQtZwWJybsEkiN8+L+4ih0bYuDTLZO8YRinFkL25UNtrMdfA4ZDov3yi8N3Ljc/8mO8gIgouJeq8V9a8Q7t1426o/g2RLjecOvk0/+LiSa6JYG6nJYAnnlgDfTnyAzocWhLeD3Lp18qgg/syATJA739iKKlk6ewteIcL3u/U/s4r0VU5bn8VuTamGk77U2Jk8exgDEMo48imnpZf6D23DMISHeC7qyAHAH9Y4VpO0HffpsUZq3EF+fCOw4lf2R+r5n6cTwYJctAcQXeXdelEox1cTSzGM+JPZJBTiokP5LWfxcGIeekKeQIsvP5CEZhdWZinQxfSVojMu4A51LabRjY6iwpaE4yvwXK2H0Da+qG/o+rdquU3wJZYIthoAwMkI9R5tzxBDsxvgXcy8ysRshJNcgp0fGw/XuOI+2fP8acOxWO3xjLAOiqPnGl1JT/JOuWMUCSgMCleSiaRq9i6zyEUDtdsH3O+0OH3W5ofY1v608hyeWSUPVQjsiWt8/pbj4EdsJ87hrjkUVA7nwDJ0PvBmpH7Z9ig+KK5DJ0IRmlGMRiie2oYGdYSRuHUZZRDzB9HudXIs+M+pbsSJFWXvt65Zx/95e7vrO17xnGBKaqtW8PXUXQbCseKJB9gkSSbGkMusn5cDrghyMeBdUwalvgOVZzKDtAm1TY5Gqow0+ArZlrf43W54xooic0Yr2RAtAycBgJpK4EL0w8M7H0EC3byNx7D92AX78CogrShGo9DEz1rpRaowXd2GkZZLTVfI031T6pQc2Hi4BgY1tdauJBoNZ4G1j0fIKuluVwQC6tM0usClq1YiHIe+9bP+GZSfcmr9ed1ARXP9Ky4L3DAlQsbE5vCEKKl693qQveM/bXD3xzN6MoyRJC/g56IzueBzcWQY968f4skXxOnDGUJLS1i/e+OkRO/ddK30/2AEvF+pIiBgXFEO3C2SYsJicEKfYUiEyMwlOf4Zi+sOoDvOohy1SIvDbNw1yvZ+COhpW2hZsvM0ahpabTrBz1NQJtpsEM+10jlGRYKcqhAXTStqMmOWB0IeI8cnTvqqGpw22xZ0uXs6o8ZW1xFQLF74KtZt22EmZcpUAAm58f+977hrhroISqzhQTFyhnWLVxE5ivgZfkKAa8gezG14FTi2AaVosGkG/zZqm9OujIxB8O5Pe99TirECuiV7RsGFXJvm/196Yg1u/K+P8eamY6CUutYPU2QCAI5vQs8z4jAHs23nz7RGcd0vl7ncXgtObwaaanxugXziqVTCca1cd/CsTwguTsePqV3CxQN3bvQnlzla04g6iXvuuoNnfaVyeLRoBlbs5RQW3Pxyr8zGzF8txzmv+yK74Ig3SZkcbA8nWqJn0P1fiY/x3cR7uA5mMj17zRj+MWeKwDpyERufpTieZ4F15CysrzwnsIY7famWwppadL+Ciss/yUJVwqyUbtfKz791Tp5W5guKbjiLMtIAQvrZ3yWgIQXNCfa1EK51zGYkopu9G4ggD5n4T0cbGAWALa+afyenR7rXiZGTX5ePFmDZL/DEh51wgPbEA9f2AQB8g7wDLdGKC7TIdw87NBOe7F9fTQQxORQf7jyN2SqQbzSihVL8UF1gxZfcZV5y7FNXFilhKx7tDtWakRC4AhBQXPPzJXhYtqtW/8Z1rbsPEQOTPQFas78ad6m5IWQy8i37/plVh/CXt0+0P4tKeDBNbEfUohF5mKluEbblpeeFnngUNp+ltB7D1Ggp/nu1HkCl8BdzTF5mXvQ+zGQn/haixGPK+vWiAudAQ9r0QjWacbO6PvxCWAopl7U/YkdNNUB+h1DJuAz1uC1hMkTHaWfzS08XWprbT4S4HvanC3dg3vYaew3w8xAnaYoMoqfNZbC8qhBx6u+Ae3iLnDehByB+R7phQLOEyjzaas9TEW3Ajk8+RCtdhhQJ61mOMDenQ9X1GGP9HRhWAIDawpi3zfCxeafyBnUTTmkdUYUOGGoJ0smmQbhO3Q4gH6f3b8S3E59w91ObGf3b17di0Y7TeHFA+DnqC+tkf1TtxgwJ3YoC/on5c6C2WcNf/2mrGddlC7EU01Uz5nLniVpcdWwD1457hOPIXnRooehiKT3f2nwcQB9P3xSg1Ha/E62r4TiE29XNaNWn476n/YJNaeuZkByqsDcta/8vX9vCnZPEpD8UqKBVoVkj2Rgq/+M24e+sNBFDmlMS8TSkFzmDEjRhF+2LhhYNHYtS7vHG1JRHyk+iiddZX3rSUs4z65XteJuZtVgA0eMYuuYKYZChhDhvWFyqxo2weDumpNNCbEkyOlJZ3YBe1t/fVD8A4F4LuqcUU+T4v8sUVwQ5D+5LLAMAnMd0+7u71dXoRarwP0u7ua4VWeR4iBi/CWQ3pig7QheWpgO//GA3UpLf2d2iFNDhiLaoXQQkIjFh8xHUAwt0HafswwG9p01cE1SX2sXiErOuqAG4WK5+yilshem6GMUM7UrH7umbrPo1urae8tkCQxlgI14CAMN2Q7NcW3Qj0Pc7myQVXXAeDchHJlaYqP0GvcKvJz5EA82X/h7uK+9mFIIQtdi7l5kXuVYalOKTQ+f8TF7AeKUpxiXjuj/xEUh6jrQ9EfrUbUWB0I3O7+ZiGHpgfJ4QtSeAjS8Ag28Cel0T71742XWNs9bqBkWa+0xAcbSm0Z7TU7XN6NGhAIDbIncLlyG3VL8AoDyzwSBu1srApkz3zzC3Wa/1V/e6/rmvH04OoxplOEh7ONdw61Wlmssix/+fuUEu+E63QBLWVrzv+d9ENfTYd7eopouWYkwDYGYp/PWSfejGzT8hjnvYsRqTQY0UUyOT5CSlRiLPMzUwiBzD7eo60PQw38+1zWmhgvTWR1fi7QnnpUtruroNqRZiq3pF3iLNabe7pIh+Xk834DxplYabxIljIgSBEzORbkeayBMURbGepj0p7ZvSGhcXTe3/WcK2XVpffyNW3LBu0EieJEDE973yv+T3cw0YBgUhwMOJN6A0jgEw0Xd9VV2LW/gMgdC1UpJsJAhBujPR+hF9V9+ioxxAot4Suqn3HrMT2drirYIdiN86e8W18gp8YHEFnY4vc8UO7TkVXBhZtAinqp+BkHBby5oD1Xh8eViNHBpYGDZbZKMICmao3cykKImB7w6DYgQ5BDXC8/YnJ/HVxFIU73PHcglHlEkSFcktcVhhf7KT8I4eX74/shuQrK/71I+EbqQPJJbgu+p7vvo/wnZ8RFcimHg/CyaILy5eFHCA+5lIj3At6TNoXNJXz0KL9LSr3pbo+qNnG/C6IG4laFlFLjjsuim7zGU2rK5dbtpGfO0zGq24iNp4MTsyaFx21cU7T+PJFf6YQzZr9z6+xop9AQpoE65XtoLAwFDlqH09S7biry/nB/UIOkA0i9x1yjZ8T31HopSjYCNWCYHo7boYzrSboZLVkWOYoppukmZPZtuq0cxltXTq3IkFsPh0r745jU5wey/8QF2ApDXXfDdemvDqp0ew9oCTmlwmFIqUJd6C4KLZ9vbHrP9NQuGD+qwK9c3hSjavsoNyv8TBAHLCFRJAKXC1FVqRbPHWprPmVRKjXlUXlt0x+D2/ufkYHl9+IJB+MsZdzyIlfthqizqDfCbeny3cKYyV8o6zxXLRTEID1Ux6ECp8WjFr724/iQVbo525UVgJWegFoxbMtTJZd8QmyX1a/Wfy+cZWTPi3Jfi3d8OtaQziGDkacoWgnQiX5aEVY8h+DCNHUG4JWl5BFQAKzoqtrwW0Adcp26QZ6sLGwJdv+Xzb4kxcEeRiYARxMxd3PbY6cJE8tVxcWDQKRISGguC19Y7b2KYj56WWvX7/8K60bUWQhlaEOBpWBvtAYLVJCMWLaysDtbkVjXvxoLoQTp0y839e01LYcBSz1Y24TtkeOgZW2DxZd9T1/bRBnaM9BDyMrldbLjmWvp94xxe/IW3f08bWY87BzmofrdqfeWICGbqRcyiFWAunEANPr/DHm7DnT0KcWSoqoRS5ZPzr25vwQ/Xt0Htrm71ZzryCXLQF+uvFe12B/CKwUZZsfhLY+Jz9/acH/bEgstILolUwhuzH7cpal8smv7YCC9YjHustu9ZxVeEtznrOEpuEQVaUecMhh8kX1ZE6VduMvo078HBiHvLQivWVJsM7om4Vrlb2obfE+rj3dPC7Nsfi/y6KgeYaZS+KSLOQBn9NXYwfW+s6UmbNfe5sqF6B5si5Rgz5x+Dab1PqFuEOS7gDBR56yWR6bUWZRBEjwt3KKld5DwC447er8LXEYtd3eaTVFu74Zj+tPId+xInz/smb23H/7xy3vNc3HBUOpblS7g7MmFxZfPEg4igV3t5sCvqic1QB9a13Ue0zL/xWd1OZe+ujK8XjlVDGO9U10pAAavhd6Q5U1dsCS2yviwiWiadWHHSstgLegNFtUWZZINpecd60qP1o7npePLv6EK76Z399108OnnV9bkqbZ8f31HfRc/uTAPxjvu6Xy7DxsCNEU0uBdzBgXfQlp9AF500Xc/BPKJ+QD3eKa4U2tuqueqzFRz4CexUi+nTeUtLwiWtCwb3bUxeaUVnd4HZBjPgKosTIDVcOY6a6BXPUT1FCTH6DfwzmWinjC69tXo1rlL3IaxKXaAmjqbxF7s/VtzCRRBd4L0dcEeQCMH/LcWFcT1QcqAq22AWhgtRgBDns+ZZi/hZHO/R3kvpEuQK/yZyslcFUW/T7P83fYRfkdLdvtjm0di0KSItNSFgb96irnHZ1U5NWiOj1ZbwHT34is+U+8z+XuT43pw3bJcWLKBZDAHiQK8B+9Fwj/u/8HfbnVz41hfXHrHICUY9uuWXM/X2YX7oXbBmMaxYHfkdlLkSktws5L60Xx+MnLywJbSsKfrN0H15aZ+4r2YHrWOwoUO8ICD962V8/S+Z/z++dm5T1+J76DmaqWzBIOe5y4+IZCkLM+pX7TvvpBjUoKozgguH8rIgyc/JjSmpOH2aMnKC1kEk+39Qa2+WZ7XnvbQfOyONU2foaoVQCAErRaN9PJIwqK/wb6PvQdB5oFifN0SnFuoNnQ7OjmX340YnU2syKqkRwXPXUe6QC64c3Rtvbv2E4Re1dTfsUUeHop/jPPU3SfynxK4YIKO62FGoi/Pt7fsbqg89Oog/x13PzjldEb/qSM7hdjZaYgo+RM6cmppbSHhfFp4fOiq8FkEei1fCkHA0xDMMXm/vYMrlCeOW+KizbI6+BF9fhREjLrbmqrhNHwslpAK+wCmgfvEdFfEuxF29vdnsJaLqOs/WtSJG0TQ9EY1641REaohTknqFsxQOJJcA6Uzi8wJSNXNMDibs2Liux5HXXpCD4aLfzHikFFMhpGOWuC4Mo3OWmX8zH3F/Ndyk6osaRRRHkRODHyrJgsqVe16K5kvAwT7MorpUi8KSKEIop6g75xZ8DXBHkOPDuNJ2aj+AvX9uCh17aGHBHMLIhSj1JNWZ7Cq963X26osauKxQVJTU70Gnv65GuFe2hsC0sG09tU9qvGZa0LWJGGFIRD0fAn1yj03m/4EupgdO1fvcrnpn3umf9ftVBHD4XkLJYgpX7xBa2bz7nTr17wdK25cpI4nNxtP6PyoQzYlpkNLo+O+0FCJCrfwNsfc38bHXMJ+gpRrjrGwDc0Oy2BHhdiq9SDmMM2e8fy7Jf2H/GFzrcn3+YmB/53mZqxS7UncZw5bDLbVTjXOr4uSQEePDFjZj96xWCrIkUE7XotEh4+FPnXZ0+sNUZg2EgaLX9dMEOvLi20vXd7tN1eH5NJT7eFy9jXW/FZFa8wsXAToXmH+ePCK0CAKBBBWDSGIMCuHAc5S1it6emtO72xxRh3RPA2sdsJRXDreonOFzdgPueXifU+Pst9CGB/VEscp42ozCSviYkD5uOULA5CmT7/FbVtErzmQIjK/y4yx56aRNKBbSfJZbiWU4v8kl012PCWeTiUASRRS7o/vGi+PWjfosjn62QUipxvY6mSBW17W5BjKB2mbXsxy+L6U80shrQvv1P+JlXzHmTdEGNsEyO91ne3nzcLAzOjdVNXs0PPM311nEUwRGm3P21cPttuEcZX9PYGpzZmoMSwZrqO9Oq9oovhNs1+NuJD/BnicUuOhM1TjpOhm83xDHmDD/kajKLylTw8JLUak/JIeNKQfAvLs6fcAhvx5ZosR+BBDDrEbnB+/sXGXX4amKpr36VcBwcY1R3dAc+OeTxw5fsFjeRCBbCmJDJksXwKEAzmtI6qEFdMRalxEwJHSlGLoNYtnON7sM9v5nTXJ4yfbOX763Cq+vlWQ7jazTl2HhEXCrhQFWDa17TBsXWWKnkWd9RLWPBRNILdr6x+z7YEd1Kvf3QSRzYw+rJmFlWea37HPVT2a2B8M7zWOUAZqpbfG5XKzn3VPYcrM6jtG0SHGjtHof4mhO0k/nHhmd9v/GWDZcgB4K1lluQSJDLNnkZhZid8tYHI/xfH/8S59a9jH+a79ZoHj1nMlSvfnoUjyyRMw+Rx2YxTnWVm3y/sfHo1nGVIAYACmxyykyInuvNTUellvOz9S3YebLWjNEU3HzWk46cF9a87yFMkFM85QfYOw96nV5B7nplq5SBEhWWBpy1yWhztslO4iDq2acQA+OIs35ESrwyWgfUnrDHLXKtjCPgELg1+pkqXFnG2jgZ8Yx9iwXfOiK4QYNrkcqUckGjjIJgi1iYEBmgyPNcEjbesNCEfsQ5e0TWW8C/PtZwyiZ+nhlYJmzeU0JkEffCySvpBs9PiOasRaBY8VN7IKE1iH/k4Fsqn70BNJ5z0QKW5VSYOdd1f7R1cLl70QAAIABJREFUPMtYG+m64L5M8OP/7LjDGx6sttwxJcKs6hnq+J8vwXLOMn0l2ckXGE+963fNSAnjgqIRx1wnIqlvdsZC02GWDJ5BdP7+tPIcKs+6D0uZC6jL7G79KYtPCMr69WDiHaSqPkO6cjW+lliMrjAZ6TLSgK8nPnSNVIYohNV3j6eOT1ML9y53LQTgZC3zwbr15U8Ox2QS4jMFFTgH/n31r1qKZS/8C8d4RQxCloxHFk9W16zhtx/tC62ZZXgEbaZQCLewUizdfRoLt53A1qPn8eamY/hBYgFuUTIT3kTPEPb9xsPuuo5jyX5H+RHyqqK5rYibCVoHLoaBv4w479ArREYZSx5pBXST2RclJqASEwI1DN9eMYdDAEPHAMUfp8B7BzyyxHQBPt8otoqEpRMHHDdor1sUD406FjlnPuQTc7i6ATtOil02r/n5Eny48xTe++yk0JLVGlCEN+4O91rkVqz2x1R5GRavIHe1sg9jSLDSzq0UcPY9U+TZtDvMlCRBHMXkjxLBca/8/mCMpgyUAqhz1iBzWc0UHVCP1pZWq+3oYpiXEaY0noIxrRvSZFK2UGCECXKZW+RYT0EQzgUJjk08VSsOd3C3Zd47glT6Sial9AYkWEx94OjckOWf9s7R6VrO9ZfLWsnAwiEMl8t7+Dx3srJvs0tFK0msdAgHpRTdD/wRAKAT/3NSwXPYMDSpdd6LOPUyGfpQefKXoPUprLfK9c9q+blCeiTvwSvIAcDWow6tzyYxz+WIK4IcB3cWSorOuBDqThVU2DnYlSE+Wjjt8o4T4tgOp/3oG/T+p9ZIfqHQLJ/9DudNjbzM7SmM8KXqjmLhStNVtIQ0YgMXWLzrZJ3Vm7yNJz72J+EIQ9pyxWIQxxKI+3zlkyP46YId+Kf5O9pckLs/8ZHrc+f6fSih9fYaKSLNuFkJrwk2yOOPLwNr9//M/wy/+nAvPgyxsMmY5rC4Bx53PbYaS3ebMV4KycRtzL1jZH0GKU8MSl31nmQxR95U1UGImrGTx88W7rT/5g/S9YfO2X17FSNfemKNz33Ei56kGtjyMgDgo91+N165Pj1+xULRAfuL93bHbIVrj5XmEKiN2Rwz18oEdKyvPIetxxzLqoiJktGqKNB0ufvQ4p2nXJK1t+98Txyv4qkjx+JDgiByrRSttfHEmfNTHhdxn/XGrlEFHOFcw3/x/i68u02cVCCsf4b+P5En13Lh3CFo65+LSSfjKbTCcL26FWObHatC1LH4rLQxl9d//vZRD01xhDc7Ri7EIhfsouj/zasAnaLsENYNY/cK6SeR15gDgO3HxbxIAbcPGL0YqhzFDxILXP10adjneOrEsKRonvPdHq5nnA0tGgaQE9Y44Pqfv553afV6KQQhiHqmSNpHK4/UiJKNudf2HzccxWdHrDgy7rfZ//0x/u3dnXjCSqQnVWcKFHMiZp/yWZmJmVVTbw02ErBEK3EhmlLvGXumrtn1bmQWOXFdTudGUWKebpDHs17uiCTIEULmEEL2EEL2E0L+QXLNlwkhOwkhOwghr+R2mO0DrxdOZyLW5rq0iYpcmxjsdhmfyfj9kuhFR3kBM6yvJllKXAr8dtl+PLv6EIrrKwPbWr6nCvM2BrujnuEYjVVchqakleyCD3b1IpP5akXS9blzUVJypR/XKrvw2pr4NfoyddPh6dLGIzXQDLcl7SrFm/jGj1nqZsG38lqHC620yjKBhmHbsfNYsPWEK4HGrF8tx5Jdp31jD0I2MaN5nhgYuSAn72PZLrcg72V8GRqsdbhJ4grrhVCICBgH75rKH2SPLz9gu3W+v93NWBeT0JK7AIAjlfLyEZRCyH0ahu6LE5OhOa3je3/YgNUH3MLIkbONSGcRl2BYB68qGccEshsDFXO9ElAkqndh2Z4zuXETFDSS1uS06KGXNgUKctMUtwUy4XGtFI/BPYjFO8MFK8C0dgaV7ZBhwdbjGEiOoxc5g6c+PogfveJ3aY2DsdiHzpAnrLGx+x18tmtXqHszD8r+CZCcxiphpXrc6EWdxEFZuVbGuL6waqv0N9YOpe5kJwPICQwlR+z1kwyIiRc+h4cRHkP8ClH+vgpSgxnKZvQEF+8osMhFedffS8iF+xmKw8t8UnnO9vKIU5MuqkWOgNqlOpbvrcJfvLrZ1Q97roNVTobKC80tgZm/eWwTJHJj6EHO+pYtn9QkCPurWNp+h3bsO1OP3608hNctXktGc4WzSIAX1lRiQ6WjROcVRhTA8H9ehD+9/GTguDJVkIlKuni/am41YFDe1Vjclt8iR/HSOsel9a3NfqX2fYlleG97NLp6uSFUkCOEqAAeA3ALgOEA7ieEDPdcMxjATwBMpZSOAPBwG4y1zcFviiC+hv+JBe+Lr8sJm2FjFl0LgGIc2YsCEqydj9O3jHgybUgDJ+jJtMkPvbQR//v1gIOKZqL3zw6tnnr3eYpzCB6taUS/f3gXNQ3yIPmHEgtj95mrd24ebNm3pYD64k4K0OKrBxWErzy9zjr8nO8OVjdgxSv/gW+p70e2SkXN6BkFsu0ZVFrjqVf+GKltVt+rqTXKeKU6UfzP0n2hQrL3oGLP5U3Uw4rXhuHNzceA6n1i7bzJDftvajrvYpKZ0oAqZmZKHj9dsAOLd57Ghkq3kPsfH+zKKig4rWlo1QxpsdmpHvfMMRFig6OC5Z5xxaly760C51yZGb+vLgQ2v2h/7gB3inJvwqdIWSs9WB+QDTEqwhJY3KGujbyuTMjbu17dij9LiOK/vE1QLN9bhS+p4pT9IjjJgeJb8WRwu6FmBtO1MsObzRasdniLnIHPOG+bO9U1dpFzAL7yD/w7Fj5HxAHy7YxVDuB/JT52/Wr+6+yJu7iM0pnAW9qCIc58yrIve5V5BEArNXmB2uY0Fmw94aK7zDq46YijXPj+C+EeMAwrrCRmsvMtinAa19pcgkaUoBFT0+LyN6KJbGhuwf9dsANzn3Ss0S5Bzrpl+355zoBsIBbkgoU7qWul59U/nHgDqXpHeFsiKcvAJ1T5PCERfgkmAthPKT0IAISQ1wDcBWAnd833ADxGKa0BAEppNJXDJQbNMBzRlsoPQhWGVBvEI9eCHAB0wzlMV7ehnhaE9C3+WwRN04QrgS/WfEES/8KgQsefJ96S/p7ffBqlWg3ORhiPCEGWFhl0j+tFRfoEmB72jU2mRmvvqVoMCmknznscTQ7FGGFmfcQBS9nOgx3Sj2hzAQBbjp5Hmf1r0DjcBxWzWEcdeybvUAa58CgXnK5X5YoGEY6db7RLFcjHIbPIAf+1eC+Ki4Pv9x5UTIF0uq4Zo3xtRpy/7fOEFgpZTE/eznmgGCxs6q1NnGZTa0X+gfeRL7i2rCCJVi3z9/u7Ffvx0zUt+KlwGPJ2oxTuDoMdA8p9l047yiuv63MhaQFqnTgRPpNuf0Ha/jc3HcdctQ69AgjfP769HT2430WXxmX2cu3an5v9K2uDQjaqZk0H3bsIQGEO+vcjU9rb0KJhxbZoxaJFqK5vRWdiPjmLQ6UGxTeezSyGeKTiP3uixPAR0GAlG2eRS0DDj9T58a0yESW0OK3KeLCJyi4sN662PxNQaFCR4pIF/eTN7bjZ+lu0rs1kTqUxRiPfH/HUD8S3HkX3fyfxHgDTg0H3XiCxQtRW+T2meNfFbJNphaHP8XfhTYvFaG8JacLDiXm45dc6GjQVX7ZYN5mLq1eQA4A+nFEl14kGL3VEca3sCYCvrHzM+o7HEABDCCGrCSHrCCFzcjXAdkXEhTxV2Y4kNExWgmtTBB6kGZqnGcHNR7BgxfugZ3pQ7eQ0g59Ungu4Mry+W17rBeQbDVmMJ3cMG99m2kcF/Ygz3sk5rFeSC2I0QZQC24PnVldG6lOaCjjC/HREbU6F1TmSmMFcWv0AoLoheF3L+mP7+0JzcDyB3yJnvoFUk98iw4LrMwYVW+ROXWiSCglsfySgAae2YYB2EJMUXodn3leUiqITlEOFWZsxyprnhWc2vmzeuzerIwDUNga/dy3HwfTe5+4lKHAetS5ZFAQxbX/9J7ELf1HEUiGZdPw1Ndiap2dv/pIOJ1O6tP5wDTYfiZ9dOAhS75gM25PVWXRdA6eEhLhvR5ArQGtGvEvUO8KsV1HogzeTNwE1lS8cdp10aKkoLjAzRYfEzTHCw1u22Yjx406D3rZrGlvx83d3oDUCXwOIsztms8smCeIv7b4ELXvJqKq5aYxMEUFCFHhtpRi/VBFFkBMrB91IABgMYAaA+wH8nhDSwdcQId8nhGwghGyoqhLX1LocMFY5gAnKbmHQMI+2WEzeotm5gIwA5bIPCiqNSYqCTMbivacqJFnExYTo+S4GMeotSOk8khw0k61wRJ9fM1HWz9cTH+Y0i6vswMul1S8KEpKYlajv7h/ecMfYMtfCPuncuQ4yyBiKd4LiBqzx/DjxNv7z3W3w266sy0iwO3oYMk0atfeM6TVwTxauXiLm8bnVpuvXQ+oC4T1Pr4iXfEmUfGA4OYykZSVIekoLiFxHJyrxkskErUE+Dmuash094LjMv7lJnDQpkyRFDB1QhwI0uxhoHmFKivWVNTkV5JzU8dm3mXUSFleSDXOOu+EsCnMhOEeguWG0irWggNolQOIi6gxFecUDyXF8Q10kPKvEfQc3KqI9JaTRFccXBVJBLuIaG0jCrbt5aMXDiTfsz17a9cnBsyje9jz274rmfWJwSUHmb3H2fXGGijmW70AEcfkBr/WRBP7OsGiHf67c7/mKIOfFMQC9uc+9AHhn8RiA+ZTSNKX0EIA9gN//hlL6NKV0PKV0fJcuXTIdc7sgbPOzFPrZtJEJwuqsiPoOG4fsEI3DmMkSwzAcPttoMw+ZCWW5R/S6a20PkQtk+wlyTj83qn4f8hvVTbhKOewazbdUp1ByVOGpPYSsrOcsJrOYgB67zxKuqO2HO08LrzkXYgnMBGfqmrBIkqE0yhNsO3wapflJjFX2o5yYAlR/YgqBb246jgJdXMYkCuJY1HKxL7pzGcxYtjre0sDWqqzQdFjsYxSkiGan6Q+jn5khSJBzxj9e2YMvJ5aHtpaN1fObiUX4tvoBFm4JSoglH+/uk7U5pR4JhWDHiQvYe7o+/OI2Bm91eGqFKcDfl1iGr6pLc9F46CVh59uRc83WdUbGey9qmvso8WQ3KRtRTuqkcXZeZCLI3ahsjJ1AR+paGeHZKYjUq+nouUbsOVUH3aAohSjjpYNkwmTpOzT63WxFWHfAoYPMikcA5KfEGUGzgci65hfkvPeIac71SrCgesW10o/1AAYTQvoTQlIA7gPgVVO+DWAmABBCOsN0tYyfL/4SQhg9iZJFri0WEyMWYW27s1YGQxbwHmf8d6mrA38/UJXdgZmpNack4D0xnWwY2kOgGiWIb2gvYhT5+TiiWsIlf5C6F3o+59rtUYSshcWYhURlNa2C5vQ7iffwcGKe0DW7oVW37s8cskxmT684iOo6sZZfTO/8STr6djLjlJh1KJ+0oitqcLahFWe2RUh2IUHQ/va6kRM4ySEyxVcSy+y/D1b5i1BHVZhFRfvrh4NnKBPjVrb719TWyzv+khKQAIUA+05n6VrMIW1Q3PboKqvpi6u9p5KzmucxxG9TnpHYvoJ70Teom3zZf80+Q9rgxpYpfc3VHIudw4MRNmbRXs9krcsFuez2DQFw8yMr8N+Lw8MkWKH7qNk/521wEpvwa6wteA9RreG1B4OTOsmmrhsJzih9sfd0eyNUkKOUagB+DGARgF0A/kQp3UEI+Rkh5E7rskUAzhJCdgJYBuBvKaWXXdGGziV59t8f7RZryu1rI2hQ22IxRSWkfN9dQxZ9lDZyiUyIRKaExR3P48ZoQSpmcd8Xhyi0V79R5/bkebFQ7B3niO5lka5rC2TtvhmTw01Cy/i5mGt2f3ISDyfmoRSOQJGNIPHYcrEm+aNdQfUC/avADPh3g2Vo4zFEOYZZSnbZwNh7E6Xmvl1d6/pMIHZVzBQt3rozMOmsN/vkFx25sKgHvbWgDNAXmtIZnwHdSHB8t8w9ur3AkxwZ/RJlqR5H9oXSuxPngy040cBi5DK3yOUKmawBkbcLj0yLdvN48uMDAa6V4bQ8imJq0+EIXmBWMyfPR3PLVTlFpEuQawNJji85JYO3W1E9TfM6/zvjrZUdSebeIZcjIjk8U0rfo5QOoZQOpJT+m/XdP1NKF1h/U0rpX1NKh1NKR1FKX2vLQbcVbh3ZzfU5W6LVFq5kjFhk4i5wOSMXMXJezFC3RCLYBSGJZdoKQan0cwOz/ajCT1AWV9dnK9CrwFPf6luJD9DWyH7dx7t/ADkpXENR1lUrNesajiKmNZavrdUWGtHTdfJ1LFoBr2887io9ImM2xit7LDenzEftrCFRvIpbgZDLWEtxj+Y6ipIo6FJFimgxSws4kNUIu01dl82QAGR7pka/9yZlY+RrZ4S4aYUhW4pDqMNMKzFsTtPVbYEeJ0C0+X4gsSTwdz7ZiWhsF1u4C0OfkFg6sSAX75n+4/3d8vIDES1yYT1W17eECnxKTAmMH7NjeaU4F1CWqS3hnfddx8X2INE760ccRWV3ctnZkbJCZpGrVxAR8q1ZXpDKqEXbtTKEyc8FcW07i1zuhbK2QgJaqNto26Ftnzmqm24YOnms04pFVeLUisoVBhNxoobIoAZSAQHbXsi0vVHWa4tVsJ4luuDrHrZNfK28TVEa/0RMgWkAybzYqgIDs5RNGBQh4L8zuZDT2RExRwoo8pCbLJEdUIeKGAWwc4VUQJbLoLUQqR5chshmXcehU6XE7y7Lo4iLR6oIsdjJx5PdKmRePfopx8VaieAuGQe5UOiyuexYmMiivdw8UydSK41b7Vaan1HfKjEwiBzzZPqOj3qIS0It2xYerxY2O11Rg/ozwaVsgPiWND4TLQVBKeqhQhe6QbYPqD0WANh5VGzFK4ZfgdGMzHjqzwOyyxl9BS4M6FyMg9VOLFhbMGPRtaLZ971k52ncmnUrflxKglyYdv8BdWmkeMi2wDByNPyiLKDAgAF/3RoZZGeEN0GKchFDjQcomdd1AoC/n7cV3WPeM03d7vsuliBnCY4adchxW1jUSQCTqAtcSmerG1yfw/aKKP4mKhTQyMkLxin7Mu5HBJEgN0o5mHUcHmBmmftmYlHoCL4ouFSSEPD74GJ7r/xh5T4MsJRfBEZOx5NpWIUIF5paQATCSnu+06AEJLw16lvq+/bfYeMbTioxXDnsqs2bCb9xmFa4vCoYfjN/FW4PyR0SRmu+mjAT37ys3Rh43cbD8d73bNWxXBNQfDsLr5m8hIIWLTtviW+oH+IQdU5gWRZMUQbdNCfO5IJ2X064YpHjwRGCjIQNz9q5WEspn7TitoC6MFFR1xzdMhEHw5VwzZIXPTIwlUc5EMOCmssvoq+1qMBrLvHjxNuYo6yPIchFvO4ypqHzA7PqidGT+LWGURLpMEGOZSuLk2k214iSWa0tX6uaRWr7bCGKPxKl/88ED0TIPDietL8LZ6Z1TLNFNiUMhilHwi+KCEIoBpAT6IHqLBJ4APlowQhSmdVY+FhMBfSiC5YyZDO29jgSmtPOPJYRPt7YPeY7lDXoAkfg6WoJX7zCNsiaLYOMZk9X/Io+L6ilZhOBF2bC3GCzQZgLahj8qbHiQyUGBimOV423LEsQ+Cqksrnshs+ny+UVQU6CEUpl7CBo79IJ0mC3NamuyIEm7mIyV14MzMDSEoUZvtT9+9sa8ZijiHN1GQtyubKCElD0RHBwt0ZVjCIHbdclRZD+PpcgkK/3zUejlFPJLT3oUJC0/w6rydmWkNXript+XIQwFz8A6PQFC8y/VHCnugZfTiwXCvJRMUdZjz4BSVqioIiLJVZgCpiXIhQJe3ypnKFpSRFsLy0dqJzAHHW9/TlXpT9k8xCFBuTKjdtuT+IdocDAn6li1+lMeCxX221w7qdiCHJFAndLL+5LLAPOt62n08XAFUEuAEEZD0W4VCxyucJgEt86EQW8C0NbIgoz3D3D+IjPE3JdTy8XmrmLhRlqvCKwMhBQ9Fb8GR55UBDcwLmlugWl9mWODlWHlwfJ9Vu9aUS38IuyQGHEorYX3wLi7n9UT3HW1yu4tEBAc+J2zwsSCgxMEZQluRRAQGMrN1jiq/YQ9lQJNyvyujEuMdaXL+fTlrhHWRVZcO3XqShW26QNXHHieG/xiX+CisWv3lmZzZAuSVxaq/kiQ1Xc05EfU0tywpPy9VLRVGWKtqr71V6zki8psMkjG23s5wW5ZmQvXzEud1BhwAhJke+ddX6/xU00EgVy553o9+cS7bFO5o7rFWEcF5dOX+Wxil/OipAvEtoqIVFBwLmVSlw8lo2ACt39g9yQ+3Y0hYH2qCHaQAqF34vcJIPmOFNkv2vbft8HlfjIFnEzZrYlgkJx/rjhikXuc42bRlS4Psf15+dTdQNw+fpejihB22iJ2ksDHif74BcZvUiw5Yghqvb5EqLnFw0J6NAQHOHuFav4fZGI4VISBzLmswLhlumcC/ztsFBK8pOh17Tncu1SnIfSkDFd2T9fXJh7TL4ALqaQf4enniNDByK35jN3u/aIyYxTAvRiJTC7nBB3pREC/OWswehaIsseemngUhI4c4UrghyHPDUktVBMiJIgOMiesF3bv1PWbQShrxJcFD1TFJFoxSqvoH0wS9mc0/YyYdCLIrrBXS5QYERIh0w8n0yaUIxGdCa1OR/TDxPzcY2yV/hbfyWoWLiJi225ygRRlmJ7PVdKVXD/xD6hY/oc8hmXPDKZcgVGzuKrGBJEzyjRxqWK9lDWMFzMiP5pynbkXaR6s5cSzPedPT1tS2V/Xz1+sr1LHVcEuRzi1pFxE5dnhyvn/RXkArK6PO2JgV2Kc9ZWe2jc7hjdA4O7ysecgBHBnch9WOUjjQHkBL6beK/dYibi4HJ0rYyG9hHkVIVAISS0PMcX1bVyUhsrJoMQhWZ8bVJf1+diSZKcbNAJuVfgXEwk2iIDhgQkjkkuxxiv7MkoGzePS01NdqYuM/fTXLyGtizo3Ue/4lr5+QYhKMnL3DLQubh9CxJeLM3tdYM6x7q+rRjrwqT6uU0MkFAu360Z9ra966FXhwIM7BIvsJph+uAuvu+GdSvJqK04yE+q0gPLoArySKsrkQnDiO6l9t9ereNsdQPuVNdE6n9oRds/oxc5F+TamH5Fbb69k52EPXdb8b49yuRJpm4f1bZKyCFdw9drRVnbumQ9fMMQ6W9RLEf5CbfHTlt4lojCMU7Rjjnvp73QnjF9hMoVZ3yG3EsVl5r6xhsqFBUXUZ72oZb6+YrPo8fD5csttgkIstlO7e17e7HWY9fS8AOXTzKgtqFW7qpupeEXXYYY0+viC6iZCgtxt8Hs4d0yXiPj+pS7PncvK2gXi0amS3pM7w7239nEaXQobF+lEeBPyhGGgZ2DrayXiuWpPRIx8OjTUZyUgaG6aFA7jaT90JZnQDbobgm3kYbnucZrNag02iYL614jPGHPpYq8iILc+L7ZC6tB8sNXJvTJuv22AL+khiuVAICvjO99UcaSK1xCcpxwLJfKuZNLXBHkPJAxoRP7hROaOP7gOVnsl7BqobQgiU5FeQCiCbhhzI0Ul+4UZIcMnqtXh9yWdchUixk2dGEtolytZUpjb4sxvTqEX+RBEGMalCSJjwXMdXxNHFzjEYDbAjOG+a2lLlwiezdT12KREuk0DZ/X6UOC56VVzcw6nR3a9mVEEeRkV+w3euZ2MAIohGBYiOIq7An0NmKn0mif+OFshO3uEmtvVIvclIHZu9UeIm2/TnKNUT2ds4flVJDNZS4xumcZWmn0872R5oVewyxx9CKb5JJcHQpRLehLVKeUFa4Icjy0Jp+GnyGKFaq9F8iluh4LkioKU44bihqBs548IDNCnss5GJTDOK1sEUdrNGWg6epKCMFi/ZrcjSFT4SrmfZl207vcL/zHPUIyVSAEMT27DLn291KxTPTIsdAvQngsWNuirdmJpEpca7CalmF3wLtnCFNslWVgbb1zTI/Qa3SS22RecRBVkBvevdQnINcjmsvlDqNf7HF1t851hQA9BfTENb6Q99ZWAlcL2tYtkDHpbeFRNCDimZqLnps8wsb7+kRUlOTjRzMGBbZfmp/E2AyUeV5kEubRnscBb9mdNawCE3qLFUaPaHN93zUhDwaNJi5cbItcab6zD0V7pz0T8LQXrghyPBqqMLKn2FUvyqtP95+VUbcazeyADVuPb+rXRW6rgcaLT3hWuwXlBSlhgPqD0we6YrxkhTqzR/QN+ZnRP7w1q7mSvCSO03hxgLkAHwsRldYs18faQjMhwAmau4QBdQVu5rCZuhlM78HJEHo4CX4Pet6eEqHjrrHhzCuPVmoSeF67OKFvRxgk/gINUjrWQcwQJlUFKO+DD/SJ+MS4yv5+uT42dv/e6WqieTgUw7VrQOcidJnxAyzQp8Tqt5rKmRXqqZtHCPChPl56fVucp/y+bUYe9MIQq2CW+KD4bszTr8cj2ly8pM9GYQ7ipspL4lvkBoS4sa7QRyNNxPs1LElXA81H/5jFgb1IhRwCLRZtuWl4N9wcUCi+habwG+1eXLBiX6ppGTYZg7FGH4HFxnis0EcL79tkDBZ+P7RbCU7STnhNvQNnOgYrwQgQOLaOpM73nShGJy6unxJvj4bhee1m12dmSYyzHXlhe1TPMuG9w7uXIhlVUhFc5s1kvFofGcgreWN4j9KuSKrEttAE3pslMVIV4opBXW8MlV5bR53rZP3OGNI1q/GIsJu6lUxBybq84EvlfKyPAQAcNZwxvqrNwkfqVPPaiyzJpXVnAGcF59UlokvNKa4IcjyuuhNIiAWaE4Pux0EjhHGsGC78WsjMcIu90dI4vqVPizRMEf6kzbD/HmwFlh+hFZKr3UjTRORrAaC2yzjUoghFeSoGeJJU7DEs3ObuAAAgAElEQVQc/262XxSFBApSC/XJOHvVA5H756EXdJIKoUyD9Ix2K87SKLF05oiHdSvBgA6Za1cX6pPxhHani9AFYdb4UTg76vuugyiM1nxiXIVHtLnYQh1to0IIGpEfyjzUU7Fg9KR2h/33O/okqJ6D0avdkrkSaXo8Su591kV0UuDvDLKEME2JUqzWR2KFPhq7jT5Yo48AAJxBOZ7Q7sTT+h2O0EyA5V2/iee1m/E77bbIY1aIPPXHemOY8HtKAXL1A9hN+7i0m1to5jFRjNnZRfugJbTcgQNCCB64caJv77ymzQy8L8h97He6M38PTh8IQgh20n7yxhQ/Y8ULuDxe0mYHjouBV2ScIl3QOPTuSPdFcR0S3keKcIw6wmJS4MrDEJV/0ArltLiOxrcgr9BHYzMdJF2v/TvL6cV8fSqWl92No8l+vt94Wh+GkRJrxU7DzARJQF0TVCGpRaVBAYWCpcY4nKMleFWfhRXGGHxKzXWziYoFthXGGOH3CZUgD62oRSEOFY+TCoLWIAMt+F1Jje+78zkQ5BKJcIvcVmNgpLYaaD7Oo8RmxnnEodqEOAz9rGHyc44XVH6j3Yu1Fi3m8Yg2F2S4qRAJwno6DBuoXEAilNrKpIX6ZItWsUJ2wHJjDB7X7vLd98fEHb7vomKjYSbQ+fZUN3/j3ac6R+8PUIePFAoVvcbjqu7h8em8QJim4fyKrK5pcYTSPwYUO2RgN+2NV7Qb8LYx1Vbm1qIQR4j5XDRDm1wrTaKGOs99LF98joaBCZKl+UksMcb5fr9ikfu8Q1FB8p2FdE2fcrys3YCP9THQCrtiuTFaqvUuzU+iI+cS874+0f6b37gMu1TnwFGtw59fxCLUeRjwk+VmHwZVcAKOJnrqoE42Y/Kq5lgJeY1UC01hlT4Sg7uWYPKgLsIFL0NrkVyD+4ExAZj6F/bnBfoUrE1NwRLDre3k58qAAmJZRappWWQL5QZlBM4NvR/vGxOFv7+qz8Iuow/qkQ8jAhvVoJaCUoLVvb8Hxcg8Jf8B2hMtSGGRIbdG8DjT+Vq0qkWu7HmEEJ+L3hxOG3xEICQSmMJWptkFm5Fnr7FmpHwWk8MeYV+WJCKtm99vMQbZa5rFoR00uuMUPFZDAlzoN8cWfPfoPVzWHRHh5ffK7KvMcW0zBoACqEuUYz0dhk10CD4wJqLBUpR0RK0t7LgEEkJwHiVoQDR3w6t7l6NjUQppJPGI9iUcNJz9UE8LXC5WPIM1dnAfJGNkI+VpiBfHyicAcBiBlcaoyO0CAIbfCQB47bsTUJA099sSfRzOIDjGqxDylNRMIdVM3WuHUoJzAtqWLvcz3RQEb+tTfd+fRbTEO2uNEXhPvxYL9clYTuTzx9BA87HD6IdDNMOsjZ73eVWX7DMvavnyd7DBkGdelMEU4hym1uuCGMTX1NBiIJFvZwQcwsWRySzPDIv18Visj0enohSSKsEifYKQbpmgjjt5XgmuHcUzcc4Aj1Lz/iO0An/Qb4buY04Jlutj8Yp2Q+DYGJKqgiQ0tGgGGloNqSC4SJ+QkfvfeWTvrh+mF2uhKSwzro7UlmHRPV7hQbjvo4KAYA/tbQph3ImzznCU2WdTPZDuawpnB43uoJww4EPFcJdCBBALlqpHUdJMU+g85hZrTLp9ztfRQheNJwA+owPQ6lFGVtMy1KMI+/Tg/d+9rAA3DDPPGd7qv9UYAMBM6sKP15sJtxqOIoNZiUb2KBMLFYREEjae0W+zrastSGKePj3weu982n0QU3EbBJ5/akUSZ1AOHSoW6FPQdeBY0/WSqMCIe0ApsEYfgaX6uEjuzswjZSftgw/0Cfb3Zd3CvagY3GUuzCe9YVhXTB7a08dXf1aSucHkUsUVQU6C9cZQ9B8zHVUox2Y6GIQAtSjGfMNZBH/SZmCf5Xd83WBnc9fSIuzhzNheTblGVaxTx1uHq1lzCpBrTOx2UYT39GttBr+2qB9e0mbjGf0W13UEBGsMU/PFm8QZ8X5Ln4Yn9DtxmHZD97J8qGpCcCCG40iyvy+Wi0IBUo4W8iDtgQNKP9+9hBDbwqnAAAhz76B4Wr/dde1z2hxh/w0oABIpn0sXQxU6YJExERRKpINqVYe78Jh+FwgBVOoUZZVZsMJQj0Lb8hOkMUsrZvteAWyt4dZe8kHQhDjXHuxzLwDgfLILeKZnizFQ6AoXxBc480RsQa0wmcD0wV2w3WNVLSBipl6xiKoBYh8AzP1zJ+0LzXOYsjW0wJiCl7TZMKDY94ne7SPaXLygO+5BBVbbVbQDVubNwM5S94F22noHBVzBVmYRq+l9o/AZeMwa1hVpmrDXQf/ORUCqEGtLboI306330GAM1nem9se0gR3tuWHvIGhd7KXybHVOzSTWXvD6fka71f1Fhbm2+vfpg45FJn1qjKDwSEGckvop7Xb7/9/rt4LAjCEryU+gZdrf4Q0Bk0Go33rVShM46XEPXquPED6fiNkxoGAv7Y0DtCdakQAU91p7SrvdZX07Tcux2BiPPPiLMJ/xJC6ppmW4fbSjlDOI/93V95iMvUYvbBC4Vp0l8jgc3sXVyOsg9SCoRXwLD5s75kK8mwZb0t7RJ9lu1AYU3Duul/2uOhU5ZxkBxVJdrAB8UZuNHbQfztAOAAiU0grson3xpjHdlRCGnU+uXdR7IlqLnXlOW2fTdqM/FhvhMcBb6CCcQXmgGzAAvK1PRUpVoICiRTNQ25wGQLDNYs55VNIK4XprpclAy+SquAoWAXQjWJIjMbKusv19Gh1tIYCA4nHjHqyCSavO02Dhs4HmgxBx/BEvqLeQfBBq0osqiNf+Pi5u67Xvu4WJE6SrbyznPfT1ef1mpMuHwKAKdqO/LbxRmPwUe2Xpcd8S9j9fnwqDUrxPpuIjPZowzJ/TtZagTkBwqqsTyvKVq7vYGTtP0E4uC901k2biTf06dCpKiS1y+R0iKw0uoAgHjB54T78W/DnkDYOA61f357fVm7E/4KwBzHWzQh+NNDV5xcV/ZdLzk+iE7lPud1rrOgzPJO7Dp/QqbKcDsNgY7/IWE0Gx1i+FgtPoiOe0OXhSuwOKKp6FFwXeGWxvztOnI50stb+jFL4z7WSBWFlzOSOSIEcImUMI2UMI2U8I+YeA6+YSQighJJop4hIEYyoHjZyExn6OVk9ExE+gMyppBeaM6IbBvXsAqSL8VrsbL+g3+a69iwtGZwRw8hiTmVpoTMY+oxcaEe7es5f2xiJjIn6j3Yvm/M6oRpnPktA06qv4jJpMNzsoG2kedlHTjYURR91KRxAUIyRipPWkef8n+dNQO+AW3+8AgF4TUKfID4Q9iSE20VVhgFiB+AqoS2uWpglckGg1TR0ucQlp+ySpmmUMKh+XZhAVGhIgIFAMh2Gdp0/HKn2klDF4ViJoAsB7+rVYbwzFaY+lY5E+AUv0cdhiDMLY4SbTp3AHMoFbCAfcmnN3DJ81j/bv5kGzwRiKk4IaRImAg59XJrD+disDsHnAQ6jyPINXCLEtqSx7FQgW6pOxyRiMvZ1mYaE+WXpgaMU9kUbC1lyytZFGQm4xsFyZ2Z6tpmU4rvaErrgPMbbf+PncQk1LWUtpv0iuIBTEzoBFCIBOg3E+Yb4Dfm2JNM4DpnwJJflJgKtz1Gwpd/Z4mOrl+li8ps3Eo9q9LuFlkzEYm7k4H8ZMuCxfAeNvlSViSBXiZKIX12YwCyFrp8miXU3Ih4YEFEKQUBRs/+nNuPvqHr61DADEcAtylUY37KD9Imf/k5zzNnSDolN5uctdtAn5eE2fZVsI2bi8Fs3fa7f6NNwL9Mko6+JkxhNZvlvUIrxnTMIqY5QracBifTzeI35h9o/aTLyi3WCP4wItAiF+IZLhEO2Ol7UbIrlSeUFtJjd4fluRtC0K/z53LB66fgCOJvqAUuJLiCFaD8dpZ5xFmZ1GncCd8Iq3VjiCHDeXWgv0PJPx/8S4CuuNYVhvDMVyY2ygwvHB690CWJduwQLrBVqEVEIBAUWHgiRO1ZrxjR8ZJl3mYQSk7nnfuFaYIAJwz4/IbXiX0Tc0pELT3efCO/okl0s0bwWT4Q+ayZPwZyX725x7BbDOYBV6oAvpWmM4Pur+HeG74GkhAaBYghw7GzYYQ7HeGGrHK39sOK6sk7iEZw00H2sxFs/r7rN1B+3rstg3Iw/pVAke1e9FNcpcikgXLSv2uyvX0BLUodB0eYf/vPWCcP9/agyzPSYoJQABzpWPti1b5cWFdpwbBXG3TQiO0Aps6/dNEEJs7ygbintPBeU6oFCw0Jji8sgCgJf0G/FHbSYe0ebani6K99y3htRIwpVDFASb6BA8ppuu6oM5yzyzhrFsld6slU0Ijq1ne5+tnQsoRjPykJAc/Gfh58PYM/z3n01FnuUqyu72vlf1Mq7RK0PoExGTw34MwC0AhgO4nxDioxyEkBIAfwHgk1wPsj2hEOAH1w/EP98xPFJQ5A7aDyWTvwVM/hFACDQ41q0F+hS8YW3CRGfzkKk0uuEt/TpQUEy6+we47et/h2O0C941JiGMieLjakw3BfF1pKyX3ZZhH5TALtoXv9XutgUjAyYBElmr2EG2lboPx9X6SKQLHTcE6YgH34j5eXcKf3pEm4tNqQnQOEGOPYyP2Fh4SZvtJnawBDkSzbdfRqRd7hcW4SAEIJwgR0GwgQ7DS7pjveEF3FoUS5NG1KIIq41R+ECfYPvTA+a7+IwOwPP//o/o3sEkQm7XSj8BJMQUVBfqk93MmBVrRImfgC03xtpMKzs8U0jbGaw2ely12Fqg1GGU9yqDbEsSw/v6RDzrOWSXGWPRTFOoLBtvtWW6LK4wxqCqcBAOUJMJ3kLdfWoVo2DkOcS5R1m+/XyLjPE+q6+NYXfY8/KcNgcnLZdNL/1nzBS/Tg7QnnhEmwsj6VYS7DL6+lx86gr7YIEx2b02qeGkW+bGx+ITX9Nm2gL+jGkWo8YdcPtpTzTRPJ/2fwsdhFPo5NuTK4wxWMEJGwrxC3JBcDFw3uxjhGfo5Filj8SbHqbTqZ0lVzoQScuGdRETSrbRAWhByifIyUYVlglRNyjykyr+7svuJFS1KLKt3WxeGj2ZEetR6FIoPaJ9CbUoRt3Ir+MxjcXd0ciB/TtoPzQRv2X/JDrhDMptjf1Oox8UQgIto1Uox2O6P9aHxyPal3zfsbfQygmBZ2kpjGt/iMODHsDz2s1Yoo/DEdrVXuv5qRQIIahMDMSj+j2uOT9g9LBp1i6jj72W2X6oKM0zaTwB1BTnTeAS5LjvWNMttWjoMg6vaTOx1hiBViSx2hgV6jXidVtW84JdP3UoUAjBbaO64/WHJuO+Cbzg536xpvt/YHMSBN90gnbyWaABU/DZYgzEC9pNKOay8D1NvoT9tBfeN661v9tEg91tF+vj7fXEK4t53oAQYGCFacm4gOLATNO8YO69zE23qH2OMgVhGgmc7jzZ/izzlPmdfrvEgk1888WUC5SCs8h56JGgJXatIdnEm4zBdn4D/n4FBtYYI22vq2f0W4Dx3wZg0vWF+mRUdxhlryDqoX/8nBXlmZHoTTz9IcR1TVWIZVmEehTa5yHjs7zunuf734Y6WuhzNxUhKGOld614Dcj8u9hu9McuT9IVNi4vzVM8tIbHCn20S7HO4ki7lRY4vJF1u3eNtV3yvYuHKI80EcB+SulBSmkrgNcAiE6RfwXwSwDZp+26yMhLqNbijEK5CYzSXj6KtvmfZiNdPhBHrbiiC4PuxpPaHXjbmOb4SycLoJeG1z5hh7yX3PDa0QFdivCaNhPv6JNcQ2HxOsy3XOM0hIy8UEFa6u1Gf/yPdg+WG2PxhHanrU30xvvRZLjbodDXXSGotyyJaagwksVooPlYYbiDzdkYf3THZGygw3xmdeIRRCnE2uwf3yAPkl6pj8Kb+nWut72P9BWM37niCd0tpB4UxEHyqEchVhqj8ZR2u+2G5gUjaDuNvtjQ/yFoSNiaVABI952Bd41JtkDE0JLXGWv1EdheasYjMCa1GSnoUO2MbXst608j8rDUGId1xnCsMkbioNHDdpFiRJeC2MlOdDhrjbml7aF9XIfPXqMXdtD+eFK/054w13vhDssj6ObSYLf2v8G1Zq8f2gUXLBey47SzS2HhqtNlMW6EwFZOiNZaC5I4R0vwYYSYxUXGBF/Q/eEet+MY7Wq/HwIAXZz1xPrcZfTBR5Yr5Sl0wsO3T8Tiv5qO0gKLeeIsco3Ix1P6HXZMWh0tsLXWMh6KQrGf39EO8xc7f/MWm+e0OYEi2u68UailRXb8kQiL9AnYQIehBo7L35v6dVhgTMETml9hw49L4fZoC01hiT4O7+qTcKHPjfjUGIZjngyxMovRZk/mwRYt2KWMLbm07r+OCSqMeUiHupYzxpUXsvyzGidjG68MqkYZ/qDdhE/oMCiEoJKGZSD1LJJBXhdh/yJi65d/1hf1m0AKypDO64jzKMFndAAA4jB91tlgUOpSHjbTlO2RUkcLsNEYiv0WXTKs5zIoUINSbEiOhzLCSTrDK0R418rmEovm9pkMohB/LG0IEh4T7Z6ia1BpdMMLmt9D5lNjmL0mx/QsQd9ORbhucBf8cu5o11wxZFsjrpmmfOqMt/Rp2E77+4SOI0ZXPKHfieXG1ahBKf581mDsN3riDC0345AAn7IpCDtoX5xHMZbrY/EuFwvFW+RG9+qAv7/VVJSep8VYVeL3MuFpLxPoFUKA0V/GxtR4HDW64ixHH0ANKJTxHc6aU4hj0fHOyX6jp50YTbaXJgwUJwMyKHUUkdZ3GwqmABO+K6SpC/XJ1n3ifg7TCncWaKsNb4KoehSCFFdYZxzBAdoTlKgOlaDEcxY6947qUQYK4rFsuwfbhPxISY5kSnAmcHrdtVvKh+AZ/VZQgUfWNmOAK/NmkGLJq1Dz6teaOYX0R8bVWGuMcCW9cQQ59zj4ZGYLDbeifBMdgiOu88psQ1EUl4JCNPZLpQRQLhGFOvUEcJT7fMz6zgYh5GoAvSml7+RwbBcd2SS3KS9KoYwvqKwk0CxwnfRaGxix5LUNB2l3XN273Efw+fX40d/MwCl0wn7ay6UhYQRC5E7H3EWaE+YG/412r+12aYBYGlCCFqSw1hiO57WbcQ5uYqDnRdAWWYSLdwdUiOkSskQfh/20J4iawO/0231CCsMgK1XuWTi1mkyy6XZboCB4TZ+J32rubHX9BphaS+Y7zieh2EiH4gitsN83AbAUTqIEEWMZRYvFoyTPfA9NyHdr3ziwWIe1xgh7LA3ctXqva0W3gQL4hF6F1oQp/Oyg/fCINtfWYPNs50J9Ml7XZ6AFKawzhoNCwQJjCrZbltd8K46sEXm25opSR0P4kj7blUCHwS0k6VZ/znvhtZ52W9psPKndAaKm7H0wsEsRUqqCt/Wp+ECfiGbk2Zq5J7Q7hZnNeKcn5ibjBsEf9Jtdcav29RAzDLxfP+O3mYvmqRHfBTo7QgXbs9uMga5EJ3lJxWRY2EFJ/Xtw0oCOePLPxkGf8CAet6ws/HhaBLEOzsjlNIpnDC6gGBpUO0OgFxcSnfCsfosvlreGluA1bSYW6pNtt2weR2gFDCjibJmj5gITvmOPkTFye2gvfEYHYB/tBV0twhpjpL2/ZBZBto4+FmQevCugfppuTWRakC3Czzw4EynLnGm3a93TpEbJhMvD/bK8iTBM2kqgEGAf7YUntDvtNPsGVXyFsV3ufHnhyWDY/HotW6Il1LejRXcswYGtSabQYcmxmpCPZ/TbUI0yRzFotditzGxj5MRZQJ7zrHxKcN618uzAe4CZPwEKO0ZSoQJmwWlWgzTpUbVTksDbxjRH+dDdWT9rjJGccOasD9vS5LPIWQkorK+djMT+teWNCXpRm40X9Jt8bR6m3QQ9meDfUX5SxTvGZLyiR0vgAsCVgIm5GW6hg2zL82vfn2QzuF+b3BfPfnMCSnqPxEZjCFYao3AuUeGriegokahNdxQCoNNA7E8OxRvGdL/VNGHyPN6wkW2Fk1FLi2yXbIZ3jMl2YjQ2L7w1qFtpPsb0cYcL2GEvAovc0dQgoLiL0KuDKf9G9iwFBVDjSahE4RbATlTMwiJ9AhYZE+CFJGeJ/Rx2THTPyc7vlIIQgmHdS7GP9sQ6Y7jpxUGIPV7mhvhHfYbLe+bL4/1uw0lJ/PJu2gePavf6QlTYvIk8DT8yxmE15wESR5BTPQoVXpCjUJBGAp9Qh8ZWWsaOSk8iwXMFfXDYqAgMXWGwdxGnaNOTRcKxt0W9xIuNKIKc6Klt2kPMdIO/BvA3oQ0R8n1CyAZCyIaqqqroo7xI4F94CefesEIf7Yqf8LqdMfDEQ7Z2vN//UZ+Jx7S7XW58lbQbBnQpws0jewTfbIHfWEzgEMXuXEAxjnSbjYNdTMacQgHxMTjO05z3ETqA5ncMTRvM8JY+zU7xTogpKDINsMx9jpnhFUIwvLsVxMrGaAkY/EZtQgoGFJflEQCMvDI8os21NZmMseTdjPj3rRmOxpw/aD/Ux7usZCLcNto8RMsLHWFvSLdgRosQt4uB7S4SYQ2x8cnW4QHaA3W0AJuNwThAewYmTNhoWT3qUGi7VtpMDExL0mn44+54jXWzYrbPaxF54YSNshplaEae6crKDT2pKmhEvl33hs1FC1LiorttQJf5mAM29o+Mq/GZ0R80xQ5E84eNdAhe1m6wXVl8UJJAsgAY7F83CiGYM7I7bhvbW+hm9Kw+B7/3JioBoKksQY64RtbS1EzPNwRLJZlpZQfbamMETqETDtCe6NspXtp7pctgoNhkdtlef0K7E2Nnfdm+hgn3zPUnbuY8wF/Y/G6utiBLEkFhWhR5ms3oAO/aetDojg/18b4kQzwYm79An4JNHf3vJRjOJlioT5ZmmSPcen9Dn47F+jV4VL8X7xgmEzjIU/+pkeYJicM7+iS8rDnnyFnVfOZWJPCsNgeva9e7+uNRp1i0VnG7n53vMAIr9NHCWFdvrEvHohT2/HwOvjOtv+u6D43xdvZn27WShEUohcNbq873XMPc78teb5yChZ2d7M5PjWH4QJ8I/jR/WbsR71qujaL4bW+80lmUSZV3gN8NMEXEDLkXz2lzhIkk1hnDscAIrj3Xo6wALE9oz7J8U+msqFhpjLYVM3z8LovjLEwlQEBtmiHMHUA7oZUmsbtoEoy+07BUH+fz5DmV6oNn9Vsi7fkn9TtcVn+v4m3uuF6YNqgzHrx+gI9pt5WzksX13Dcn4LdfNeniMdoFL2qzXQlbeEXq+bKrsIv2FSquRPNwrLfp+m9Asd1B/+Z+fg2aD3LP1WYozDpjuJk8JVVs14Rlwns9Cl2ZdbsU+40CLIabByuLIJpnxi6wlf22PlVafmalIS/L4RXk/GWBCJ7U7sD/aPcI7z+NjnhEm+s7P4sKi/CWcZ2dUAZwJ3xz98D+cJQtNf1MXtO7vxJfUIvcMQC8+N8LwAnucwmAkQCWE0IqAUwCsECU8IRS+jSldDyldHyXLm1bqDVjlPcz/0/mu17/uD6OW8EmOgTHOLOubFkECf6MGHkvMSyNBfulkeaZByQF5ozqgeuHOPMmjZHjOlZVSxPOZdYa09vxPb9QMhgacQjTUmMcztLS0NTSDKmE4nLzePhGUUpxExoSdmIW79hlc8Vc1YjgmvNNGggBzqHEtiTuklgdGE5ZWsXdRm+s1keK3e0IgWZQlyaJYSft57NKeiGKL/AGAIvAC3IitwAZw83alsU1NFpa87BxA8BWOsi25llJt6ALrVwmmIWTt1qeKhiC+fpU7OCsOLz7incm+LYJIRjfz+0au67DbcJMVQCAST/Aqau+ZX+c2L9jLEs6pdFiLAEzrm6JcY1AYCa+RDAuKAow7WGgu/8wtBkiya0tSKGe24tLdNNdrKpkBBbpE7A/MdiXqONDfTzOCrLEsbVUG7K3/6TNwLPaHBezzh/W7+nXCksEMPzvm4a4aBD7qwUpJBKOxr6DpehYZozFBmOorZn1Iuz91NIi7Dd6eqwQnBWYUuyifV00uw6FPuZhgTHVV/fuXX2Sq7YYe6yDtAdaVf88xllLsnIX/PKqRRF2ULcg9Mr3HMv8/2j34Bn9VqFFbj/t5coWuKlgMl7WbkAz8lCLYhyHSbdFa+/jwpsxT58OwjLQWnN5pscsaUwWo8E8w5mXUH1MbhoJ+8zg6cZVPeJaON3wMpSi51qqj7MVH7byiXtpzD2TCaUXaLGtUGLtVaEDmpGHhfrkrGq/MngZzUZJXVQvLqDYJzQCLPlJMBF0vxL/qi0vStnfVhrdcAbl5mfbMuv+n8ef9Jl4XL8LLWohlETK8vaIzzyzNdeKpC08sXG/r0+0hdiywiRe+u616FqabwssstI4XozvV47ivIR9hvKJNChMy2g1LcPmvPGhj+CdRZU4iqRtdACe126G0qGXk0lTLQR6XA2M/or7xo79Qcfcj9f16118mEsZKhiLSJD7q9nyDI1e5Xkl9ZcGOmD0wD6jF3721ettryIvvHyJyHWxGXmxMqMPrSjxKaze1yfi5m/8o/2Zt+yvV8aglSZAk0XOe1CToPDH98kU3pczoghy6wEMJoT0J4SkANwHYAH7kVJ6gVLamVLaj1LaD8A6AHdSSje0yYjbGgNnAdc+COSV+DYLX8eLh9Ta5vpbYrULWFO/1e7GM/qtLucL/nqFEMz/0VT84dvuekn8Op3/o2l4QrvT5Q7A0uKKBnCEVuBF/aZImjICMxX7L+4dhfzBM7HL6OtzbwHEQozv0JVam5z2GMHYaAxBM03hKO1iuVYqeF6fg0e0uUJrkTkG8/8NdCj+oN2EKpi1xkSaUgJTm39CEIQ+sV9HfGtqP/FgA54lCoPHW0NttxI7IFuRCmqGfbjmlkAliGP5lLW9s8e9VupjBxTEYuace4IEWfL/2TvvOCmKtI//amY2RzYQF9gFliwZJCOgBOGMoIg54U4UkzwAACAASURBVKlwep56eGe48873DKfHeabDM96JOZ+egoIBRJIEkZxZQHZhyQu7OzP1/tHdM9091d3VPT1h2fp+PrAzPd1V1ZWrnqeeR3e4e1x37YT8SEpTpqUqAEBGfshQSlF2Gu4Z78yJqBmRKZelpRaFynNeymrHWE8V8vFBcCjg9WE9bYulqQMQtkaoTh0jPfAwJUH6ifZeFGl2QfVsoq2xw8Tv2vRR2smDuu6UN5UWHL8c0R4lTaRJykmkY2HwDE1b/zAwRCW1Yb/Rd4Fu8PeYijcCI/Hf4CB8FByieRdFImdhvd2UzbREs3AxNLzDS89LmZJZNVYTDXU/EIBXmiDltrQ08x0gPuaGA6vu1XrSUUGbht5XycMUE1Ohh5GDZ/3nYY2spm1W//Vleu3gMuSm21NXD4dFLdOm8CNtF3IOHlrIZYc3IhVpgtIDK6/w0rX9I9rJVtoqwkiOwh4aucAyTn+YbwI9uP2P6tmvOxv+mn+0qYPzADxS4WdFbqo/8IuuobEnfPaKQCk5j/qMHNjjG4XxmMTTiuoZZ2CV5zbSNsxFbCAizfJzBhGy0qe/8p/AOdiS2tk6zbrNSsXy6i7aDGqNprDnGAJ0GgfkNMPTU7XaEp6C0ogjHZojJF0izyV7shm+ZXXvp1ZT5Bl7Pg4OxifBgZLbFc6FrJmhHF7OPSNyfNlI22jaqrJRfIqmYrunDZ4JXAB4fKH+QEmGejN8Dy1yJX3JhuVsnVLqBzAdwOcA1gN4i1L6EyHkQUII2yxhQ8bjBTKlxYC+kdvpDPQPGJs4N65UigXMn2mBdFsrrQ8dD5Gka8M7Fuuuh8PMSfehVlY3VFAv5AjsHdBncdmANjjabABTdxxgd/IReWvVS5BwdlaiCZ4LnIeTSHdwjpEYSqbUQfmDQXwWHID3AsM0EpFXrx+AB37BVr36MtAH7waGMeuD1WSSEGC1bBJffTBceawaOWB5iehf2iQs3XW5fzpeJE14TtA0w7Bz8otDRlQUWK/aqomxURyCcPmzouF9r3ZFWfB5PbYm2xQclgd1Nyjz7PN7mxsq4lq8h17OXuEpd5sd3J4X6Bdx3msrbaWpz4CxZN+IPm2M/aGxUJff4PaFmP+bEfjtOGPjQ4Ak1Vkqp32XSlKnWFud5Z+EpbQLkN9GM5lWv4rS5nik4QpZqea7xlG3sYJ2QElfjO3Glj4C1uVhNN6wJrZqjIcpkwjln5Q8tNoskiQn9jMpr4k9wyYsMlPDEoNJfc39YgHyJmGvqcAZYXXfwR0KUd40G2nyolAZN7s0zwWyi5FSauxkXjnPCAAfBIbiRb/WNY/e7Ho4HeH8+oF2ZJ855eDtwAjMVhnSqkITpvT05rPay+dWfXgvMAI4Y3LEPTnpKaH32Sm3P6Xt7aJNLTUJFHiPlOiZPrID6hhGiggxt60b0EnkQpaoDVKqN5AzshNbU0z9fLNcazdRlAL+9EI875+AlbSD5f35mdpNDLaPTOnaPloIT/PuEb/ffN4wPOs/T3N2Vh/KUWRLR0P6XhM+w+dw/vf8Vf1wRqs8ZOkkdbzGRJrlGkue/UG2RFVv3OtF/3i8pLOevdUr5XcgVZrnKfOTF/3j8HbgrEZr7ASU0k8ppR0ppe0ppQ/J1+6nlH7EuPesBiuNc4hRtdBMKgwk/TwTgxPIwO6etwEFZbalfKzwNRI5TtRnTxSowWcerBbJa4LtNNahiOqcluY5zvh4fIUpgREC+AMU9fBpJpH6dH4WGKBxiPsjbYfdKqMp2gRYx7842BWz/BdrVBAoPHg/MNRwgfi3S3uFVFBMJ2Sc3DSiHUrkRdfJZn0xyz8JtUjBmWVsSSdT+ii/qlqFd0gHZ5NMO3CVsQso+XyeiaENXqIdU9R1Qi/l+ImWmp73UuBKgpy1X9wxAu/dYqxWyUKdRkKAdsXZXHV1Hwoxyz9Jox74aXCgdqLCkXg7teKvkyMNqrhHOLH/vLIfOhucm7XKG0UaYqTq5CZKSpRFsZ3zJWbtUZEe7aGF+DAwBOh9pdMkhshKC1t95S7HJm2B1PDGRm56CubdMQLtm2v9WRICoP8NSO08FjsenoBnLo88bzonMDp0froevoizyKtoB8wL9MXf/Rfp3ENIeerEN6AaP3yGEkI1vx3XOVTH9pJi6fwugyPIxmz/RKyQF4N7UYTZ3ktRjVyVaqVxfaCUOtYSuXNsJ6aRIjMIgM8C/bE2WIZ90BtEYT+TJqt6KzEVqc6eURC0Up3BVfJsULtC7Hh4AnY8PEETlr6+ewhk9WlrgQBPLu1HE/wYLMNngf7M+1O9kYanCAHeu0V7XrIauUBui6i1C87p2gwfzxgasTDqX2pyzEDFTl8pvgr0Yv7GWsQDiMioo8jSvDMhwKaUTtIYIdfrn2gp/uG/MKRl0mgXco0VXl1ao4FXfVnvq8TojJyduDIMdo/VnSerI01TnVNx0s+6MenWn4fVBzk/2AfPB8K7i4Q42ecNw6XmporBbyBCU9+zgbYJWXs0ukdhaDmPqg0B6y130uaS9JH1hGqH0o3+iYCE8kpRk6WUol1xdsTApcSvRxnQOquchhIAvVqzJTmEuFOn1OFxoz74oWNrsCWCntSIX90cB5xOdFhlXkWl/D2CTDTLTUNmqje0KFejj9LOBkC0/UUiLIZFq3HAw6OTemDJ70ZHxPVRYDC+CLCNzMyawp7EWOWRUuYs/1dLg52xJ5utTudk4qbUDSUutyZBe1CMf/onYgstkdSw052fj1OyQZHIuaGhcMbwi7Ak2AVbZCMd+qBY2VCLVNNzyEF48BMtk1XmtAF8FeiF9IHXOU+wTfSGLoyQFoaqzSJdlbOS6sR7znwU2fgi2DdCLZE3GR5CQEj4ZVjSfN7+sl9pAVK8RGMozxCuDSkPvgz2xYwJ/TVz054l0qYDq20SEI19B81vLpWNEoySVfdO7Iobh5VZPrc4dQhWGUgr6/0G8y+eNCsb26pL6s1xsZBrZPAWt1HlUlsWMnI6GY0UZQJDjzgy/MhrozqrDbVYuQFWwjFPp9mvrFfnVVtVh+/07BkvhGNw4ykuVj8xfaTxoWMWvJNPgvBg40bHrA5DUTsxS4qZ8DFVrcJrkjiCsNVSJ7uVPG3oleuMVaKM+Dg4GHc8+E9GetwbCFghFWbxq1ap330VbY/X/KNRQZsizefFugfHMc8a6OEZ16JpZ25Iig3D5igLO2lnJVW9S2/0Ks1z05mqQttoS9kybyTNctjSE6vyUCYirL2m74Ld8djMXzOfs1MM4b4Qmrj0qmhmWPVhvjTjc5hO6puy8eSGVbpRZ7TB4mC30IJAX4fdrtMf/OU2TJ840PI+tzYlou3DQu4oLPLa7Y0bQozzQLl8cZ+wWq0SuzodXwT6GFra9niks7c1yJD89qkOHpPwRy4KslKx+aFzI7RZWOm3Ux43DNP2J+ojdxHhmgTrVtnog0nxetClRXhD40/ns7VCzI6bZKd5mTlCACz9vbEbDrXxMqP3a6zuBxotvOVtdNtjk8LqHYYLObtpUn02dHugkQRG/n5x35KQ4RZ1x6i3EuQE1g6WWuVgct8SXNqvNc7pqj8jYrFQJNENPUa7Yiw1AI4jI6bY7VB5MQpX7+MpqjhUn0MH2U06XFYVVOpAbobP9D5mpC7ACm5ER/bZB555kdEutO0HGbAmhE9cypbUsNDma6T1TL76akMix30nGzcH0ekjO0SURVpKeEhTFsRWZ+R6tc7X9AN6yXGqavHCo30RLVZ5FDZAwj+rf+jCyDM1dtLAe0bOFjGYT/11ck/877ZhrocbIcV2PQbni0Pex56a2hsfTx+qfcbhiyibdEPaG2uaUJO08YzmBYwNLZ53tRp/19J2qKDFmjlBuCkR7EURXghORB1SNHMXm0epQ6SlWFtrNHuvIR3Mz48q8dqVNNmtbka3W5VleTO2CrmR6vXQDkW4ZSRbUkeIseE1haDFxrZYyDUynBg7ueWs9qGzQXmqA6yGKr/ci0VjiYXRvYDx7r4yyVYHd253tlVOwGCX08HuYIu8dDwyqUfEOT1LiRxxPtC9MW0g2hVbL1KjHNtU4USGQAjwwa38Z4tY+c0MFyTccVmE2bette66Oouz0rwoyErFH88z8avFVK2U8BCC5rKUQp121sLIqFN/4pKe3OXudLfa2vqk9gY3x4GmuoPzvdvka/wPGqG0H/XgzZr4KNmungy0bpLJusUUXoMhrM0g7eYAVzAa3vnlIOZ5st4Moyszx3fBL0e0x8fTh4Ym9Pqk3zuhS8T3JpnhvNO30+x0H6YNb4f+pU0sJzN2zmkaTnI5+kIpLn5SWF5/OVD6FuWv2kfUmIjNOC1W6VNe86mpvR2ljRXPpL4lzInjF3ewffbxoi+SeE8G7xnfOeQTTA9vWib2aIkzZDU8p2OdktdZqT58cccIPH6J8VlESqOTXH48Yyha5mml1na3c0OSZUY6pp4ZdniuvFdZkdQ3ntFKyid13xHqAw2SYFTfH5jYlZkmzTWDZwFIPv4YfHb7MHx/z+iw2rPNvHarBof7I3vCCiO7EdcPLUN6itcwn1j1vWW+VE9SfR7VsSVioBprkKAGjFjImcBb3uqKcfe4zviQMWG3s3saLcrkbkr/1kg32A0aWi5JKLrqfPe0K450Fn3D0DL8XjX5MRWuWO0mE8K8zyqvpQZscROD5rnpGNiOzyIaz4Bo9n6/OUc6FM6aMxEQwzNiyh1qrhzUNmLgZkXtUUnkrPL+39dbqxeqB0qfh+CH+87BxSYW4FgxqiWE4YHUbHeWHT8AXNSnhEO1Uv+dv6I4aZbqNFrtllpx34SuEdesJiteD0EnebKqfld1H6MfVAe3L0LTnDSM6doMb/9ykDY+juzKlScTykR+fPfmuLSf1lrpTcPb4f1bzB0R2ymbVJ8HOx6egH6lBRjH2GRiBZWXkYKZ4zvjjJI8NJU3EfR5obZuqHDFwLYAgF6tw5sdfds2wYxRHfDC1f3xu3O74O1fGr+bo7ODBuVs1Q8pjq/vHmtu+VON3fFHKSflKUWzQ71xYLUxZJUlbWQn820K7DmbN4zPJMIOTdlSAV70ZWK0Lv7mrpHM67eObB/6nK6SGndomo3iHGsriDeNaI/7fxHZVwDAXy6U/Eh2bJZtaHUxAlW/7AQKig5Ns0PzC1bt4q1xRm4jWuVnRFjkNtv0Y2H6ehprbdKX/qUF+Pz24SEXQ6yY7C4m8zg25gIOfKR0bp6L5nnppmquptpFoTYe27mpUZ9vfNzILCz2PPC5K/riyct6o1luekhabNRGT8Mjcoi92auGjE1pmRnuLeSs4/J6CH78wxjmhEXhvJ4tMaK8GHmZKZi/odI0vHsnsgcQFkzVStUlpZFGSju132df2RfT/r1C8xwrn82ydf2D45idwp1jOuKvczdFXM/Pkjpcs46Xr0rY61BZpKd4cf8vuuLFRdsto+I1RGB/F9lZj6cuY1YIZguveFmetEOEsRO1G0bdG5Y3zcbmyuPcYbMMFlkV0wW9WjGNnQQZkwG1JH/p789mhmfVf5U0ycA/r+yLT9bsC02+n71CcoXy5vLdmvtyGL7A1O/jdBA1kkbzVGlLiSuA4R2LNcZ8fvrjWKR4PZpznkB0u7nc2hcW93k8JJTWP3+ynnnP81f1w42vao1H21lEh8pJzjulj1Hnh1V/w1p8K/xqdDkWWIw7yQTvZpFRFs8YVY6nF2wFIFnGPFVfCwD4vwvPwAADi8C8XNy3BCUFGejULAe/eXs18571D2pNtIfdB9ir0FaS+bM6FeOrjVWW4ajzSZ2GVfefox0PohwO7EoECSHo1DwHm/Yfk+MPa7s4Va3kyeOaukhn3grqM7rMeOW/bJ94xnG7JZkKSeRcGrrN+hUj6+WF2WkhK9JPTe2DOUt2omsLAzdTp6FITkjkTOCd+LL8eymc3UVSP7Gq5Fb+i0JxcdbBnPQUy4E2YsEibXdZYre9qt/dyP+M/vuYCOfrfJM2tQpWRqqXKZHUOyxWuH5IGR66sDsuP7OtYfhmaTA9dGz8WFQQkNBunlV58xgB0AywDhN947B2uKRfCa4fVsY1KLuVN07GER4/chGqoKoU6/MoU2US3um4Zmdx4rHIX55BlhWfXv2wRV5GxCF7roCgz6/oNgd0AXNuotmPLyvNF7GIk6LU5ndUkxeDpDsN89/XD8CrslGfomytmq06yAk9zA3gZKaGDQ0oCzglTWp/V1ZlqRgfYRIHDRVW6t692VxibBiWhQbJk5f1xqX9WpueW//0V8Pw+o0D8bTKdYHeeMwjF59hO20eIkncCxkT/kv7tcZTU3tHbBjFajy6eURY8mi26NNkp+pzfmaqoSqhwnVDytCPJQ22W6UsJD+Aru+g2t+4o+G4v6beeCF3z/guhgZDAPX5VXtxu1UHnPbpQ2WXRD11mkpmKqJGEjk1rfIzcNfYzobpOg3XcWIhZwZveZvd988r+2Ljn8dZSuQKs9O4HE3Gog5q9MBdDJfVkEL+Z/TuByxezEg1z00Jjs/rweVnto1YEOkntUaYqdBbq5xah89cIBIgwGm1krXQu2FomTY862RYkpPuw6OTeiKb08+V0e4sb6KiTbPdOqTORrMJnr25avhmq8WJUTkHGBE6zRv1oo1bkmR0PUYDJ+EMW1++sZCqhS670B051d4YVl4cUkXT18sgDXsZHG7iCmVU56ZY/cCYsNqVTiLnJQTnyz5Fo1FRokiMShfPOWF2WNrv+k3e83q2xCOTehjmCQFB15a5GNS+EP1LC9BCPvulP7t4af82rMct0mZcEI9M6oGJPSL9XYaPONiLy/Lco8uNPaLtQnIk/Y7JgtxgjcgKnPVRfk6p/9H3qTz319T6DX/LSPViygDresFUrTS7X9fGneK0xId1LMaGP41Df12bjLUl1NPR2IlQrTSBt1MyqxheD4HXEykVorqdzkQSkiRx3s9eqJiEr3pJJU/tNqamOWlcz0STn0b9h1qqx1MnYiWRY6uXhVXqrA47mxkmUd2kCdsJLImVdPDd+P5oyk0x+27ldJwFT7wRg7xm4ekudhcn6ns1Z+R0ieY1VsKMi/PRWI6PrKCNVHf1ROaFu+lwHJbLEjlN2IwwlfjMcs3nIUjxekJ3hM/IKbv+4WejmRBp1O1jJh9yD30K7Zo2j1DNlP/acefAgx23Neq/UYdvIhXiDoPj3lirxYXyRSeRU5/NM0qCkQCap52UFkXaJmCli4WZ1WpTtz8JbnYEYGpMWSUr+oVcVI8nJUIiZwJvgfPUq8EmZnqVMJQB7a2bBpneGysIcT7hY/tGkX9TXQupVkZIMowz8buZo1DSJJMtkdNP0kz2DN+/ZTDuMznvZ5QGNzq8mEklCAlZRHXD0SWB6lyAUzU49Rkym5JGJ1G2LsjEdzNH4fbR5Y7DMCOyTagns+7GBdhLv7rOslQIEz1YAy5tYrA2R1x6N1tdHmecd47piG/vHhn79BhQpDOgQbUrJ0vCEjnpOcXCnDrPrXbOzchJ9yXFJiYvvBasLSW2OkzVT2NIaFHvcgehDi4Wxcu1caO+n/HAjFFs0/aseChjc8xonnBB71bssAw3bMJhWxlkMysnZc7D2sg1yy87ltDNsHreaE5p3IbMF59Rp7cBbBzZRSzkTOAtcJ777EyyzVTSkmFixkIxfc7Sb1dLCpT067PD7L1a5mfIz0T38r3bNMH1sirhL3pGqps4ad9Lfxd2Tmm2iHRjwGQF4SFhlTqe/Jl6ZhuN9Ur9E25Im1jPRaNGxdO+WuZnOJpYUlhPnPV12ky10g0sVSvBTrPZJkw8Js2G6XaYRerHmrB8ShkcfNcTjTSSF30MLfIy0LrA3M2DUcpZqpWzbPgWBKRzIt/ePRKXySpZmsktx/N6iUToHI6q8jtdxz14fjdcp1LpjroJxaNuc45XxhI59nUji42xJqRaGaNwLe9zo1Mw+e2awaUAwLQIyjICp29yitEm/YaIGWk+L64eFHm+3o0xwqytKW2UaS3bZQkpi2gXRpFqy+ZxRTsPTNY5dDQI1Uoz9J23ixIbfdsxUz1Tx5FMuwnqyfk1g0uRlebDJTqT5IBWUuBx6T2uGtQW1w8tC1l7kqSJ/J3SlQPb4uPVezXXzM43GKGYOOe9PxpYoap9pfB0cP93ofYwfaTKjxsLznAY4bMG6l1O/f32jXGYxm/zHayqzMV9SnDXO2tU6Um8RI5lWIcpkXOhPKNVrXQjDVP6t4GXEDz79VbsPFgDQMp7npCdGDsxQv8u+ne2JdwzyDBWGIMduLloXZAZMnCkbn9cadOlJjRZVEvkHM6IrhpUGkqTm8RyZIxwP2BXtVL/3eERAyt4s9RptFabIppgDW4lRHujWVKMdSHMeeAXXdGtZS7zfGBo3sIITMmXIR0K8dikHijISsX1ryyXxlndPdFiZ4FnKpGzMf5rw7R1u2U4TptzhHZWSGuLHVe0yT4drVYm1UKuvr4eFRUVOHXqVKKTAkDaGX3+PMnC1/r16zG1kxcXlEVa/Nq2eSNX5VDCAqSzCOvXr4c/EMTz57UIDbj+IIW/erfmXgBIP7EP69dX4orOPlzcPpwmVvjr169Heno6SkpKkJJi7cNEPaLyNEbWu/q8ntDur0nwoc6GZwI8oUcLfLJmX+h7v7YF+HbzAQDAiI7FaFuYhfX7jkppktMejZuHaK0cxXrjn5k+EvZB48Z5C7tqjqxXVj+m7uSNsieRmxM80hq9pE/71XqA1WPlosAqN4xUoE3PyJmE51a9jWUpej0EUwa0wexvt2kidGPH2Y4fM96+IJq5AqsPc9pGQu2PUlsTGL0hBPYZOUdJihvxXNiFrxukJcnyKlTFXEpXeJHj8sLUTt+k1h4mBJMZm8rqMDUWaCMMIknPf7flQORzyVaW8l+W1lc8Fi1OYzDaYDOXyEX/TsnebzkhqRZyFRUVyMnJQWlpaVKsmgNBisDeIwCALiX52HnwBI6crI+4r3PLPC61rvqKw6HPKV4PurTIRa0/APrzsZBH+vpAEOVNc4DKY5pnu7bIhc/r0aShS0k+M/zOrfJw8OBBVFRUoKyszDJd4T49OqMThuGrAl1TIeUnT/E+PbUPnp4a/j5jVAe8+0MFdlXXRKTTQwiCNDo7aG41cCdV12nUhNhTrbRCnYdWk8cJZ7DNmLPUM7UGb4zvZ4Zn/rNp/Hbh8QNn5n6Ah/dvHYLuD3xuHL6NMK3cO4Qn8vxhOsXuuSFHcWg+8wVs1CtM6d8afzy/G9J8fK5f9PEDsTGc0s7C8IEdQgsydbwcBaJXrVQbfXCrOG8a0Q63vbEq5JvQKfHwPcnbZxlvBsZnPsOtRmwglJo2vB1eXbzD6jFD1OEZlUtUbYan7nKHxXpWe9GpFI6nHFxT+TYxdsL1uL0q4xrK5pCRtJoFISTqeVriVxbuk1Rn5E6dOoXCwsKkWMTxkpeR4v4OjS68gsxU+GwciiaEoLCw0LZkM1bZrt5hrvMH5bjsR+bxEHRslg0g3KlEWGyKamLFpxZjRCymE3+fEj4bw0oHQdhqpb6Du2tspwj3AlYEgsYLLj1qk+Zq1AMKYUwk9UjS1MRYPtCfkbt+aJnGMTQLdb5k6v0zETDPSaixdssgReDGhN6NJs0thTKIrSAz8nwbi+6t2A5cjfAQvn7E0H8hga1FnPSMeR/hdHL2nOxgHZB8aUXG6yjYEOrdb56gwt2p9CBLfStaSfr5vVphx8MTkMtwIu+EWM4b9JNktZEStY8v3knm05f3wdhuzUJuCOJN2AKjNsG/O7cLNvxpvKtx/e+2YXJc9p/VjwvxlqaopXDqLU4jEjF3dVvl0zIio58Nfjd8zCA7zV7DFYncaSiSS6qFHJBc+qtWKclM9aFtYZZraXbzze2kSetHzv0JtTpExcmuW2cDmsq+9849o3lEXHaJWqKgm+y4kZPn9wpbwmKlw0OMrVZe3KcE95pY6WTht3GgiFKbZ4KMrjMWftEQ6x5EncQ/ntcNt45sb3xzlOGrefgi6Xyj5rwGZ5jRtGvutYlBYngHTvtnPPju71fqzHeYdfz2fjOT6rgtldaHSw02XYyfk/swE9XKWDa05JkFSOjTk54ijWMdm2XjSvnMH8Bfh3u1zsc/r+xna4MWcG+yHq0wiMtti/4stMF9pu8UEUb0GcByoG3nfZweOdDj1ryRGki23MbwnRxGbHQMxqwNuZFlyda3uEHSLeQaM20LM9EkMxWpibJkxXlfr9b5mNCjBR6+uAfX/er2quxkms3t1FIo4zClQIuy07DmD2MwQzY9H426grqTePbyPo7DyctIweS+JXjpmv6Ow2DB6vgJMZhkga/T04cZsFjI3T+xK4bJDoWNFgfqIJ+5vA8u7N0KpYXG0iWCyIH0msGlIee9Sng+D8Gb0waaps8O47s3xyALs88s1HmWn5mKu8Z2Zt4XUxmjalJx47AyvHxtf7x10yD0bpOvjdvByPfrszs6SlK0vRafyl/4Ht6N1WHlxVh9/5jQ9+gsqLqHRkVX/jvMwFk3IQR92zYJWePj5ZazOuCcrs1wSf/W9lR25b9K3/LytQMwuW8J8lUWXJNlQhQftWHt26bLktxT9UHNdX0f/Oa0gbbLLB7kZ6bgkn4leOW6AdY3qzHI68cn98QverZE15aRUnUz10R2eeLSnqHPd5zTkWuuoCekJsxIhb6NqPsKnmqWJi/wFSNsZujnKr87tzMen9zT4G6TcOS/sRaCRGN/QOGRi8PG1oymGuYbZPbekZnkJBIWuUVSnZFLNIcPH8acOXNwyy23SBdslPesWbMwbdo0ZGY61/fPSPWhdYEvYjKdGKUzY1J9Hjw91XqhEzpnoXofxaiLUVtqlZ+hkUIxQgWgzZPc9BQcPF4Xcd0u6kF4vMH5Lx4IAR5z0CE7igsk1ME68SOnf6I+EJ6YsMrouqFlaJmfgW83H+CaQHVpkYu/DtDfMQAAIABJREFUWZhOZ8Xzh/O6RVz78wXdcSbHwou3n35WVmezO7G3yma9NMMtqOZz+NvvJ4Slrn++oDsmPLkw8lkbaZk2vJ2T5EWN3eprZzzOy2Sp7zloLzGaAyh1Js3H3lslAN69ebDtcItz0vD8Vf10cfGnR6Fn63z0bJ1vek+iiWVy9HVTmbDX+rUTdn0azmxXyNVnxRtCCB6d5HzRoKe8WQ7+cVlvg2dUapyUSucsOVV09fF1bJYT+vwrefPWKfY2NkioEzV7rFB2k1J9os48LAbThjvT7AgfL3H0uO14TO6wDOPS/m0wb91+fLG+UiVJ1CbcbUuuek5DzUo+iRwhZBwhZCMhZAshZCbj9zsIIesIIWsIIV8SQswPiSQphw8fxjPPPGP4O8vhosKsWbNQU1NjO06f7PyjgOEniUUs6qBm1ykGq0aNNT0D3XxejIw3KKHFwvgAv1EFe/e7ASFhKZqRClt6imRYh4dAkKpUSNjh6Q0hRIt2UGf8zli8u4rNgBPtAsSOdluoXTgM3w7RDsD2n49/OViVfbT5bHaezy24FnLyX1O3IK6kJoa4mmfawNI4JXINmWgnvPxGNIxvtKNhw7shx/bByR2NafsZ3rEYADDUQLIOuH98JWiwIHIbI4mc3XiVtqQ2oKT93XbSbHE6tVEFy4UcIcQL4GkA4wF0BXAZIUR/8GYlgH6U0h4A3gHwqNsJjQczZ87E1q1b0atXL9x1113462OPYeqEUZh0zhA88MADaJGfjhxvANOvvgSTxwzFucMH4M0338STTz6JvXv3YuTIkRg5cqStOL0egh4l+WiaEz70rK9m6u+pKfYO5/Og1v2+Z3wXpPo8oTMAU/qzTfjaYfqo8M5ZhHESm3SSd+T0jj6b56UjPcWD345jq7lFhNM8Bx6iTZthmiySetmA1hqVKCevZvbMr0aXo3PzHMPfFbcPozo3Rc+SvHCY8t8NfxofOnCu8PYvBwFASH1RQX1GzihJ/eRnbhxWFvFbRooXKSzPpBaUFWUhxUvw63Mi1frs5qfRAvSsTsUcz1qHbyb5/NUovl3iu8Z2QmkU1vp4Jx7n9ZL8KJ3XM9KfkttEOz7qs9UqPP3947s354pnZKemAIDLz2S7SzHFIk1Xy2p0g9sbT+QcBGvI6M5NcVEfMw2GMJcNaIPmuemSVWQdyjnCG4ZJ0lglb80mnckyH3I6Lb5yIN9+M2uTNS8jBXkZKbhfdwZZXSebM3yMuo26v1eTl5ESOjfulLm/Hh5xbVLfEgDA2G78YYfN/Ye/81YdfdnyPGdVL0ObySbxKJzRSsrfm89qb6qSqdC5eS62/+XcUB9jnk7zhI7r1pyr375nfBekp3hC9gKiJSc9rKg3vntzTOwhaSc5bWeUSseGlLlZqG8xWhja7Ff62zwDnSTdlqvwqFYOALCFUroNAAghbwA4H8A65QZK6QLV/d8DuCLahP3x45+wbu/RaIPR0LVlLh74RaTKlsLDDz+MtWvXYtWqVZg7dy7efvttvPbfL0Epxb23XIVFCxeiqqoK7du2xlOvvIXMVC+K04LIy8vDE088gQULFqCoyN4AzoO6ujfLSUPl0dj42SOEYEKPFpjQw7laIYth5UUoyu6Bu95Zo+oMnXH72eUYWl4UsQBJT/GGrG3dOsc6nLyMFGz7i9Y6oVNrRn+5SDor+NfPNzp63oo7zumIOxgLHEDq9Lq3ygtZWvxw+lD0f+gLVB2rNe14+5cWYMfDE1DnD+Kcrs1Q0iQDLy3agUDAursuzE4LxdeqSQYO1dThq41VAIDVD4yxzEfWr1lpPmx+6FzLuHkwiv3lawegdOYnps+ey6FSa2Z1cmTnpvh6U5VlGLeO7IBbR3YIfbdrPMBKaqoMku2Ls21Z4Uwk+nex2hDQ3/+syvKjGS3zMyzzxDjO8GdWmfVp08Rx2EDkZMlDpJ1ro8njCzbO4Y7u0gyjuzTDiVp/xG9FqjYNqHbNgxG3qu7hjtoVbhtdjr9/uVmbBoPPPPzpgu5c9/1w3zkR17wegtUPjIm4rt4M/P53o22myD4fTh/KvP6Py3qHpENO6cBY8Hdoat2fPHt5H9z82g8M32zhz+ohwo5Ex1V1XlVYITU/XfD5mamh91V81qZYGKjhTaOVtPG5K/n6M/Wc7a6xnVCYlYqZ7/1o+ZxRMl++tj8ufnYxAF2fGoUg8eu7wgIOKw0bpQ3x1guzOf0fz++G//tkPZ6+vA/u+2At3l5R0TglcgBaAdit+l4hXzPiegD/Y/1ACJlGCFlOCFleVWU92Ukkc+fOxbx583DpuOGYMn4ENmzYgM2bN+OMM87Agvnz8bf/ewDLvv8OeXnsHbFYkWznEngJO5hlG+bgxef1YGCczxwks8IXKx/txJ/q8+D5q/qhq6x66bfhfgAASppk4uVrwwfm3bLoxXwuSuuJhuHKfx+f3BM5HKbQFWl1LLDj4wtgSe+jr31Ouxi3JXJWDu4bZk9oj1B9SJRqJfP5xOQ8S1pPDT4DiVGBbqDDMzd81hit73G6acrzlNU4oZcQasM3jqFOPj+e4ouukGNZL28d2QFTBjjQNFBhNDdzqhJqtKA3Kge7VcNsPG5fnI0XrumP9BSvoSrn6QCPRI712swSJYRcAaAfgBGs3ymlswHMBoB+/fqZ1gqzVXY8oJRi5syZGDxxCgCgh8r59sLvl+DVt97H4w/9AZtXLcH999+fqGS6QjyMqSib62ELi9rfk7lxWe3AKURnDc+9gc1JKpRJcyAYjJlVP6dGQOzWDbuqnaly+VotHMLp4dxxtZUKnvDsWVDjDjfivKnTuhhdI9ZPIKxMsydiZ9XNGNXJV+peivw3zedBrT8IDwECcLd/5CknxZgHa1LlmiNjE+xM9NNN0hpvEr3RGuuiMbMTELpH7n/Nxk11OGZBRvRNJvdyn2U3kL5Z4Ze1VZwcHdDEnyTm65T+U29gyVjLw914gwblYLcN8foCDZd7EnQULsOzkKsAoD4oVQJgr/4mQsjZAH4PYASltNad5MWXnJwcHDt2DAAwduxY3Hfffeg1ciIys7KxZ88epKSkwO/3IzM7FxMvuhRNcnPx+Qdvap51RbXSYT1rV5SFOoZq3Ae3DsHq3YfxwEc/RZkw54Qbr/S9ITWmCT1a4PY3V1neZ8fPzOwr+1qa+ufBLB/t5LAy+GrPyNkvo2Qo15vPao+nFmzhvv9353ZBXmYKl1olD25lAQUw58Yz8d4PezCgtCC0I6wuWX1cLfOlczmOzn8ZhBnr5xQiFnKMmblyZUzXZrYdiD9xSU/NWWQnuFm/1e1rWHkxbhrRDjfKZ9Q+mj4UX22sxONzNwGw5wPOMl5VYA9dyFYvnDm+C7LTfPiFxRmdu8Z2wmMqlfKB7Qrw/bbqqNPYqyTf+iaZxyf3wquLd6B3a76zMnNuPBMVh05a3vfC1f0ijJkkE4PbR2qmTOpbgoVbDqC8Wbarcb1y3QB8u6kqdEbOjFGdm+Km4e1Mrd/yWliOkLLGqP3xoFh0Vi9QeetSMvGkbF20RV46fn12R1zQuyVGPPZV6HejolEWXg+ezxay8C70wsbStA9c2q81muWlo12RsasiFkaWfvWEjdGdfvAs5JYBKCeElAHYA2AKgKnqGwghvQH8E8A4Smml66mME4WFhRgyZAi6d++O8ePHY+rUqbjyfEkPvqhJHv7zn/9gy5Yt+M2dd8IfBFJTU/Di87MBANOmTcP48ePRokULLFiwwCyamJFtoBbWq3U+erXON1zIxcMPj4LRLkwywyuRs8MYG4fFzXArG5VJc7SLS7P0ON0JVULl3cnMSvPhhqFl+NfC7Vz352Wm4HfnduG6N5rzT04Y3L4oZDjjP9/vBCDlX1gqos1M9ZkOpySqaerrhZmE9M6xnWxP6i7qYz0JtSJWeeP1ENwzPlwHOzXPQafmOXh83qYYxShNgC4/k23wIy8jRePWQo06328d2UGzkGuSyWd92QqPh+Ci3q3w3so9lvc2z0vH3SZGrh6dpPV3ymuIZnSXZlz3JYKV952DJgwjLBf0boULevMZv7HDiI7FGMF55s7rIbjHoj91qlppBrfVSpPfzLoUlmqlXaNGQGJUfhWGlReFDKgQQnDb2ZHGuYxVKyX0BliiNUam5EdJk4yQP2A78ErkQtpgp6H3bMuFHKXUTwiZDuBzAF4AL1JKfyKEPAhgOaX0IwCPAcgG8LZcSLsopefFMN0xY84craWMkRdfDSCsWtm+fXsMGzkaWyqPIzPVGzoQPGPGDMyYMYM7nuQQrkuEXQLELo7QGTndd0F0mKql2AhH2SGt5zB2wkJRBYsFRi4nzHDiUy/Z0L8B6zxQPJrRnWP5HIRHu1s+bXg7fLv5QOi7mQpTPDef1MTbDUD43uSpz8qmT62BtGpct+aoqbd2iGxJlK+cRFnWqAmfhSJQei7e7lnZsOrTJh8/cRq/s7Ra6fCslKJamRqDjd2GgKWBLc5wlLLXS+ScdOmpXg+y0nhVK6W/iXYfFAu4HIJTSj8F8Knu2v2qz2e7nC5BAohVBadUPRm315E3JMKTaycqic7idGuCl6I+I+egR/1w+hB8ub7SdKc1npPRZFjIxeosUazfTF9OF/bmk2RFky6WFJElkWvIk/No+tdkem3FHH91DdvpMa+1PUHjICQpU1VizRk502clrh1SZqnmazc96nh5umpFtZKl8u0k/ngyqnNTzN9QyfWeVn2sfmy1zA1dnKFjNkG++MzY9NB47nsbojYYL41za8EmWSbmxh1j0qB46hmvOJmHLs2lsyYdmrqrV69uMG0KJJ9ZimRTfVZlWHlRyKT7IIbef6xxq2Ervt7KXc5HPf3a8p0FifqMnI0AOjfP1ZjTZ6H4qrLjg0iNneGva0t756fcxMmEXfGLaFa22fLOY15GiqsSqZ6tteeR1Kln+dByQpNMa2ugADC0Q1hVaZAN67S9WvOfqYoGddl2axmdxWI7tcTNyYcyERtW7sw8veL6pVV+RsRvsZKUtshjn200yxbFB1jbAuf+Gp1i5N+tMaLUCaUPOLNdAfemnpKPJU0i65qe0kLpbFX3VsZ536YgkymRO7NdgZxG4/6ui2zZubyZsU9XM9yYF9g9P6Zw7ZBSAPYWkUYLVv3ldNm38RBV393WxEeq8rg+JXb7Dlb/Y0ZPee7ZJgH9QayJwQrl9KJz85zQJFeP3TGra4tcnKwPYPuBE+bWlwhBx2Y5qD5RhwPHI+3GSGmyP7Ivv/dsZmM5v1dLdGmRi04mTqeV553SoyQfc389HB2Kpc6sTWEmvrhjBI6dqke7omzkZaZg/m9GoKRJ/BvZD/eeE9pt42XFvWdDf5zsvJ4t0bm5eT4u+/3ZUU3Kvr17JAqzU9H1/s+dB8KAdUbO7UnZXWM6YXLf1igrysItZ7VHTV0A+RwTfG9oB09K0LLfn20p0Z3YoyVy0lNw9YtLNde/vXskhj3q/hnWFfeejUAUO35tC7PwxR0jUFqYiZ3VNcx7zu/ZCkdq6jFlQBt8tVE6iuzG/P6m4e3Qu00+psz+XgpTDnTxPaOQmco/RJi991d3jURNXaT/Mn1ZPn9VP1Qdq0VdIGg6GVDz7d0jXVtwWqF+x8sGtMZHq63PcEUVX+iveyu5FK8HX991Fpo5dFg9pltzfHb7MHSyOaF9/caB2G/DB6r6nT+XnVP/7dKe+PWbq7mev2pQWwxqX4iODifeTolnfYw1rHHOKc1y0zHnxoFoU5CJh/+3geuZG4a2w1mdmnKV4ZntCjH318MNF0yLZo5CbroPz3y1FYBW8+C+iV1x9eBSNDfYMACAKf1bo0+bJpbzJBYLfzsS+fIi0WlbXvjbkcjL4NsQ02PLVx8I7pvYVbOppkZ/LCYrzYcFd56l2Wzp27YARdmpOHA8Umof8lFJIyWj2vukv4PbF+KRi7XnXBfNHKVxXM7D9UPLMKJTcdz7g3ggFnIWpLoo+fJ5PfBx9orpKd7QTodbaSrKTmNeJ4RwdU5Gz/Oib0B6CWC74thKsoxgHRq3opCRFzz5qEhenNI6RrtJysaA361Rm4HP6wmVuZ1dTSVtSsfPm4esw/nR5r8RrPpgFyuJuMdDcM2QMgDOz3kYhav2zagMtC3y7O14mk0W8jJSmJMQfXlkpHrRhnMBpxCrNmFGqs+jlSo4KIdEnntrW+hsZ1+hc3P7Eu9otC1yZUNeF/Yu4V7IKRui8SYR9TFWuNGvqWkvj/G8G9Eej70yNLvXTIKT4vWE0mYE7zyJhRsb1NGEYeecOSHSoscIln2DMoaksLxpDg4cP8h4XkmL/owcO3GF2WkRbcquNA6wX5caEkK1Ms4Q3V+BIBlgSeSSRZdcGTjccdcQdRBJRTId3D7d8jbW8GRXQ8vTeBuDSSajYQI2rDJKpLGzRBlKSiRKbusNjDDvtSiaaI+fRywqHfqXFYQRC7lE0cAGaMHpjVoil2z9qWIkzJWF3GnS8JKtjID4dmmJrqVO3rWhLcqc4OZkrBFkV6NCXZ5qw4/xlkzTkOXMRlTDYnDGlhd9l6C3YN6ISiFmiIVcjMnOlsT1e/fuxaRJk0LXWRPKWbNmoaaGfT7GiK+++goTJ06MLpGChJPozsynGDtRnRVMdJoUPCHVyujDiufYHcsdRjdVK90iHmlJ2oW4g7K2k1+JXrgmgmSq2wJ3SQaJXGOsX1yqlRZ9LO/C2+g2/Rm5UNq4QhWwEAs5B1DZbqqZnyM9LVu2xDvvvGN6j34hp+xaJYMpdScolilTfaKauU1WqvE5yeayEQM79SZTtojo9pkIN/AadPxOiEdLUqyzZds8jK1QlCWVgZm5baW83DSqUJRtPyx1HXNqzc0OimU0txxP20V539FdmgKwt7Ac7sBKZEv5LEjSLmB19OW0qMtDoso4mVH69lg41I4VafL4rz4Pm8iyVc7q2jWW4RaKga94xq8YreKxc2A0X7M7PihxpadowyvIkt4/S06TUh65uvxQfi/gtHjcmBHGTnTs2LED48aNw5lnnomVK1eiY8eOePXVV9G1a1dcd911mDt3LqZPn47ybj1x052348CBA8jMzMTzzz+Pzp07Y/v27Zg6dSr8fj/GjRunCXfixIlYvnI1AoEAHnnofixbuACEENx4442glGLv3r0YOXIkioqKsGDBAnz/zQLce98DCPjr0L59e7z00kvIzs7GZ599httvvx1FRUXo06dPAnPLnCcu6Ym56/Y7PiDslM9uH4bKo5HWPu0y79fDUXH4JABg/m9GYFvViajDtGJU56a4e1wny/s+u304ftp7hPnbi9f0x8ItVbYWZe2Ls/HYpB4Y3aUZxs76hvu5eBBS+3TgrPy1G87UWMbk3U385FdDcbim3nZ8ADBteHvkZqTgkn6tHT2fl5mCdQ+ORYaBsSMAOKtjMf58QXdc1KeVozhYfHDrEKypYNcpI768YwQ27T+GIR2KYuOmRcfvzu2Ma4eUOra4GC0pXg8WzRzFPal5+dr+aJmfgYwUb0SaeerinBsGYumOamSYbNwkC1/deRa3pVEefn1ORxyqqYvwY/j57cOx8+AJTPv3igayvLXHuzcPAkDgIZHGp169bgC+23rQsfXCRNClRS4evbiHxu3MVYPa4mR9AI99vjHu6blxWDvkpPswpX+buMcNAL8c0R5NMlMwqa+z8YGH+b8Zga2q+UrPkjw8fNEZOLdHC+b9y+89GzW1ASzZfpBpuASwPz48dGF3DGpfiD5ttJs7M0aVo3luOs6TNyqvGtQWPi/B1AHa8hjdpSn+fEF3XNyHz49pYyZ5F3KbvwCO73c3zOxmQLm1Cf2NGzfihRdewJAhQ3DdddfhmWeeAQCkp6dj4cKFAIDRo0fjueeeQ3l5OZYsWYJbbrkF8+fPx2233Yabb74ZV111FZ5++umIsCmAd197GXt278TKlSvh8/lQXV2NgoICPPHEE1iwYAGKiopw4MABPPTQQ/hqwZfIysrCI488gieeeAJ33303brzxRsyfPx8dOnTApZde6mYOuUp+ZqrjyWw0dG6ei87OXJVpKG+WE5IytCvOjqlVTWVSN6y8iMsiXOuCTEPraMU5adxOnNVMlssq2Q4de6KQyA3RmVDmnfhF4yMs1efBVYNKHT8PwNLsPyEEVwxsG1UcekqaZNq2jFZalIVSh76NnODzehJuFVBtMc1K5fGsTk2jiqt5XnjCk+y4XQ/SU7x4dFLPiOudmue4umBMNvq2LTD8rWluOi7o7d7mTby4pL92HuDzenDloLZ47PONcV+Mu9E/Rxv/lTGOXz9fIYRgygDjhWtRdhqQDVOLwXbHh5z0FFzGiDM9xat5f5+XXR6xGONOV5J3IZdAWrdujSFDhgAArrjiCjz55JMAEFo0HT9+HN999x0mT54ceqa2VpIALVq0CO+++y4A4Morr8Rvf/tbbeCU4vuFX+Pya66HzyeLjgsiO+7vv/8e69atC6Wjrq4OgwYNwoYNG1BWVoby8vJQ+mbPnu3WqwsEYZJku1vvfkAgSDqSpK0IBAKBoHGRvAs5DslZrNCrvCjfs7KkHcdgMIj8/HysWrWK63k1FJL/DCu1GkopzjnnHLz++uua66tWrUqo/yGBIN646eNONB2BQCBIPGJfTiBwB2GFgsGuXbuwePFiAMDrr7+OoUOHan7Pzc1FWVkZ3n77bQDSomv1aslJ6ZAhQ/DGG28AAF577TVm+IOGj8Qbr7wIv98PAKiurgYA5OTk4NixYwCAgQMHYtGiRdiyZQsAoKamBps2bQqdw9u6dWsofYLTBzG4RaIsvlwxdiJWcgKBQCAQCE4TxEKOQZcuXfDKK6+gR48eqK6uxs033xxxz2uvvYYXXngBPXv2RLdu3fDhhx8CAP7+97/j6aefRv/+/XHkSOTBUEqBiy67Ci1LStCjRw/07NkTc+bMAQBMmzYN48ePx8iRI1FcXIyXX34Zl112GXr06IGBAwdiw4YNSE9Px+zZszFhwgQMHToUbdsKHWKB2yTXalJxVh50w/+AQCAQCAQCwWlC8qpWJhCPx4PnnntOc23Hjh2a72VlZfjss88ini0rKwtJ8wBg5syZAIDS0lKsXbsWJ2r98Pl8+N2DD6NDU63xjBkzZmDGjBmh76NGjcKyZcsi4hg3bhw2bNhg+70EAjski8lzxdiJysWdQCAQCE4HkmOYEQgaLEIiF2cUza6G6htOEBuyZL9gaSmJb5KKaetkqaKKWXu9PxqBINHkpEttJcXrvG6Keu2cfOFjquEiFCwEAlcQEjkdiuQsVmSkeNEiL104O20k/HfGUGw/YO1/bsaocmSkeBPirkHPq9efiS/X708a5+CT+5bg4PFaXD+0XcLS8K+r+iFPTBoFOh69uAfearsb/Rw6wn7k4jPQv9TY3HxD4H+3DcPGn4/FNc70FC8eurA7hnWw72RdkFwkyX6hQNBgSbqFHI9Fx4YMIQTFObF3ZkuF1YykoHurPHRvZe2TLD3Fi+mjyuOQImta5Wck1M+OHp/Xk/C8Obtrs4TGL0hOmmSl4qYR7R0/f2mCnBK7SZcWuejSwtr3pdtcfqY4Hy4QCARcOh2EkHGEkI2EkC2EkJmM39MIIW/Kvy8hhJQ6SUx6ejoOHjwoFiFRQinFwYMHkZ4e+wWjQNDQuGl4O7z9y0GJToZAIBA0WnIzfLh6UFvMuXFgopMiEDRoiNWiiRDiBbAJwDkAKgAsA3AZpXSd6p5bAPSglP6SEDIFwIWU0kvNwu3Xrx9dvny55lp9fT0qKipw6tQpRy8jCJOeno6SkhKkpAh1MIFAIBAIBAKBIBkhhKyglPZz8iyPauUAAFsopdvkyN4AcD6Adap7zgfwB/nzOwCeIoQQalO0lpKSgrKyMjuPCAQCgUAgEAgEAkGjg0e1shWA3arvFfI15j2UUj+AIwAK3UigQCAQCAQCgUAgEAi08CzkWJZH9JI2nntACJlGCFlOCFleVVXFkz6BQCAQCAQCgUAgEOjgWchVAFDbRC8BsNfoHkKID0AegGp9QJTS2ZTSfpTSfsXFwmywQCAQCAQCgUAgEDiB54zcMgDlhJAyAHsATAEwVXfPRwCuBrAYwCQA863Ox61YseIAIWSn/STHnCIABxKdCIEGUSbJiSiX5EOUSfIhyiT5EGWSnIhyST5EmcQHx/5ULBdylFI/IWQ6gM8BeAG8SCn9iRDyIIDllNKPALwA4N+EkC2QJHFTOMJNSpEcIWS5U8sxgtggyiQ5EeWSfIgyST5EmSQfokySE1EuyYcok+SHyyE4pfRTAJ/qrt2v+nwKwGR3kyYQCAQCgUAgEAgEAhZcDsEFAoFAIBAIBAKBQJA8iIVcJLMTnQBBBKJMkhNRLsmHKJPkQ5RJ8iHKJDkR5ZJ8iDJJcohNn90CgUAgEAgEAoFAIEgwQiInEAgEAoFAIBAIBA0MsZATCAQCgUAgEAgEggaGWMipIISMI4RsJIRsIYTMTHR6GhOEkB2EkB8JIasIIcvlawWEkHmEkM3y3ybydUIIeVIupzWEkD6JTf3pASHkRUJIJSFkreqa7TIghFwt37+ZEHJ1It7ldMGgTP5ACNkjt5VVhJBzVb/dI5fJRkLIWNV10be5BCGkNSFkASFkPSHkJ0LIbfJ10VYShEmZiLaSQAgh6YSQpYSQ1XK5/FG+XkYIWSLX+zcJIany9TT5+xb591JVWMzyEtjDpExeJoRsV7WVXvJ10X8lO5RS8U86J+gFsBVAOwCpAFYD6JrodDWWfwB2ACjSXXsUwEz580wAj8ifzwXwPwAEwEAASxKd/tPhH4DhAPoAWOu0DAAUANgm/20if26S6HdrqP8MyuQPAO5k3NtV7rfSAJTJ/ZlX9G2ul0kLAH3kzzkANsl5L9pK8pWJaCuJLRcCIFv+nAJgidwG3gIwRb7+HICb5c+3AHhO/jwFwJtm5ZXo92uI/0zK5GUAkxiO1S8pAAAgAElEQVT3i/4ryf8JiVyYAQC2UEq3UUrrALwB4PwEp6mxcz6AV+TPrwC4QHX9VSrxPYB8QkiLRCTwdIJS+g2Aat1lu2UwFsA8Smk1pfQQgHkAxsU+9acnBmVixPkA3qCU1lJKtwPYAqlfE32bi1BK91FKf5A/HwOwHkAriLaSMEzKxAjRVuKAXOePy19T5H8UwCgA78jX9W1FaUPvABhNCCEwLi+BTUzKxAjRfyU5YiEXphWA3arvFTAfCATuQgHMJYSsIIRMk681o5TuA6SBGkBT+booq/hhtwxE2cSH6bKay4uKCh9EmcQdWfWrN6RdbdFWkgBdmQCirSQUQoiXELIKQCWkyf5WAIcppX75FnUeh/Jf/v0IgEKIcnEVfZlQSpW28pDcVv5GCEmTr4m2kuSIhVwYwrgmfDPEjyGU0j4AxgO4lRAy3OReUVaJx6gMRNnEnmcBtAfQC8A+AI/L10WZxBFCSDaAdwHcTik9anYr45oolxjAKBPRVhIMpTRAKe0FoASSFK0L6zb5ryiXOKAvE0JIdwD3AOgMoD8kdcnfyreLMklyxEIuTAWA1qrvJQD2JigtjQ5K6V75byWA9yF1+PsVlUn5b6V8uyir+GG3DETZxBhK6X55IA4CeB5hFSNRJnGCEJICacHwGqX0PfmyaCsJhFUmoq0kD5TSwwC+gnTOKp8Q4pN/UudxKP/l3/MgqZaLcokBqjIZJ6snU0ppLYCXINpKg0Es5MIsA1AuW1NKhXTQ9qMEp6lRQAjJIoTkKJ8BjAGwFlL+K5aQrgbwofz5IwBXydaUBgI4oqg0CVzHbhl8DmAMIaSJrMY0Rr4mcAndedALIbUVQCqTKbLltzIA5QCWQvRtriKf2XkBwHpK6ROqn0RbSRBGZSLaSmIhhBQTQvLlzxkAzoZ0fnEBgEnybfq2orShSQDmU0opjMtLYBODMtmg2oQikM4sqtuK6L+SGJ/1LY0DSqmfEDIdUkX0AniRUvpTgpPVWGgG4H2p/4APwBxK6WeEkGUA3iKEXA9gF4DJ8v2fQrKktAVADYBr45/k0w9CyOsAzgJQRAipAPAAgIdhowwopdWEkD9BmhABwIOUUl5jHQIdBmVylmwamkKy9noTAFBKfyKEvAVgHQA/gFsppQE5HNG3uccQAFcC+FE+ZwIAv4NoK4nEqEwuE20lobQA8AohxAtJcPAWpfS/hJB1AN4ghPwZwEpIi3DIf/9NCNkCSRI3BTAvL4FtjMpkPiGkGJLK5CoAv5TvF/1XkkOkzQ6BQCAQCAQCgUAgEDQUhGqlQCAQCAQCgUAgEDQwxEJOIBAIBAKBQCAQCBoYYiEnEAgEAoFAIBAIBA0MsZATCAQCgUAgEAgEggaGWMgJBAKBQCAQCAQCQQNDLOQEAoFAIBAIBAKBoIEhFnICgUAgEAgEAoFA0MAQCzmBQCAQCAQCgUAgaGCIhZxAIBAIBAKBQCAQNDDEQk4gEAgEAoFAIBAIGhhiIScQCAQCgUAgEAgEDQyxkBMIBAKBQCAQCASCBoYvUREXFRXR0tLSREUvEAgEAoFAIBAIBAllxYoVByilxU6eTdhCrrS0FMuXL09U9AKBQCAQCAQCgUCQUAghO50+K1QrBQKBQCAQCAQCgaCBIRZyAoFAIBAIBAKBQNDAEAs5gUAgEAgEAoFAIGhgWC7kCCEvEkIqCSFrDX4nhJAnCSFbCCFrCCF93E9mEhDwA/vXAZQmOiUCgUAgiAdH9wEnDyc6FQKBQCAQMOGRyL0MYJzJ7+MBlMv/pgF4NvpkJSFb5wPrPgQOOz6PKBAIBM6oqwFqqhOdiobNriXAgr8A9af4n1nxMvD96TmkCQQCgaDhY7mQo5R+A8BsBnE+gFepxPcA8gkhLdxKYLIQPHUUVcdrAX9dopMiECSUyqOnUHWsNtHJaFScWvgMjn79lKNnt1Qex6n6ANe9u6trcORkvaN4kh1/xQpUn6gF6mu4nzl6qp4776KhevNiVG/+3vZz/kAQG38+FoMUCQTxZd3eo6Ax0HjadbAGR0+dnn2aQAC4c0auFYDdqu8V8rUICCHTCCHLCSHLq6qqXIg6fsxb9zNeW7ITG/cfTXRSBIKE8vgj9+LRh+9NdDIaFa98uwEvLtpu+7ljJ+vw2KzH8Oc5X3DdP+zRBZjw5Le242kIfPLjz3j1+504cJx/E+LFRdvxyuIdMUuTwquvzMarr/zT9nOPfb4RY2d9g21Vx2OQKoEgPny/fgf++/Rv8M7XP7ge9vDHFuDCpxe5Hq5AkCy4sZAjjGvMbRVK6WxKaT9Kab/iYkd+7xLGrmppF7fyqJBECBo3LchBtCIHEp2MRsVJh1KhUzXH0MWzC0U7Pua6/xbvh+hw5DtHcSU7Ow+eAAAcr7W3O+807+PBip2HAAAHjgtNEUHD5dDudUglftTsWBqT8LdWnYhJuAJBMuCGQ/AKAK1V30sA7HUh3KSEsJatAoFAcBqQSurRi2xNdDJiwuncdYtxSSAQCBonbkjkPgJwlWy9ciCAI5TSfS6Em1QouttUjJgCgUDQYDmd7A6fTu8iEAgEAvtYSuQIIa8DOAtAESGkAsADAFIAgFL6HIBPAZwLYAuAGgDXxiqxiUUaMsUyTiAQNBTEvlMkp5MHGWWDURSzoCFDYliDJ3u/wuZgSczCFwgSjeVCjlJ6mcXvFMCtrqUoWZEH/1h2OAJBTFn3IdCsO1DYPtEpaTgEgwAo4PEmOiWCaDmNu+4Gs2A/XgXUHQcKyhKdEkEjoRU5gFZecaZbcPrihmplo0DZxG0o46VAEMH+dcCatxKdiobFyn8DXz+a6FQI4k3dCeBU8lsobnDCxWX/Ala/kehUCAQCwWmDWMhxElrAeWK7lKOUYuHmAwgGYzxEB+rt6xjVHpcc6h60bwzh4PFarN1zxPZzMefkYXsOgp1SuQE4lUTvX70N2DQ39HXp9mrb/rK+2xqfXc7Ko6ew4ecoJ9WUAhs+AQ7ttPfcUWd2m/YePoktlYn37+W0t9rw81FUHo1Du7DJyl2HHPuEspUXi54EFj9tP5K9q4BjP9t/LmpslnQwAJw4GJukCARxJpp+oaGjzBnNfPCt3XMEBzncrlQeO4X1+5J/A0ugRSzkOGE2ksO7gBozX+n2+fTHn3HFC0vwnyU2J5x2qD0GfPNXoGK5veeUCcqeFbajPPfJbzHxHwttPxdzvn8WWP5i7OP56X1gxSuxj4eX1W+GynHnwRO45J+L8fv319oKYurzS0Lmz2PJ4IfnY9wsF3yb7VsDrJoTfTgcDH54Ps5+4pu4xGWOs6XcuFnfYsgj811OCycHt0obRscrNZdr/QFc+Mx3uOEVm/2WDI2HPsXG/wHLX4p9PAAQ8GPAqe/QAg4WZFvnA0tnO5M61h6Pz+aXoNGRGjhp+5n6QBAXPvMdrntpWQxSZAKlQMAf3zgZfLxmH654YQleW7LL8J6J/1iI8X+3HkOHP7qA6z5BciEWcjYh6sMIK18Dlth34mrG3sNSR7bzYI2r4Wo4eVj6W7U+dnHo2J/M/vfiJSmrS05fNkdPSoORE6mXHefKTvHHWjp9WiNb23WghFcfSFC+H9gs/T2yW3M5INeDHyuctVel7z5tjJ1UrkPmofW41LcAvrrD9p49LG8U1tufOOO7f0j/ko3a49j/4QMIHNye6JQIbKLMqlIObbH9rNIvrHHYLzhm+zfAN48Bfps+HCkFdiwKz8OipOKQNFfcfch8zlh5zHysPnSiDqfqg66kqf7UcWz9YcFp1NkmN2Ihx018KmSDObQu4CcZOjOTNERT55Lh1bhoMAl1F3IadSiKoSkni1IAIIoLGddSlFhWVRwOaYp464/HN/Jg4iURetZvWo/Xl+3C3LmfJDopAodUHHawsaAQ765u32rpb8DmZubJQ9IicO27riSDumSI7+LH3kd7sseFFAEfv/k8Pn7vVezcYX9hLrCPWMjZRN1YVu0+hN3VsZGcxWLeueHnowgGKQKU4utNVThUY0+n3B8MYsHGShw5aXMHKgZUHat15QzPD7sOhXa0YsmS7QdReSyx6khLth/EfjnP9h05iaU7tGrBiVrr7K6uicv5hsXb7JfBzoMnsLrCnZ3TxNDwFnInav34csN+1Pq1u8PKmjTaemr2fE2dHzsOnMDWquP4aa/9Hf4VO6uxJ5rJqA0qo9ByqD5Rj282VSHoIDPX7jmC7QecLRx3HDyBNbr2dPRUvSvjaJXct+05zG7jm/cfw2OfbzA9S5RoAkGKjT8n/mytwJoDx2uxcIv52TQWlAbx7eYqHDzm7ryDEEnNdNP+yPpTQiqRA/P4zvN/hl94F7uSln0HpCMX2yqPospCEiiIHrGQY7Ct6ji+3Vxled9Xm6rw7sqKOKQoetbuOYJxs77F0wu24Ke9x7By9yG8sdRYp5rF8p2HsLriMN5Ylvh37v/QFxjwf19GFUatP4BvNlfhnR/C7/PfNXu5DgXbglIs3nYQc2zmt9ss3nYQry+T0vDm8t0hYyWhCbLq3kCQ4o2lu+APGKta3O57B7666NVZhj26AOc/tSjqcMygNIgl2w/ijWW7rW9W8f6qPViwsdL6RoFrvLdyD37ccwTzN0SX7ws3H8DWqvCCg0c4ec2Ly3DWX7/Cx2v2Yt76/bbj/HbLAby9wl4dcwrVvI+9BfvrS3fhh92HsLnS/oLsiw378eHqvY420j5YtQfzde3pvH8sxLBHF5g+t+Hno1iyzfwsYCAo9VVGUujbZn+CLV+/gUMnrDcif6w4gh92xf78r56/f7kZY2d9E71xp0ZIvLesXl+6C8t3VuPAcXsb2zsP1mDFrkOmZ9qcQAA89Ml6jPnbNxGb05O83+Bq7+euxmeGMpf4/ftr0f+hL1wJ850VFThRy6cJcPRUPd5vIHNzNxALOQajHv8aV76wVHNNUefhVVWq5hgszHCqPmSEcvZudcURKM3MrpVCBSdHlvJxjFtsH23e8fLEvE2a75XHTmH6nJWY9m/7xlzMcLssnSXCPA0p8IMGw4u2OUt3YeZ7P+Ll73aYPpd2yh3LldsPGJ8fTEMdsi12E61Q6qwTCYQT0lCHTCSDQQhn75sCPzxw57yEXczKKAV+7vZ0xQtLMPrxr23FrZdSJzPqkciuCq1y/DEazdup/1ri/GEVOzjOg4+b9S0unf296T0h5+gGLzUm+A26eHYCfmuJ6S+eWoiLnvnO8j63Wb1bklbuO5IMfUfDgFKgF9mCfMRXkhmeBzlrRG4NRSRQh7M9K+AN1mKZ3H8dZmhb+QjffO9a7//cSZiLrNh5CHe+vRr3fcA2yKafM9719mr8+s3VjcYCp1jI8WLDkdwPuw6hz5/m4ePV9k2XpwRPYar3S6T53e2UtH2G9BI/29xRJYrhBAc90DW+z7nE9ou2HECfP83Dgih343nQi/wV4w57XVaNoklurMNTX4NbfR+gW2Bd6Fr94b243fcO6g9Z7WrF/t2u8M7DDb5Powoj3upU13s/xTTff+MaJwun8/RbfR9gstfeIijW0EAAt/o+wAiyytnzUZ6xS2YSoUAbD5V0OwQtFnJKLiWzamVYfTh505h0BAM4y7sKF3u+imu0yVJCTY/+hO6e7Wh9bLUri8M8knxG2WrqJEkcy2DL15uq0OdP8/D1prAW3c+y2rlTYUVDQyzkYsBPsr+07y1UQVgUHNuIpuQQSk785HayAES3AxsPwwk/yObsl++Mw864rtML7ei6Hk0ydPnGafDWSZsGbQNhVY/8k5J6WJOTFm4w4jDhyCHRL6zjXQapJFmMQTivzS1IovyMGZQVlQblLtjhKNRQ95Wo5lh7zJmVSEMa3vnHWEJlAbKRq9eGkFuhKpoMQ0YDgcqaA2mI79l9ZWPbbsUKT6PcKeRwKCQpZhoAYtbHssbxFbIUcmUCVKGTBbGQswmPZaCQ8C5JRw6n6YrnPChaC0w86N8jZP3J5YKLlzqfGY19h7fxvr4iRU9wMmwQbofa4Sk8iEf3MgnLi++eAhY/5Vpw6n4qWceaeBKkyhk582lNMjcFz+nmIiOOxMVPpAvEah5FiFq92OXAbeL6u3GULeuextKMxEKOFwc9a2rgVIRT24aMJ+Fb2u4SDEaeAepNNiOLuqtawIon3phVX7NO36raJ4e00RpKE18GAj6UOteq8mtNBbTbBZeSfShEnH1LWZEEDoTdwq3FRieyC2M80TtzDloYO2kIKGlPhs2/hoJZVjWKDUzGK8ZjIzyuUIrBnrVIC0ZqNLBK+DR7e0vEQs4mPGMEpUA6anHmgfeAZS84isft3SV1f+Y0ZOW5WK5L0uuqcbvvHWTVuWNEw4y2J9dpvpPaYxjhXY0xgW+kC8crgapN8AeC+OvnGx2byE+GscRswcUy6849GYrBy9FgEB+9Pwd79rhndSoZykBgDwIAwcgzDrxleYF3Ea70zYu4vqs6+c6AOEE9RtiduLmhhNUeFUD1tqjDGe9diq4eCxVuC+b+9HPI0INaILel8jheWqR1EJ7MfUGRfz+me98H/MLYCS9mRyLUZf2PLze74rIo2VBUSwkAT9CPNmR/aEwPBin+9fFXCUkVLy9+sRK7D5jbhEg7UYEBng3oc3IxKKV464P3UVkh9T3Ztftxu+8d5NSFrQw3D+zFLd4PQOz6+GugiIUcg25kB87xLNdcC0+ErQfMzFP78Uvfx0il/J3GP7/eit3VNarQ3R9t2pD98NAAiEcq9gIcA/zuVPRT9QH89fONUR8ubXJyBwCg6KT5BMGDYNRW9bLr9WeApPBSIS/Ylr0ArH0Xt725Ck8t2IK/fLohMhB/LbDtK+aEUyFWZ+/MWL6jGh+ukqyErtp9GO+tMFsUsboBvvqXd2gtsEuyXrf9wAm8uHC7xRORNMUhZCG80/ZzVRW2rZiHD1/9m+2wBFqYpVh7rGFIhnQNJmJz69h+oJ6/j62X/dL99p3V0aYsKSAm3zQsehLYoDMW5MLwMt6zGFj9ZvQBcUERkeiAPzRTv/3fi7Bqq2RcjKj6swueXoQ/frwOlNKEq5vx0LF2DXwkgLSanxOdlAaDmdRN/csr85bhV3OWG95rP175g9OK5dYUTzU1PdO/BBd5v4W3VjovtmTNWhxf8opLETlJmnne/HzwMI5+9SRm/+sZ45uCQRTsldyTeBHAhm07sHf5R/j6jb8CCJ/nr9y5Hh+slOY8Z9StQSrxw3eq4VghjgaxkGNwjnc5unl2aK4Rxicj0k/p1Cn9tcCeFeytQH8tKiu24S//24BrXloa+btLpNfsw0Xeb9Hl5MrQG6SROuDbJ/gDYfgbU3j+m214asEWvGJhrt4tbvB+ghne92MTuK6Iv1uzEbf73kHu8R2R927/Bti5GNhvbJwmpFoZx5nEpOcW47Y3JOt+Fzy9CPe8v8byGVa5WqlOZpzYA2ydDwC4+Nnv8OB/16HWb28xP9X3Ja7yhiUnylkXf8A9i1OedR9Y37To78Bmd3zeJBuamvfdUwBPfrjN7qXAgr9YGvzQbpmpVSt1GzfLXwRWv84dvQdSfRrt/cHwnmGeNbjd9w53mKZUrJA2eeKAaddSdwLYp128KhOshrC4AYAp3gX4lbq/DwaBbx4DtkjtdZrvvxjulfo4tTZBTa3kBkQ99DL7tA2faNr+VO+XcfW7FUaakjlWCaw7IbWxwzpfhpRGXjtNMBuj1Pl4hW8eutZEr8Krx24TYvlt1RAMOBIbEwD5QcncvicgGX6hdYnVPujm2YEuxFja7t0rLayL600svB/ajpRTYUMmeT++BEDydSsh/V256whuf1Nr0TiZpe9uIhZynDipEKsrDmPO0p3A5rnAprnAYYYDyLXvIuPH/8AHP2rq1BNXd0dYr18yFZ0VPBo5eFMqpc3iJUnE1CpMrbzbXeePz1mkTFILQqJtpdrnFTcB+l2kFkTa1Wlex5A2BWTpHTWRyEWRQjdohSr0IAYSTtVOtVrdykntO37KrwRpmzQSW4tjpHqr9U11NUCF+wM9N5Xrgb3OTOtboyuUA5tjFI8JyrtZTC6U8Xne+v0IMlx3aK4c45dceOUnWxFjte2+nk2Gv9lm81xpk0fmvR8q8M3mKpMH7JLYVVggSLFgY3zOgDcn1fAQ1dii9LeM9uJRma0c71mKab7/ymfOTPJr3xpN229KDqEJia9fMgCqWb7DcVRZrFXoNoX3rABW/gc4sMV52mJINBsKpmfkdN8Lg7E4smFvwLN81a8fBTZ95ij2ZDO0192zHWO9BmPqqSNI3S37ajRLr66AlTHBa/KS4Z+SJCNijFjI2cRuA6k8VhvegQ4y1JmO7QMF4Ak5HI8ufYaYhbtvNbDyNaCKoTqoDoLD1olr2gJx6Yki7Fbau52TkDU1Z49HzWTf16HdajOiLbticgjDPGuSchss+VLE4KcPgI0uO2OVpcGhzYkEls2u6hO2jePUq1SWozVckGjDPLsO1eAHF01kJ8NkbXXFYaySnVgnDap8KfdIKuWaumNSj47U1GPz/gQs4BRCVitdrqs18jGCU0lm/MeCfUdOWvsrDPKdkWtQ2NrQU8z86rUZEgdXvpscRzF9LMK6uHQhhfiRiVOaa40FroUcIWQcIWQjIWQLIWQm4/c2hJAFhJCVhJA1hJBz3U9qYqGhhRaH+wEHdagJjsFHAwibC49NRSSq/0OclPWIT5oPyOGNzsi0sQxmOCFkejwOPXDkpqcyIGjzxxvlWbxEDCbNcRDlhMNYCGVrsTsxUDqZzJckGibSSUFiCElbo62M/lqg0nzDh8Vna/fhXwu3Y+2eoxx3q9QpVRI5t/oWAP/P3nfHSXGcaT/VPbsLi4gCgQBJCCShHBFKyMpYwQqWOFs65yQn+U53/uzD9p3tc053hxWsLKGEEpIAgUhacs6wsCwLbGCXzTnPTnfX90dPd1dXV3WYmd0FxOOfzM5Md3V1dXXVG58X6DyxcidCjc2ed02vc4bxwNPrUVzXnvF2U4UiWNGMkB6uB59Zjzv+b02muxQaDmvlp4tlVyZVXffHFZj255W+5/qGVvaBQJ+q0pTpnhEo3oWgn/SZUJdlZGlZ7UcRLEbXJNWDfctTlAN4NLZQfFJNAdDRX3VRex+BihwhRAXwNIC7AFwI4BFCyIXcYf8J4F1K6RUAHgbgk7l4nCI5W6pbu7E9oFg1v3i0dPVgUX4V6ttNYpHlBTU4VOve+B6JrcANxlbPorBoTxXKG/0335rWbny4MyzDn7tvr24sDXme895lG91mHD6Td6FQHZeRQ4EhIZ09Gl7fWBpKUd1wuB57KjJg7dXiwK45QJfbGs4/J6tLlmpzpLETO8ubfHNqwoAafe+Rezi2EveomyKdYz2T5s4eNHaEC3X8eG8V3tycHuNcX6C/aKg/2FHRr0xporveVNyA2rYU+7T/I2Dfh5E3xbIGcw3LK6xBe4+YaIVSire2HEGX63dR4FCKYOfAztfTaytNtHYncLQ5veLgrAmmo0dz7RMN7XHvvGs4DFRGW8ve3VqOpsC1gCJescsJM+9nWGReAFOzizEIKK3yvfJwXbicosLqVqxKIax0X2UL1vqG15o9Xn+wDiX1mctvKqppw6y8IpQHebdC4kB15ryWRTVt2FaWuqfaXtsZxaA9ruGNTWUCA0fqu3B3QserG0qZcO/U1iPfeuCUYlZeETYVh19f2b3N8El/yTgoBeoOpGVhc/oe/rmECa30oGA+sOX5CD07vhDGIzcVwCFKaTGltAfA2wDu546hAIYk/x4KwCdz8fjGHxcX4qFnNkaqIv/O1gocrG3DjGfNeODvvLYNt//v6uSvzmQcS2vtzdma3j+cswP3PbXOt/2vvrQF//bO7tD0+Oz0b+oMn5tkpaSdkkyoRZUTrjembR9uUXfhtPYCwZkOfrdoP/5r/j6sOiDbzJxF4Z9f2Iz7nlofun9S1BcBTWVAyVr3lbj1xykoa37+YGcFVhc5/Ux1ubJrAvV3vIMEhDOHXfvHPCzON3OPXMru/o9MBZ5DXbub+fSYCWdJdPV7Tsi/v7sbX3+ln/LuejqgNpo5X4xfC5tKGjBniyBfNwys0CwjdaFdptjmH23Bzz7Id4XqUYEeRyn/Qzi45nKqbL31h4CW9Mti3DVrLW7404q02mDlmB/O2Ykb/+J4Lq763SeY+oe8aA12NbnG9VBtG376/h786zv+YV5nk2oMK1sGFK/2Pa7PIFhnKXW+HnBggZlKkEYdnTtnrfV/ryu2A61Vnq/veWIdvvKSnNTM8sitPViPW/62KuX+oa7Idf3NxabxOROG0YV7KvHZWWuwON97f6lg+v+twYbDqXtLRMrAL+ftxX/O24uNERQiCy2dCaEs9fe8g/jVgn1YsLv3xdtNJel5jxyjdC/i6HZg7wdAzd6Um7D7F1Ipo9QJrQxV1/gYlbkyjTCK3DgALN1RRfI7Fr8G8GVCSAWAjwH8SNQQIeRRQsg2Qsi2urpMJn33PngaCNZj0R7X3En5HgVBPNE64l7LtGjeNXX6C03VScFI13tZgrbZlry9jFFTMIoZ/gKSZd11E7uIrpV6+mZ3Qg9JusIn0Yq+ZY5OMSnl2C5K6iUB6E5Ixq463ILd37lINvZ9COS/B/R09FqP2roTgc83Ze9Xush/D9nFpjBvG4jYvnJhdn02T6k5bjy6BGsCy1TpYq1MRZHLxO3lvwfsSN+bF8Ub59lfMglrUNpqgE3Pugg/rHWgrs1/Tb9fXW8qIIk+ZMjzeZhsaLw17z2his1HgLgozJciI+LvwWXA9tnRz4u4x3jeI/b8Un8DcKqwvHFFNb0fTjsMbRgO/3Bs0bpVn5Qzurk1JczoXvabZbj018s83zcnjd4dfERBiguL2CGXunGBvTcinNsZhnWNeO/PA1Zl40MrRVCOFRmkjxBGWhbmkHKfHwEwm1I6HsDdAF4nxCuJU0qfp5ROoZROGTVqVPTe9lnT0+kAACAASURBVAHYRUHTnZeKr+82LDfL/ubiXy3F35YdkLZ5sFY80S/61VJsKW3Ey1zB0qgIpLOFe63hPTCH6zowK68IpQ3hNmLRdawXh1L/pdLpa++8aC2dCZz/X0tw59/ZPIew1p7e6ZORQvgAAJQ1dGDCzEXYV9mC9Yfq7dDcdMGH9oTtVVFNG/IKa6S/28pC2kJndIW5vj2O9Yc4RjIrD8rQesU0WVrfgUt+vQxvbvb3brHTqiOuYdk+L9NiXVscT6w4iNc3lWaug13N9m33JOs7snO8s8U9D6JN/2jPSDESGJFkAXx1Yxku+fUy1HCeOVH+sfXutHQlsDo5b1MtZt0rb3fZBqBc7JmZv+soZqdZjqWlM4GLf7UUsz4Jz6Y5m9lPZGF8/Prb2lSL59ccRlmxdx877ozazDyy/jIMw/dG3thUhrnbK/BZZRsej73fa10biRaMJz5G7GTf/WqkGgbFwj2V2FLSiEt+vQyfFMjXZK7ZjKAv58PXY0vxtZhXqQLM+qhlDQyBktATm8m33rmAblCh4SldsHtnUUjSHVu6IM79Ln/3GfM3ye1vL2sMTNkJDcHkCjPsnT26ndoTZU7ZipwPMcOnS40Lp8hVADiD+Twe3tDJbwF4FwAopRsBDAAwMhMd7Gss3OOECzy1kgnL4mZGTkx1fZ6/S+5utxRC0WRdWcgs6swBlIZfhKK8BMRD5WEWjwYQyKjmuxkkfzMCdgxiW0jFv6e77n7vje0AgGJhroM4J877u+QeBJ3bW9mCWXlFOOKzKKZaEHx5coN+f/tRfOnFzfjicxsDzggHV2gPc0/uKDbC/4yP91Yh/2gw61l/eOS++NxGfOnFzdLfn10TXH5gVl4RPo4QLlSSNHwsDxCkWI/8zz/Mx6Ovb/ds0g89swEGpWgImZsYBE038Pa2clQ1O8pSbWu3a03h83TDPbXUnu2oNifk+pP95nhVtbgVOatvrMffqsH42Jwd+OncfFc/ZuUVuUKfg9Arhpri1XYtMx4lDR1o7krveTZ0mMabj/Z456V3JTfx64+csf7KS1swK6/ICQfjxsBqY3dFMzoTOpaGUArk6DsRXzcMzMorwvpDoucvECxdwcXm//7l7V3YkDT+1HfEUdHciQsUeb7vxsMN+NbsrWl5R78cW44Zql8IqpCOzIW3t5bjsTk7MfN9M7VhHWPAqmrpwqy8IhysbUNvi7P9HXnxwNPrcdNfV9lTOp5gvfeSvmVoir6+sTT4WgEQeuSYv6f7kO7817y9eHdbefL63t+7A2q5PvTMRlcodkoIWYhdhgbGMO33WGrauvE+wwGxJGkIPRBC0aWfEmL+MHe5FcC5hJCzCSHZMMlMFnDHHAFwGwAQQi6AqcgdX7GTSbCT62iTN/xlKDowmRyJVLvED/yxhFPmwoCkSVlsWTb0AK++7d4WXMcu6RbUB9uIIg1gdF0rKsJ6Fc0+uG/YCb8Jf/UdySTtfZXuUIajzV24/DfLcLiuPeX9lM/hDpuIHxXW3Wo6TTtvB+ifUFJrbNINQSuqDZ/Er9gMc/7XZH+1SD/aut3hOX6GgFRQ0dSFkroOLC1wvH9xzXA9G97mQtPIGQpEhDnBetys/hbVtAk9cTvLI5AkHNMhzmJkqsfF9f7hT46xSaQEAUcaOvHiWkktSvS91y6hm4Lq1lLv83eNmbU36u6EgB7NwKoDtXj09e2B1/ryi5vx3OrD+O7r25BXWBs6Fz0sNhyqxzV/+ASdPZq9l/t5na1QVytCQ2fWvEO15jpYWCVex8KuzT//MB8/+0BSsqaX61785N1d+OX88HlX1JdV2iNhBbY3XdmKmxX/vNBaLtw4v6IlI8ytYdlKX99Uhp/O5Z4P8c4a/nNnj4Zro+bO9gV8HgtL+iN8L0TyaPK4b7+6NTRx2/GMQEWOUqoBeAzAUgD7YbJT7iOE/IYQcl/ysB8D+A4hZDeAtwB8nR7biUGhMG97KcNMZb5gd6jbcZe6xd8akSHq4CAB0YIdPhJa8RNfJ4pAmjIiTItH1DzcrURjXlTS2GSMlHIMvZ4rAFi4uxLNnQm8s7U8NSrpim24svgZZEFztd0cgZwmHJzGW7q8THrWr2HqX/kp+qmgpSuB7kS08JWw70wm4Nyv/3GsculXwsOCblC0dKUnLBq2YC7+XvRbX41clHlihRrp/OKW0nPO/B22dCXQFk8+q16Ye348SbKc3VgULm+rLUuJl5z6zy9uwu8W7fdff3zW3nUH6zFv51HfPjS0x/G/yw6kbYxheyHKkattjdvzKUsNHqt1h+rxx8WFoUoPWWjoiPuuXZ09GuJJr8mflxSipjWOopp2WBkpfoqc1Y3WpDFIp971hQJpzcc5m4/grS3lvsf01lI7d0c5Xtso94xGwYSDr0Y+50KlDJcr/iRZhDjPiILi8affwVf+Z26o9n2dACmMKZX8LcKh2nabU6FXEepGnPdJ85G9IrFTCmBFv6wuqsOEmYvSautYRSi/I6X0Y0rpeZTSSZTS3ye/+yWldEHy7wJK6Q2U0ssopZdTSsVBzccZrlPkDEWUq5V1tLkL+RUtaI9r2HXEnxnqXFKBU2GGqPHEIeynsPtZDnowntT5Ckaul507bMPh+uT3AYoc5duSC4UyOEqn7FpOS6NJE85TojHECd95QtDU2eO5P0/JleQzjURqEiI/0VvA0o3W7gQmzFzkLiFRboY/DkS3K4Tl8t8sTzu2PQuON8jloRFau8x/HvxHMHuolrzRTNpwwrKqDkEHzidHXEKNlgGFyA+W0cAvxOjx2FxMjBeiJUlY5Hjx5O3+57y9uOy/lyER5CL3Ad/+QBIHoZqrr/x8DPPcdMMwwwXT2Fxl74FfqFFCp4zgFO3aFvERe3upjm1Nazc6GbKDVzaU4KV1JSm1FQncLRdUtqKSCZtlxyRHNdeNUWjC9Yrj2WgUvEvWWmINjejZEACtAe/RukP19jgndAPLC2rw9MpDtuD0lZc24t/f8S998IsP9+KJFYdcoYJS2GG4Ioi9ihY+2lNpk21lqdFDr8Isb69vKsPbW+W5sxf+cqkTOsd49q3hn65uw4WkVHguARBj1nBL8V2cX4WtyTSJps4e4R6biZVZ9vYt3V6Er/78D2iKmMudi26cSqKTc2QjARU6iOBVtm49luiD+oYGxb3qRvxTzC9k1sT72yvw5uZS6e8pOQHYyJ0go6Lg98Lq1sgKzs4jTZi9oVS491W1dKGKUxa3lzX6luHx26f9DCgdcQ0dcf+1yXoPIkVvHGf4dASQpogsOGxhnulqeBkn731qHf79nV3YXeHOIxpJ3J/vUTfhK7HlAEwBSwQKU0DMggYSUJB6Ol2PGepq6Ak/S0syZIN472UsNb2OHqu3BKKNzCExIUB1vjRvxBbGesmaJ/LIFVS14tWNpZ66P546cilYgh0Hi48SHRCyVtHQiWlKPt5c6YRK6JTa4Xd80+mG4f0wNs/dvxDn3KuEz89LV5FjF+6wc/IL6ircqW5xPcMle6vwyoYStHSJ65alC8v6HRSReLVSiO+8vg0AMNKow5fV5aCaW6geAid8xPJcBDGvNnb0YF+lLGfR68pREh2u8fF65ILHetm+GszeUOohKkkF/NWURCcej83FZKaQvfXuZBndOJ84HoIoAo9m09E65yzOrwS0aN7thG7gra1H8M42iaeiVxY1cZt3P7FWWgP0HnUTvhtbiEfUlZiqOMXbX9tYii2l7hqoP03mWVn7HC80nU2qEKMJX0UPAMqbOrEhSXH/f8uL8J3XtuGVpVswhRSCUoovqXn4l9gHPvcJdCY9WGHf+SgwuJc0rhkAKLJj4UUg9tavJEWB0SLNAcqvFWbNevbZnJ7p6jbheYO7K/FYbB6mKfkYjUZ7vL7/5g47l7KpswerDzj5jr0RDck/pYOr38KVykEcKTsYqZ1vqotdHrCwXf1BbD6+oi4XviE5RhduVPYkn7ODdIZhaE81Ho/NRXZPC3K0Dgwg0aNjfvzebsz1yW1jv8tFuDXWL7SU34tFyv3yfdHzYh9+fhPyCmuTnjT3qIoKuD/0zEZ8dpY75y/snHSxU3L9/8xfVgbkSZPjMaI+Mk4qcjw8E1/8PdXFwuEhQZz0YBK98CtNTsAfxuZhuiJe0C2MRHOyr+GEG35iDyPtyfMDZrznZwlb0f6FUiY3lRg4l1T4eCTSe+vG0Drcp6wHgYGfzt2N5s4eVLWY488XWOU9UKmwS7pCWVhQijNJDajB5CXJQqG66zFFOYAbEw5d9NK91dhV0Wz3ZSRakI3Me5cCvbDJfycp4WvnpMtayQrpYdO2BsEqweF4youTz7tdUOYjEyCMJT0IVnjHFT3bMZK0INbl9jo8rDq5iaoSrt37nlqHe55wU4wX7duOuurypFDI9RcA++3uimY8mecIXWE2PCsXMUr9SR6ykNRY3LSYZhNnnltjcIexHjepu5nvo1+XPaW0vh1Y+z+RzrcE5t708vLwC62UYRKpTJ7jHaQjDRIjkGDtU7ubcL+6HtcmNnnydUWwDA9lSUPTI2oepql7oRvUY8z0QxiDgm/0iYswmw2tdBuICIDsFDxyAPAZdU/kaBEZnDGloaTbIXFTWZuiHMAjsRVSxbeiyasI7AyIFgoDWRctpk0SUXKOkdTZH4eRduFcuKJ7I65SinxZlgFgZWFtaI/66d2msnlKVwVO73AIhTIVzk8pxd0M2/ajsYURW1AC13DRWK1IobA9G1rKQzYfPWW0AuZ6Y0cPpvxuOYpr2Rw5N4Z0luFi4n1+hOlCX6Zb9BdOKnIchrW7Y6N1SvHetnIkuBhew8g89SwAe3ITUPulvEAJV7w3nADtPSZMuBfgMCGJDrM9bQH70OSO7bhH3YTc9iOYt/OoPHE8RdPZLfoGTFSqMAjdeHdbBf6ed1DK7sbnYlgKRH17HBsFBUpbuzVMmLnIDl9h+8mP3YiOQ3hQXYsxnQdci6vFYLq5uAETZi5CdUs3SHLVURgFxilZYf725dhyPKCuS/ZTfv+pINPLXLpsZs79UVeopB8MS2ATeMp7K13XVuJTaN6gFJRSzN1egc4eDbmMZ97a32RKbI9moD2uoUJAxvTxW0/hnX/8Wsi/atJTO5+fyDuE/1lehAkzF2FNUZ3wRhbuqeSSxZOem7AvKKWhPV8iwcB6J3MpX/POX8MXPnMB0UuPZghr2qWLvy4tDD4IZu28778hJ9wI8oSJYOWUECKamFaEibs9O6eSuU5jq7kGdTQ7YfuhekGtfpjPKGzOW5T3lNrzUDBnBDVIKXWvSpphQIERGFop6lMmVhM2yoY1bIge85zNR3DVb5c7x3MHaZLxzcny3tv2sgyGl0me13s7KjGHK8miGzT0PLCeaUWT2OhQUOkOBbTWArZ1EtKo/Y3ZW/HbhQXBB3I9ZBE9TJty/5owqPyeZfjFh/n4aJep2PNzx8xnlTgmGIiU+64e3TfHk3jMgpnH2oN1qG/vwdztbASE+4r3q+uRTdx7/oSZi1DZ4uyNnwI97qQixyNmOFYsAmD1gTr8ZO4e18QAIAytBOA7swkonl7pn0TLNhNkTbKQk/TU+IWk+E1mRaKM8PiPZBiO3ZbeA6z9X6DhcGi9K9cwhYPSmiY8/s4u/AfPvJTuS2crwib8Ng9e4bDCbygIHnnBGzZjKVcvrS0BDB3YvxC5mji2PydhWqDPa16HrBqTASueMHDOLxYDAF7bZCZzbyltZBZFpz+WAHEuOWpvSmNJg7DfLHYfLMVvf/ED+7MWsMnwgso5pAI5SI9QpbK5G69tLA117CIBrTo7WUOH+9qKnHO/URSt+bsERAxdXqFnwsxFtpCuhPScAUAzb42kwKbiRvy/93Z7BAnLIydTYr/28hZc/Kul0mtphsGQnThvJgHxhJhZkFmlH5uzE4++5o0ICKtXHNyyGLN+/V0cqWPGMgThi32EZAyCpoXod3c+qIlvvboVlwiK/4r74vPjjtdBqxymu6dXBpe7AIBlBdVYvNdbV5C/ppDsRLLq+il93jxn63vvfHn8Hed+oiiUnnU1bBislffGdW5LiWM4q06WrPAzWroUOXsjcBfPNpIeOTWAGIatERmc3x0eKth1yhGKBeV38fMP833LksjWiQGx1AMJB6ELp0CsVEiNOMl+fFJQg59/mO/6adLPP8Z3BOuIuH2znf/+SKxg8bwF4tuXvBuhehANYcO8hXsMAy0F1mDR/LRw+W+WY8letwxpGBSj0ITHY3Nxn7JB2u4Fv1yCq38vTo8BUg/VnTBzET7YkTrvQdgaoqzcINvzTiScVOQCIAvLMrToVtwxpBF/XSovHA64X8bH5vgnhwMA4u2RNhgC78JnbyRRN6iuRkCLA8Wr7K8oNfMlguqNxTVzXPlaUk4/U11yHY8m4BboPMIL/35HSTRuqQCq8zG8xxTC7KFb+Udg55sY22xuWvur21C1x0vpTwSf2P5Zf9+o5mNcu3tT9HtMhTvXukJ5gwRe85mbBw1GFz6nbsLD6kqcRpoDryXDt2Zvxi/n70NTUviglGLCzEV4drVXuF2816vIsdcMKzRZBDWG5ryvUUIfPcXEAWDPe66PllHAEtJTEezsPsFZW2pb3Xmy1vso29g3Fnu9xU0dPS4rtehU6mMCsDyEIpQxOZm2YhGSGfHwflMZqDjqbN6y0ErRZLOUAH4zFwlP3351K/45aYBh70WkvGgGRX17HGsPhiDWsNrxEyJaKoADS0K3NQxtOJMEG+qsvBJCgIM1bZgwcxEKKv2JIaKQVjrPwkdjhDPHwxBq8YfoaZD2AMAXmPqZljLAXsLwtC8LrXRAkZxHAdeet/MoRqPRpdRkQpFjh3kQbcdNym5QgwYo4dYzch+jSxj/onhxeXwntgjfjn0s/E0xNFyn7AOhvGzkPy55heFC+G5WdmOaki81wnrKpvSqX4i5rsAQBIQ3Nq4pqneda3DhS2a4b+r3sqm4wVO3cnuZOyeWdLfgSzGz/MDEZLpEFjTcrOz0tMeXyHG1k/yXfRfueWIt/j1p/JHNvKFox1ubSpPHsONJpSEoCrOgRR0fK0XpRMdJRS4kPMQAPrNDNtnYxPMgUO4ll7IK6T1oT7Kohd9g3C+M7QEIabmgoKht63YtYCzZyfs7KpBXWIMJMxd5BGSe7MQjy4W8AwvN+1cBPR12g8LSCraiyl1Lkg8ZxIrn2jhsbyYzds1HbAW1s0fD6oPyZFzKMJXJkKO7c/uijFEUocNiQhtO2nBuGvkfFi22dV/WPPnLEu/8F0fAOfX8/DbJJXurMGHmIpQ3dtokAZQJeXaKz6e4kuvuTVGnpjXT8lgSxpIeFiKmS/75hyVRYbG/yi3cW+2zhWEp9bceywQit1fX67nxQzfJAQDkKo7hK8rjkB0r+v6T/bXYkAyJFhlwBueoruPf8mEVTAVR5sHXY0vxoLo2cCx+oM7HdGUrCAiWJgvhLsr35quOI/WYSvYDCCfAe/Yo2+UmFglk6zXfKnushdDvn8Qjx8IKxWfnMe+RYj1yTmSGe97XtcWTRk3/vumU4pHYCnxLXczUa/U9JdQEZ8f/uvg6XKEchNpZDbkILPfOhg0/zxTGtOXjGmU/xrTtS68hSlH6yXOery9WSjBFOSC9L95QIQx/DTEk5yWjY6Li6ZWH8MEu5x0M1ONqCoBdb9khmDL5UBYiGwQrhLq43ltnlid/I5o3HP8ycgiXK+EiCJxrmu1WtXTbG9i+ylZ84FNiZAopxDdiS3BhwozC6mScJKeQLmDHq67jrWfoLj8QbYwIKAxquNIDToDKaB6cVOQ4hLVhyZgI050ifm7kn32wB8sL3FbcujbHo+W3DrCU+vw8tgXukJ1vbO/BnC1HzLwavtMclu2Thw2ZfQlndZPhrXfeANY/AZRapA+2jRmAm9LZ+3S4Z2jIcwBlEAm0PbphFgLnwLYbJGy5h4UTVPyMCB5l1fcyppfG3xgfCoZBbQXYaieMosMKeTZDbMjQyg+Tm8beoy12jpzO5q6mkcMmgq4b+FIsD59XzVIMYUOSRfA7J8gjJ0JcN1whsUIFGX6hilQariaq8RN2rljPj61tJrt1oUBmOEp90LHnkgqcT44kr0E9x04efYqwb2HRH/t/NkngQqXMJBegOq4mhQJPiEm+cb26z7xX37VF9vzNcZZ588LcumV79Iashx04Gngtq3tP5jkpCh4DpDBHzv3ZDGkPfr8cNs9wa5LwYgK4vRHWefB9dvYZvEdO0h9W2c0ka6WaNPgRD09AtIt0drZj3io586dsmPk9N1IeI3NqT4CnOK6J74839AbOh4L5QFNp4Hqebv3ESaQSo4k7HcDjvRRcQklBaiXJ/+bvOmqXrxqDBoyAPFpgmmqWQhmlmTLsK6+/7D6gjZMVKcVkcsQm0QEQmUgHoDAo8FrSCwiktl8f6zipyKUIXTL5z9GLXexqUcBbCPll8a0t5Z44c6seDiAPsTDhFWzs6xDLmxGun9ZlRGGRXiWRDyLkPHIRLO4W2NAie7FtOCS8nmE447ijrMkVKhvVcnwqbZHnjzGnBuWlAe5nSwTfuRrkuhUlYT2UtdayhIt+CrnIJ5hNynrGjqIjb4O1lNt16Jhrsufy89Zhd4TQI9eQrGeUsgXOQyqQzFVUzHCVVEKS7SYNeShjU1sHrlP2QdfCs23SrhZ8P7bA/mxQ6hE46tviOFgjrqtkGHLhpy2u2XPadtyE7JfF/s3WXaY+842HnbvFPQtRIv496ibcqZr1F1mlNFMbd2/s/6HDwijFaW0FuEHdi7FtZqi1mBwGvnUwP9h5FLPXl9ifnTbMf8d1S3K4qW7WtAyxxfDHZG36u89JXqjxZkCLo6Kp08s0nLy3NzeX2d/xgjQ7762/Re+aKM2AB9t02FDqqKF+tunRMEJ6U91YUViLCTMX4TxSjntVpkxM2G7E21BS34GjzeHYtQ8lGXjD3GdLZwJ72TQLXbMHPaH5n18q8DAB0UKHeRAQrDpQ6wrXlWHKb/kcMXF//295kW87DR1xzNlyBE3tyUgOH49cOqGVImZY3iOXMQZHplmLdOvh2Ep8NbYs+bOPsTn522nxMukxADCo4wjuUrfgCs2Rp1N59J6w6pMeuU8BmInvieFlILNe36Bt7p1+ScFaCoMViCyaQG6NWxm0FsboIRre8eFbENV1c7cQ/aW6+4m13i+VmNkPYvXHhE6dbV2FgT1sUUhec7XZr8R9Po00YYYqroUS6T42PYOzu0zrFDvk7gWG/dvdzydXhCPMAYIX7oTmmCTSMdqGIdoRHcGeZpPNMN+x7cqMBKzSYuheAT9U7miIx6fboTHR2hdZ3/3OuFopxDXKfqg1e3yOckApBbqaue+8x335pc34ykvi9Un3yZEDmGLSkhBmGaznpzLFgGzVwXM5kWKSvB73/e8X+TPNCV+lXt7AU2nd06WeTqDFG550plEO1TCfgUrlbHLi0XLj73neOl9Bc/gm7MJ3YwuBELnhnpb0sPnk5plnHXwN2Pk6pv15JW752yrXEZP0EqCp1N28z75nr88CK2UYoVmUPsAzWLvQ0wlaLNifANS2eQ2f5Y2ddkic6ZCLniNn4TIuPM7dS4mo11QGbHgK3/2f13HDn7y53Dxq27qxs8I//5297hef34jPPWlGywxAHFjzV+BIUokKWEOk9VK5+xfJYn5P9kdzdroIdGRo8/AjiFvdeNivjhmw9mA9atu6sanEnSPHt6brBr4X+yiwX1EgTDXJMMKm5ESFapiGWJaxuKwhWoF3AnhyFE565E7ChpyJK/VZ0tyVwKZiZ4GJbJ0J8ZIO12oxoNmtCFiejbCWCpsq3eU9FK/KvPVMWneNQ5RQkJ3lTWjtsTY5Jdkf87O5cJmNTVIqMaJ8GebtPGrnVrEIE9owijTDzQSYPDd8d4GuZpzfYdbZo6CMMuiASj/4w2tw8D/+0de3I505a4EVbnil3m/zYEOUdY8iR92KHHeuwipy1t+CsiDSd5VSaSJad0LHGo4Iw6pRZ1v57X6LmxfB3sSpnNggOxm6ZEhqVfIwqEmE4f4u2jM16dlTU8YBk65aRJ1tPVOWHdASqj3Kv+A5xRO66Q3kxqqwyp/wgy2S69xXevM8cH1MoXlPkzvfAHa85jluMDqkxjJ3e15PrB/4CAnRlKQgOMcq0m7IlTLH+8X3KWJfAKBdLBzfqG0Cdr3lWud4MhWVakD1XteFRc9Ogf+cB8Tv0S/n75WfULQEOCJmA+yMs/m7Zrs/eNMhNKMgQtZK53fr3JDP1+VNlNxnu0lAYjEiB6Ej7ld2yXuNwmpnXbJqfaLGzK1LNZTQ65EL306PrkNVIwgXSXy4swLlgnIvHgiMMFbU1FAuR3cEbQG6mpDQDUyYuQhPrvAvpK4bVEzK5YOgMNRUnwHbqqhKgb/s6vPb0e02W7To3UzFY8m/wnx60omAk4pcipBt6umKxPkVpmV95YHayJPWEprKGjowYeYi7C4PV/yTFYgtfP2VLb70s4D7XtWkS0PjZDFFEgdhef/km374xXZ1UR1mbyoXntXSmcDvP95vfz5auNWm1WbH9+P8KhyoNi2NkchOkpi9vtQOBZEJLiox8HhsLlhRa/WBOrvX9e09WFNUh0ee3+SyGh0Js4EAQFs1sjliFKH3ksG20kbM2+FPixwGLss199tCUYkBAGgux8QOp4bWvB3lyffKG24JmO/cygO1qGk1BQJrPzYotecd1Q3c/r+r8StG2PIoDJaQWLgQWP1ndPXoeHe7m/jixbXFWHXALUxqukXi4jZ88GuBb10ypmajdV6cf2mSqG+PC7/noRsUb2wudX0nU+Rkawql4nmrQgcBU84gecw/Vh5y1YD82itbMO3PK719Sx4vkp34Po4qme855ovPbcRDz2wQMNU5qBSEhLECZKaM0HwzjRwlPLsuqEixzminWKB2Pzf/PKowipznGOp4/If0xgAAIABJREFUm//7o30eci1HFfYbTLPNLKMb0xSHadeQhZLphqscj/WcFu6pxOwNJcJzmrq8oe28R+CMlu1o2fEB2qsPOp56iUcuaG641w6zLZ7p9N1t5fjXt5Osf4YmbVOkJLM1yMqbOjxrQWG1Y7AIcMh5sK20AX9aXBhcgoZ7Pgv3eMl0LEQxEO0VMFfvKm+yy21EyQGmlGL2+hIh6Zuz/hLboCXr5dHmbm8pmBD4t3d2S0M9XY9j5xtYuKfSNa8TmpV/ypOdUKC2EE8lI2zYcGELdW1xO4z8uTWH8aUXN2MlV8DbV0705Mi5j/2NtIae/3MmhNjXzVSu8ay8IqBoGbDzTRxt7sJflhzw9CSqTExAPfPsH6vCRzQdLzipyLHoaMC4unX2R79JE4WpPlVEtRtZG6ZFQvLxpt3Ct4b/xhJMLaGrRzOw6kAd6tocQbJaWCbAaUlWU4vfdKxkVevll256EV/YotouTJi5yL4H6/y8wlqX0MKWRWC79oM3d+DldcWRrsk3Yi2wQUnU7D3P21WJXzA1d7768hZsLG5w5QCVCIhTRFj66h9RUrDF9d3R5uACo+9uKw88JgiiTZlSM4fxp3O5+oNJtG58BbnVW+3Pv16wF4vyqxBPOG09/LyTDE8BfOOVrXjwH6bF2zZAMJc2qIFDte14daOzKXqsjttfMf+tNpU9UakMNvfUgkOk4ihjovv6p2fl+ReivEEvBb75228WFvoWZb2AlOE+ZT0MSnHHBaO5vooFetl7ZVAqjDn5UexDzFDXMIyu5h+rDtRicb6joFuhStvLGoWKlQvJew8rFO4WhXIxC/D1f1rhIheqaOrEjGccr4h9nQyHFf3kPXku9LkknHEkbI8Upu+H6zrwPXWBOx8qCYPSwNChps6EvbY/HDOVbzYX8ZX1pT4dDu7xRZ3bMEVxyuzITpm/q5Irx+Mc2NzlL2yzM1vkVXhlQwn+5Y2t9oFVgjkZpvwAm25wibEfj8fmusgXAOCnc/dgvs1i6G51X2WLrayx48B7QgHgr0sOYNl+t5B+5yzHEOe0G04y6NZ0PLv6MJb4EY4RgiIub/axOV4qersPrJcz+W9FUyd2HPHmbVshlfalAKwqqsP6ww3YXd6MIw1ixUiENQVH8IeF5j7CP27ChO7e95RJRDVE9w//TA8+408IHpuzE39degC7yptxsKbNNj7ogrD/TSUNdqizqNWrf/8Jvjnb3COL68zxqmsNZ+ADRDly7t9nbygN3RYLtllRSk46aRrQurCZKbHjfm/CwXq/xpM6j2wSSyfJ8hjFSUWORYNcU+cFIN7C95CyBo/H5vZKt8LCqqezt7QGp6IFV9d9aNd489t/edKGbp6tqbEYM/70tvdEwQvGU+jKcuQsYpZMiVYWa2FnjzuPKZWX9nTSgIuI2CLMgw1d0HSKhG7g1Y2lvuewJREAeDZS7zXCjdL+am+4WSqMVCzCyr6s8mX3V+LlscBbRhUYKKnrwJdfFDOZWW1ZSflj4qWIQTPzu2AZI7wKpYfWWRB+KZolfNftelX2nOIUkoptwOq/uLxBgBmKPJFUJs8IT2ZA4R5XHp9Vt2KiUpUcF3dvRVZS/srsvDIJY8QPaxypZxhF4TqHx0PPbMSNf/F65tj+WW2EseQ64XZciBDzdw56XMpjc2fCdW+ZWmP4XBy+zpJf3aWwaEkqMLWt3fghE3ZHiPMyHarrwAAiJl0yD/GfYwPRjeFwz1FZLqK7Xf/32frJYjW0kBAYttYV1aGLM1Kc0VMqb5xBfXvc9Xx5Qc36pbjRmRNdAsMMIf55oYBbSbyCmpEdWfB5zsRdt+qeJ9bhD0xEiH2Y1T53/VBhsRG3NBHrrIUeTcMn+4NDzQoqW7G9rFH4/G/52yrbuBYW9z+9XpqvK8Lp+c/hn5L56fwzO2WvGYqcTRL2nDrFcM/vdFDVYs6jMPswO9e7enTc8X9rYJWS6klornY6EzqUktWYoa72bX/D4QZ8a/ZWdCbLTEV5/rz4E9Z4FnSv7tBK97ETSSVOI+EJ2Vg0d/YgoVOX3Mi+E1EN/Deq+VA73YbSmHriqT0n3h1lENb0GYt6j0BcxAnNZyimJa0lwJIY7frRJu36Q/WYt2ojTt/3LCYr5eZLyyWGd/Zonhhhi4fAEqx6+FCv3e/Yiw0Lp3eOFZLdNM4hFZhW8QKQYLx5yUHVDAND0O4RqkXCZJQ4bksJtZ7XgCxVeizhGC7Y8b5D3c4fHmh50gyKgoDcHcCsQxPotZD0K9MgcJiy0rmO+36C23l29WFPiQYCito2ubVxE1sIu/kIrmhbiRuVfPfGLpgr3oLBXoQiPrDbcecCGZSitrUbbfkfJ+ezt63pyjbmTCuXCTgVLcLjAeBy5bB3zrV6w1R1SmFwm6lowyacmOhSdgLITpx7tb9x5b25+iNUItnvonjkJMcw544iLb55Q0H5faHB9re5HJMSDltde1xzyrF4TpNfeV+l23NgefX/sqQQixiPp0JYRjv5vXb16Gju8lcov6kuQRZxH2M9MtMIYX6YonjZ+HzHkBDhUa9v8oaMWZTlLK7sllPRs3iDCUGj1JsjZ3mH7lc2ICsZ4iqaa/com5FD/ddhV2h38t+o66TFMsye5TY0iIVWHnZopeQYadi0T6t5+2uFijaPu59Yi4ee2Sg03viRv+Si265PyiPqOFrU+nzucm/D8vLJwN6HKI3AMjKrSU8ua9vecLge40mdpx0eeYU12Lm/KHmcWfvtDBIi18sTkx7OiBmEM1CDyxXT8TEkXgVozr59n+pV6seTcMXgZ28sxcI9VdIi4CnlyCXcUUlWasaJhJOKHAf3vKc4HQ34QmwVRhF3vhlL4RwN8ok4mHRhMHE2lqiT9oU1h/H6UjPc5gxSZypA3It8tLkLTZ1ua65TONn8LMvZ4cHujdbf2ZojnE9RisyWBXkfV7atwjdjS3CpZoYV7jjShE9YBZPpdxjlyEJ3wh2HnhOTT3F+fMN6r1q7NLR2a3h76xHsrnDmhW4Ynvh1ESjgyi/qPTUN+Jq6NPSxvGILBOXEOPji85s8wqHfuX9aXOgaO8Ac/z1HW6Qby1dfdsJG8/LLQAjBYHQlvUni0F4gmI2V3+teWleS7L/7B80yOnD18SgFpv4hDy8l1wTRe2u15LDoUWR31+ErseW4hhRyx5rnDydtXiFLQIRhUIoEZxDRjeAnN0mptMPEdle0oKBKbsU+0tiJ836xGM1dFoU2kOVDGuDU3/IeYyuFIZYZ29Ovi70uFhbsdkIZCeEF5Qy8Yd0tIO3M+rTzDVwVd+bji1xYtktt9bk8H8Zozd94wv0usaPoF2TwtZc3I274i2b8e1rb1m13slvT7bGbrFh5xwxdjE9OweDuSqC71VXiRQ7RU4nynJxj+WLfmj33qL2m88cAwEASxxRtF97dKg8tZw2TYXvHH9ed0PGT93bjUK1/bdEw+O3CArzsF/oq6o/PRU5riMay7S4H4/7NJqtiZuujsYV4SBXnaUeRb9hlZHd5MyYxocuiVjK5p9b5GBcB4C7VWQeKhfVjzc4HyRd+b+2V5CAeJssxFqYSe4u6SzquFk5Fi6fEg6z+cZS+oKYA91DHsD+yqxTY96Fveyzb99Em/5DakvoOVxFwv5JcMviRIVWE5Rw4jnBSkWOw5mCdi5aWIFlxXgCR0JsJ8BTCFsaTWgyCKM6fBWUWDSOpmBGzYHII6/e20kYUVLZiB1enrFzARmddrbU7YQrKyfbP7HAo03Uo2F/VinfnvGB/V5Vsq8SKj28uQ49m4MF/bMC3mRp5p1Q5G0yU1BbDHhHzpPaOdpsFMAhhN5Yryl7C55/IQ3Vrt50PR0EEdMXRILs+v3hdSErxH7/8maBgqRdDif+iSQTtu5BCXpHjdXJOH4Y22zIr81AoMAIIepzzViz5wP5mZaGjPC/YVeE5i1/IxX122v6tJAGcJnMcuhMGXlpXYisr7Ls1d7t/viFbJD2WMBUnvogrC493XDBH9h5tQSNHjKIbhssoBAC5cIekXakcxHXKPvvzN2e78ytZLMqv9OR+siUFeHgo7l2bsfm3J69SMC2sYz0Rpq45RPHutgrmHLfPYm1RvfcUAWZ94lMPauM/kL3brUTzOqonhDeJKGVdrCHpTugYAufdLanvcFhBfdgu8o82Q4+4rU/9fR7AFBnnBU6351bezoB4I7D9FZRJSCFYvLE6HxsFXrmwGJ00rBqUIr8y2NAno0jPpV346fvyMh/VjPXeCpHzJ5cg3vWtdj8WbC921YB1cuQ4QTvAI2cZmaLAL6BFNaznbh7Ek4lMmLkI/zXPIY7ye/5xST7v6UlGTH7conqC2ON96+UJQufDYskrvxV+PwYNUkVMVL/N7FZyfwA/b2T7vHxwTyPNoJRiklIZqtYgAHwlthwdcbfRvrolOGc+EAXzXc9CpxRolRPkiOAXZWVQ6jJWpRNaCSBSPdbjFScVOQa7ypvR0eM8dL9k6GFwLC8sQ1cQUg1fm6GuwZdUk0VSlHDMQ00yzR2u78DnnlyHuTvkLxqbE3f3E2vxo7ecZOcNh+rx/o4KYd874hpeXl+CDTv3YkSb6VVw1QWjCtriGiqPOqEwVQK3tkhw3lflLI4UFN+b9TZ+8ouf4A+/+F6o/DVr0f1+bAHuULcJj0l1Y8kmGk4n3jo0r6/2r22VOtz9nK5uw+lGNSb/5xIhi1d/w+sNofh6bCk+p5ihU7LcKNtrJZnVFxJzHl1ESjCKNEMh5iK/jPHkzt3uCPSWIiMvFeK+LouP9lQKPHJGsj2C3y4swLokFTTb24rmLmF7TviqCd2g+LWExpy9f49HTiBJ/fMLm3GAC/VW4l7h4gF1Pfi5NAThNnarFAL7jFQfgeLveQe5ulnOdS2Fp4cLyWLXXgtychZ5X3mP3I99SElYvPmJXJGdt+sonlvr9rrxty8zeB1t6grN7GbtOD2ajm/GFjvXAnVCi33GnQCRFTkAOFLq5Id710Xmffax6K8/XI91BUdC7XEPqWuxbJ87NIwy/w/BLyzuUZ0wzB+/u0t6HcvYJa11FbA2fFFdaf8d1pfBvqIj0Iq71c24Q3GH6l+j7IcK3XVnBEA2oqdmXEP2IwuaZ91hlUV2yrR2J2xGXOv7y5XDGAGxQsyGxvoZhNmlahzq8Jjq76WJLAtJpj0fnowSbxqIuxlDOs6Fh72EZ8PRiodjK3G+YjIb+/VaJc4gOFPOMa5PV7biPkVMhhVmPK6yopxCgjcSPrfKv8SBqC8rD5gF561cwadWHkIno7QbBo2kPBPAdT4PSs1Q8hHEihBxG+2iorfq3B1LCLXiE0LuJIQcIIQcIoTMlBzzBUJIASFkHyFkTma72TeIwotxu+okorMMXUFgLzEScmYlCu+LnUvimEr2S1nF+PwXg1LUJBmO+JppLErq5BbUGkERUwvdyQTy0oYOHEpS97MLvSaYXp46Z3ByCABgc7HXSvurBftwfv1SjCP1yCVxYf5a0HXEx7gxnIRPkBa1/nl1neDbYARNu6Dfw9b/k7cvPz9syznwki9QmAK3pVSflYzpl7F6kgBRaXpSIbeef2VLt23t9DNt8MVfxfVp3Chv9Hq/Ddv7asIiXfEwtUqE0ebOHuxJMmRuOMywcvn0pbqlG/N3BTMgeusHejfKbJJ6/u7uEjnznSzH5l/f2uUow4LwmB7NwK7yZpvGX8SuJ5v73QKlLxj+SsKXYnnSM0sbOjzvWdh6Xjf/bRX+c56s9pi7TTu83RNaySr3/m+lDp+8YMEYjEYj9Jr9zDHyc4IiO7aVNYYalYHo8XgwdYO6rsV6JP0QZq0XFY0GgpWz0wX11WT397/Li0yPHPPdBGLO6XOUo7iIlNrfX6KU4Epy0DMlr1TkgrZFZsUbmK5T9+EaxUuoYoG/8xv/vBJTfvcJ8itaXKkAVs6TH1zpFJ65axmrKK5WDiBGgoT7aPuWbNy384yZbdW+Ld+k7MEPYvNdJUL89tAcgdLn5zmNQQOBgdKGDtexKiguVMrSWocBoLg+fFFsnbplsFTIz+ZsNhXY3eUtQEe9J5IioVPAiLYe/5d0PTTnz8jaTfacZkmkUum/iC30REOgIkcIUQE8DeAuABcCeIQQciF3zLkAfgbgBkrpRQAe74W+9jr45P3eJJkAgC/Hlkt/I5LrX6/uc5GVsBZS9ngVBorrO9DeYxUxlsNvUWLZgzwbfDK8tKGjR6jwGSEtw6zlvlpArbvzSLh6eCxiRBcqFyz48fXbDHmIxmxoSMEjKoLmYY9uoCREOFMqbde1xfFxvqQOHIP7VSchnLUEU+oWzsoaOjxx+xacRTrce1ffHvc8B+talxNHKHl9Y6nrmL/nHXTXkuH6aH/t+kA9BcFbOhN4PDYXX4+/jeGMNVuWI/f/3nNCuHpChMUCwD+/uBn/+rbb4zAQwcnaQV5PFmeTKkwklb5zgTcEmdEK5vH/s0wcksjmSrEJ5lcnDV9lDR144On1uPK3y33DbUVo6JDnrShMjSMWfrOKpbsOAwrq5xjz4K0tTp3CST//WHqckyPnnh8KnDnqV5SZgErHTAY+/FqUO2zN+cO1YfKVU9s3q1u7XfPzm7HFGI1GfFddKD1HJQa+F/sosO2gkjBhMJCac9g1PuVbcT45gkHowjt5mwEQfLTbiX7JJc485SNDYkRPxivA264N57t/e0fueRQRilhj+eSKg1jCeD8tQjY21DMsWOVtW0mjOzoo+fcA0mMTe4jbsEINwyPKGfurWtHuU8vzwqRnbTQcBdDPPhHVw/1YbB7uULb7GG/ECCtvPr1SnH4jAt/3i7lopiDjKY/aVc95vtN0Q2gc9cOHO/2Nk7ld4t/DKnLsTIlSr/B4RZgZOhXAIUppMaW0B8DbAO7njvkOgKcppU0AQCkNR1FzjIGnyk+FzScImVAOdcHiabXNJ9ZaSl9nXL6whe1TmONYJsKwC2B9u6NwWXkIqcK6/xnqGnw/tsD3WPZ+RiEaXa5Y+U3t2UabE86xFg32kYZO3PK3VSldO+j6+Udb8AOGBl2G0+ENNbWEFLb9+55abwtVCRpzHZ+KtY2C4HQmf8F6KlMDlPK/LDng0EqHzHe16shZR6u6pZxQ3KI4QpZsBjd0OIqn394SNB++G1uIU1whkV5FNGxSOwXB/ep6IdNYEOqaO7C7rB5LJXWqYqrjs2L7d65SgfGkDk+ucJTp9YfEipRVRNersLN/c54yzwOQj6d17hefD8eYaOGdreUp7w+sku15bhJFjmWXPUeRh8kTUMSRFak/MmOI6PMP3ggW/sOtZzJDg/v74aQdA0n4ulky8B5OuxcpyHgDWAPhoU9wp7oFX1OX4ZHYCgBAZYvjzfdTaADv/u0HzS7ZI555svPLG7twKvEq4KJQZj+cSWqQ3eBEH1W3drsEcuteHlDX2++tG2EiF2QI/7a9uLbEN189O/n8vhBbZYdY/mZhAfJF9SoR3iDN4kLFCUf1V9RNjERLSrJhDnp8DdB8mxMVt1FWxh9gnXewps2WIZs7ezBno9drmzCMSKn0oaKlJA6EVMbI4Dxy3552duQ2jnWEmaHjALAZ/BXJ71icB+A8Qsh6QsgmQsidmepgX4LP+ThXqcANDBlAJhB2IpoCsBh2omhrJYbufdX+PhuaHS5gWWWHoCN0iIoIxT5hl0EIswCGqpsTAWHaG4J2DEG768gxEeueiIstpwr/OTGEOEI7y3B4c1J5+N17a3EZCQ6LEaE3vM4K4xWglMmrIhQtXQmQQ8txo7IHDRjiOc/skx/c/T2VtOKLsZUYRtqTbXgFCFl76w/V2+GRonEYBEaApNSppQYCgGLfwcPWT675IPbIUReDqsF4Afm5dJFSKumxY13MhVu45XM2Z0oIHPyet99vXgIMoHnpH7H4+V9IvcFZiiId+xnqagxjapnJhMp06yACsCnoRcJGqu9sdWu3Q9gUgH9RP8C9ilhR5q/vMAd7WSutY3N9PLIEQAsdFKpfFvhhIaC4VnHyfdln0NtRKnz7Mur6qIj3JIRrdhRPgm3AEawxVrjcbxe5heorfEIlzybuEECRh5cdjyDFa4wgbxswx9CiuGfB19YLerYPqmsxtMSdk81GMXUw7QW9t0PQjlgUbxARj0+6sIyhszeUYsaz4nfUW8My1Y7Ix2Sakp9Sq1cEhMOqAc8hBv/IELYG4swPxFwQtW3xlAuLyyAzcIQZo/OIm3CMZ6ydOOqUtPp2LCIWfEgo10MMwLkAbgYwHsBaQsjFlFJXTBwh5FEAjwLAmWeeGbmzvQ1FkCQXJW8q05An+pvf9xzd46o1ZFkEAUegHUy68M3YYszXb5Bexy/U4e95B/F4cpZEDR0U9X4cETOVxaBhGDpSZgO1+h7m7G/GlgAAaulw+7tMiCepCjm3qKKQGactNk/jOtUxLAxKCnQXVs1HjuofRtrbYJ/b9co+TFIq8fuPxmDciCEe5ergjlW4SmlANR3hbiPExs6PMV8WxI9ohEdFcxfe216OGy93/56LbkxT8pHDFV1mY+2vIIdwk2qSaLT3aK58ENH1YkRHNlOI1E1YFH4LZ8lc2OtdxdX8ko1lqnPUas8hbaEghLq9EwwuIqW4v30ZtjTm4mxFfF32XBnjnUwgDNrcCf/+1InzmHtLMWGfqUIMTCJiL5oCw2Xw8vPI2d5cHwNZJu6HV+QAikGkO9nfENb0tK7tRljG4SD09MTte2ARiRHZcOa+DBXN3bggpAOHL5p8JfEqfQPRAx0KhqMN1Z2nhu8s00+LZMr8DrhO2YcaOhzFxtjIdHcUbuGfXdP41A5vf0zkIIFvxpagkoa/n4V7orEihgVJxo2MJ3Wo0EYJJeJMGJPMa8mRRTThvLpPWY8Fho/sFhDBxMoLIsgUuSHoRCNnaPVDq08oK490clrDnDtd2YZ2DLQ/F1Y1YyzbRm+E2vUzwihyFQDOYD6PB8C/VRUANlFKEwBKCCEHYCp2W9mDKKXPA3geAKZMmdK7pr0UEIXsJFWEvcT55AjayUDhb1lGF9DdiqX7atDQIRakgiwxqUBGsytDGAF1HKlHLrpxm7IDk5RKbDMmp9o9ANHCINIRek7jQjHN3JRo7Y1GI2owAmOTilrU8y0FiVc4ooAg8wvbpGTo1+Ld5ehGDnK43zeXiOmoFbgFpcGky6OQBBPDhPHq+eNBda1wrhuGkyNnkRhYGAVHoeSVKgvDGM9qfXtPSn206NBdlnzBcWHblpVX4RFmbk4mR5AFDXvpRNyi7ERPXIGKAQCA4fAaxNg+tnSKw+cUGBiKdtfziBEdZwg8DBaormMicQxcD6prgb3i4rm97WEKAv+cEjpFYXWrySoYY4+jNhmF4fN0SQZiHPhnzX4Oo1iFJZq6X1mH3XSS6/vzyRHxCWlC7RKH7kbxyI0eMgCVLV0usopDXN2wC5Ro/W/tctqaKAiZfTTm5Ae+rN2JCaQm8oydoDhr1SVKsR1mOUubEbElYN3BelylOGvG95mwe/a5iyMjzN8tL9hYAZFMGETNAWXBey0VGLiMHMYt6i6s1C/3HL+7vDlja4RfOzlICH+fqFQBRu+tU1kSRe5qpRBLjamhSx1kGrrEIxeGKEaF4TpHry50GSxOQD0ulNS7FcC5hJCzCSHZAB4GwCcfzQNwCwAQQkbCDLX08rge4yhOkTAiCsK+kINJl8RTA9zf8T6w8WmMapGXPeAF4POI15IvB8UNSr4nbywronU0rFL1WWUrxic9dUGu/uBrhn9N2WdxmRJtuvKx5jEYkrwAOR6JrcAERuCMulgrvVTLMFNwPL3h+skrcgBwFSnijgkqJSC6VtD13TlmYs8zS3YiV0IBYKriLvBtoZOpCceWCzhXifJuekFAPeF0snHi3w425MrvzeEt7KKQnrvULS42X7Y9VfBusGP4qwViyzEBxTeSHnQWspIiADBi+yyb4dRC/tEWO4yWxSnowuOxuRhP+ietm59Hrd0JLNlX7fn+FKaGqObDSilqMwi86nerstP1mW3vi7GVge2Fub4KA2cr1cmSGA7Y3KKMoke8t7dF8CRkJb1PdytOmYp0PUWJzpbQCs0/qatxq7ozrbqogwW1aJ3jg8Hm/1nIRTcUGK41x0+RSxdXCDyXqeIGZZ8tZ4lqrj74zAZkJl7H3xg2krRIn6vqIxMNJeEZLEWIQcMQn1qz1S3BxFqpIIiw683NqRt0CKGueX6GclxSdkRCoKRNKdUAPAZgKYD9AN6llO4jhPyGEHJf8rClABoIIQUAVgL4CaU0NXNLP6Ldhw0sU8jEYmaF3+RkyR8fv2iwFmppu8l/c5DA1coBD51+NommyFl1v4KQTTT72umOj0GjJyYD3hC9qDhHCaaIF4EVZIaRdkwhYiVABFMIT2+8FBg4x0fJT8e+bz1LeXicty88RnPP5bHYPN9rXqcU4PHY3GjeTS6GXmZMcGLtvWMS5nqbih1rcIzorlpYcsjadefkdSQ9X1H6EwUx6C7jEKt8qtDxWcUJvphEjiJGdDR3JXxnjzs8UtzfaUo05jdATCWeV1iDpk6v59oK9b6U9I/dUUYyI8pJtOD3TrKkKLLfgzCJ8wxFXQHCHC8zevF0/6l6bXisPiD2yEaB5b3LBPmKhW/H5AymPKy8WBGJ2HhJygKPdKnvecSg4dHYQtys7HLN2RGClBRrXgQRwAQhqhzih8mKk08leq90wxtpE3VPDGvQlBnKb1fk5ZbSNXyoMHxzsguqWjEU7XhAWRfZkO+HayTGTgtR8+J4yNaXkWhBbvy4U00CESa0EpTSjwF8zH33S+ZvCuDfk/8dt8hSjw+na117HCsKazAgS26Z5RfLKGKdRdtvbhjRwmpYhPVQsV60dBf5VD1y6UKUTJ4Kpql7sU07P/TxfKHZqLhW2Y8LfDaDdMZISeYf3KzIabNd1yIUoJwnJ6KH1grBY5XCoBlHAUsUAAAgAElEQVTx7OpD7o1D4On8yXu7sHHXHsxQxRt5mLnOnhW25qACKpzTlykOBfVZpMYj8Mq8takK+Y/EVqCeDhUqiD+KuQv/3qs6BW/9cl6JyRnje+1hISzOYUOt6ulQT8ispSimUkTbv0/y+x4LR+geT+rweGyu55iLmZpjJhghWRCmamESqYwc1XC74s9KG1Vx8bPwR0WqBjIemTGgZqAjacCaU59RvURGolBwc9XITKdFHpRrlQIcNEzeuzNJbaDxyDHshd3j+3bArTqnPPi5c7OyCwNCpDMMRyuamDyzoDkok33Gk3pXPuGpPvWHoyLMvnWjko8JSjXOovJaotERfh/KpJx2o7IHp9fVALgiY20eC8js7nWcw5AkWGYS10aoVeaHPUdbsKVUzFIFeAWoMAuPfWySkncw6cKpTH2sdGLT/TCO1Nv9S1WRszwE/aXI9Rf8rGlhECR0EUAoaIYBAUUMOs5jvDdj0OD6nYVIEEh1PmQxVtvBpNPnSGBNUV3grPlg51GcS0yhMtVZE7VmDyC30l6slNh/s4pT0LXSMVWNJC2RhXS/d2yGuhqXkGJ8T10gJU0JgwfU9RjNlL+QCdy1dJjnO0tJiZrbFIQ71S3S325Vd0p/s8BTirOh3H5elTvU7Z6wbx58keBMepgAYCAy214mIMtbjYKgYui9jahEYFnQcDYJL3xP5tj+WAyTEJ1Znrc4sgL306AIDR5nSsKdgzxiqYbSyTgAcrn3I6wsxRu+g/KRcyTvNS/TjI7IsO2HmxQxuzGLVOr++WEkacFYCcMqYIbhZ/Ie+bZB/EPTj0ecVOQYZBm9Ew/Mwo+O+FhADnrwkLrW/szmmqTrLQuDdJVFeoJMadmiOXRgtBpRABBT5GMiYxG1kM4zV0A95z/sk2OjwEAuul25CpkIERQpOlFxm7LD9oKlGm6aylmfVaIX7QUgpfa+xUeJ6A/Dxm3qDgwgPZFCzERgGXuDg1GPfUTNtw0LAkAPyLFLF5kMfTuW0N8euajIQY8v0/SDyhrX5yyieUi82N9EsMLDR5Mm34idwei0SbXCzu0pRMw068fUOBj+RrsouF7Zi+nK1pRqbAKOAmbtgXf5GHcA4H4uX9TCUNJh17sz282cjCMnsHPGOFNpLyx4xlY/pMpkLmwLFPQEVORChVZ+WnBBogAnXvRsMCyL7FDSgWvIfhcLIusR6C2PHAt2wUoFUV75Y1Ww+4K6UjoOfNH6MNBCFocWXi+NZ04Eihz/O4sBSLhY2oDeE2hZTCRVuEXx95K4C7ySlOZOKmPJs2OGhSy8zk9xvzVkCGwUZDpXLz0cG32Jyv6bSagwMsBreWJhQEgPYn975KIil8Rxs4QwDQDOFHiuBpNOV6mM8aQOF5MSz3Ei+LEnfyv2MQqMs0K1Y2GgoL1T0eIbdfOtNA1CLGSkVWHxpVgeNugXZSQv8WyGebRvZiFl/opGWnYsQ4UBkBPD2M/ipCLHQJQk/2nCJYp3wWaTlvtCkRsckg5dhihCyrG6MPkl+PNF63sb6XjkghQ5HqJwtCCPYSZwrVIQyYuQ6qw5lxxNgZnUSOmKqdTfEtGfpwuevKIvICtQnunwyeMRWdDSKlfih1Gn5KCu/dgLqwzC5Uy+qR/0Pki96G9MJuWuUPh7lY0Zmy9RiTlEBGSfVbdhh3FuRvrTF7g+oI5bKuhLQ8wp6LQJYUQexQExFd1a75MEZgoqDNATUJE78e4oDXzK9bhAhBHK+fyLqPCjRwbMWj5+6EZ26Gsdq4qcH9Q+JuS5WKDch4WpyMkX+SEZDIMBgNvOHx362BwmJ0tEO+2HVDfS69V9KbHwTU8hvNKPnv9Eh1Wn8CS8SOd9DsLkMYN7re3ewjhSzxU/l0NWs/VEAr/HR8k57ysoMKD2RdHfYxR9ochdoBxBDnoCQ/tTiRDqT4wizcjW0ivZcCzipCLH4M5Lx/V3F45phCkynu4iE2T981s4JkX0eIi8FhpVscs4J3QbfY1YigtnkALcG1BApblaQOapsKPg+zG+FGZ4UBBpzkhvgLdkX3P2qZIjT+Ik+g/Hl0gXHcdbaGUmkGkinHRh1vDs+8iUYwl+pDSZxBB0BBKF+aTfH7MYGO/9KJ++xnH4GHoPo4ed0t9dOKYRJrQyRjLvZmcZ+PwMcfeqGyOxOIo2qTbkHtOhG6l65C46fUjwQRkGAe2TcFznen0jTI4kLRjjw7rV2yAALhk3tN+ufxInIQL5FAvXQbhu4vFhfDkeolQIjOPOE5RJZKokRxB0qIGlTKxscT8CmmMNJyLZyUlFjoUanRHw04QYdGSrfT9lWMKE3l7AiaRu17GCVC2R/SFkKcnyA30G8ukRJqeePaK/u3ASDBL02Eo3H5Qdw0NXjE/p3Nzs6PcyPDcbn5JXLyVMPXsErjxjeOTzGmjfGuCCSlccC1BAfQ26J5EZ3KLsCkynsd75RC8z4WYUJ+BCdVKRYzHx5ow3mRMLN8RXnRl9ke9rZJIGNgq+qK6y/xYpcqcOysnYtYrp6Rml9800YhE9cueedgoevGJ8v6xd/6Su6hUPrQwEwDmnfTq86qnxZp5Eb6ENA/u7Cx4MyEpNuEpl9cuJKWjs5xyyuy4+vV+v7wcCklK4QOIkH50HCuinxmDXnzhDqQ0dWsuThU0569g1NJ4kOznRMeaSjDfZH6pPB+37fKjeBFtzRGSJu+2C0zJynZ3GuVhrXHLCeOQuHTcU91wyFmeOyO2XO8omGh5kahL2BaZfGJ7w5HiFQU8SyB9riEKyFBVnDM9N6byRg7Nx3mnRCUhSEZJVQtDS1X85rwAwfvixp0yzSOWd1U+KaC6MJk0YQVpPrn9JfKRf199dEGLU4MwZ1zONgQOO7XUiFZxcJXobfajJDUxaYEdlHz8FWc8aMSjUcWOSZB0iISNTi3obHQhq2vtCHd9Cw/U9k1AjZBcPYYqHn9YPZCf9gZiiICd2bIV5ZJphTac0pUl/xwUnvpLbXxg3clh/d8EDAoJrJka3jKc0XUn/sz6fKMI9G9oapydWusflZ6T/nlyqFNsBf2OH9q1Q3hupHd00G9U0NQ9WAjG8pk3PcI/CIxOjUWSkFgKeCgbnZOHsMcdHvmoUnFTkOPT0wcIptHim+UZcOm4YxicttxdednWoc97SbkUVjTapB+VkNtTj81eEYwq1xqw3IyosBS6sIpcjKNp9lI7MaJ94lA6dktJ5o07JwQ9vPge3nh/svWyj3s2RVUbKDXkbNVQcIvyRfp3vJt5FM2nB6/+E/Te0O1I6b5sxOfCYbiL2sJ4/xj+fZujYY5eNtTdRR4fhtdiMXr0GiWUwvNtIP0QwnZpn7P4U1uJP0Ld1WJ/XPuf5TiEE548+dksgnHlqsGd19OABmHaOs4e0ITVvbKZwfRokLYNzvLLUkAHpyVeWsdro45p+lUk5adIor/F2ylkj0lLwPtBvxIf6NPvzOv3i0OcaIOhAOCPty9qdkfsWiBRue4F+vetzX4YPnz0yFxhw4hGFnVTkOHxh6gTcfN6ojLHwiJYbdsN7WbsLQPo5L+ePGQyDUmwzJqNu9DTXbz2CRPx6OhQ1GBFZgL49wKq/3zjL/vt17Q7UU/lLY+U0nMa54UuMMZ5jCfev6zduEc0/5XrBUfK2LQxIlj6wEneDQlSzoeEf2v3251naDLTRzG28kwVCSSLbGc8gIUsnzHO/7IvIGn+5TVazUr8cW4zzhecNhDfXhRUMS+gYvKndZn+uTSpvS/SpaJQk59fRob5zXGOWoucEQloYWEJCulv8VWeln69aD2ccBiQ9hHuMiYHndYZ4H3uIN4xvnzEBMR9XyjZjMprPeRAAcMg4fsqsVNBRKZ+7QL8e72o34239FsSyejfUZwDtjnzOJ/qVwu974BZ2rae63zgLl40P59F4pfsm4Dy5pb6JDsZC/Vrhb9ZyOlv7LI7QsF5cOd+hyDAUFXGabY/XS9rd6BQIr4QAbbFw47PZuED6W2WAcfNp7QHf82UIE30yecxgl9Gsmo7I6J4SFQrTlzBG33n6Dfbfd17s3WvTiU6op0ORnWW+G1YpiHSNB6I91gJrsOym5prrp7DxMmO+cXbg9efqN6EWw9GTVGa2GpOxjTr78tPaA77nGxHq9rZiED7Wrwl9fDrwey78fE6VKCWVfYwCwPmpyRfHMk4qchwmnDYUl58xHG/ot+NZ7V5fRSQMumg23tZuERbKzs1S0Qrv4l5Lh6ONDsQSfarr+zmM8MziDe0ONF72KJYNeRDrjEugckJLA7z38LZ+CwBgpXG55zfeImx9vv2C0Rg3wt/i2ZK8n83GBWjAUGjcS3rAOMMOBZg8ejAw9TvYPOweHDbG4mntAXykX4eFhlxB2TXkZhQwyuIVZwyHnu0IzduN81CISdLn1o1szNIc63wXzbFd+9bCS6FgljYDL+jOCz9Xvwl11C0kLDWm2EKXNUZB+XWtEcIxbzjH691TFGc8g9oqGn23+UfuCGDEROD8e6DHBqKFDsJueo5dL6+ajnCNiR8FtUEV7KTnoA7Dsdm4APV0KN7Xb8Qc7TYU0jNd5QZYxjUdKtaf/lWhkDRLewiUWYq6MADfuN58FnP1mzBb+yxW6FfgSe3zmKU9hDX6pZjPCAwWzrjxSwAc8pt7Lx0rvId9xgTp/QGp5yS5QewyFpeOH4o3tduxwhAL7izK6Wl4S7vVFFYlSl2PkmsbL9bql6CN5mK5McVXSIrTLBBVxSxtBhYa1+FN7Ta8LvAa1tOh2BsggHyoTxOOYZASyhp5wqCRDpZ6f7NjCh6Z6t/eUToSlRgJHapQALMMXIXGmfZ344Y5Sser2vTQArvFrGsJfDKUGY5i1AzxWsoyvc7VP4PNuZ/Ba9p0fGJcie5cubduKBNKXYPhwLir7M+8B+uer/4YJVTcVocyGJ00B80YjBe+NlV4DA/ChVbuMM61DRgv6ffgTe02vCoIARMZo1rpILTTga7Q9VXGZdhLJ5rGMomXSr9pJtYO+zze0m5FKx2EJuoe363GZHTQAXhTux0bjYtcSgc7B3YY53rWehYJxFILBxssNyKyYGeqAYJDNLrAut84Cwcj9FEWdn1EPxV1dBie0e7DTp/6qruNSVikX4syRvEX6TxhFTl+Lamkp+IN/Q6sH3YfAKDBGIQKOkq4U202LnApC8XGWKmXe5pgj7VQQM9CadLwa73ffopcNZzwyBe0e5BnXOU5ppYOh0bN9+Ip7QF0DzKfrSlzPIT1htsbF+Stag/pjTPXOoIieob93Srdkf3aUzS2EMjl0jnabXhJu9vzPa+4dcN81sNzvWunX4TTKuMy+2+ZUUqI7P71cvcGTipyPBTzxTFA0I0cxJOC+gb9IowTxGNX0xFooYPwjnaL57d5+g14jd6DapyKD40bPb/feJ5jbbbWhze12zFHvw0v6fegkJ7pOr4WYk9BPYYiZ9BQW7DnFTk2YdoSLrXkAtGGXLyqTcdb2q14Tvsc/q49iAXGDWimJvvfW9qtWGhchw/0GzH2omnAiGArEws+TJGAopHxVmDQSDTGTsNHxvVIIIbDdBx0gYWGAHhPuwlnnX8VlhlOeOHgATEYOUOw25iElfrlWGtcCsBRVAHT8m0JUAq39A8kcXxsXItZ2gy0CwSE17TpmK/fgAo6ylbSPtavwQb9IhxILopPap/HR0nlMyg5fXkIYd5Cz2mXYJ5+g2uRJQzjkkxpLDDOwkL9WrQNOB34zE+Aq79t/3bonG/iFd30AndiAP6uPYi39VsBmILrcv0qdMErkM/Tb8D7+o14Qb/bVro2GhfhDf0OxJFtz03r/iklWKI7Ib4JxGAo2dCp+9mu0S+FSHUceo5pOaykp6IZg7GHTkrOC4Id9DyU0NOx25jkVuioAVz/I9x/2Vh8/opxmDTKnMMad831xsXIk3hDALcAsl4S5rLNmIyXtTtd4SoHjDNc51iCaNnIz6AOXsGwlgtDpZSgDsNQgxFoQy6WGuIQaQID2sRbsVy/CtvpZLykm5ulxZD7jnaLPWedc6jLI1qH4S4DT7FhKr1v6Hfgk6QAcqWESbeMjsFyYwpe06a7LLzWs5AJwR0YgPe0m1zfVdFTMUe7DYv1qR7DlQHTaMDjae0BvEwfwOi7ZuILU87w/G4hzni26tq97GubjAsBAJ3IwcqkUDN/4Oft35swBBuNC/Gk9nmXYGhQBc9q9+IZ7T7M0W7DTuNcFAy4AoB3fWFx2BiLj41rMFe/CXn6lR5PVTsdiIX6tRjCFOGtoKfhiHoWGjEEOlS05LiNE8vhKEKWUGoK8Oazbjn/YSzQr0cnBtjvwfQLx2DqWcM8a1WpMQZz9Zvw0cD78bx+r3k/jOGIn68sCDEJDgqMs7BYn4o1xqWu96gOw9GEIS6DEQAcpuMwS5thC8yAaUx4Ub/Hvl4dHYZCKn/OFiwhuwYj8LJ+F6q5/m42LsAL+ufsd7GUjrHnPbtPURAMHuke5ye1z7s+815THu9qN9t/P609ANzyM2DKN/CWZq61/HtgGR4JgIaRzv5WSUfaq2OYkDvLa7bHmIglzPrBnrtOvxhvaHe4nsX5gjqj7XQg5pNb8aZ+O+LIRgk9HfuNM7HdOA8r9CvwFOMtWm1choN0vGscRbsTGzWwWr/M8/tL2t2Ypc3w5IxZa8PQQabi0mFkQ4UhzMs8ZIzDG/rt9ueNxgVYYNyAp7QH8IRmRiVU0VPx1dunCtNcLONNPR2CFUlDd3HS6MEe/qE+DTpV0JJzOmbrd2ITY/Sxwh0HcaU8KByFz5vC4VRCfV+/MdCI1EgHow25oVJBWKP0m9rteFe72RWSWUDPkqZFsHhGuw9rdZYUkEhZvmsx3GV0qaEjkgYiN7N0gqpYrE/FmSNycdgYi+X6VVijX4pJ9/wYD3/j3wCYBnoe1n130hwcoo7RoswYLfQ8ztIeQt5p3wi8x+MRJ7lteUyYBhQswGvfvw3ZOQPxwpOrAQCVOBUfD74cBxsrMENdbR9+0BiH7XQycpLhaNV0hF0suJSejgFQABiooKPwsnYnblD2YbJSDsBZ6F7U7gYdNxl/P1Tu6U6RMR7nKRXS79/UzAVrQJYKzTC9IVmxGObqNyEX3bhb3Yz/z951h1lR3e333LK9F5btfdnGssAubVlk6R1FLBh7lFhAjRUToybRxDSiJho/jSYx1qhJNGoUiRojKkpUFAQRhCiigiJNpNw75/tjyp1yZubM3Ht378K8z8PD3pnT5vRfFyjBHeHZyMR+7EAuXhK0G+hXMG7iu2gGcsg+HEASBPjwES3C4ZqJwEdPGb5Txn6arKgXyIfPKqEBs/2vsvs6m5/TeFig+ASFyEgROUsyCAFAfHhBGKo8EyhVCFUA+ICWYSMtxWnkOazSbQi2myWyFHVB+eKzj6ZiAyIXCzXhKad5R6hBGdmBPLIXn9NcFEmeNyl8ikRyJzLRQv6HSvKZZozvD03CtwLLcXhAG7bQ9bgvPAnnBf4h5kktRypENZ1bJw3HG395TtPeD4QyLJMOcEoB+HVLXHdwqSVhXyELX9EsVNHPUU+24oHQRMzwr0QO2YevaSqTGAFE5wiy5qW8cS8XhmGHivFwCEEQIkoKJhZ9g19ta8UmidM8oXEAfB+Ic/exsMTwqJ+C34YOWIaCUI+5+DECkJyBlKBfo8b0H2Ew2nwfIp/swaPhY7AfKQZO55c0C/lkj/Q9kT5aQ6vQhTXK77bSHJz9v0lgQVb3CsOHgI/gHaEGh8JBzMpoBPCBIf0D4Ym4JPCo8lsvvf4fHYgXw+3YgzTM8b8S+UwQCCWdWEu/0qRPLyhHYfYIfPrfDIACm8MDcaxvBap8n4lXBIvz/ilhJJIErc2nnPwtoR5Dfcb2y2sjT9iLj4VCfI5cvBBux/u0HIVkF47XeSyliLjp/5qmaC4X8qV9Gl4HAKwRqrFKaMCsYVV47e1mjPK9p6Q9jAAOIgAEU5BhYrOrJxjCAlXYlm8LddhHU5T+DiCM1bQOq0N1GCzomXUEYfhxd3iGMla3hudF2o0kbBdyMd0vznu/RdzE54WhOIgkbKWF2IpCJe0emo6VQiPep+UIIQCfQDHDv5KpVUAlRqM8Xx//wWm4/IeblTEGgKeECHc6nFmKD6lIlNwTno4hvk3oPrQDCKYBIMpeAwB/F0SV/FbVkvOpnCtZSeoJCEbV5OOsLe2QZ46Z98vfhI7D4sDfNM+eE4bjXJ94thwubAY+j6hbvyXUgcIHv49oVLwfDE1AHtmLqf43AIjSHnUL3xAa0eT7SPnNujg/I3RiClbhZaEVTb7/ARDXb05qEtTKsnrmop062DYU4NlwJ3bQHM1e8zki2g/Ph4digv8tAOK+XeDfjYPBTOxPj2iI7EUaXhOa4EcYb9M6rA9VIAwfashnmOB7E36ijfMlnz9+EkaY+vFquAWfIB9b6QDkCF8jl+zVqO79PjQD5wSeNnhDfjo8Eh/SYgw7HJnPhxHAs4KW2XJXaCZC8Kv2abGcrbQQO+uOA1bdilfDLdhAS3FGYJlGIvcWrcc7oRpM9L2JZqnvWdJW9VpOysjHS+E2bKBl8ENAO14EIBIY5weeUNIdRBLWCZXII3uUc0i+E/wmdBwoCH42bgZ2r34SwIf4T3gwuv3vYhvNx0qhCR8KxUq+20NzcQgBfBIqwK8Cbyh1bKMF+E14Hi4orMHu9Zuxk6bjH+HRKC7IBXZITN/ABOz/Zhem+8V9TYAPT4THIBd7FcYkCx/TInysU2veSTNxb3gKCrELg3xb8bLQKuW3D/GjnoPyOV6GHcqzt4U6HCYBFPm/MuQFgH+Fh2E9rcBhBJR9cw9Nx0vBSTiruxiHXxXvIYdpAGtpJRpqjwNWb9GU8RjtwSGB/b1yvLpDCGItFYUFlw8YiOG1BTheGv/hvg0AgGfDnUjFQWU/2q0jDEWhCcUMrNTVQkCP0LAVnkROj6IWoOdqDK4cgEEDMzV6z4cCGQYuqnw4lBXm4h/h0Xg8PEZzAKs5RnuQoeVYSZNqH9Ig+NlqSU8LWs7CXpqGQzSgSJHkRZkS9ONwWKws6PdhKy1UFlwIfhxAsuZibYd/CiKHXL1ICADkiOpMb0hOGd6SJHyAuFnoj/pNtBS3h+binxJHTf76/wvNAoYsMK1fVoX4QCjDuPpC5KYFpfzahbg9vxN7q6Zqnum5dIcQwAEkS9xYsQ+WhTvwfHgoXhVaTNughzx2Pot4egJ8yE9PxndnRw68Z8OdeCzcjUM0gB00W7wAIwsAwVpapag4/SU0HjeH5uOXZ09B84KfQsgUL2AHkIwHZFU4lUQu6BPb8SXNUribammlW/uBZUIHHghNxHbkKnPIjOv30MJRmjF/XWjEy+FWrKPiPPlzaLJiyE0IwStCC17Jma0QcQBw6qgK5aL0ucyJJURDjFtBkYbnVBjevSY0YzWtwz/Co7FaqMUnEsd6h7RG3xLqcUtoHv4SHo8HQhOxWqjVfCkFwWtCM5aFxX7NSmW36RuarPSDbO9A4cM6WgnC6Wl0O4NQfpvW4UNagqfCoxRVsa3prWCFwvm45kQMGaM2aCeiih3EGJCsM+xDoQSbhBKE4cc3Kg6tep/7wiYo8WtCMz5BIQCC1bQOB5CMj2kRbg3Nw52hWYoaJgVREbvsi7Csgr5cGIaiohLUFmZYOv/4uv1s/DEkrn/Z/tMKh2gQLwrtWEUbFYmdWrLdUuIuAHNYGnP1xVrPRdZLwMLw4+nwSDwa7sZaWq3M9w20HDeH5uO+sKj6evGkyB67PbMF64UKPBI+BjeH5iOQnIpnhE68Em7REE7Xz27W1FU3IAP7kYJXhRbUnHAj4Be/fQdy8PdwF36vUoFSX+rVmnBmhNwtoXn4KlAoXdKtJTLyd++nyfhIpTb7tSoO32fJVQDEtSlQHz6iYroLxtdqyvkceco+I7dbveft1DEoWRoMhxDEk8JofI1URWK5j6bBztL2AJI0al9/D3cZVDnX0Up8oTNrUK/Bd2jke1bSRtwdmoF1lafiQFoZngt3KAzXA0jGv4ThCCGAfUjDN0jBWlqFx8LjDKrHrwlNCFG/IhVfSZuwVeq/5cJwPBIer0m/D2lKu9X3ls9oLkIIoCzHWuXua6TioC70xq2heXg0PA4Hs6rwh9A0rKSN+ApZeFOox1eVWlW7MPxYJnTi9tBcjRqe2VzLSAngTdqAfUjDbmRgebKomXAQSbgzNAsvhduwQ+rzZ4VOPBg2qv2FZcLT50e4firuCs3EPmn+fUwHQIAPn6vUJEXpK0FeYQkGDp1pbJRqUDfRUpw3J6INtN1XhC00Im1eL5TjEIKa8u3wXFjUkBA1rgh2IBcvC4MhrzAeidyJHUY1232SD4CttBD7kYI36CCNzb+MW0Pz8C6tUYjBJIhe0TfQMvzoWz1ISkqSykvFbeFj8aIwFIeCxrOM+LR7fk1BOr6g2VhHK5UyD6nOfPmu9+NjtZLodbQSn2a1YR/S8Fx4uKKevVJownPhDiX3a0KzIhmXJdV97Vk3XuC6KRFCpgG4BYAfwO8ppTeZpJsP4BEAnZTSVTFrZQKAgMJHiCHSfUtpDvYcysA1M5tw5h++BiCq9cl2DlbzRntImte8ShikOOm4JzyNmTYp4FO4lXLQaNleyU2A64NIMqh2ggAoHY57QtOxB+n4c2gydiJTw62XNxX1RnwIQeUSIz+//vhO5TLBWlxPCF2AAFw5bRCGdVfi0odWAZ/sNFxGd+SPQGmS9gC9oKcW1z6+VtUm4/e/R6ssv5+FXTQDpeQLHKbm3FjxOykGl2TiN9ntyNvzH+xDKnbSLNweZhsur6OV2BoqVLiR7eU5yE4NYtuub5Q0suqimpD1CeLmdwBJeIvW461QPWKBwwio6pOMyk3SjtJ5NQvDr+H4folsfKlSGxLgw55AAYBtShpKRTWVcrLdVmWJhU+Rj5tD83FJinRxy60CvtoCIBWkYgcAACAASURBVOIsYxcyNRK8L5GNu0IzJfUSIqmHJuErIRM+8t9I26QDAQCmYBVzrj4Qmoh9SEUYPgjw4T1aBTVNYWVX8fdwF3bSLNSRTyztAT6gZfggXAaA4syUCtP9Ql+VTBjpDfFrCtLx4Rdf4wmB7Rjoj+FpSCkpx50ffoTD8ONwOIABZBf22DheyEwOYO9BcV4K8GE/UhRbyRD1I4QAloeH4WPKtn17KDwBVeQzAESyu6IalXKZISQPA00VVW9fCrdhdGATgvjatG13hmZpiKkNtAy5wj6N7Y/g8qQP+yLz9qFQDwJE1MJ4WWjFcb6XUeHbztyHN9ioDBKijY9GA8l4RicVOYBkvE6bQBCR2vqlCcj6mtx07cV7i85WTu3gQi9VWxFuxR6kYS9NQ4dvA75CBih8eCVjEk4Z1Qwsj7TBat7LqpssBKW2b0euRvppFuD8vtBk5JK9uMTC/kovoWXhtvBc5GMvvkA2CD63SU3wSHg8SrED4/2r8TEdgJVCE6b5X7e0k1w8oR63/sso3QYI9kLyRktEBp8dtqEAjwnj0E43Yrz/bQCiKu5vw8fZ5NRC3neeCY9Aq28z1gpV2CMxcM8fX4u/vvWJo/LkeU6pVlrykjAE5xU04iNhALZBu9cdQlCz9/+PDkQ1PlNUUWWEtdcvfEoG4j1pT9qPFLxJjSp4VvD5fPgaqXifliMpHMJ7KsaAHt/ursHB4iy8L7yEQb6PFcaAfpqrpY5+n3i23ByaDx8EAzOBR0C0llYhR9in2LSbgVICQigO0SCSyGG8LdSi3bcJAHD8sDL8ZZVWs2sXMvBCuB2bqKxGTHAIQdwcmo9G8hGmSVLEv13Yjbm3rVDyraMVKBG+QEnrOLSWZmPFWuOdT42VQhM6yfvw+yMfe29oCiZm5eCRz8QB/QJZIIDCtAEi9+PTRlXiB39fgz+Epil32u9OasCVj72jSO8AGJjy8rl9T2iawqQ8agk5QogfwG0AJgPYCuANQsgTlNL3dOkyAVwEGOSZ/RrfSNwmgfpQlpuG9Tox9qjaAvx4+jF47cMvlWchBCLSBIuJw+upUuS+yMUZrTBOGVmBrJSAcgmRN5KANOmvntWKJ58AF9Rqcj87fjCueuxdbXsJURy06J2oUBC8T8sxnG4wOEOQ1RO3SOoCJ3UapSd6bLkpwv06RESJpf5i4fcRw2Z4+ugqXPv4WrwuNKKWbEMsMKW5CM+/144tdKAlN+1DoQSUbgZyq7DJfwjLQnxe39QqJfIGxoxSoXp3KK0IbwiDsFqoNSZEbDat3TQD+WQPU5Xo/04b7qwek+kuH/i7aQY7gVO0S5Le0CHMD2/BzctZFyetFEDGYQTw+fDv4sCqJUghhzSH01ZaiC8zjH2tJjTktRoQHbID0H72n0OTcVogog4rX6KrhvbgzTc/QVddPlZs/BLmsFZbaxyYhZM6yvHwKlFN+y1ajzThIN6k9Zr95umLu9H4g2dMawnDj5A/ooK6gZbbEh0Ae7tbTWuRIhzCm1RkNKyh5t47dyBHY2Mn70W3huaBwsiUkbvhTdqATaQFheHNCJqoGuk9HVL4lMMeEJ05CVSUKmf5DiE7NYjSnFS896mocvtAaKLG7k7bkMj6+Az5SkdQ+PAPYQxyhH2umBQpAb/GAYsVcbSraCQeCYnq7noPpk4Uiqwkcm+omDRPCJHLOPUlwadz6/1UcBK27zcnrPV4U6jHMN8HuPHYVkz+9Uuadzcc24qdXxu96QKijbgsTdLPvwdDExAkfHFVKXyKBI3VXxuFUhSQ3Zpnn6AQ90v2WOtpBdaH7M81KxBiPM9YOHVUBR5/exv2HgjhbVqHGmEb07aZBy8I7cDwTnzx7Jt4Uef8LCngTmnr2PYSsHaD5KAPfxXG2eZ/m9ZiQ6jMsGZHVOfinhWbld/RHnGRPZHgXYt9CRAZHD5CsEzowAqhVaNVoJYEq9eMeh26YajLbVshDDZ9e/zQUuBdkYn8+9AMUBBln/qGpuAjOgAm/mmxmmGDrIZQ2IwhurBB+5CGx4WxOCEomS8Qa0LuVaEFr6IFGYFIX+xEFnYHCgGJYbKVDsArRQuwaUtE3VN/xqmZAslBJ946Y3SvSGDw9MYIABsppR9SSg8BeAiAUf4K/BjAzwE498OcwPiXMAwvhdvwCQpAKcVD54j2R7toBtYKVfgyUzzYzLwxUd3kfk1oUsS8miyM3bsgIxlPX2R0kqLHD2Y2gxCiXKh9hGDjjdOxXboQ+Yv4XSWrvyPoZ1+azPCq0Iw9SMcd4TkGj2w7kYXfheZgjYqD4gRyL+qb4CPmBPErQiv+HJ6CSyc749KxcMepomrLB9TaE9inyMefkhcAWWyPiW6gHpOUgB+HaBCHSRAg4gavdtLyxKIuLOoRN2fWtmpGAJjhWaED7xdMxbQOY6iCqS1aL2zLL7U+oJNV82miKp6dXgoytSVGgasDSbhkEnvspzNcY8sQbW2M/fRo+Bh8kDeBkYMB9QVY9feXyMYT4TERW0AlOZHq5jugzIQPfh/BDcdFVFEOI4AXhXYcRkDTDp5p0MxwgGAHljpvGH68IrRyq8rKUM9VAT6mZF1P2GykZRp1uycXj8WP57bg+cuO0WdFRZ5RuigIFK8IrZh03FlYfd0UHDMo4jBmO3IN9hiRtopq7yyHFIcRMLUvtUNuWlDTD+px/9UJWlvn3QNHSSquxvOItRfcfJLRY7E+LyEE6ySPjpY2coQY6vzSX6io9fHgJWEIbg7NR0lOKv5zZQ8mNWnzcsUw1TXxc+Q5aoOMnUFxD6KUKB4UnxRG44/hOMTi0sGOMXb5lAbccOxgzdz/qzAO/xSsXct3mIRVCcMPZLHVl93GRzurq5r5HckBXlfzhBliIlMKMSNPNTPzgSnNnGeIxeedMFx71vslIjsMo7dxdSvU6zVak6xSG9VWAPjJPJHIizjoS4LsOGUlbcKnyDeVZtthxmBztfaAdJ4fIin4nOZqzDrUGFoh7n36M0s/tw4H0nXvzdvFP4+00N/HjxTw3BpKAai9cGyVnikghAwFUE4pfTKGbUsIHESSJK4nECjFwdQivCtU42/hsXhO6AD1aTcWALjr9A78fL7oPVG/z+xCJh6WPSoGIhxaObvIyRKR5CfITrPn4hLdpub3EQT8PuxEFm4JzUOwyHgJ/4XUPj3Ui0vfdrN19SnNx+tCI97Xq2LqENlgXEBqi3rtH6IB+Dg4mCOq+fXRzeDT7SqVjOCut5wsXoycSsKSAz7NJShCtBo/rLU0C3eEZ+OfWScy37eV5agOOWftYOEgklA5iH3h06PMwm3/hMYBqJG8SBICnDwiMlf0zWRdsHsTPkIUL2V6W64QZyBa9cicMLwcwytzsXCcyPH9kJYYDNnVc/h33xqGJxdrY0Eay49kaBwoMk2q8tMNdcu4sEdr+8ejDTC33d4Z0d8v1IaBYPVOpnQB/9PZfK7sZVw3u9l0Dst7HWE8U6O1NBunja5CZb4xVAfronD++FpU5qdhgsRocLKG7g7P0KgVxwL6i5T6kjhooJZZVlcYITJlSYDVKB87tBRXTze2V70X+QgUl+hW8cx8xNifegcaTlCel4bfnqL1LHv66Er8cE6LZn+4ZqaWScl7UTt/fK3C8GLh4+RBuDs0A7eEj7dUA40WD4d6VHY9zi7+veG3QX/u8YIQ9l6Q7FLCp5Qr/S/fU8xUodX3GD1DwK49pTmp2HDDdMxp1zJj/T4js4JdtzZPNFDP9V/qGDf3nNmBFUsmwEcIJjUWGewx1RhSlm0gTKOFIm0kPjwYnqhR0ZbX4ewhJYrtsr4v9DxLPWFnNb/dzqMjVbWSpzdY3al0BxH9of8awGW2BRGykBCyihCyaseOHXbJEw6UilyPfwnDDZxZ9QFbPyBDCZxtttHcH5qIbYPOUH6f1FmOyvw0XDEtcrBS8JE98gKgym9Vm+FjctXMOC1WG4+ZNOfhcA9eEexdI0cDuR/lb3kkdAz+HJ6C9vIc2wMt2sODBZa0okl65nSvaC11FqtQgA+U+G2/O5bcJ54N0Ip7e1KnuVqegWHQx56l/D6CfwnD8PvQDIN3y7COkLO6JMjITU/CY+ePwbfH8kmjpw8utp0T6i7658XdeOmKHiUPaxxy05IcS+R40KpzDsLa73LSRWZUaU4KFowox2UcEvKR1XkYVZNvP4c5v4OVjDXP6osy8e8repCXbh0PznVDHODxC7tw9QwtoaKVlmnTl+elKfOR9wLJ2hv1Erl9SMM/wqMNjrfUEBlq+ouaeyIAEG3iThkZYfgE/T6cMUYb+L7BIqCzZR0ATmA4gFA3wixeXSzxKfI19nAE9mtT7ufe2CWdEuPy0PhUGkJq6LV8HEOmHaT/zfhqaiJh/vDI2aN3nJES9OOVJRM0d6am4kwkBXwGZteUliIuVVOtBD3y99ofTmUlt4RfM9e1d85BA7NEiV0gCZvLZjNjq6rbtGAkv9rvfklNNxQ0X1+yL4bUJHPpmJ9ExsqKKQUY57PVPSDgdzf7j1A6jouQ2wpAfQsrg9pTAZAJoBXAi4SQLQBGAXiCEGKQs1JK76SUdlBKOwoLC/WvEx4C5eMAib+ty9qBXJDkyCIpyUnFv6/o0YjSKeW7cOklMPICWNRTh/K8VObFzuzSrd649V/al9dr5duk35+gED+YPwr1RZm20oWiLL6gmXawG1M7LiEv0iQ1CNYQqcfYtDkyYR+jXYuCmh6Yalj1D4GWsNRIh4gxbbxh1Tc+IsbGkVVWN944XVHPDesymq0jpn2jRXvkd7yeRrVEGUGFSkJsvmcQxl/RwaDCx2i+es7+dF4bFk+0d8ojFyPPOz0RbCW1ZsHpeFjliyadE5TnpRn6105l7CfHDcb84WUGtWczJNmoKMnVb6KlBu+EarC+3wkdd8kkd46a9PXy7nmEOFMbtFMb54ZdA/uYiaWHU1pcq9Fj/NZoJVRy+fK6Nztr1fuCTPh31xfgtFGi2vVA1Z2gJCdVR6BJdeiampYUQE1BOr43QyvF1u9BZhI5lmqwXW9YMtZVf3+dVm66PkfrHJLx4CM6AP8Ij8aeIvNA2zJRfvroKlw+xZw5J/fPjMHF2HjjdOX5vKFajQ+ee8C9Z4/Az44f7FrafzRL5N4AUE8IqSaEJAE4GYDiOoNSuptSWkApraKUVgF4DcCcI81rJWB9oVVPrOSgT+FGWnuttJ6MVBfE164c+aIs/7586iD858oJzBVhVrUVFzVeZwyP5EhOQwiU2FGK+pBFu168fDxKOPTMeRCw4SbqCWpeFUF98+V6WJ+lthU041gRXVqrunjBM0ZWh456rutTTWwcgOoCo+pbX4HoDuKA36cc9HqJnLNyY7e2rPYFHolmrKSe+nJYvSOvB0eHr64gvfOOSP18xTG/lyMvN2HAl8wRWGXWFGagODtFem9MMSArBb88YQi3TUxBhvHyp16rvMSOE2YhC+Ma1MHrjfnMhoGXkHecT/e6tjADF02wdgxhhrntzuyleb/I6Rp2s3M5rcOvOpNZ9bmRpKiZOET/h/nEMLRJxsrvTcRzOsKcNR9YLSWE4OyuasNz9T6h7jOzfYsXVt3POzQX9IgOuvTByW1qFkME+SykbdK3JQV8WDTBnBGjbqf6DtVSkq1xaGfMZ/zAmsJ0nNRZ4fr8Ompt5CilIQCLADwLYB2Av1BK1xJCfkQImRPvBiYUqPlFTj2virNTlUuLNeffpjoH3EV1eqNRKV85gHbj0XPU3B6aeuRy2P3pIXc7IURRH5K/26pVVTEkEIIWak0AUJgpqiPIuui3LBiKO04dHnW97APFfCM/p7saxw8rwzndxgPHNTjmohtCZULjAAT8Pjz8nVEoyJC8rvUCU9pqQyeMv+V1EQrz2sgxLgYx/C6nZeml+3HrYhtJp/PyxAL1F0C9hN4N+MkFjrLi0KH2Knb8ZZlJeiczJHxV+WoPutpKTO2NVclKJELTiRqdZs05+C5CgP9c2YMHzxUlB/JnZqdanzGEGJmWvz+d7axBTE9w6ZRB/A1TYaaFwwhDPQ7KjdcavkglMXciQfvnxd0RQg5s1coApzMnNWRnGUDkjJGbZS6RU/2t+4SirBTFaQorjfK3GbPbZoKqu8xOvVhflCwxZMHos0B1V7OsRcSggZn43beG4fend+DfV4zHd8ZZe+m0Q9Di26a3FuPEjjJ8f2bEK7DRhEL7e0CmveaUfvw9iOBaVZTSpymlDZTSWkrpjdKzaymlBqf2lNLxR6I0DhA3DTPbCXlx1xSma35bwW6TpOA71OTJLSiEHGG+1z5jl2W58ThYPE0mHu+mthRh1TWT+QuSoL646dWqeksbxU4il5kSxAc3TsciiXOblRLEtNaBmjhQLJhuwozvUl/IzD47MyWIX504BFkpzglmJixUigHRM+DFNupyhOi5ltr3AzJTMF7yEMgiglgXzmhgxSRhHeryWg0LAiOHdRnKM6v0jLdPLDK3eXBDFPFclrvqtGo4L13R46gOSwLZkUCOSv+LSA74ceU040Vavbfpa37n+imWdfS1LaYdzBhnji77tsSgMcH3VA5E9K+HVeQyL1HyfNx443S8dGUPzhxThV+fNMSY0EE7zKDxEAhRBXV0rRTwV3p70zxzd+1yPn2NaSpbn1jODCfsgUSYkmovz04uzE3FWQoDW5TIGb/cjYRKnluTm4uU/vHp7jx6aD1H2tfJYt6Zrj9i/duNRFuG3obPCuqieZn+0wcXY1Jzkej8yeVc66wSvZ9a3YdSgn78fP4QFGYmRwQNuvlg148sKDaYbim5I1Mg5zqwxVEJCqC6IB1PLh6LBSO0zhtkRpMiFVP17BKGZzAxjQ0hR1lO0K3TA4wFwkhrtklpHaXo8sSAA8zr+YlRotSGCKcv0p7eOf14DqGg32c4OF6+yt5lfXTX8vjDav9rLc3Gd20cWKjnm+byzSBMWfMsx4bDHlsY2zqxUSQk1YbzfCWonnFILNXLpq2M7bLe6b7Aqt+sLfqLR0V+muIVkwextkGQGQgE7PVn1Q9JnKrQVuBVxYmVtoKuUOvXPO13MR5q196sy5ZcpCbwsfRnwO9DwO/D9XNaUJrD7yzE7FNYzzVnC9G/E/+3O1tnDSnhYnj2Ngj44sgB7og+uzWhh9MLs5zeZ6Jb6XehWhmxi1MTWSLM1qc2/qE9WCEDzPrXbp5U5htjwprWa9M69Vu3PgvM9gAzIrOpOMvgWEXGiOo8RSrPOzXMGVJubj3y/HKcFcARS8d5hJwTyAuitTRbURFQOPaKKiXV/AaMbqJl2BEGAq/bSh2MxreMC5BJuVZ2LE6aEq3DD2N5kTZEQ2BGA7V6V7QXt+EmMX3UsLMV6c17R9TDSYCxdWIA4TPGVLElVkRJ2qdQt01eohX5adhy00wMLuPzMMqUgnPWyVc+X7pzWPYlcYTVunfGCBL/l8MAjGso1DpSAINppavaTrUvlsRXn6hWOmi/WyKFdXbIYzOMofKmrZO/HrO0PYPE8R9azmZquB3DhqJMVxIBN3Cyd/Jp4Ch/OWwHxbPfdea0xalTCVsbOVcSOfF/gUbmmaKFZKIg4bQWNrPbOV64fLxGbdNtHD4uRFm0WfYxtfkRzbMYNJ/FpATcEWNKxAOX/crrTKy/wSPkHMBqCsgTS07Ds4BrCq0jzjuddEZJFfu3FTQLxKDTzF+QmcqD23WkljYabfeMmNtegpRgbKe3G/1+M9x79ggsPZFf9UgPcShccLRc7H8U/IS5FYNgQFYKttw0E+3lOYon0cEqqVNvqsparmXN3+4aw7wYxPC7nDs64Bs/K6+TbsG7jy0YYXSPPbwyD1tumokh5TloKTES0VbjY8sN5+hCXu+PbhC0kU6Ye0TtvXVidY6p5+ComuhidWol9pHnk5qL8P4N00zDceibp3YGdcH4Wpw6ytzluv7LNOs+is59+qJu3ZP4XB7dNJGVpTzPXPWfpT2zZHqjxvsgKz0Be99wo42j9gatl5aZ7S2s8bPchjQSPGdtJCZ/A9ERcnpHILH2WWDWNE01MZy6Rga8tgGyWZIlpCxu+/XIJOM8Qs4R1JfZM8ZUIj89STno9R4LfSY6iuqDJdXGs5gokOOfsHqvlTKc2uvoy5PhZA92IpHjSaomkHPTRG6R7IWJlf2Wk4di/Y/Zh41bxPLilJ4cQLmNV0tWfVZ2Zm7BcwnT9/FvFgxlpjNrkv4AbynJxlMXaW3rIhK52N5Q1cbyTuHaqJq55ixlcgBi71VLzQ3lUsVj1O+kTayUyuXapgFzhpTgkfNGm5YzujYfj50/WvOMmJxg/7myJyaqcsMq7CXngHnf1hSkK1529bBjDMVyFbjlROvnP+vSetnkBpzYYVQ5joVEDtCqehry6X6rQ11cOa0RNxxrbitnNT/OO6Ym4nzJAY5tL0GzLraiI4mcg7rczA/13WBqi6guPr7BPBYmq4ty04Km9lFBlUSuKMvYf+o5P5AzLJCcRVCplNvZyMkoz0vlk3JytYSjHF1B0fJ+Y+np2JDf4qut3unDXLmFfm+Z0FiEW05uV7XBvF1m5/Ilk+pRP0ArINFcxY9QSs4j5JxANQnqBmTivz+YrEgW5IuqmoCZN6wU9317pHIR6hlUqDlYeLxWOlkrEc+O2udsD3rsgq0OfKcX7FtObo+ZVEzZsAlw9YxG/GhuCyZyBGOOJTRdFkvpioPnxzQUYlxDIb4/oylmTbDz8AbAcLM2y8NrewWIxBwrwLGdjYIev1kwFP+67BjT97d/a5jhGe+GbufgxgzMplt8j5n6SSzBs36jlchF034e2z99TEiz9LIHWSvE0ibKrG9Tgn5kpoiE3N8uGKN5Z6dmZq9aydGuaC97FkxBeU0PyEo2USV2K83mz6evVw7y3VLCdralzWv+rqUkG6uumcTdDis4iViiT2rpe8yNRE6Vp7rAWiNIrF9bSVqS39JOOKjEYyOoL8o0eAJ1wxhTO3OT/5ZV/747me1kS272oCL7eQBoGe/KXszfwMifurnLO5d/Pr8N/1g01jJNS0m24hFWLDsCNwxAq/mjL++KqYNU75zWIzEpOSSKZpJ3GeqA8yywzp9/XTYe01vjp1mRCPAIOQewtP9gTMqlJ7ZjbH2BYXJdM7MJSQynGHq4dnaib5tLiVxzsXZROSIqBYq57aWGGG5uLxbqb0tLCuD00VW9bpweF4cGcLYxpib5ce/ZI2IaVsHuu8Y3FBrmvlnX80rkeHLzqk9MaSlCrYWacjTjZqf+5gQxcgjrGlwSORYhF2W9s4eIcbSyUvjjGJkxlJSYmTZc4d7kwgPAzDa2i/kTJcICMLbVzvGDrSME1Wu1x8VYgsUUVNtBOckbq7RW+aa2DMSWm2ZyxQ7lcXYyq60YI6qiUxtVX4rt1pI4r9VERfx3Bqsq9H10VleV5V4eYU6IX9pSGiGkfnLcYKZTESsMq8hR7PQEIXIfSg74sOWmmTipk606G2m3uu+t7m9RQO2wS79ebAqePUTcN6a3DmTaX6uzJwV8uOuMCGGsdRrG31xW2XaJZM0EN/1kHAnpOYP6sCvfjVp5dUE6pkmE3BEqkPMIOSfgcVlunUZMdE53DTaY6Jhr6jN5fpmJh8CICpP2uRNnJ+o6eR07sBA2ISqjRVyNh22grjoWreDdtMzgZlNiXQ7t1D/G1BmZEablmzSZR7AVUa3U/g/Y2bRFJ9mwaZW7XMw11/tzNxa2dNEaiF81rRGrr5tiiN1krNs5cWCWnId41897t5+55aaZmGESK+zMrmrT+J62qpVmzBLd83U/moY3f+A8pAsPWPutfLG224udzDwzGzn7fO7Bk/e3pwzDX84bbZ/QAk7mlZ5hxqKZomFMac4wF8wOO+cnsoOhw1K8zSyN4w/7+gbrJDIPLRyt0Xbi1Vwgmr/tK2YRmK6II4dDs2R6E9feyKzLcQ59Ab18Hul9LjCS8Mboc20jd4TqVnqEnAO4jZHkNngtpWYXQrMM8nsdp5GR1M2l0plEzn09zPJMQiv0JrRe83oP8f5mnjEyxIAxmc3mYS04DtNIg9T/RQ12MVZrOfqKnUrB3V4eeJ0H8BBJZvU7aVJOmvFC4vcRLvVddd1mdRpUl1Q/1Xl4uiVeEnbe+tx48NOXCIhS+hQbe2u3YDVRL5Ezm7NO1lGsJHJO0FtMQSfrR79O3doxmebRqAFq/2en1/62C0cge3Y+HBYvAGpJcSqH1FhfX9AfCccgUMo9Zk6HlpWcW11RQwQ6q5h3b7Sp1l3+6LLz1yPvEwafCw7utvJ7qdVJAXPShXn2ypoc1sX3W3iEnAPwSNtY6pdmkjL7+pypVsp18zg74UWNSoXPycERNjEMcMsQyUwWNztWHJxYM1nMziqrr7cL+u0GvbXR8hyO+uE0Pc9NJXI8XFFtEbyHom0yxnvWnOmqy0eFzgFNLO96VmW5uZQtPXEIltm4E3daaoCl7udgfT1+YRd+Pr/NYa1yNaJ7JysoTqWk31ExDnqZKaSvz25NxEZ1UUxkF4qBhQUjyplniUyA+mwuR07oVPfaDlEMoi5rvOaDnRTg6Yu6kSszQDhV2O3eMdsBnaSKh9mhVwe2ySRLmWWJnDr/rLYSrnbq61ccm5iEGmBBluypnfDwaFQBqj0lBuqK8dTCUO99Vk01ZYqZNI2CmvYVhfP7lulVgcnstKXkAMDSlMKyDUcoJcdvtHCU4rHzx+AXz67Hax/utDRalicK21mAu9ljxkU3K04da03Ttig2k+cvH4+qJU9J5fDni7XXyp/OG4z2ihwlGGW88L0ZjTipowJDfrTM+NLissET9BsALp3cYPCqBJhxkbiKjBpcgZGlMfrx3Bb878v9GFmTz0xnVpQT7reeoLNNz12yOa6a1ojzx9cCADZ/8XXU5bHaFAt30eq1Mm9YmXliZn77+n95whCM/unzTpumoDI/HZX56bjy0Xcc59VIBkTQfQAAIABJREFU5MxFctqfZkwXLolcdBhcmo15w0pd5z+rqwo3PLXO9L2p1NtBw2sL03HB+Fqc3FmBcb94gTuf7Pp861f7De983DZy/A115FBHUwd/Pj1Yeb83oxEjq9l7W7zQXJKFmW3FuO+1jxjOTqwkcs6hLk/2/uwov81hkaSoVkaoLr0bfRlWY3797GaFGGSFH7BDcXaqUu+KjV/Y1hfNbuCUOI4ZopbIcTC7YFzrzBieVmXIDB+DaqW1RI5VvltNCzOp4JECTyJng+GVufj22Brpl/kkiHAnzSVyTleeFVeE/Tx69UNLrpWDchRVSPdN0SA3PQnnHVPbK3ZGmSkBdFYZ3Y7HQhXnoon1mC7Z0/TFluJU5S8CsbUDs1NxzaxmU2mCuY2cA0IOWo4/EJ3U1S6wOgCFiDPmdVmnC7URO9hJQKxAKd+3FGcbJcu9NU/VjCte1UozcO0TUQ7I8MpcnNVVzZ1eXV1zcZZt3CR7NSOeOkU3/BX51qFOzMDa8wwSOc4Jcs3MJpzcyfZ4qA2rwj8u0ezJBmkjgIXjajHEJPi4GqNNGFkssPqnIENLRJn1pbVEzv23D8hMjiqmmxmumdWElpIstLm0r5dLH1Keg3PHifeuwaXZaC3NwvdnNjlY/8YyedNHIZBjzikzsOJmOkHUqpUO8rPmMPdYmJThhnntds73thp9b8Mj5Dggx4Wx4oBH9LiN78wCdduBgrIvoWYEniKRi8+kdbKIzFQr+wN8PoJHzhuDpmKt6+KoTVocorc2HyeqlXYpzdrsiJAj2v/t01snjDXtL7u+tqzTYZk8HENX88+Gw8mD3jIQp5Qq9iINDKk1YPyGqCQy7rO6rC9So99HHDlsYL7vBaaWob9hL5UxwzndNbjpeHdqt2aIpgeiyetEfVitrlwqedNcMr2J2Ra9JgsrjEZUjFoGs9fJPLLT0G0ry8FTF3UjLcle2YtZLeNhapIfTy7uxtCKXAdngvEZr9dKN90rxwTW57Vq70/nmcc4NMuvcQrE2zgTxM3TpVl9+rKYhJx1DbYhu0zKVd7332upJRJKtfLw4cPYunUrDhw40NdNMeCfZ9QA2IV163Yx34cFirvmFMPvI1i3TqsuU0wF3DWnGFmpAcO7u+aI0hn1c/kZIcDWLR8ovwHRFmvPN99onsl5f3xMLkJCDnZ/tgWb96SirKwMwaA7Q1oWnCziDsllcywvXr0B3oXeXJKFJ9/5lLvcJxePRbLOQLcvNmIWeA5yxf7S5iBXF7V4Qh1+8/xGMR+PzZKuR5IDPuw/FNY88xGRqJwzpARPrN4m5bMr1xrjBxU6Sv/sJeNw76tblG9j1snJbUxL8mP/obClanYkP0E08jG3jIHelMjVFmbgwXNHmQZx90UoXgDab3JKcOrHgyf2WDTQ12dLyJmsGUXdKRaNsoGV18pYMuuoA70VrfTOfZ3R2JKb2xcZMb01claf1FmO4pxUjKsvwOWPrFaVZ5TIpQb9GFGVh/99aVRvdQNKo2f29rWDGF4VOc33ORTOs8ai2iLcT01hOtKT/fjmcNg0TTyg2R8sNpNCF4HtY7nnK2Nm8MhqHBi3jGL+NrjKnvBIKEJu69atyMzMRFVVVa9wG2OJw2EBwqd7EPD50MS4EOw/FEJq0G/4rsNbRcKwqSzH8IwQgsbiTIS37QEANBRlIiXox6e7v8GOvQeV9HJe8ukeHAoLaCjKwN7du7B161ZUV1fbtv3EjjL8ZdVW23Q8Q/KfK3uw/1BYcRqhX3jxWUjxWZ1WASzPG1eLsXUFmPPbFVxl2QW6ZMLhErhy2iD7RKxqOOqJBJu3kX6ZPHemWimCtdGPqS3Ayxu/cDTirDarx3amiet4Ma/xWWFmMlpKnI8n6xDKTUvC/kPfcOUfV1+A5eu2O65Xqd+1RM51lQ4rEv8bXWuutsbD8c7nkJgCkfl1/exmDK/MUzQvYoHXvz9RsfGRL50+QvDEoi7M+e0KfLHvoEH6MrauADu/PoT3Pt0jpWeX3ZtHI6sutTt4gM/uxIkqohPwXOze+P4kdN643Jg3GmmuIymWSopCCI5pKDRNq3ZI0lVXYNMG8f9fnTAEl6mIQiuoHa+5WdesPXlWWzGum93ivDAGeC/yZm0/pqEQ/96ww/HZaTeP/n5hl+m7OUNK8Mtl7wOAgZiL51JVl201lLHc12wrY2BWWwmWr9uOQQMzNc9ZfWMb0sRlhyqMUs9GLv44cOAA8vPz+x0Rx4O0pIDz79LNOcXFtI3tHCE+5Ofnc0s2f3Z8G166osc2HU/7y/PSMGhgpuJq+EgaSvW3+HwEbWX2thQxqZfzOMhJdafyx1O6WbB5Q1kmA27n7QywDjERkQgyuHg2RVu9vvO04Tihg2234xSlmiDExlpZF/PIN0sXFIvyu+vNL4B2iOYAi/fh58QQXT/WrJAgtSZqmYaypP+bS7IxuCybm9mQyRHYfEBmijIf1Kr1zcVZSA36cenkBsPXZiQHNG1PhHPQcLEiRFEVdOLQ6r5zRlq+dytl40nLUk9k5+WvONZq9hEbOXWf2kidpDboTQCswLuPm4G1RkpzU0372C3MQ1pY57OyzbearurPYl36rUIEEEJw1bRGAMa5Fv0aNs8fz+3Bqmg1M4AHxw4txcYbp6MyXyvVdBV+wC0hd4RL5BKKkAMS4/ByA/mimp/hzBNUWpLf9KJekMkuy2wuypxov48w+3HBiHJ8a6TRwJYQgmBAvkhS+H0E7RwG37FCInFJRllwjmOtViI7IJg/nG176cam0g7Rcufs+uDsrirlb3VKO5VMALh/5UcAgGXvfS7mVxWw/1AIADCqRlTZnTl4YKQeF+Mi9xTT3b4K5kS0sa9vXdCuahOjLKZk0LJ6BcMrjc537DCuoTAmNhXxPvycOM2IELzGC5us/nQ8pyfJEzrEdVfl1BGI1E7HqpwAAn4f1v14Gk7oKDd876wh5pJhlvOl3tg1Wc4bTh1ZCSCiMljH4QqcRQAMKspkpIz/HUCWDurXtj70iBV4mWtzhvC53FdfNJ1+v5vuIoRYzp+TTJhbnVVGr9HjGwY4b4AJYjX02nh59oVGO+dmtZVgy00zTW0DeZg/LMxpdx6yQQ0nc1oGO5ao8aGTHguojCvP7Ra1xJhnpOpvLWNUfm9Tq42748S5acYWCaVa2dfYtWsXHnjgAVxwwQWO89566y1YuHAh0tJSHOWrG8A+zADRgxzLDsHsAjEgKwUDstj1q10A33ic0chWvUA2/WSGaZt6AwOzUvDa9yY6yOFsE57WMhDPrP1M8+y9H001bMJOPIi5wYDMFGVcrn18jeF9PK4zlfnp2HLTTHznz6vw7FojwQQAV09vxE//uV7zjDcg+6VTBsHv8+HXyzdongd4KDkJn+2WJcmRymRbuebiLFN31maQ25waNNox2LlAdgZroon1jFeq8dj5Y/CnV7Zwt0Tuo5vU4+jyu+JNyCkccC5Czvz3gMxkPOVgbpzUWYGTOp17jnPbHUYbObGkqS1F+L/TOgBAWZN6PHLemEg5Lut3A5bk6dxxNYpHwXnDSrkcW7Dw+KIuNP7gmWia52qtPrhwlCHvghHljqRKvPXeumAoX3nS/1xSaeV/FwwslvdBRjE/m9+Gn+kcuuj3Xaf7sDP03ZU7lue8XNTSE9st05lhzpASXPTgWyZl2zf0pSvNNa3k71zUU4fl6z7H+s/2Ku/sbBSjwfdnNuP7M5tNyhcrSAn6kM+w7eMKP+BC0tffwXW7IoRMI4S8TwjZSAhZwnh/KSHkPULIO4SQfxFCKmPf1Phj165duP32213lvfnmm7F/f2yMku3Qn8TD7qQlvf+Bfe2etrfrt5pDrFdOjORZ4+eAjmNuut9IhJybS2M0fWs+fa0PC15nJxHbQ+lBnKa+GH4gMU8znf8S67SGvL3/TVHMJs0vRUUpQccFMLZN391uiThWWa7KiKLvotGwiPWIsVS/ROmcfZ7+CuNa5u9Xs71C7j/Whd9qf2H1ZSzuWXFVf4yybLmPrJiJvT3H7FUro2tQf7o7O4Ht9YoQ4gdwG4DpAJoBLCCE6MnptwB0UErbADwK4OexbmhvYMmSJdi0aRPa29txxRVX4Be/+AU6OzvR1taG6667DgDw9ddfY+bMmRgyZAhaW1vx8MMP49Zbb8W2bdvQ09ODnh5zDkiskJbsj3mZ6VKZExqLYlruuHprg20WnLYhJhcCRhnH6L0ZxnFTk91Zl+dF1Amcblr1FtJdPcwCepvB6oA0S6vuMB4bORmsy5ms8lqWa1S34ChQbJfqKB9tUV6OKlBuTyO/2lBA7dQAxNReYmpLZH6PqBZV5qok+4FYMzHsiEseTND1waw2UaVuUpN93wzhiCeVEhD3HrfcVhlWatF6yO7Co4HTkTJK5NjPEwkkTsYXOWlBncdRd+VE03d+H8EpkqkBr8ZAQ5GkRsqoNzM5gHOUmLP2qFSp9EaCXmuLtuqXnkHi+rOy39IjK0VMO5Fj7fYlTG3k7PIpKteqvZhrX+GvgwfDdF539VpUQRuVfqdwFUpANef0GCs52inOFjW8SqT4omNqC0w1whyrqLPaJP1v9j084QdYzoSIJsWRBx522ggAGymlHwIAIeQhAHMBvCcnoJS+oEr/GoBTo23YD/+xFu9J3hpjheaSLEvvSjfddBPWrFmDt99+G8uWLcOjjz6K119/HZRSzJkzBy+99BJ27NiBkpISPPXUUwCA3bt3Izs7G0uXLsULL7yAggLnhItT5KYlISM5oBGFR4vMlCBeu3qiIxu/5Zcegym//jdzI5BxyaQG/N9LH3KV95PjBmNC4wDHdoY1Bem4sKcWt72wiTvPO9dPARWAIT9aZprmqmmNuFPV9nhyzo8dWoru+gLFSQwfIh1//vhajKg22i+Y4eyuKvQMKkRGSgC/fPZ9bamM8RQiIjluqJMG7AIQ2eC7kxtwysgKlDD05m3bwWjzwnE1mDWkhKmHn50axNofTsWeA4dR4MB1c7PK6QAhwIuXjcehkKBJ8/r3JiI7LYhB14gqZWeOqcb3ZjRh2674h1zhHbofH9uqsV+6bnYzLuipxeifPg8A+O0pw3DtrAPITrO/QD56/hjm85rCdHy442ulvnWf7cH4QfaXS/kgZ83RheP4LtFvXzvZVTDk88fX4ncvRvYY3suTnEwvAVJ7s9TjmplNhmeGcnuBvWy0kYt+D3zrB5MRDPjce1F1cRn77zWTMPwGo+fK62e3ICM5gEUT6rjKeeqiboQFir0HQoZ37/5wqqM2PX1RNw5Iqt6yrW4oLDDTTm4uwnPvadVur5nZhO8cU4NcFeNp9bVTQHxA2/XGc40CyE4L4tWrJ6AwIxl/1Klqy3n7EjxOn6zgmiHAmNdyUd0MZvSbP5iMYT9+zrS8B84dhb0HQrj6r+9qypLhZv8BgJIctumMm70gIgU25l3UU4fjh5cp52NVQTpWLJmA4qwU/PSf6zT5ZTx9cTear33WcTvU8NmMPw9z+4qpg3ByZznG//JFQ74jVSLHQ8iVAvhY9XsrACsXVN8G8M9oGpUIWLZsGZYtW4ahQ0Ud93379uGDDz5Ad3c3Lr/8clx11VWYNWsWuru749oOpq0NIUgKxF4qNzDbmX1faU4q/D4CIWy+OngYnfLiKstNddwGQOyPK6Y2chNyFFThTEbKMKbTb7bx5pzrdcJtuY+qbncqqSKEoEZyUmAIEcHYRp2ogbFmgz6GnnXbtP8D4li4IeIA8zXEIuJkpCcHkJ7sTG1MfeklShnaNCwb1rLctF4h5Hhx2iitZnzA70NxtravzGxx9QiaEPA5KilCXnoSrp5uT7gA1vOPV4Ktlrg6QbojJosR+tYJ1OQFzD0tAr2rThpr74wAkCs55TqsIlrirU7PsrcBgKSAD9+bwTf3AHE+B/3A1weNhJxTqPcYWSJ42IQrytqr5HV5MBSx++VhrujXsrymePLGG7GabswlYjHFtJoL9q3IswlxkhL0IyXoN70zBJ3YGqiQk5aEJL8Ph8JCDFQrI0STnsDx+Yzno94Lrx7RqFnLiMXW5vcRVOni/sXZcqHPwdPz3EuCEHIqgA4Ax5i8XwhgIQBUVFgbmccqLolbUEpx9dVX4zvf+Y7h3X//+188/fTTuPrqqzFlyhRce+21fdDCvgch9hwOJxzcvlQxSmQ7ld5uGnNMHahWylCPp9mFnpmPv4qEgpv564aT6iSLukmJ5BFY41XO5ZzqbUQrLTBzdpI4o2JEPANAx6LkvpoPsV5LQRuJnLZu3e+EnkH8iMVXsBRHeMplpY+lxFtflD/GqpVuoNjICdQVIyUe8y5ec9lK+ngkgOd2tRWA2hdtGYBt+kSEkEkAvg9gDqX0oP49AFBK76SUdlBKOwoL3cdEihcyMzOxd6+orjh16lTcc8892LdvHwDgk08+wfbt27Ft2zakpaXh1FNPxeWXX44333zTkPdogVPdc9u0US7itrJsfHtstau8Zu0cW1eAEyU35b299cbbAYaMb42y99ynj3fmFI4Cgkt1yDmKsqKLUdRbBIy6nsum8AVn1zPg9edMR2UuzhxTJZXvvm2UUsP8ndwcW3tYJ+BVZdPDiWOUeIP38mPnKEhNLJ05RpSGWtn7xXNbqNPF4LPyEhot1Oulv92v9N1wii6szzUzmxx5wZQZXVopJWdb4ry91RSk45JJ9TErb3BptuKC3gx288HsQm5lAmC1XjVnhGHOu+/gc7tFdW99+BgnXpz1+OHcFqQn+S2lennpSbhuNtszpB76XulTYidOczmRzo14gEci9waAekJINYBPAJwM4BR1AkLIUAD/B2AapXR7zFvZS8jPz0dXVxdaW1sxffp0nHLKKRg9ejQAICMjA/fddx82btyIK664Aj6fD8FgEL/73e8AAAsXLsT06dNRXFyMF154waqaIwYExN7LkJPyolzETywa6zqvWdWaQLa9zP51JM2MYgdsK8vBlptmomqJaPfJ2sgZ/kviDrmuxy90P66AvQF1LBH0ExwOU0xXxbmzgmKcb3LQmNmYuYF+7O46vQNn/uF1vPj+jpjVwYueQQPQVZePFRu/dJSvP0sfeJydDK/Ms3frbmEnGA2evWQcBupUZuPZ3/13JI1jqY/Pek53Dc7p5nd8EiHkqKZsN55cTeFywjx/+XhX+czwj8Xifv7UO59qnhNCbCUnvOeP03nrUBOTGyOq2es5EIXO8oIRFVgwQjvf9G198weTbctROzBzMjXieYwq3eKgEh9hO2xRoz+fGzywJeQopSFCyCIAzwLwA7iHUrqWEPIjAKsopU8A+AWADACPSNyLjyilc+LY7rjhgQce0Py++OKLNb9ra2sxdarRqHnx4sVYvHhx7BtkMf98hHDHoYoH+CRyToiRvkMiqZ0ZEGPJpxvIByvX+RPlnIz1t/TF0PIeHC58yLhGoh5m/Ub9OsZ1s4Ka9yUGDTR6vdWv91i21SnBoqRNALZ6rNeSrFqpkcipPtRq7rHUX7vrC/CfD76wrDMRvaZG26+sqSHbVo+tM9cC0wrktFy1eHRPIAFUKwWFkLMODm+GeMwbN/cwOz8NaiTC3hEPcFknUkqfBvC07tm1qr8nxbhdHjjQVJzVp2JwHvsJfQrL5vblJS1GaWKJRDpgIxwv+0Y5cYzCQswJOURn2+QETi9HcvoG6RK9qMedyqEZWPGpNO9jWpszuHKZHftm9AIkJoiOKhKkO3siM5EMXisTt6m9ixj3g+zVN6STyMmwWius9Hed3sEdbP2IGlKGLXd5XhpevXoCijLNHTSx1qBeWyKWiEYiFytEvs9ZW+J55YwI5PgrEfcoMb1p245w1co+djbrIRr4fSRqt+7RgMDoAcuQhmOPiPbiHwvE2t6vN6DelGLZNNZmKLvhTwnazzfZI2hWavRerIDoPdrFe9ycxHHSI1nqz6yUILbcNJMrbp2T/tCsqQSbv7InwdQkJx5NxY/QqwAm9eI+KMfc1I+7XWw6fffL5eS69KLZG9cS/drJcOjJ1bpsosQidDJ+A1S2Z4kiZY52/sleXDNSAkiR5lFuehLz6zINHpfFVGpb4pQYxEnsCxRkimsh2WX75dBF+u8vzk41MFLU0MypOEqhZRRxev3lhRviSqtaGSkgmvMsWiieNHXfY3Xv4LG/T5c8auYlgGfWeCB2u7KHow6EAA9/ZxRe37wTFz/0tkkafo5uPC/cz192DH77wkb89c1PNM/vP2ckHln1MRdXipXi96d3GFzd9newzoRfntCGZ9Z8hpYS+wDPZ3ZVIegnOHVUJUbX5uNTh6715cuZIkmL0X2VAHho4aiYX3KeXDwW736yW1sX51zu0BnBWyHa5WHVpsUT6tBdb+2A6paT2/Hu1t2G54+eNxpvfbQLQ8pzGLnMceNxrRhVk4dhFfx94PcR3HJyOzqrIjETf/etYWguybLIFRss6KzAio1fYOmJ7XhmzWc4qbNc8/7ZS8bhvpX/w0QTYlzf/1OaB+JHc1twYkc5M70Z3M6De88ewYyLeMepw/HyRradpHpfvH52M07VhaaIFr88YQieWfOZo/G78/QOdDBiwvUm1GP58+PbUF9kVEt1gqkt4lw4YXg5UoI+3HBsK44dWoofPrHWUB9rvvxmwVAMrbBef4ksjRhemYvLpjSgpSQbY+sKMaTM+pxRf8v954zEt36/EgBw0/Ft6K4vRJtNfj1+e8owQ1y44RV5yErhjzHIg1eWTMBVj72DW04eappGf0Y9dv6YuJjQCIIxjuVpoypxYQy/lwfqfcnsjFp2yTFYu8149gCAn+Ow7azKxQ3HtmJue4nrdiYyPEIuwZEY/EY2CCEozk7F3PZSU0IuUVBTmIEpzUUGQq6rrgBdde6DuE/qQ89/8QLrzMhJS8LJI+y9WwKi4f6ZXdUAgMaBWWgc6OySzYojFwtQWHsDdIvyvDSU56UBcN5mJ2ot0R7lrJrk+tvLc2wDys9tL8Xc9lLD846qPHRU8Qejl5GVEsS3RjonDPRtmD642HEZbpCbnoT7zxkFADhD8iSqRkV+mmVMMr30yOcjOH20sZx4YVwDm1Cf1joQ01rtnfPIazqWcLKvyCjISEb9gAx8sH1fzNvDC3kkM5IDOLHTGSHOgn4uyASzfs03DsxkSiBmD3F+QY137D47qPe+m09qV/ZQvQdQXS7DE/X5nZ0atMnPRl56En5+fBuufOwdpYbstCDeud5ZkHc7lOSk4s/ftgrDbDyj9B4vWXAzkoJaIic9O2NMJZJtYhTHet6Y7UtqVOSnoSI/jfnOStIqgxAScyZUIsFTrfTggROJbMsSy6b1+QGv+53InGQzxNfbn/OyKRJ7/h4NiDljoj8ujBihL7zo9iVioZ1g1lVHSx/aoa/Pvd6GJqSQAxt4JWUcJo46SDl/npg3o9/BI+Q89Cr68+UjkfeLWBIOfT1G+jhyMUMvfFdf950eFuGRNEi0dh+JiNV89gjyCI6WnvCGvPdwtPR1xBN15IP7+tvd1M/jdO9Ih0fIxRkZGWKA1W3btmH+/PmWaW+++Wbs37/fUfkvvvgiZs2a5bp9iQTvMslGb29TR9ow9En4gTjWGUvOsXcExh8RT6Zeb3voOxxp+3qscbTdP1iqlTzoDa+VjvJ426pHyLlBOBx2nKekpASPPvqoZRo3hFxfQO0dKxZIDvTuNHS7ESXahqH5jgRrWyzRlyE2nEJ2OBCP4YimTEoTb/4eLYiXGmD/WRVHLuK9N8lnbTw8CfajbdWIOLQ9Ebxnu4WbeVieJ3ocr8hPU/I7+fJ49pKT71EzyI429VgZnrMTHbZs2YJp06Zh5MiReOutt9DQ0IB7770Xzc3NOPvss7Fs2TIsWrQInZ2duPDCC7Fjxw6kpaXhrrvuQmNjIzZv3oxTTjkFoVAI06ZN05Q7a9YsrFmzBuFwGFdddRWeffZZEEJw7rnnglKKbdu2oaenB3n5+Xhu+fNYtmwZrrvuOuzatx/lldX460P3ISMjA8888wwuueQSFBQUYNiwYa6/9dLJDRjM4d3pz98egTc271R+P37hWKz/bA93PU8uHos1n+zGkr++y3z/3ckNSA740FwcX89zPY0DcNzQUlwxdZCr/PIG/91JDbFslimSAz6cOaYKxw4txbtbdyFd5/p7WEUOxg8qxK79hzG7LXpvTFdMHYTGgZnoqMrD5i++xviGQny+15nHyWjw1wvGYN7tr+DO04YDAO45qxP3vvo/lJiEuHho4Sj8ewPb254aSX4fzuqqYjrqcIuexkLmXLr7zE5s+eLrPg0LogbR/G08en90bCuyn30f3Q3uHf6wcPmUBjTFeT33FpZfegx2f3Mo6nJidfG549Rh+P1/NqO2MCNGJcYPl01uQGupMw+CPOhr5k5GcgBnjqnCvGGx21NYuHhiA+oGZKCpOAtLn9vg6KL6l++Mxr/WfY4Ptu/D8+u3G96fMrICa7ftwQXje9dLoYy7z+zAtJv/4yhPTUE6FoyowFldVZrn181uRl662zAeIo5tL8Wrm77E5Zz3gyXTG1GVnxgeq08eUYF3tu7GE6u3cec5saMc5blpGF2bj6biLPxhxeaov+e62c1KWBk38PsIzuqqwhwO5z1/v7ALx962Avd9eySeemcb7vj3hzi3u0Z5f+/ZI7Dqf1+5bkt/QuISch8sB/Z9HtsyM4qAevvY5e+//z7uvvtudHV14eyzz8btt98OAEhJScHLL78MAJg4cSLuuOMO1NfXY+XKlbjgggvw/PPP4+KLL8b555+P008/Hbfddhuz/DvvvBObN2/GW2+9hUAggJ07dyIvLw9Lly7FCy+8gIKCAnzxxRe44YYbsHz5cmz66jDuuf1mLF26FFdeeSXOPfdcPP/886irq8NJJ53kujsumljPla67vlDjmnxgdgoGZvPHQWktzcZHO80ljcMqcvH7Mzq5y3OL5IAfvz4gjV8bAAAboElEQVSp3X0B0k1sZI1zD32uqiME189pASB6FdQj4Pfhj2eNiFl9F6qCUf9mgbl75HhhWEUuttw0U/ndODALPzlusGn6UTX5XF4oCSG4bnZLTNoow2wuZaUE0VbmzA1/b4ElESrNScXSaNaECRZN4Ntb+gPqBiQWwVQ3IBM3Hd/W183gwmLOM8Yt+krKrN6b44mkgA/HDS3D+5/tdZx3RHUeRlTnYfXHu/D8+u0GCVxmShC39sE+L6NxYBbKclOx9atvuKWDPh/BT+cZz4SzYuBRNTXJ76g/zjumNuo6Y4WM5ABuXTDUESFHCMEYyeNnQ1EmfjrP2Z7CWnvRjoOTs7q9PEe5LwwaOAiXTtES4OMaCrk8Yh4JSFxCrg9RXl6Orq4uAMCpp56KW2+9FQAUomnfvn145ZVXcMIJJyh5Dh48CABYsWIFHnvsMQDAaaedhquuuspQ/vLly3HeeechEJCCFOYZCYPXXnsN7733Hrq6unDgcBiHDx/G+O4urF+/HtXV1aivr1fad+edd8bq0+OOI0G9q1+rpHjw4MGDBw8JgCPhPuDBQ18jcQk5DslZvGAMYi3+Tk8Xxc6CICAnJwdvv80XBFsPSilXmsmTJ+PBBx/EO1t3AQDaysQ6+7PRfH8mguReP1r1sD0kBtysIQrqXZo8eDgK4a17D7FEX6s1ezAiMQw5EgwfffQRXn31VQDAgw8+iLFjx2reZ2Vlobq6Go888ggAcWKvXr0aANDV1YWHHnoIAHD//fczy58yZQruuOMOhEIhAMDOnaL9WWZmJvbuFVUoRo0ahRUrVmDjxo0AgG++2Y8NGzYodnibNm1S2tcfcCScJd6B6KHfQY7L4529Hjz0exyp69hjjvY/eNehxIFHyDHQ1NSEP/3pT2hra8POnTtx/vnnG9Lcf//9uPvuuzFkyBC0tLTg8ccfBwDccsstuO2229DZ2Yndu3czyz/nnHNQUVGBtrY2DBkyBA888AAAYOHChZg+fTp6enpQWFiIP/7xj1iwYAHmT+7CaXMmY/369UhJScGdd96JmTNnYuzYsaisPHKj1ScsvDPHQ18gSk5Cf/TGdiTA42DHHkdbj8aCiZiIxJK3J/U/JN4s8pC4qpV9CJ/PhzvuuEPzbMuWLZrf1dXVeOaZZwx5q6urFWkeACxZsgQAUFVVhTVr1gAAAoEAli5diqVLl2ryLl68GIsXL1Z+T5gwAW+88YZGtRIApk2bhvXr17v8Og9u4R06HvozPIly36I/q8QnLrw+tUN/OLc8XocHD+7hSeQ8eOCEfA/zzhwPfQIXtx1i8rcHDx6ODiSiJE6Gx9vov/AYU4kDTyKng1py5iF2SNyjhB8KIXckfIyHowoU3sHbV/C2Cw/RoqYgHbPainH+ePcu7/uDZM6DBw/O4RFyHjw4RCJzOD14UINFu3n0XN/A6/YY4ijbggN+H357yrCoykjkcytxW+ZBD4+RnXjgUq0khEwjhLxPCNlICFnCeJ9MCHlYer+SEFLltkGeYbgRSQEfSnJSHeXp7X789thqdNcXmL4fWZ2HJL8P546LPnBnX2FRTz2SAz60lSZmwGcP/Qcz24oxf3iZozwTm4rg9xGcMrKCO8/c9lL4fQTHtpfAR4CirGT8zGHg1yMF3fUF+PbY3t9/fjinBXnpSchM6Z980+GVubhoQl3c67lmZhN38PUl0xuRmRJAWS7/uTiiKg8XRCHR6q+oLcxARnIAl00eZJ+4l/G9GU3ISgmgODulr5tyRGBSUxFOHcV/PrjBKSMr4PcRTGouims9HvhB7C78hBA/gA0AJgPYCuANAAsope+p0lwAoI1Seh4h5GQAx1FKT7Iqt6Ojg65atUrzbPPmzcjMzER+fr6nBhQFKKX48ssvsXfvXlRX91/CyYMHDx48ePDgwYOHIxmEkP9SSjvc5OVhEY4AsJFS+qFU2UMA5gJ4T5VmLoDrpb8fBfBbQgihDsVCZWVl2Lp1K3bs2OEkmwcGUlJSUFbmjOPvwYMHDx48ePDgwYOH/gEeQq4UwMeq31sBjDRLQykNEUJ2A8gH8IWTxgSDQU+C5MGDBw8ePHjw4MGDBw824LGRY+k46iVtPGlACFlICFlFCFnlSd08ePDgwYMHDx48ePDgwR14CLmtAMpVv8sAbDNLQwgJAMgGsFNfEKX0TkppB6W0o7Cw0F2LPXjw4MGDBw8ePHjw4OEoBw8h9waAekJINSEkCcDJAJ7QpXkCwBnS3/MBPO/UPs6DBw8ePHjw4MGDBw8ePPDB1mslABBCZgC4GYAfwD2U0hsJIT8CsIpS+gQhJAXAnwEMhSiJO1l2jmJR5g4A/4v2A+KAAji07fMQd3hjkpjwxiXx4I1J4sEbk8SDNyaJCW9cEg/emPQOKimlrlQVuQi5owmEkFVuXYB6iA+8MUlMeOOSePDGJPHgjUniwRuTxIQ3LokHb0wSH1wBwT148ODBgwcPHjx48ODBQ+LAI+Q8ePDgwYMHDx48ePDgoZ/BI+SMuLOvG+DBAG9MEhPeuCQevDFJPHhjknjwxiQx4Y1L4sEbkwSHZyPnwYMHDx48ePDgwYMHD/0MnkTOgwcPHjx48ODBgwcPHvoZPEJOBULINELI+4SQjYSQJX3dnqMJhJAthJB3CSFvE0JWSc/yCCHPEUI+kP7PlZ4TQsit0ji9QwgZ1retPzJACLmHELKdELJG9czxGBBCzpDSf0AIOYNVlwc+mIzJ9YSQT6S18rYUHkZ+d7U0Ju8TQqaqnnt7W4xACCknhLxACFlHCFlLCLlYeu6tlT6CxZh4a6UPQQhJIYS8TghZLY3LD6Xn1YSQldK8f1iKUQxCSLL0e6P0vkpVFnO8PDiDxZj8kRCyWbVW2qXn3v6V6KCUev9E9VI/gE0AagAkAVgNoLmv23W0/AOwBUCB7tnPASyR/l4C4GfS3zMA/BMAATAKwMq+bv+R8A/AOADDAKxxOwYA8gB8KP2fK/2d29ff1l//mYzJ9QAuZ6RtlvatZADV0n7m9/a2mI9JMYBh0t+ZADZIfe+tlcQbE2+t9O24EAAZ0t9BACulNfAXiPGGAeAOAOdLf18A4A7p75MBPGw1Xn39ff3xn8WY/BHAfEZ6b/9K8H+eRC6CEQA2Uko/pJQeAvAQgLl93KajHXMB/En6+08AjlU9v5eKeA1ADiGkuC8aeCSBUvoSgJ26x07HYCqA5yilOymlXwF4DsC0+Lf+yITJmJhhLoCHKKUHKaWbAWyEuK95e1sMQSn9lFL6pvT3XgDrAJTCWyt9BosxMYO3VnoB0pzfJ/0MSv8ogAkAHpWe69eKvIYeBTCREEJgPl4eHMJiTMzg7V8JDo+Qi6AUwMeq31thfRB4iC0ogGWEkP8SQhZKz4oopZ8C4kENYID03Bur3oPTMfDGpnewSFJzuUdW4YM3Jr0OSfVrKESutrdWEgC6MQG8tdKnIIT4CSFvA9gO8bK/CcAuSmlISqLuY6X/pfe7AeTDG5eYQj8mlFJ5rdworZVfE0KSpWfeWklweIRcBITxzHPp2XvoopQOAzAdwIWEkHEWab2x6nuYjYE3NvHH7wDUAmgH8CmAX0nPvTHpRRBCMgA8BuASSukeq6SMZ964xAGMMfHWSh+DUhqmlLYDKIMoRWtiJZP+98alF6AfE0JIK4CrATQC6ISoLnmVlNwbkwSHR8hFsBVAuep3GYBtfdSWow6U0m3S/9sB/A3ihv+5rDIp/b9dSu6NVe/B6Rh4YxNnUEo/lw5iAcBdiKgYeWPSSyCEBCESDPdTSv8qPfbWSh+CNSbeWkkcUEp3AXgRop1VDiEkIL1S97HS/9L7bIiq5d64xAGqMZkmqSdTSulBAH+At1b6DTxCLoI3ANRL3pSSIBraPtHHbToqQAhJJ4Rkyn8DmAJgDcT+lz0hnQHgcenvJwCcLnlTGgVgt6zS5CHmcDoGzwKYQgjJldSYpkjPPMQIOnvQ4yCuFUAck5Mlz2/VAOoBvA5vb4spJJuduwGso5QuVb3y1kofwWxMvLXStyCEFBJCcqS/UwFMgmi/+AKA+VIy/VqR19B8AM9TSinMx8uDQ5iMyXoVE4pAtFlUrxVv/0pgBOyTHB2glIYIIYsgTkQ/gHsopWv7uFlHC4oA/E3cPxAA8ACl9BlCyBv/3979hth1l3kA/z6bWAWtCiYL0qS2YLqaLULdoXTpCyt1l7QvkjdVEnD9QzG7YJVdRairVKn7YlUWQYh/sliqgq2xLzRIpC+0oogtnVK3a1IKQ3XboUKj1r4pWuM+++Le1ul0kjlN70zm7Hw+MOSec5577gPzy535zu93z0lypKquT/JIkrdP649lciWlhSRPJXnv+rf8/09V3ZbkqiTbqmoxySeS/HtewPegu39bVZ/K5BeiJLm5u4derINlTvM9uWp6aejO5Gqv/5gk3X28qo4kOZHkVJL3d/efpufx3jY7Vyb5hyT/Pf2cSZL8a/xfOZdO9z054P/KOfXaJF+tqi2ZTBwc6e7vVtWJJLdX1b8luT+TEJ7pv1+vqoVMZuL2J2f+fvGCne578oOq2p7JksmfJfmnab33rw2uJn/sAAAAYCwsrQQAABgZQQ4AAGBkBDkAAICREeQAAABGRpADAAAYGUEOAABgZAQ5AACAkRHkAAAARmbVIFdVt1TV41X189Mcr6r6fFUtVNUDVfXm2bcJAADAM4bMyN2aZM8Zjl+TZNf062CSL774tgAAADidVYNcd/8oyW/PULIvydd64u4kr66q186qQQAAAJ5rFp+RuyDJo0u2F6f7AAAAWANbZ3COWmFfr1hYdTCT5Zd5+ctf/jdveMMbZvDyAAAA43Pffff9uru3n81zZxHkFpPsXLK9I8ljKxV29+Ekh5Nkbm6u5+fnZ/DyAAAA41NV/3O2z53F0sqjSd41vXrlFUme7O5fzeC8AAAArGDVGbmqui3JVUm2VdVikk8keUmSdPeXkhxLcm2ShSRPJXnvWjULAADAgCDX3QdWOd5J3j+zjgAAADijWSytBAAAYB0JcgAAACMjyAEAAIyMIAcAADAyghwAAMDICHIAAAAjI8gBAACMjCAHAAAwMoIcAADAyAhyAAAAIyPIAQAAjIwgBwAAMDKCHAAAwMgIcgAAACMjyAEAAIyMIAcAADAyghwAAMDICHIAAAAjI8gBAACMjCAHAAAwMoOCXFXtqaqHqmqhqm5c4fiFVXVXVd1fVQ9U1bWzbxUAAIBkQJCrqi1JDiW5JsnuJAeqaveyso8nOdLdlyXZn+QLs24UAACAiSEzcpcnWejuh7v76SS3J9m3rKaTvHL6+FVJHptdiwAAACw1JMhdkOTRJduL031LfTLJO6tqMcmxJB9Y6URVdbCq5qtq/uTJk2fRLgAAAEOCXK2wr5dtH0hya3fvSHJtkq9X1fPO3d2Hu3uuu+e2b9/+wrsFAABgUJBbTLJzyfaOPH/p5PVJjiRJd/80ycuSbJtFgwAAADzXkCB3b5JdVXVxVZ2XycVMji6reSTJ1UlSVW/MJMhZOwkAALAGVg1y3X0qyQ1J7kzyYCZXpzxeVTdX1d5p2YeTvK+q/ivJbUne093Ll18CAAAwA1uHFHX3sUwuYrJ0301LHp9IcuVsWwMAAGAlg24IDgAAwMYhyAEAAIyMIAcAADAyghwAAMDICHIAAAAjI8gBAACMjCAHAAAwMoIcAADAyAhyAAAAIyPIAQAAjIwgBwAAMDKCHAAAwMgIcgAAACMjyAEAAIyMIAcAADAyghwAAMDICHIAAAAjI8gBAACMjCAHAAAwMoOCXFXtqaqHqmqhqm48Tc07qupEVR2vqm/Mtk0AAACesXW1gqrakuRQkr9Lspjk3qo62t0nltTsSvLRJFd29xNV9Zdr1TAAAMBmN2RG7vIkC939cHc/neT2JPuW1bwvyaHufiJJuvvx2bYJAADAM4YEuQuSPLpke3G6b6lLklxSVT+pqruras+sGgQAAOC5Vl1amaRW2NcrnGdXkquS7Ejy46q6tLt/95wTVR1McjBJLrzwwhfcLAAAAMNm5BaT7FyyvSPJYyvUfKe7/9jdv0jyUCbB7jm6+3B3z3X33Pbt28+2ZwAAgE1tSJC7N8muqrq4qs5Lsj/J0WU1307y1iSpqm2ZLLV8eJaNAgAAMLFqkOvuU0luSHJnkgeTHOnu41V1c1XtnZbdmeQ3VXUiyV1JPtLdv1mrpgEAADaz6l7+cbf1MTc31/Pz8+fktQEAAM61qrqvu+fO5rmDbggOAADAxiHIAQAAjIwgBwAAMDKCHAAAwMgIcgAAACMjyAEAAIyMIAcAADAyghwAAMDICHIAAAAjI8gBAACMjCAHAAAwMoIcAADAyAhyAAAAIyPIAQAAjIwgBwAAMDKCHAAAwMgIcgAAACMjyAEAAIyMIAcAADAyg4JcVe2pqoeqaqGqbjxD3XVV1VU1N7sWAQAAWGrVIFdVW5IcSnJNkt1JDlTV7hXqzk/ywST3zLpJAAAA/mzIjNzlSRa6++HufjrJ7Un2rVD3qSSfSfL7GfYHAADAMkOC3AVJHl2yvTjd96yquizJzu7+7gx7AwAAYAVDglytsK+fPVj1F0k+l+TDq56o6mBVzVfV/MmTJ4d3CQAAwLOGBLnFJDuXbO9I8tiS7fOTXJrkh1X1yyRXJDm60gVPuvtwd89199z27dvPvmsAAIBNbEiQuzfJrqq6uKrOS7I/ydFnDnb3k929rbsv6u6LktydZG93z69JxwAAAJvcqkGuu08luSHJnUkeTHKku49X1c1VtXetGwQAAOC5tg4p6u5jSY4t23fTaWqvevFtAQAAcDqDbggOAADAxiHIAQAAjIwgBwAAMDKCHAAAwMgIcgAAACMjyAEAAIyMIAcAADAyghwAAMDICHIAAAAjI8gBAACMjCAHAAAwMoIcAADAyAhyAAAAIyPIAQAAjIwgBwAAMDKCHAAAwMgIcgAAACMjyAEAAIyMIAcAADAyghwAAMDIDApyVbWnqh6qqoWqunGF4x+qqhNV9UBVfb+qXjf7VgEAAEgGBLmq2pLkUJJrkuxOcqCqdi8ruz/JXHe/KckdST4z60YBAACYGDIjd3mShe5+uLufTnJ7kn1LC7r7ru5+arp5d5Ids20TAACAZwwJchckeXTJ9uJ03+lcn+R7Kx2oqoNVNV9V8ydPnhzeJQAAAM8aEuRqhX29YmHVO5PMJfnsSse7+3B3z3X33Pbt24d3CQAAwLO2DqhZTLJzyfaOJI8tL6qqtyX5WJK3dPcfZtMeAAAAyw2Zkbs3ya6quriqzkuyP8nRpQVVdVmSLyfZ292Pz75NAAAAnrFqkOvuU0luSHJnkgeTHOnu41V1c1XtnZZ9Nskrknyrqn5WVUdPczoAAABepCFLK9Pdx5IcW7bvpiWP3zbjvgAAADiNQTcEBwAAYOMQ5AAAAEZGkAMAABgZQQ4AAGBkBDkAAICREeQAAABGRpADAAAYGUEOAABgZAQ5AACAkRHkAAAARkaQAwAAGBlBDgAAYGQEOQAAgJER5AAAAEZGkAMAABgZQQ4AAGBkBDkAAICREeQAAABGRpADAAAYmUFBrqr2VNVDVbVQVTeucPylVfXN6fF7quqiWTcKAADAxKpBrqq2JDmU5Joku5McqKrdy8quT/JEd78+yeeSfHrWjQIAADAxZEbu8iQL3f1wdz+d5PYk+5bV7Evy1enjO5JcXVU1uzYBAAB4xpAgd0GSR5dsL073rVjT3aeSPJnkNbNoEAAAgOfaOqBmpZm1PouaVNXBJAenm3+oqp8PeH1Yb9uS/PpcNwGnYXyyURmbbGTGJxvVX53tE4cEucUkO5ds70jy2GlqFqtqa5JXJfnt8hN19+Ekh5Okqua7e+5smoa1ZGyykRmfbFTGJhuZ8clGVVXzZ/vcIUsr702yq6ourqrzkuxPcnRZzdEk754+vi7JD7r7eTNyAAAAvHirzsh196mquiHJnUm2JLmlu49X1c1J5rv7aJKvJPl6VS1kMhO3fy2bBgAA2MyGLK1Mdx9LcmzZvpuWPP59kre/wNc+/ALrYb0Ym2xkxicblbHJRmZ8slGd9dgsKyABAADGZchn5AAAANhA1jzIVdWeqnqoqhaq6sYVjr+0qr45PX5PVV201j1BMmhsfqiqTlTVA1X1/ap63bnok81ptfG5pO66quqqcjU21sWQsVlV75i+fx6vqm+sd49sTgN+rl9YVXdV1f3Tn+3Xnos+2Xyq6paqevx0t16ric9Px+4DVfXmIedd0yBXVVuSHEpyTZLdSQ5U1e5lZdcneaK7X5/kc0k+vZY9QTJ4bN6fZK6735TkjiSfWd8u2awGjs9U1flJPpjknvXtkM1qyNisql1JPprkyu7+6yT/vO6NsukMfN/8eJIj3X1ZJhfm+8L6dskmdmuSPWc4fk2SXdOvg0m+OOSkaz0jd3mShe5+uLufTnJ7kn3LavYl+er08R1Jrq6qlW4wDrO06tjs7ru6+6np5t2Z3EMR1sOQ984k+VQmf2D4/Xo2x6Y2ZGy+L8mh7n4iSbr78XXukc1pyNjsJK+cPn5Vnn9fZFgT3f2jrHCP7SX2JflaT9yd5NVV9drVzrvWQe6CJI8u2V6c7luxprtPJXkyyWvWuC8YMjaXuj7J99a0I/izVcdnVV2WZGd3f3c9G2PTG/LeeUmSS6rqJ1V1d1Wd6a/QMCtDxuYnk7yzqhYzuRr7B9anNVjVC/29NMnA2w+8CCvNrC2/TOaQGpi1weOuqt6ZZC7JW9a0I/izM47PqvqLTJaiv2e9GoKpIe+dWzNZHnRVJisZflxVl3b379a4Nza3IWPzQJJbu/s/qupvM7kH8qXd/b9r3x6c0VnlobWekVtMsnPJ9o48fxr72Zqq2prJVPeZph5hFoaMzVTV25J8LMne7v7DOvUGq43P85NcmuSHVfXLJFckOeqCJ6yDoT/Xv9Pdf+zuXyR5KJNgB2tpyNi8PsmRJOnunyZ5WZJt69IdnNmg30uXW+sgd2+SXVV1cVWdl8kHS48uqzma5N3Tx9cl+UG7uR1rb9WxOV269uVMQpzPeLCezjg+u/vJ7t7W3Rd190WZfIZzb3fPn5t22USG/Fz/dpK3JklVbctkqeXD69olm9GQsflIkquTpKremEmQO7muXcLKjiZ51/TqlVckebK7f7Xak9Z0aWV3n6qqG5LcmWRLklu6+3hV3ZxkvruPJvlKJlPbC5nMxO1fy54gGTw2P5vkFUm+Nb3+ziPdvfecNc2mMXB8wrobODbvTPL3VXUiyZ+SfKS7f3PuumYzGDg2P5zkP6vqXzJZtvYekwesh6q6LZPl5tumn9H8RJKXJEl3fymTz2xem2QhyVNJ3jvovMYvAADAuKz5DcEBAACYLUEOAABgZAQ5AACAkRHkAAAARkaQAwAAGBlBDgAAYGQEOQAAgJER5AAAAEbm/wBwnsGjHonKUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4,figsize=(15,12))\n",
    "for i in range(0,3):\n",
    "    ax[i].plot(y_test[:,i],label = 'test')\n",
    "    ax[i].plot(y_pr[0][:,i], label = 'predicted',alpha=.5)\n",
    "    ax[i].legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
